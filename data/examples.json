{
  "examples": [
    {
      "id": "001-getting-started",
      "title": "Getting Started with Structured Outputs",
      "description": "",
      "order": 1,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Learn the basics of structured LLM outputs with Instructor. This guide demonstrates how to extract consistent, validated data from language models.\n",
          "display_code": "",
          "annotation": "Learn the basics of structured LLM outputs with Instructor. This guide demonstrates how to extract consistent, validated data from language models.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Large language models (LLMs) are powerful tools for generating text, but extracting specific structured information from their outputs can be challenging. **Structured outputs** solve this problem by having LLMs return data in consistent, machine-readable formats rather than free-form text.\n# \n# \n# \n# When working with LLMs, there are several issues with unstructured responses:\n# Using a standard OpenAI client for unstructured output\n",
          "display_code": "",
          "annotation": "Large language models (LLMs) are powerful tools for generating text, but extracting specific structured information from their outputs can be challenging. **Structured outputs** solve this problem by having LLMs return data in consistent, machine-readable formats rather than free-form text.\n\n\n\nWhen working with LLMs, there are several issues with unstructured responses:\nUsing a standard OpenAI client for unstructured output",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            10
          ],
          "target_line_range": [
            11,
            13
          ]
        },
        {
          "code": "from openai import OpenAI\nclient = OpenAI()\n\n",
          "display_code": "from openai import OpenAI\nclient = OpenAI()\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 11,
          "line_range": [
            11,
            13
          ]
        },
        {
          "code": "# Ask for customer information in free text\n",
          "display_code": "",
          "annotation": "Ask for customer information in free text",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            22
          ]
        },
        {
          "code": "response = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract customer: John Doe, age 35, email: john@example.com\"}\n    ]\n)\n\nprint(response.choices[0].message.content)\n",
          "display_code": "response = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract customer: John Doe, age 35, email: john@example.com\"}\n    ]\n)\n\nprint(response.choices[0].message.content)\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            22
          ]
        },
        {
          "code": "# Output might be:\n# \"Customer information:\n# Name: John Doe\n# Age: 35\n# Email: john@example.com\"\n",
          "display_code": "",
          "annotation": "Output might be:\n\"Customer information:\nName: John Doe\nAge: 35\nEmail: john@example.com\"",
          "is_comment": true,
          "start_line": 23,
          "line_range": [
            23,
            27
          ],
          "target_line_range": [
            28,
            28
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 28,
          "line_range": [
            28,
            28
          ]
        },
        {
          "code": "# This approach has several problems:\n# \n# - **Inconsistent formats**: The LLM might return data in different formats each time\n# - **Parsing challenges**: You need custom code to extract specific fields\n# - **No validation**: There's no verification that the data is complete or correctly formatted\n# - **Error handling**: Missing or invalid data is difficult to detect and manage\n# \n# \n# \n# Instructor solves these problems by combining the power of LLMs with structured data validation through Pydantic:\n",
          "display_code": "",
          "annotation": "This approach has several problems:\n\n- **Inconsistent formats**: The LLM might return data in different formats each time\n- **Parsing challenges**: You need custom code to extract specific fields\n- **No validation**: There's no verification that the data is complete or correctly formatted\n- **Error handling**: Missing or invalid data is difficult to detect and manage\n\n\n\nInstructor solves these problems by combining the power of LLMs with structured data validation through Pydantic:",
          "is_comment": true,
          "start_line": 29,
          "line_range": [
            29,
            38
          ],
          "target_line_range": [
            39,
            42
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, EmailStr\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, EmailStr\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 39,
          "line_range": [
            39,
            42
          ]
        },
        {
          "code": "# Define a structured data model\n",
          "display_code": "",
          "annotation": "Define a structured data model",
          "is_comment": true,
          "start_line": 43,
          "line_range": [
            43,
            43
          ],
          "target_line_range": [
            44,
            48
          ]
        },
        {
          "code": "class Customer(BaseModel):\n    name: str = Field(description=\"Customer's full name\")\n    age: int = Field(description=\"Customer's age in years\", ge=0, le=120)\n    email: EmailStr = Field(description=\"Customer's email address\")\n\n",
          "display_code": "class Customer(BaseModel):\n    name: str = Field(description=\"Customer's full name\")\n    age: int = Field(description=\"Customer's age in years\", ge=0, le=120)\n    email: EmailStr = Field(description=\"Customer's email address\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 44,
          "line_range": [
            44,
            48
          ]
        },
        {
          "code": "# Patch the OpenAI client with Instructor\n",
          "display_code": "",
          "annotation": "Patch the OpenAI client with Instructor",
          "is_comment": true,
          "start_line": 49,
          "line_range": [
            49,
            49
          ],
          "target_line_range": [
            50,
            51
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 50,
          "line_range": [
            50,
            51
          ]
        },
        {
          "code": "# Extract structured customer data\n",
          "display_code": "",
          "annotation": "Extract structured customer data",
          "is_comment": true,
          "start_line": 52,
          "line_range": [
            52,
            52
          ],
          "target_line_range": [
            53,
            63
          ]
        },
        {
          "code": "customer = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract customer: John Doe, age 35, email: john@example.com\"}\n    ],\n    response_model=Customer  # This is the key part\n)\n\nprint(customer)  # Customer(name='John Doe', age=35, email='john@example.com')\nprint(f\"Name: {customer.name}, Age: {customer.age}, Email: {customer.email}\")\n\n",
          "display_code": "customer = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract customer: John Doe, age 35, email: john@example.com\"}\n    ],\n    response_model=Customer  # This is the key part\n)\n\nprint(customer)  # Customer(name='John Doe', age=35, email='john@example.com')\nprint(f\"Name: {customer.name}, Age: {customer.age}, Email: {customer.email}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 53,
          "line_range": [
            53,
            63
          ]
        },
        {
          "code": "# 1. **Type Safety**: Get properly typed Python objects instead of raw strings\n# 2. **Validation**: Automatic validation with detailed error messages\n# 3. **Self-documenting**: Models clearly define the expected data structure\n# 4. **Consistent Results**: Reliable, consistent data format across requests\n# 5. **Error Handling**: Automatic retry with informative feedback when validation fails\n# 6. **IDE Support**: Full autocomplete and type checking in your code editor\n# \n# \n# \n# Instructor works by:\n# \n# 1. Defining your expected data structure as a Pydantic model\n# 2. Instructing the LLM to return data in a specific format (JSON, function calls, etc.)\n# 3. Validating the response against your model\n# 4. Automatically retrying if validation fails, providing the error to the LLM\n# 5. Returning a properly typed Python object\n# \n# \n# \n# Structured outputs shine for complex data:\n",
          "display_code": "",
          "annotation": "1. **Type Safety**: Get properly typed Python objects instead of raw strings\n2. **Validation**: Automatic validation with detailed error messages\n3. **Self-documenting**: Models clearly define the expected data structure\n4. **Consistent Results**: Reliable, consistent data format across requests\n5. **Error Handling**: Automatic retry with informative feedback when validation fails\n6. **IDE Support**: Full autocomplete and type checking in your code editor\n\n\n\nInstructor works by:\n\n1. Defining your expected data structure as a Pydantic model\n2. Instructing the LLM to return data in a specific format (JSON, function calls, etc.)\n3. Validating the response against your model\n4. Automatically retrying if validation fails, providing the error to the LLM\n5. Returning a properly typed Python object\n\n\n\nStructured outputs shine for complex data:",
          "is_comment": true,
          "start_line": 64,
          "line_range": [
            64,
            83
          ],
          "target_line_range": [
            84,
            88
          ]
        },
        {
          "code": "from typing import List, Optional\nfrom pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\n\n",
          "display_code": "from typing import List, Optional\nfrom pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 84,
          "line_range": [
            84,
            88
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 89,
          "line_range": [
            89,
            89
          ],
          "target_line_range": [
            90,
            91
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 90,
          "line_range": [
            90,
            91
          ]
        },
        {
          "code": "# Define a complex, nested data structure\n",
          "display_code": "",
          "annotation": "Define a complex, nested data structure",
          "is_comment": true,
          "start_line": 92,
          "line_range": [
            92,
            92
          ],
          "target_line_range": [
            93,
            110
          ]
        },
        {
          "code": "class Address(BaseModel):\n    street: str\n    city: str\n    state: str\n    zip_code: str\n\nclass Contact(BaseModel):\n    email: Optional[str] = None\n    phone: Optional[str] = None\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n    address: Address\n    contact: Contact\n    skills: List[str] = Field(description=\"List of professional skills\")\n\n",
          "display_code": "class Address(BaseModel):\n    street: str\n    city: str\n    state: str\n    zip_code: str\n\nclass Contact(BaseModel):\n    email: Optional[str] = None\n    phone: Optional[str] = None\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n    address: Address\n    contact: Contact\n    skills: List[str] = Field(description=\"List of professional skills\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 93,
          "line_range": [
            93,
            110
          ]
        },
        {
          "code": "# Extract structured data\n",
          "display_code": "",
          "annotation": "Extract structured data",
          "is_comment": true,
          "start_line": 111,
          "line_range": [
            111,
            111
          ],
          "target_line_range": [
            112,
            124
          ]
        },
        {
          "code": "person = client.chat.completions.create(\n    model=\"gpt-4\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Extract detailed information for this person:\n        John Smith is a 42-year-old software engineer living at 123 Main St, San Francisco, CA 94105.\n        His email is john.smith@example.com and phone is 555-123-4567.\n        John is skilled in Python, JavaScript, and cloud architecture.\n        \"\"\"}\n    ],\n    response_model=Person\n)\n\n",
          "display_code": "person = client.chat.completions.create(\n    model=\"gpt-4\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Extract detailed information for this person:\n        John Smith is a 42-year-old software engineer living at 123 Main St, San Francisco, CA 94105.\n        His email is john.smith@example.com and phone is 555-123-4567.\n        John is skilled in Python, JavaScript, and cloud architecture.\n        \"\"\"}\n    ],\n    response_model=Person\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 112,
          "line_range": [
            112,
            124
          ]
        },
        {
          "code": "# Now you have a fully structured object\n",
          "display_code": "",
          "annotation": "Now you have a fully structured object",
          "is_comment": true,
          "start_line": 125,
          "line_range": [
            125,
            125
          ],
          "target_line_range": [
            126,
            129
          ]
        },
        {
          "code": "print(f\"Name: {person.name}\")\nprint(f\"Location: {person.address.city}, {person.address.state}\")\nprint(f\"Skills: {', '.join(person.skills)}\")\n\n",
          "display_code": "print(f\"Name: {person.name}\")\nprint(f\"Location: {person.address.city}, {person.address.state}\")\nprint(f\"Skills: {', '.join(person.skills)}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 126,
          "line_range": [
            126,
            129
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python getting-started.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "001-getting-started",
      "section_title": "Getting Started"
    },
    {
      "id": "002-installation",
      "title": "Installing Instructor",
      "description": "",
      "order": 2,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Set up Instructor and configure API keys for different LLM providers. Best practices for secure API key management and environment setup.\n",
          "display_code": "",
          "annotation": "Set up Instructor and configure API keys for different LLM providers. Best practices for secure API key management and environment setup.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "## Basic Installation",
          "command": "# Install the base package",
          "output": "$ pip install instructor"
        },
        {
          "explanation": "Install with specific provider dependencies:",
          "command": "# For OpenAI (included by default)",
          "output": "$ pip install instructor\n$ \n$ # For Anthropic\n$ pip install \"instructor[anthropic]\"\n$ \n$ # For Google/Gemini\n$ pip install \"instructor[google-generativeai]\"\n$ \n$ # For Cohere\n$ pip install \"instructor[cohere]\"\n$ \n$ # For Mistral\n$ pip install \"instructor[mistralai]\"\n$ \n$ # For multiple providers via LiteLLM\n$ pip install \"instructor[litellm]\""
        },
        {
          "explanation": "Set your API keys as environment variables:",
          "command": "# OpenAI",
          "output": "$ export OPENAI_API_KEY=your_openai_key\n$ \n$ # Anthropic\n$ export ANTHROPIC_API_KEY=your_anthropic_key\n$ \n$ # Google/Gemini\n$ export GOOGLE_API_KEY=your_google_key"
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "001-getting-started",
      "section_title": "Getting Started"
    },
    {
      "id": "003-first-extraction",
      "title": "Your First Extraction",
      "description": "",
      "order": 3,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Create your first structured extraction with Instructor. Learn the step-by-step process from model definition to validated response.\n",
          "display_code": "",
          "annotation": "Create your first structured extraction with Instructor. Learn the step-by-step process from model definition to validated response.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Extract structured data from text using Instructor and a Pydantic model.\n",
          "display_code": "",
          "annotation": "Extract structured data from text using Instructor and a Pydantic model.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            14
          ]
        },
        {
          "code": "from pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n\nimport instructor\nfrom openai import OpenAI\n\n",
          "display_code": "from pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n\nimport instructor\nfrom openai import OpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            14
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 15,
          "line_range": [
            15,
            15
          ],
          "target_line_range": [
            16,
            17
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 16,
          "line_range": [
            16,
            17
          ]
        },
        {
          "code": "# Extract structured data\n",
          "display_code": "",
          "annotation": "Extract structured data",
          "is_comment": true,
          "start_line": 18,
          "line_range": [
            18,
            18
          ],
          "target_line_range": [
            19,
            27
          ]
        },
        {
          "code": "person = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John Doe is 30 years old\"}\n    ]\n)\n\nprint(f\"Name: {person.name}, Age: {person.age}\")\n",
          "display_code": "person = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John Doe is 30 years old\"}\n    ]\n)\n\nprint(f\"Name: {person.name}, Age: {person.age}\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 19,
          "line_range": [
            19,
            27
          ]
        },
        {
          "code": "# Output: Name: John Doe, Age: 30\n",
          "display_code": "",
          "annotation": "Output: Name: John Doe, Age: 30",
          "is_comment": true,
          "start_line": 28,
          "line_range": [
            28,
            28
          ],
          "target_line_range": [
            29,
            29
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 29,
          "line_range": [
            29,
            29
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python first-extraction.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "001-getting-started",
      "section_title": "Getting Started"
    },
    {
      "id": "004-response-models",
      "title": "Understanding Response Models",
      "description": "",
      "order": 4,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Instructor uses Pydantic models to define the structure of your LLM outputs. Here's how to create effective models.\n",
          "display_code": "",
          "annotation": "Instructor uses Pydantic models to define the structure of your LLM outputs. Here's how to create effective models.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            23
          ]
        },
        {
          "code": "from pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\nfrom pydantic import BaseModel\nfrom typing import List, Optional\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    state: Optional[str] = None\n    country: str\n\nclass User(BaseModel):\n    name: str\n    age: int\n    addresses: List[Address]\n\n",
          "display_code": "from pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\nfrom pydantic import BaseModel\nfrom typing import List, Optional\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    state: Optional[str] = None\n    country: str\n\nclass User(BaseModel):\n    name: str\n    age: int\n    addresses: List[Address]\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            23
          ]
        },
        {
          "code": "# Add descriptions to help guide the LLM:\n",
          "display_code": "",
          "annotation": "Add descriptions to help guide the LLM:",
          "is_comment": true,
          "start_line": 24,
          "line_range": [
            24,
            24
          ],
          "target_line_range": [
            25,
            39
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\n\nclass WeatherForecast(BaseModel):\n    \"\"\"Weather forecast for a specific location\"\"\"\n\n    temperature: float = Field(\n        description=\"Current temperature in Celsius\"\n    )\n    condition: str = Field(\n        description=\"Weather condition (sunny, cloudy, rainy, etc.)\"\n    )\n    humidity: int = Field(\n        description=\"Humidity percentage from 0-100\"\n    )\n\n",
          "display_code": "from pydantic import BaseModel, Field\n\nclass WeatherForecast(BaseModel):\n    \"\"\"Weather forecast for a specific location\"\"\"\n\n    temperature: float = Field(\n        description=\"Current temperature in Celsius\"\n    )\n    condition: str = Field(\n        description=\"Weather condition (sunny, cloudy, rainy, etc.)\"\n    )\n    humidity: int = Field(\n        description=\"Humidity percentage from 0-100\"\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 25,
          "line_range": [
            25,
            39
          ]
        },
        {
          "code": "# Add validation constraints to ensure quality data:\n",
          "display_code": "",
          "annotation": "Add validation constraints to ensure quality data:",
          "is_comment": true,
          "start_line": 40,
          "line_range": [
            40,
            40
          ],
          "target_line_range": [
            41,
            63
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\n\nclass Product(BaseModel):\n    name: str = Field(min_length=3)\n    price: float = Field(gt=0)  # greater than 0\n    quantity: int = Field(ge=0)  # greater than or equal to 0\n    description: str = Field(max_length=500)\n\nimport instructor\nfrom openai import OpenAI\n\nclient = instructor.from_openai(OpenAI())\n\nforecast = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=WeatherForecast,\n    messages=[\n        {\"role\": \"user\", \"content\": \"What's the weather in New York today?\"}\n    ]\n)\n\nprint(forecast.model_dump_json(indent=2))\n\n",
          "display_code": "from pydantic import BaseModel, Field\n\nclass Product(BaseModel):\n    name: str = Field(min_length=3)\n    price: float = Field(gt=0)  # greater than 0\n    quantity: int = Field(ge=0)  # greater than or equal to 0\n    description: str = Field(max_length=500)\n\nimport instructor\nfrom openai import OpenAI\n\nclient = instructor.from_openai(OpenAI())\n\nforecast = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=WeatherForecast,\n    messages=[\n        {\"role\": \"user\", \"content\": \"What's the weather in New York today?\"}\n    ]\n)\n\nprint(forecast.model_dump_json(indent=2))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 41,
          "line_range": [
            41,
            63
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python response-models.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "001-getting-started",
      "section_title": "Getting Started"
    },
    {
      "id": "005-client-setup",
      "title": "Client Setup",
      "description": "",
      "order": 5,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Configure Instructor clients for different LLM providers. Learn about extraction modes and client configuration options.\n",
          "display_code": "",
          "annotation": "Configure Instructor clients for different LLM providers. Learn about extraction modes and client configuration options.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Set up Instructor with different LLM providers. Each provider requires slightly different setup.\n",
          "display_code": "",
          "annotation": "Set up Instructor with different LLM providers. Each provider requires slightly different setup.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            8
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            8
          ]
        },
        {
          "code": "# Default mode for OpenAI is TOOLS (function calling)\n",
          "display_code": "",
          "annotation": "Default mode for OpenAI is TOOLS (function calling)",
          "is_comment": true,
          "start_line": 9,
          "line_range": [
            9,
            9
          ],
          "target_line_range": [
            10,
            11
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 10,
          "line_range": [
            10,
            11
          ]
        },
        {
          "code": "# You can also specify a different mode\n",
          "display_code": "",
          "annotation": "You can also specify a different mode",
          "is_comment": true,
          "start_line": 12,
          "line_range": [
            12,
            12
          ],
          "target_line_range": [
            13,
            20
          ]
        },
        {
          "code": "client = instructor.from_openai(\n    OpenAI(),\n    mode=instructor.Mode.JSON  # Use JSON mode instead\n)\n\nimport instructor\nfrom anthropic import Anthropic\n\n",
          "display_code": "client = instructor.from_openai(\n    OpenAI(),\n    mode=instructor.Mode.JSON  # Use JSON mode instead\n)\n\nimport instructor\nfrom anthropic import Anthropic\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 13,
          "line_range": [
            13,
            20
          ]
        },
        {
          "code": "# Default mode is TOOLS for Claude 3\n",
          "display_code": "",
          "annotation": "Default mode is TOOLS for Claude 3",
          "is_comment": true,
          "start_line": 21,
          "line_range": [
            21,
            21
          ],
          "target_line_range": [
            22,
            23
          ]
        },
        {
          "code": "client = instructor.from_anthropic(Anthropic())\n\n",
          "display_code": "client = instructor.from_anthropic(Anthropic())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 22,
          "line_range": [
            22,
            23
          ]
        },
        {
          "code": "# Use JSON mode if needed\n",
          "display_code": "",
          "annotation": "Use JSON mode if needed",
          "is_comment": true,
          "start_line": 24,
          "line_range": [
            24,
            24
          ],
          "target_line_range": [
            25,
            32
          ]
        },
        {
          "code": "client = instructor.from_anthropic(\n    Anthropic(),\n    mode=instructor.Mode.JSON\n)\n\nimport instructor\nimport google.generativeai as genai\n\n",
          "display_code": "client = instructor.from_anthropic(\n    Anthropic(),\n    mode=instructor.Mode.JSON\n)\n\nimport instructor\nimport google.generativeai as genai\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 25,
          "line_range": [
            25,
            32
          ]
        },
        {
          "code": "# Configure Gemini\n",
          "display_code": "",
          "annotation": "Configure Gemini",
          "is_comment": true,
          "start_line": 33,
          "line_range": [
            33,
            33
          ],
          "target_line_range": [
            34,
            36
          ]
        },
        {
          "code": "genai.configure(api_key=\"YOUR_API_KEY\")\nmodel = genai.GenerativeModel(\"gemini-1.5-flash\")\n\n",
          "display_code": "genai.configure(api_key=\"YOUR_API_KEY\")\nmodel = genai.GenerativeModel(\"gemini-1.5-flash\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 34,
          "line_range": [
            34,
            36
          ]
        },
        {
          "code": "# Gemini needs a specific mode\n",
          "display_code": "",
          "annotation": "Gemini needs a specific mode",
          "is_comment": true,
          "start_line": 37,
          "line_range": [
            37,
            37
          ],
          "target_line_range": [
            38,
            45
          ]
        },
        {
          "code": "client = instructor.from_gemini(\n    model,\n    mode=instructor.Mode.GEMINI_TOOLS  # or GEMINI_JSON\n)\n\nimport instructor\nimport cohere\n\n",
          "display_code": "client = instructor.from_gemini(\n    model,\n    mode=instructor.Mode.GEMINI_TOOLS  # or GEMINI_JSON\n)\n\nimport instructor\nimport cohere\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 38,
          "line_range": [
            38,
            45
          ]
        },
        {
          "code": "# Create Cohere client\n",
          "display_code": "",
          "annotation": "Create Cohere client",
          "is_comment": true,
          "start_line": 46,
          "line_range": [
            46,
            46
          ],
          "target_line_range": [
            47,
            48
          ]
        },
        {
          "code": "cohere_client = cohere.Client(\"YOUR_API_KEY\")\n\n",
          "display_code": "cohere_client = cohere.Client(\"YOUR_API_KEY\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 47,
          "line_range": [
            47,
            48
          ]
        },
        {
          "code": "# Patch with instructor\n",
          "display_code": "",
          "annotation": "Patch with instructor",
          "is_comment": true,
          "start_line": 49,
          "line_range": [
            49,
            49
          ],
          "target_line_range": [
            50,
            56
          ]
        },
        {
          "code": "client = instructor.from_cohere(cohere_client)\n\nimport instructor\nfrom mistralai.client import MistralClient\n\nmistral_client = MistralClient(api_key=\"YOUR_API_KEY\")\n\n",
          "display_code": "client = instructor.from_cohere(cohere_client)\n\nimport instructor\nfrom mistralai.client import MistralClient\n\nmistral_client = MistralClient(api_key=\"YOUR_API_KEY\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 50,
          "line_range": [
            50,
            56
          ]
        },
        {
          "code": "# Patch with instructor\n",
          "display_code": "",
          "annotation": "Patch with instructor",
          "is_comment": true,
          "start_line": 57,
          "line_range": [
            57,
            57
          ],
          "target_line_range": [
            58,
            59
          ]
        },
        {
          "code": "client = instructor.from_mistral(mistral_client)\n\n",
          "display_code": "client = instructor.from_mistral(mistral_client)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 58,
          "line_range": [
            58,
            59
          ]
        },
        {
          "code": "# Instructor supports different modes for different providers:\n",
          "display_code": "",
          "annotation": "Instructor supports different modes for different providers:",
          "is_comment": true,
          "start_line": 60,
          "line_range": [
            60,
            60
          ],
          "target_line_range": [
            61,
            62
          ]
        },
        {
          "code": "from instructor import Mode\n\n",
          "display_code": "from instructor import Mode\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 61,
          "line_range": [
            61,
            62
          ]
        },
        {
          "code": "# Available modes\n",
          "display_code": "",
          "annotation": "Available modes",
          "is_comment": true,
          "start_line": 63,
          "line_range": [
            63,
            63
          ],
          "target_line_range": [
            64,
            70
          ]
        },
        {
          "code": "Mode.TOOLS         # OpenAI function calling format (default for OpenAI)\nMode.JSON          # Plain JSON generation\nMode.MD_JSON       # Markdown JSON (used by some providers)\nMode.ANTHROPIC_TOOLS # Claude tools mode (default for Anthropic)\nMode.GEMINI_TOOLS  # Gemini tools format\nMode.GEMINI_JSON   # Gemini JSON format\n\n",
          "display_code": "Mode.TOOLS         # OpenAI function calling format (default for OpenAI)\nMode.JSON          # Plain JSON generation\nMode.MD_JSON       # Markdown JSON (used by some providers)\nMode.ANTHROPIC_TOOLS # Claude tools mode (default for Anthropic)\nMode.GEMINI_TOOLS  # Gemini tools format\nMode.GEMINI_JSON   # Gemini JSON format\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 64,
          "line_range": [
            64,
            70
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python client-setup.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "001-getting-started",
      "section_title": "Getting Started"
    },
    {
      "id": "006-openai",
      "title": "OpenAI Integration",
      "description": "",
      "order": 6,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Instructor works seamlessly with OpenAI models. Here's how to use it with different OpenAI features.\n",
          "display_code": "",
          "annotation": "Instructor works seamlessly with OpenAI models. Here's how to use it with different OpenAI features.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            13
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\nclient = instructor.from_openai(OpenAI())\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\nclient = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            13
          ]
        },
        {
          "code": "# GPT-3.5 Turbo (cheaper, faster)\n",
          "display_code": "",
          "annotation": "GPT-3.5 Turbo (cheaper, faster)",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            22
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is a 25-year-old engineer.\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is a 25-year-old engineer.\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            22
          ]
        },
        {
          "code": "# GPT-4 (more capable, better at complex tasks)\n",
          "display_code": "",
          "annotation": "GPT-4 (more capable, better at complex tasks)",
          "is_comment": true,
          "start_line": 23,
          "line_range": [
            23,
            23
          ],
          "target_line_range": [
            24,
            40
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"gpt-4\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is a 25-year-old engineer.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=User,\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are an expert at data extraction.\"},\n        {\"role\": \"user\", \"content\": \"Extract user details from: John is 25 years old.\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"gpt-4\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is a 25-year-old engineer.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=User,\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are an expert at data extraction.\"},\n        {\"role\": \"user\", \"content\": \"Extract user details from: John is 25 years old.\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 24,
          "line_range": [
            24,
            40
          ]
        },
        {
          "code": "# Lower temperature for more consistent results\n",
          "display_code": "",
          "annotation": "Lower temperature for more consistent results",
          "is_comment": true,
          "start_line": 41,
          "line_range": [
            41,
            41
          ],
          "target_line_range": [
            42,
            50
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    temperature=0.1,  # Very deterministic (0.0-1.0)\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is a 25-year-old engineer.\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    temperature=0.1,  # Very deterministic (0.0-1.0)\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is a 25-year-old engineer.\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 42,
          "line_range": [
            42,
            50
          ]
        },
        {
          "code": "# Instructor defaults to using OpenAI's function calling format, but you can use JSON mode too:\n",
          "display_code": "",
          "annotation": "Instructor defaults to using OpenAI's function calling format, but you can use JSON mode too:",
          "is_comment": true,
          "start_line": 51,
          "line_range": [
            51,
            51
          ],
          "target_line_range": [
            52,
            80
          ]
        },
        {
          "code": "client = instructor.from_openai(\n    OpenAI(),\n    mode=instructor.Mode.JSON\n)\n\nuser = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is a 25-year-old engineer.\"}\n    ]\n)\n\nimport asyncio\nfrom openai import AsyncOpenAI\n\nasync_client = instructor.from_openai(AsyncOpenAI())\n\nasync def extract_user():\n    return await async_client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Extract: John is a 25-year-old engineer.\"}\n        ]\n    )\n\nuser = asyncio.run(extract_user())\n\n",
          "display_code": "client = instructor.from_openai(\n    OpenAI(),\n    mode=instructor.Mode.JSON\n)\n\nuser = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is a 25-year-old engineer.\"}\n    ]\n)\n\nimport asyncio\nfrom openai import AsyncOpenAI\n\nasync_client = instructor.from_openai(AsyncOpenAI())\n\nasync def extract_user():\n    return await async_client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Extract: John is a 25-year-old engineer.\"}\n        ]\n    )\n\nuser = asyncio.run(extract_user())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 52,
          "line_range": [
            52,
            80
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python openai.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "002-providers",
      "section_title": "LLM Providers"
    },
    {
      "id": "007-anthropic",
      "title": "Anthropic Integration",
      "description": "",
      "order": 7,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Use Instructor with Anthropic's Claude models for structured data extraction.\n",
          "display_code": "",
          "annotation": "Use Instructor with Anthropic's Claude models for structured data extraction.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            13
          ]
        },
        {
          "code": "import instructor\nfrom anthropic import Anthropic\nfrom pydantic import BaseModel\n\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n\n",
          "display_code": "import instructor\nfrom anthropic import Anthropic\nfrom pydantic import BaseModel\n\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            13
          ]
        },
        {
          "code": "# Create patched client\n",
          "display_code": "",
          "annotation": "Create patched client",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            16
          ]
        },
        {
          "code": "client = instructor.from_anthropic(Anthropic())\n\n",
          "display_code": "client = instructor.from_anthropic(Anthropic())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            16
          ]
        },
        {
          "code": "# Claude 3 Haiku (faster, cheaper)\n",
          "display_code": "",
          "annotation": "Claude 3 Haiku (faster, cheaper)",
          "is_comment": true,
          "start_line": 17,
          "line_range": [
            17,
            17
          ],
          "target_line_range": [
            18,
            24
          ]
        },
        {
          "code": "user = client.messages.create(\n    model=\"claude-3-haiku-20240307\",\n    max_tokens=1000,\n    response_model=User,\n    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n)\n\n",
          "display_code": "user = client.messages.create(\n    model=\"claude-3-haiku-20240307\",\n    max_tokens=1000,\n    response_model=User,\n    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 18,
          "line_range": [
            18,
            24
          ]
        },
        {
          "code": "# Claude 3 Sonnet (balanced)\n",
          "display_code": "",
          "annotation": "Claude 3 Sonnet (balanced)",
          "is_comment": true,
          "start_line": 25,
          "line_range": [
            25,
            25
          ],
          "target_line_range": [
            26,
            32
          ]
        },
        {
          "code": "user = client.messages.create(\n    model=\"claude-3-sonnet-20240229\",\n    max_tokens=1000,\n    response_model=User,\n    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n)\n\n",
          "display_code": "user = client.messages.create(\n    model=\"claude-3-sonnet-20240229\",\n    max_tokens=1000,\n    response_model=User,\n    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 26,
          "line_range": [
            26,
            32
          ]
        },
        {
          "code": "# Claude 3 Opus (most capable)\n",
          "display_code": "",
          "annotation": "Claude 3 Opus (most capable)",
          "is_comment": true,
          "start_line": 33,
          "line_range": [
            33,
            33
          ],
          "target_line_range": [
            34,
            56
          ]
        },
        {
          "code": "user = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1000,\n    response_model=User,\n    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n)\n\nuser = client.messages.create(\n    model=\"claude-3-haiku-20240307\",\n    max_tokens=1000,\n    response_model=User,\n    system=\"You are an expert at data extraction. Always extract all details accurately.\",\n    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n)\n\nuser = client.messages.create(\n    model=\"claude-3-haiku-20240307\",\n    max_tokens=1000,\n    temperature=0.2,  # Lower temperature for more consistent results\n    response_model=User,\n    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n)\n\n",
          "display_code": "user = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1000,\n    response_model=User,\n    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n)\n\nuser = client.messages.create(\n    model=\"claude-3-haiku-20240307\",\n    max_tokens=1000,\n    response_model=User,\n    system=\"You are an expert at data extraction. Always extract all details accurately.\",\n    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n)\n\nuser = client.messages.create(\n    model=\"claude-3-haiku-20240307\",\n    max_tokens=1000,\n    temperature=0.2,  # Lower temperature for more consistent results\n    response_model=User,\n    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 34,
          "line_range": [
            34,
            56
          ]
        },
        {
          "code": "# Default: ANTHROPIC_TOOLS mode\n",
          "display_code": "",
          "annotation": "Default: ANTHROPIC_TOOLS mode",
          "is_comment": true,
          "start_line": 57,
          "line_range": [
            57,
            57
          ],
          "target_line_range": [
            58,
            59
          ]
        },
        {
          "code": "client = instructor.from_anthropic(Anthropic())\n\n",
          "display_code": "client = instructor.from_anthropic(Anthropic())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 58,
          "line_range": [
            58,
            59
          ]
        },
        {
          "code": "# JSON mode\n",
          "display_code": "",
          "annotation": "JSON mode",
          "is_comment": true,
          "start_line": 60,
          "line_range": [
            60,
            60
          ],
          "target_line_range": [
            61,
            62
          ]
        },
        {
          "code": "json_client = instructor.from_anthropic(Anthropic(), mode=instructor.Mode.JSON)\n\n",
          "display_code": "json_client = instructor.from_anthropic(Anthropic(), mode=instructor.Mode.JSON)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 61,
          "line_range": [
            61,
            62
          ]
        },
        {
          "code": "# Markdown JSON mode\n",
          "display_code": "",
          "annotation": "Markdown JSON mode",
          "is_comment": true,
          "start_line": 63,
          "line_range": [
            63,
            63
          ],
          "target_line_range": [
            64,
            81
          ]
        },
        {
          "code": "md_client = instructor.from_anthropic(Anthropic(), mode=instructor.Mode.MD_JSON)\n\nimport asyncio\nfrom anthropic import AsyncAnthropic\n\nasync_client = instructor.from_anthropic(AsyncAnthropic())\n\n\nasync def extract_user():\n    return await async_client.messages.create(\n        model=\"claude-3-haiku-20240307\",\n        max_tokens=1000,\n        response_model=User,\n        messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n    )\n\n\nuser = asyncio.run(extract_user())\n",
          "display_code": "md_client = instructor.from_anthropic(Anthropic(), mode=instructor.Mode.MD_JSON)\n\nimport asyncio\nfrom anthropic import AsyncAnthropic\n\nasync_client = instructor.from_anthropic(AsyncAnthropic())\n\n\nasync def extract_user():\n    return await async_client.messages.create(\n        model=\"claude-3-haiku-20240307\",\n        max_tokens=1000,\n        response_model=User,\n        messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n    )\n\n\nuser = asyncio.run(extract_user())\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 64,
          "line_range": [
            64,
            81
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python anthropic.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "002-providers",
      "section_title": "LLM Providers"
    },
    {
      "id": "008-gemini",
      "title": "Gemini Integration",
      "description": "",
      "order": 8,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Use Instructor with Google's Gemini models for structured data extraction.\n# \n# \n# \n# \n# \n# pip install instructor google-generativeai jsonref\n# \n",
          "display_code": "",
          "annotation": "Use Instructor with Google's Gemini models for structured data extraction.\n\n\n\n\n\npip install instructor google-generativeai jsonref\n",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            10
          ],
          "target_line_range": [
            11,
            14
          ]
        },
        {
          "code": "import instructor\nimport google.generativeai as genai\nfrom pydantic import BaseModel\n\n",
          "display_code": "import instructor\nimport google.generativeai as genai\nfrom pydantic import BaseModel\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 11,
          "line_range": [
            11,
            14
          ]
        },
        {
          "code": "# Configure API key\n",
          "display_code": "",
          "annotation": "Configure API key",
          "is_comment": true,
          "start_line": 15,
          "line_range": [
            15,
            15
          ],
          "target_line_range": [
            16,
            21
          ]
        },
        {
          "code": "genai.configure(api_key=\"YOUR_API_KEY\")\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "genai.configure(api_key=\"YOUR_API_KEY\")\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 16,
          "line_range": [
            16,
            21
          ]
        },
        {
          "code": "# Create Gemini model\n",
          "display_code": "",
          "annotation": "Create Gemini model",
          "is_comment": true,
          "start_line": 22,
          "line_range": [
            22,
            22
          ],
          "target_line_range": [
            23,
            24
          ]
        },
        {
          "code": "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n\n",
          "display_code": "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 23,
          "line_range": [
            23,
            24
          ]
        },
        {
          "code": "# Patch with instructor (require specific mode)\n",
          "display_code": "",
          "annotation": "Patch with instructor (require specific mode)",
          "is_comment": true,
          "start_line": 25,
          "line_range": [
            25,
            25
          ],
          "target_line_range": [
            26,
            30
          ]
        },
        {
          "code": "client = instructor.from_gemini(\n    model,\n    mode=instructor.Mode.GEMINI_TOOLS  # or GEMINI_JSON\n)\n\n",
          "display_code": "client = instructor.from_gemini(\n    model,\n    mode=instructor.Mode.GEMINI_TOOLS  # or GEMINI_JSON\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 26,
          "line_range": [
            26,
            30
          ]
        },
        {
          "code": "# Using generate_content method\n",
          "display_code": "",
          "annotation": "Using generate_content method",
          "is_comment": true,
          "start_line": 31,
          "line_range": [
            31,
            31
          ],
          "target_line_range": [
            32,
            37
          ]
        },
        {
          "code": "user = client.generate_content(\n    response_model=User,\n    contents=\"Extract: John is 25 years old.\"\n)\n\nprint(f\"Name: {user.name}, Age: {user.age}\")\n",
          "display_code": "user = client.generate_content(\n    response_model=User,\n    contents=\"Extract: John is 25 years old.\"\n)\n\nprint(f\"Name: {user.name}, Age: {user.age}\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 32,
          "line_range": [
            32,
            37
          ]
        },
        {
          "code": "# Output: Name: John, Age: 25\n",
          "display_code": "",
          "annotation": "Output: Name: John, Age: 25",
          "is_comment": true,
          "start_line": 38,
          "line_range": [
            38,
            38
          ],
          "target_line_range": [
            39,
            39
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 39,
          "line_range": [
            39,
            39
          ]
        },
        {
          "code": "# Gemini 1.5 Flash (faster)\n",
          "display_code": "",
          "annotation": "Gemini 1.5 Flash (faster)",
          "is_comment": true,
          "start_line": 40,
          "line_range": [
            40,
            40
          ],
          "target_line_range": [
            41,
            46
          ]
        },
        {
          "code": "flash_model = genai.GenerativeModel(\"gemini-1.5-flash\")\nflash_client = instructor.from_gemini(\n    flash_model,\n    mode=instructor.Mode.GEMINI_TOOLS\n)\n\n",
          "display_code": "flash_model = genai.GenerativeModel(\"gemini-1.5-flash\")\nflash_client = instructor.from_gemini(\n    flash_model,\n    mode=instructor.Mode.GEMINI_TOOLS\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 41,
          "line_range": [
            41,
            46
          ]
        },
        {
          "code": "# Gemini 1.5 Pro (more capable)\n",
          "display_code": "",
          "annotation": "Gemini 1.5 Pro (more capable)",
          "is_comment": true,
          "start_line": 47,
          "line_range": [
            47,
            47
          ],
          "target_line_range": [
            48,
            83
          ]
        },
        {
          "code": "pro_model = genai.GenerativeModel(\"gemini-1.5-pro\")\npro_client = instructor.from_gemini(\n    pro_model,\n    mode=instructor.Mode.GEMINI_TOOLS\n)\n\nuser = client.generate_content(\n    response_model=User,\n    contents=\"Extract: John is 25 years old.\",\n    generation_config={\n        \"system_instruction\": \"You are an expert at extracting structured data.\"\n    }\n)\n\nuser = client.generate_content(\n    response_model=User,\n    contents=[\n        {\"role\": \"user\", \"parts\": [\"Extract: John is 25 years old.\"]}\n    ]\n)\n\njson_client = instructor.from_gemini(\n    genai.GenerativeModel(\"gemini-1.5-flash\"),\n    mode=instructor.Mode.GEMINI_JSON\n)\n\nuser = json_client.generate_content(\n    response_model=User,\n    contents=\"Extract: John is 25 years old.\"\n)\n\nimport google.auth\nimport google.auth.transport.requests\nimport instructor\nfrom openai import OpenAI\n\n",
          "display_code": "pro_model = genai.GenerativeModel(\"gemini-1.5-pro\")\npro_client = instructor.from_gemini(\n    pro_model,\n    mode=instructor.Mode.GEMINI_TOOLS\n)\n\nuser = client.generate_content(\n    response_model=User,\n    contents=\"Extract: John is 25 years old.\",\n    generation_config={\n        \"system_instruction\": \"You are an expert at extracting structured data.\"\n    }\n)\n\nuser = client.generate_content(\n    response_model=User,\n    contents=[\n        {\"role\": \"user\", \"parts\": [\"Extract: John is 25 years old.\"]}\n    ]\n)\n\njson_client = instructor.from_gemini(\n    genai.GenerativeModel(\"gemini-1.5-flash\"),\n    mode=instructor.Mode.GEMINI_JSON\n)\n\nuser = json_client.generate_content(\n    response_model=User,\n    contents=\"Extract: John is 25 years old.\"\n)\n\nimport google.auth\nimport google.auth.transport.requests\nimport instructor\nfrom openai import OpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 48,
          "line_range": [
            48,
            83
          ]
        },
        {
          "code": "# Get Google auth credentials\n",
          "display_code": "",
          "annotation": "Get Google auth credentials",
          "is_comment": true,
          "start_line": 84,
          "line_range": [
            84,
            84
          ],
          "target_line_range": [
            85,
            88
          ]
        },
        {
          "code": "creds, project = google.auth.default()\nauth_req = google.auth.transport.requests.Request()\ncreds.refresh(auth_req)\n\n",
          "display_code": "creds, project = google.auth.default()\nauth_req = google.auth.transport.requests.Request()\ncreds.refresh(auth_req)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 85,
          "line_range": [
            85,
            88
          ]
        },
        {
          "code": "# Configure Vertex AI endpoint\n",
          "display_code": "",
          "annotation": "Configure Vertex AI endpoint",
          "is_comment": true,
          "start_line": 89,
          "line_range": [
            89,
            89
          ],
          "target_line_range": [
            90,
            93
          ]
        },
        {
          "code": "PROJECT = 'your-project-id'\nLOCATION = 'us-central1'  # or your preferred region\nendpoint = f'https://{LOCATION}-aiplatform.googleapis.com/v1beta1/projects/{PROJECT}/locations/{LOCATION}/endpoints/openapi'\n\n",
          "display_code": "PROJECT = 'your-project-id'\nLOCATION = 'us-central1'  # or your preferred region\nendpoint = f'https://{LOCATION}-aiplatform.googleapis.com/v1beta1/projects/{PROJECT}/locations/{LOCATION}/endpoints/openapi'\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 90,
          "line_range": [
            90,
            93
          ]
        },
        {
          "code": "# Create patched OpenAI client pointing to Vertex AI\n",
          "display_code": "",
          "annotation": "Create patched OpenAI client pointing to Vertex AI",
          "is_comment": true,
          "start_line": 94,
          "line_range": [
            94,
            94
          ],
          "target_line_range": [
            95,
            99
          ]
        },
        {
          "code": "client = instructor.from_openai(\n    OpenAI(base_url=endpoint, api_key=creds.token),\n    mode=instructor.Mode.JSON  # JSON mode required\n)\n\n",
          "display_code": "client = instructor.from_openai(\n    OpenAI(base_url=endpoint, api_key=creds.token),\n    mode=instructor.Mode.JSON  # JSON mode required\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 95,
          "line_range": [
            95,
            99
          ]
        },
        {
          "code": "# Use OpenAI-style interface\n",
          "display_code": "",
          "annotation": "Use OpenAI-style interface",
          "is_comment": true,
          "start_line": 100,
          "line_range": [
            100,
            100
          ],
          "target_line_range": [
            101,
            108
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"google/gemini-1.5-flash\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"google/gemini-1.5-flash\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 101,
          "line_range": [
            101,
            108
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "Use Instructor with Google's Gemini models for structured data extraction.",
          "command": "# Install required packages",
          "output": "$ pip install instructor google-generativeai jsonref"
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "002-providers",
      "section_title": "LLM Providers"
    },
    {
      "id": "009-cohere",
      "title": "Cohere Integration",
      "description": "",
      "order": 9,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Use Instructor with Cohere's models for structured data extraction.\n# \n# \n# \n# \n# \n# pip install instructor cohere\n# \n",
          "display_code": "",
          "annotation": "Use Instructor with Cohere's models for structured data extraction.\n\n\n\n\n\npip install instructor cohere\n",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            10
          ],
          "target_line_range": [
            11,
            18
          ]
        },
        {
          "code": "import instructor\nimport cohere\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "import instructor\nimport cohere\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 11,
          "line_range": [
            11,
            18
          ]
        },
        {
          "code": "# Create Cohere client\n",
          "display_code": "",
          "annotation": "Create Cohere client",
          "is_comment": true,
          "start_line": 19,
          "line_range": [
            19,
            19
          ],
          "target_line_range": [
            20,
            21
          ]
        },
        {
          "code": "co = cohere.Client(\"YOUR_API_KEY\")  # or set CO_API_KEY env variable\n\n",
          "display_code": "co = cohere.Client(\"YOUR_API_KEY\")  # or set CO_API_KEY env variable\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 20,
          "line_range": [
            20,
            21
          ]
        },
        {
          "code": "# Patch with instructor\n",
          "display_code": "",
          "annotation": "Patch with instructor",
          "is_comment": true,
          "start_line": 22,
          "line_range": [
            22,
            22
          ],
          "target_line_range": [
            23,
            24
          ]
        },
        {
          "code": "client = instructor.from_cohere(co)\n\n",
          "display_code": "client = instructor.from_cohere(co)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 23,
          "line_range": [
            23,
            24
          ]
        },
        {
          "code": "# Using chat method\n",
          "display_code": "",
          "annotation": "Using chat method",
          "is_comment": true,
          "start_line": 25,
          "line_range": [
            25,
            25
          ],
          "target_line_range": [
            26,
            34
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"command-r-plus\",  # or other Cohere models\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nprint(f\"Name: {user.name}, Age: {user.age}\")\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"command-r-plus\",  # or other Cohere models\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nprint(f\"Name: {user.name}, Age: {user.age}\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 26,
          "line_range": [
            26,
            34
          ]
        },
        {
          "code": "# Output: Name: John, Age: 25\n",
          "display_code": "",
          "annotation": "Output: Name: John, Age: 25",
          "is_comment": true,
          "start_line": 35,
          "line_range": [
            35,
            35
          ],
          "target_line_range": [
            36,
            36
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 36,
          "line_range": [
            36,
            36
          ]
        },
        {
          "code": "# Command model\n",
          "display_code": "",
          "annotation": "Command model",
          "is_comment": true,
          "start_line": 37,
          "line_range": [
            37,
            37
          ],
          "target_line_range": [
            38,
            45
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"command\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"command\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 38,
          "line_range": [
            38,
            45
          ]
        },
        {
          "code": "# Command R model\n",
          "display_code": "",
          "annotation": "Command R model",
          "is_comment": true,
          "start_line": 46,
          "line_range": [
            46,
            46
          ],
          "target_line_range": [
            47,
            54
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"command-r\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"command-r\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 47,
          "line_range": [
            47,
            54
          ]
        },
        {
          "code": "# Command R+ model (most capable)\n",
          "display_code": "",
          "annotation": "Command R+ model (most capable)",
          "is_comment": true,
          "start_line": 55,
          "line_range": [
            55,
            55
          ],
          "target_line_range": [
            56,
            91
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"command-r-plus\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"command-r-plus\",\n    temperature=0.2,  # Lower for more consistent results\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"command-r-plus\",\n    response_model=User,\n    preamble=\"You are an expert at extracting structured information.\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"command-r-plus\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hi, I'd like to discuss John who is 25 years old.\"},\n        {\"role\": \"assistant\", \"content\": \"Hello! I'd be happy to discuss John with you.\"},\n        {\"role\": \"user\", \"content\": \"Can you extract his information in a structured format?\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"command-r-plus\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"command-r-plus\",\n    temperature=0.2,  # Lower for more consistent results\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"command-r-plus\",\n    response_model=User,\n    preamble=\"You are an expert at extracting structured information.\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"command-r-plus\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hi, I'd like to discuss John who is 25 years old.\"},\n        {\"role\": \"assistant\", \"content\": \"Hello! I'd be happy to discuss John with you.\"},\n        {\"role\": \"user\", \"content\": \"Can you extract his information in a structured format?\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 56,
          "line_range": [
            56,
            91
          ]
        },
        {
          "code": "# Default JSON mode\n",
          "display_code": "",
          "annotation": "Default JSON mode",
          "is_comment": true,
          "start_line": 92,
          "line_range": [
            92,
            92
          ],
          "target_line_range": [
            93,
            94
          ]
        },
        {
          "code": "client = instructor.from_cohere(co)\n\n",
          "display_code": "client = instructor.from_cohere(co)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 93,
          "line_range": [
            93,
            94
          ]
        },
        {
          "code": "# Explicit JSON mode\n",
          "display_code": "",
          "annotation": "Explicit JSON mode",
          "is_comment": true,
          "start_line": 95,
          "line_range": [
            95,
            95
          ],
          "target_line_range": [
            96,
            100
          ]
        },
        {
          "code": "client = instructor.from_cohere(\n    co,\n    mode=instructor.Mode.JSON\n)\n\n",
          "display_code": "client = instructor.from_cohere(\n    co,\n    mode=instructor.Mode.JSON\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 96,
          "line_range": [
            96,
            100
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "Use Instructor with Cohere's models for structured data extraction.",
          "command": "# Install required packages",
          "output": "$ pip install instructor cohere"
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "002-providers",
      "section_title": "LLM Providers"
    },
    {
      "id": "010-mistral",
      "title": "Mistral Integration",
      "description": "",
      "order": 10,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Use Instructor with Mistral AI models for structured data extraction.\n# \n# \n# \n# \n# \n# pip install instructor mistralai\n# \n",
          "display_code": "",
          "annotation": "Use Instructor with Mistral AI models for structured data extraction.\n\n\n\n\n\npip install instructor mistralai\n",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            10
          ],
          "target_line_range": [
            11,
            18
          ]
        },
        {
          "code": "import instructor\nfrom mistralai.client import MistralClient\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "import instructor\nfrom mistralai.client import MistralClient\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 11,
          "line_range": [
            11,
            18
          ]
        },
        {
          "code": "# Create Mistral client\n",
          "display_code": "",
          "annotation": "Create Mistral client",
          "is_comment": true,
          "start_line": 19,
          "line_range": [
            19,
            19
          ],
          "target_line_range": [
            20,
            21
          ]
        },
        {
          "code": "mistral_client = MistralClient(api_key=\"YOUR_API_KEY\")\n\n",
          "display_code": "mistral_client = MistralClient(api_key=\"YOUR_API_KEY\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 20,
          "line_range": [
            20,
            21
          ]
        },
        {
          "code": "# Patch with instructor\n",
          "display_code": "",
          "annotation": "Patch with instructor",
          "is_comment": true,
          "start_line": 22,
          "line_range": [
            22,
            22
          ],
          "target_line_range": [
            23,
            24
          ]
        },
        {
          "code": "client = instructor.from_mistral(mistral_client)\n\n",
          "display_code": "client = instructor.from_mistral(mistral_client)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 23,
          "line_range": [
            23,
            24
          ]
        },
        {
          "code": "# Using chat method\n",
          "display_code": "",
          "annotation": "Using chat method",
          "is_comment": true,
          "start_line": 25,
          "line_range": [
            25,
            25
          ],
          "target_line_range": [
            26,
            34
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"mistral-large-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nprint(f\"Name: {user.name}, Age: {user.age}\")\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"mistral-large-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nprint(f\"Name: {user.name}, Age: {user.age}\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 26,
          "line_range": [
            26,
            34
          ]
        },
        {
          "code": "# Output: Name: John, Age: 25\n",
          "display_code": "",
          "annotation": "Output: Name: John, Age: 25",
          "is_comment": true,
          "start_line": 35,
          "line_range": [
            35,
            35
          ],
          "target_line_range": [
            36,
            36
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 36,
          "line_range": [
            36,
            36
          ]
        },
        {
          "code": "# Mistral Small\n",
          "display_code": "",
          "annotation": "Mistral Small",
          "is_comment": true,
          "start_line": 37,
          "line_range": [
            37,
            37
          ],
          "target_line_range": [
            38,
            45
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"mistral-small-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"mistral-small-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 38,
          "line_range": [
            38,
            45
          ]
        },
        {
          "code": "# Mistral Medium\n",
          "display_code": "",
          "annotation": "Mistral Medium",
          "is_comment": true,
          "start_line": 46,
          "line_range": [
            46,
            46
          ],
          "target_line_range": [
            47,
            54
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"mistral-medium-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"mistral-medium-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 47,
          "line_range": [
            47,
            54
          ]
        },
        {
          "code": "# Mistral Large (most capable)\n",
          "display_code": "",
          "annotation": "Mistral Large (most capable)",
          "is_comment": true,
          "start_line": 55,
          "line_range": [
            55,
            55
          ],
          "target_line_range": [
            56,
            91
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"mistral-large-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"mistral-large-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are an expert at data extraction.\"},\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"mistral-large-latest\",\n    temperature=0.2,  # Lower for more consistent results\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"mistral-large-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hi, I'd like to discuss John who is 25 years old.\"},\n        {\"role\": \"assistant\", \"content\": \"Hello! I'd be happy to discuss John with you.\"},\n        {\"role\": \"user\", \"content\": \"Can you extract his information in a structured format?\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"mistral-large-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"mistral-large-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are an expert at data extraction.\"},\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"mistral-large-latest\",\n    temperature=0.2,  # Lower for more consistent results\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"mistral-large-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hi, I'd like to discuss John who is 25 years old.\"},\n        {\"role\": \"assistant\", \"content\": \"Hello! I'd be happy to discuss John with you.\"},\n        {\"role\": \"user\", \"content\": \"Can you extract his information in a structured format?\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 56,
          "line_range": [
            56,
            91
          ]
        },
        {
          "code": "# Default JSON mode\n",
          "display_code": "",
          "annotation": "Default JSON mode",
          "is_comment": true,
          "start_line": 92,
          "line_range": [
            92,
            92
          ],
          "target_line_range": [
            93,
            94
          ]
        },
        {
          "code": "client = instructor.from_mistral(mistral_client)\n\n",
          "display_code": "client = instructor.from_mistral(mistral_client)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 93,
          "line_range": [
            93,
            94
          ]
        },
        {
          "code": "# Explicit JSON mode\n",
          "display_code": "",
          "annotation": "Explicit JSON mode",
          "is_comment": true,
          "start_line": 95,
          "line_range": [
            95,
            95
          ],
          "target_line_range": [
            96,
            100
          ]
        },
        {
          "code": "client = instructor.from_mistral(\n    mistral_client,\n    mode=instructor.Mode.JSON\n)\n\n",
          "display_code": "client = instructor.from_mistral(\n    mistral_client,\n    mode=instructor.Mode.JSON\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 96,
          "line_range": [
            96,
            100
          ]
        },
        {
          "code": "# Using MD_JSON mode\n",
          "display_code": "",
          "annotation": "Using MD_JSON mode",
          "is_comment": true,
          "start_line": 101,
          "line_range": [
            101,
            101
          ],
          "target_line_range": [
            102,
            124
          ]
        },
        {
          "code": "client = instructor.from_mistral(\n    mistral_client,\n    mode=instructor.Mode.MD_JSON\n)\n\nimport asyncio\nfrom mistralai.async_client import MistralAsyncClient\n\nasync_client = instructor.from_mistral(\n    MistralAsyncClient(api_key=\"YOUR_API_KEY\")\n)\n\nasync def extract_user():\n    return await async_client.chat.completions.create(\n        model=\"mistral-large-latest\",\n        response_model=User,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n        ]\n    )\n\nuser = asyncio.run(extract_user())\n\n",
          "display_code": "client = instructor.from_mistral(\n    mistral_client,\n    mode=instructor.Mode.MD_JSON\n)\n\nimport asyncio\nfrom mistralai.async_client import MistralAsyncClient\n\nasync_client = instructor.from_mistral(\n    MistralAsyncClient(api_key=\"YOUR_API_KEY\")\n)\n\nasync def extract_user():\n    return await async_client.chat.completions.create(\n        model=\"mistral-large-latest\",\n        response_model=User,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n        ]\n    )\n\nuser = asyncio.run(extract_user())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 102,
          "line_range": [
            102,
            124
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "Use Instructor with Mistral AI models for structured data extraction.",
          "command": "# Install required packages",
          "output": "$ pip install instructor mistralai"
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "002-providers",
      "section_title": "LLM Providers"
    },
    {
      "id": "011-other-providers",
      "title": "Other Provider Integrations",
      "description": "",
      "order": 11,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Instructor supports many LLM providers beyond the major ones. Here's a quick overview of some additional providers.\n",
          "display_code": "",
          "annotation": "Instructor supports many LLM providers beyond the major ones. Here's a quick overview of some additional providers.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            11
          ]
        },
        {
          "code": "import instructor\nfrom litellm import completion\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "import instructor\nfrom litellm import completion\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            11
          ]
        },
        {
          "code": "# Patch LiteLLM completion function\n",
          "display_code": "",
          "annotation": "Patch LiteLLM completion function",
          "is_comment": true,
          "start_line": 12,
          "line_range": [
            12,
            12
          ],
          "target_line_range": [
            13,
            14
          ]
        },
        {
          "code": "client = instructor.from_litellm(completion)\n\n",
          "display_code": "client = instructor.from_litellm(completion)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 13,
          "line_range": [
            13,
            14
          ]
        },
        {
          "code": "# Use with any provider supported by LiteLLM\n",
          "display_code": "",
          "annotation": "Use with any provider supported by LiteLLM",
          "is_comment": true,
          "start_line": 15,
          "line_range": [
            15,
            15
          ],
          "target_line_range": [
            16,
            31
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",  # or any other provider/model combination\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\nimport instructor\nfrom pydantic import BaseModel\nfrom vertexai.preview.generative_models import GenerativeModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",  # or any other provider/model combination\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\nimport instructor\nfrom pydantic import BaseModel\nfrom vertexai.preview.generative_models import GenerativeModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 16,
          "line_range": [
            16,
            31
          ]
        },
        {
          "code": "# Create a model\n",
          "display_code": "",
          "annotation": "Create a model",
          "is_comment": true,
          "start_line": 32,
          "line_range": [
            32,
            32
          ],
          "target_line_range": [
            33,
            34
          ]
        },
        {
          "code": "model = GenerativeModel(\"gemini-1.5-flash\")\n\n",
          "display_code": "model = GenerativeModel(\"gemini-1.5-flash\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 33,
          "line_range": [
            33,
            34
          ]
        },
        {
          "code": "# Patch with instructor\n",
          "display_code": "",
          "annotation": "Patch with instructor",
          "is_comment": true,
          "start_line": 35,
          "line_range": [
            35,
            35
          ],
          "target_line_range": [
            36,
            37
          ]
        },
        {
          "code": "client = instructor.from_vertexai(model)\n\n",
          "display_code": "client = instructor.from_vertexai(model)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 36,
          "line_range": [
            36,
            37
          ]
        },
        {
          "code": "# Extract data\n",
          "display_code": "",
          "annotation": "Extract data",
          "is_comment": true,
          "start_line": 38,
          "line_range": [
            38,
            38
          ],
          "target_line_range": [
            39,
            51
          ]
        },
        {
          "code": "user = client.generate_content(\n    response_model=User,\n    contents=\"Extract the user info: John is 25 years old.\"\n)\n\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "user = client.generate_content(\n    response_model=User,\n    contents=\"Extract the user info: John is 25 years old.\"\n)\n\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 39,
          "line_range": [
            39,
            51
          ]
        },
        {
          "code": "# Create OpenAI client with Perplexity base URL\n",
          "display_code": "",
          "annotation": "Create OpenAI client with Perplexity base URL",
          "is_comment": true,
          "start_line": 52,
          "line_range": [
            52,
            52
          ],
          "target_line_range": [
            53,
            56
          ]
        },
        {
          "code": "client = instructor.from_perplexity(\n    OpenAI(base_url=\"https://api.perplexity.ai\", api_key=\"YOUR_API_KEY\")\n)\n\n",
          "display_code": "client = instructor.from_perplexity(\n    OpenAI(base_url=\"https://api.perplexity.ai\", api_key=\"YOUR_API_KEY\")\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 53,
          "line_range": [
            53,
            56
          ]
        },
        {
          "code": "# Extract data\n",
          "display_code": "",
          "annotation": "Extract data",
          "is_comment": true,
          "start_line": 57,
          "line_range": [
            57,
            57
          ],
          "target_line_range": [
            58,
            73
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"sonar\",  # or other Perplexity models\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"sonar\",  # or other Perplexity models\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 58,
          "line_range": [
            58,
            73
          ]
        },
        {
          "code": "# Create OpenAI client with Fireworks base URL\n",
          "display_code": "",
          "annotation": "Create OpenAI client with Fireworks base URL",
          "is_comment": true,
          "start_line": 74,
          "line_range": [
            74,
            74
          ],
          "target_line_range": [
            75,
            78
          ]
        },
        {
          "code": "client = instructor.from_fireworks(\n    OpenAI(base_url=\"https://api.fireworks.ai/inference/v1\", api_key=\"YOUR_API_KEY\")\n)\n\n",
          "display_code": "client = instructor.from_fireworks(\n    OpenAI(base_url=\"https://api.fireworks.ai/inference/v1\", api_key=\"YOUR_API_KEY\")\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 75,
          "line_range": [
            75,
            78
          ]
        },
        {
          "code": "# Extract data\n",
          "display_code": "",
          "annotation": "Extract data",
          "is_comment": true,
          "start_line": 79,
          "line_range": [
            79,
            79
          ],
          "target_line_range": [
            80,
            95
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"accounts/fireworks/models/mixtral-8x7b-instruct\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"accounts/fireworks/models/mixtral-8x7b-instruct\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 80,
          "line_range": [
            80,
            95
          ]
        },
        {
          "code": "# Create OpenAI client with Anyscale base URL\n",
          "display_code": "",
          "annotation": "Create OpenAI client with Anyscale base URL",
          "is_comment": true,
          "start_line": 96,
          "line_range": [
            96,
            96
          ],
          "target_line_range": [
            97,
            100
          ]
        },
        {
          "code": "client = instructor.from_anyscale(\n    OpenAI(base_url=\"https://api.endpoints.anyscale.com/v1\", api_key=\"YOUR_API_KEY\")\n)\n\n",
          "display_code": "client = instructor.from_anyscale(\n    OpenAI(base_url=\"https://api.endpoints.anyscale.com/v1\", api_key=\"YOUR_API_KEY\")\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 97,
          "line_range": [
            97,
            100
          ]
        },
        {
          "code": "# Extract data\n",
          "display_code": "",
          "annotation": "Extract data",
          "is_comment": true,
          "start_line": 101,
          "line_range": [
            101,
            101
          ],
          "target_line_range": [
            102,
            117
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"meta-llama/Llama-3-8b-instruct\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"meta-llama/Llama-3-8b-instruct\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 102,
          "line_range": [
            102,
            117
          ]
        },
        {
          "code": "# Create OpenAI client with Together base URL\n",
          "display_code": "",
          "annotation": "Create OpenAI client with Together base URL",
          "is_comment": true,
          "start_line": 118,
          "line_range": [
            118,
            118
          ],
          "target_line_range": [
            119,
            122
          ]
        },
        {
          "code": "client = instructor.from_together(\n    OpenAI(base_url=\"https://api.together.xyz/v1\", api_key=\"YOUR_API_KEY\")\n)\n\n",
          "display_code": "client = instructor.from_together(\n    OpenAI(base_url=\"https://api.together.xyz/v1\", api_key=\"YOUR_API_KEY\")\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 119,
          "line_range": [
            119,
            122
          ]
        },
        {
          "code": "# Extract data\n",
          "display_code": "",
          "annotation": "Extract data",
          "is_comment": true,
          "start_line": 123,
          "line_range": [
            123,
            123
          ],
          "target_line_range": [
            124,
            139
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"togethercomputer/llama-3-8b-instructk\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"togethercomputer/llama-3-8b-instructk\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 124,
          "line_range": [
            124,
            139
          ]
        },
        {
          "code": "# Create OpenAI client with OpenRouter base URL\n",
          "display_code": "",
          "annotation": "Create OpenAI client with OpenRouter base URL",
          "is_comment": true,
          "start_line": 140,
          "line_range": [
            140,
            140
          ],
          "target_line_range": [
            141,
            144
          ]
        },
        {
          "code": "client = instructor.from_openrouter(\n    OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=\"YOUR_API_KEY\")\n)\n\n",
          "display_code": "client = instructor.from_openrouter(\n    OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=\"YOUR_API_KEY\")\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 141,
          "line_range": [
            141,
            144
          ]
        },
        {
          "code": "# Extract data - access to many models\n",
          "display_code": "",
          "annotation": "Extract data - access to many models",
          "is_comment": true,
          "start_line": 145,
          "line_range": [
            145,
            145
          ],
          "target_line_range": [
            146,
            153
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"google/gemma-7b-instruct\", # Or any other model on OpenRouter\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"google/gemma-7b-instruct\", # Or any other model on OpenRouter\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 146,
          "line_range": [
            146,
            153
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python other-providers.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "002-providers",
      "section_title": "LLM Providers"
    },
    {
      "id": "012-simple-object",
      "title": "Simple Object Extraction",
      "description": "",
      "order": 12,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Extract basic objects from text with Instructor.\n",
          "display_code": "",
          "annotation": "Extract basic objects from text with Instructor.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            13
          ]
        },
        {
          "code": "from pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\nimport instructor\nfrom openai import OpenAI\n\n",
          "display_code": "from pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\nimport instructor\nfrom openai import OpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            13
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            16
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            16
          ]
        },
        {
          "code": "# Extract the data\n",
          "display_code": "",
          "annotation": "Extract the data",
          "is_comment": true,
          "start_line": 17,
          "line_range": [
            17,
            17
          ],
          "target_line_range": [
            18,
            29
          ]
        },
        {
          "code": "person = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John Doe is a 30-year-old software engineer.\"}\n    ]\n)\n\nprint(f\"Name: {person.name}\")\nprint(f\"Age: {person.age}\")\nprint(f\"Occupation: {person.occupation}\")\n\n",
          "display_code": "person = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John Doe is a 30-year-old software engineer.\"}\n    ]\n)\n\nprint(f\"Name: {person.name}\")\nprint(f\"Age: {person.age}\")\nprint(f\"Occupation: {person.occupation}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 18,
          "line_range": [
            18,
            29
          ]
        },
        {
          "code": "# Output:\n# Name: John Doe\n# Age: 30\n# Occupation: software engineer\n",
          "display_code": "",
          "annotation": "Output:\nName: John Doe\nAge: 30\nOccupation: software engineer",
          "is_comment": true,
          "start_line": 30,
          "line_range": [
            30,
            33
          ],
          "target_line_range": [
            34,
            50
          ]
        },
        {
          "code": "\nextracted = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        In our company blog post, we want to highlight one of our newest team members.\n        John Smith joined us last month. He's 34 years old and works as a data scientist.\n        John previously worked at TechCorp for 5 years.\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {extracted.name}\")\nprint(f\"Age: {extracted.age}\")\nprint(f\"Occupation: {extracted.occupation}\")\n\n",
          "display_code": "\nextracted = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        In our company blog post, we want to highlight one of our newest team members.\n        John Smith joined us last month. He's 34 years old and works as a data scientist.\n        John previously worked at TechCorp for 5 years.\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {extracted.name}\")\nprint(f\"Age: {extracted.age}\")\nprint(f\"Occupation: {extracted.occupation}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 34,
          "line_range": [
            34,
            50
          ]
        },
        {
          "code": "# Output:\n# Name: John Smith\n# Age: 34\n# Occupation: data scientist\n",
          "display_code": "",
          "annotation": "Output:\nName: John Smith\nAge: 34\nOccupation: data scientist",
          "is_comment": true,
          "start_line": 51,
          "line_range": [
            51,
            54
          ],
          "target_line_range": [
            55,
            78
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field\n\nclass Person(BaseModel):\n    name: str = Field(description=\"The person's full name\")\n    age: int = Field(description=\"The person's age in years\")\n    occupation: str = Field(description=\"The person's current job title or role\")\n\nextracted = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Meet Sarah Johnson, one of our senior architects.\n        She's been with the firm since she was 28, and now at 42,\n        she leads our sustainable design initiatives.\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {extracted.name}\")\nprint(f\"Age: {extracted.age}\")\nprint(f\"Occupation: {extracted.occupation}\")\n\n",
          "display_code": "\nfrom pydantic import BaseModel, Field\n\nclass Person(BaseModel):\n    name: str = Field(description=\"The person's full name\")\n    age: int = Field(description=\"The person's age in years\")\n    occupation: str = Field(description=\"The person's current job title or role\")\n\nextracted = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Meet Sarah Johnson, one of our senior architects.\n        She's been with the firm since she was 28, and now at 42,\n        she leads our sustainable design initiatives.\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {extracted.name}\")\nprint(f\"Age: {extracted.age}\")\nprint(f\"Occupation: {extracted.occupation}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 55,
          "line_range": [
            55,
            78
          ]
        },
        {
          "code": "# Output:\n# Name: Sarah Johnson\n# Age: 42\n# Occupation: senior architect\n",
          "display_code": "",
          "annotation": "Output:\nName: Sarah Johnson\nAge: 42\nOccupation: senior architect",
          "is_comment": true,
          "start_line": 79,
          "line_range": [
            79,
            82
          ],
          "target_line_range": [
            83,
            106
          ]
        },
        {
          "code": "\nclass Employee(BaseModel):\n    \"\"\"Extract employee information from the provided text.\"\"\"\n\n    name: str\n    age: int\n    department: str\n    years_of_service: int\n\nextracted = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Employee,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Employee Profile: Michael Chen has been in our Marketing department for 7 years.\n        He's 36 years old and has led multiple successful campaigns.\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {extracted.name}\")\nprint(f\"Department: {extracted.department}\")\nprint(f\"Years of Service: {extracted.years_of_service}\")\n\n",
          "display_code": "\nclass Employee(BaseModel):\n    \"\"\"Extract employee information from the provided text.\"\"\"\n\n    name: str\n    age: int\n    department: str\n    years_of_service: int\n\nextracted = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Employee,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Employee Profile: Michael Chen has been in our Marketing department for 7 years.\n        He's 36 years old and has led multiple successful campaigns.\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {extracted.name}\")\nprint(f\"Department: {extracted.department}\")\nprint(f\"Years of Service: {extracted.years_of_service}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 83,
          "line_range": [
            83,
            106
          ]
        },
        {
          "code": "# Output:\n# Name: Michael Chen\n# Department: Marketing\n# Years of Service: 7\n",
          "display_code": "",
          "annotation": "Output:\nName: Michael Chen\nDepartment: Marketing\nYears of Service: 7",
          "is_comment": true,
          "start_line": 107,
          "line_range": [
            107,
            110
          ],
          "target_line_range": [
            111,
            111
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 111,
          "line_range": [
            111,
            111
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python simple-object.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "003-basic-extraction",
      "section_title": "Basic Extraction Patterns"
    },
    {
      "id": "013-list-extraction",
      "title": "List Extraction",
      "description": "",
      "order": 13,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Extract multiple items in a list from text with Instructor.\n",
          "display_code": "",
          "annotation": "Extract multiple items in a list from text with Instructor.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            13
          ]
        },
        {
          "code": "from pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n\nimport instructor\nfrom openai import OpenAI\nfrom typing import List\n\n",
          "display_code": "from pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n\nimport instructor\nfrom openai import OpenAI\nfrom typing import List\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            13
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            16
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            16
          ]
        },
        {
          "code": "# Extract a list of people\n",
          "display_code": "",
          "annotation": "Extract a list of people",
          "is_comment": true,
          "start_line": 17,
          "line_range": [
            17,
            17
          ],
          "target_line_range": [
            18,
            30
          ]
        },
        {
          "code": "people = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=List[Person],  # Note the List wrapper\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Extract all people mentioned in this text:\n        - John is 30 years old\n        - Mary is 25 years old\n        - Bob is 45 years old\n        \"\"\"}\n    ]\n)\n\n",
          "display_code": "people = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=List[Person],  # Note the List wrapper\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Extract all people mentioned in this text:\n        - John is 30 years old\n        - Mary is 25 years old\n        - Bob is 45 years old\n        \"\"\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 18,
          "line_range": [
            18,
            30
          ]
        },
        {
          "code": "# Print each person\n",
          "display_code": "",
          "annotation": "Print each person",
          "is_comment": true,
          "start_line": 31,
          "line_range": [
            31,
            31
          ],
          "target_line_range": [
            32,
            34
          ]
        },
        {
          "code": "for person in people:\n    print(f\"{person.name} is {person.age} years old\")\n\n",
          "display_code": "for person in people:\n    print(f\"{person.name} is {person.age} years old\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 32,
          "line_range": [
            32,
            34
          ]
        },
        {
          "code": "# Output:\n# John is 30 years old\n# Mary is 25 years old\n# Bob is 45 years old\n",
          "display_code": "",
          "annotation": "Output:\nJohn is 30 years old\nMary is 25 years old\nBob is 45 years old",
          "is_comment": true,
          "start_line": 35,
          "line_range": [
            35,
            38
          ],
          "target_line_range": [
            39,
            54
          ]
        },
        {
          "code": "\npeople = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=List[Person],\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Our team has grown significantly this year. John Smith, who is 32, joined our\n        engineering department. We also welcomed Sarah Johnson, 28, to our design team.\n        The most recent addition is Michael Chen, who is 35 and brings valuable experience.\n        \"\"\"}\n    ]\n)\n\nfor i, person in enumerate(people, 1):\n    print(f\"Person {i}: {person.name}, {person.age}\")\n\n",
          "display_code": "\npeople = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=List[Person],\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Our team has grown significantly this year. John Smith, who is 32, joined our\n        engineering department. We also welcomed Sarah Johnson, 28, to our design team.\n        The most recent addition is Michael Chen, who is 35 and brings valuable experience.\n        \"\"\"}\n    ]\n)\n\nfor i, person in enumerate(people, 1):\n    print(f\"Person {i}: {person.name}, {person.age}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 39,
          "line_range": [
            39,
            54
          ]
        },
        {
          "code": "# Output:\n# Person 1: John Smith, 32\n# Person 2: Sarah Johnson, 28\n# Person 3: Michael Chen, 35\n",
          "display_code": "",
          "annotation": "Output:\nPerson 1: John Smith, 32\nPerson 2: Sarah Johnson, 28\nPerson 3: Michael Chen, 35",
          "is_comment": true,
          "start_line": 55,
          "line_range": [
            55,
            58
          ],
          "target_line_range": [
            59,
            108
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    state: Optional[str] = None\n    country: str\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str = Field(description=\"The person's job or profession\")\n    addresses: List[Address] = Field(description=\"List of addresses associated with this person\")\n\npeople = client.chat.completions.create(\n    model=\"gpt-4\",  # More complex extraction works better with more capable models\n    response_model=List[Person],\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Our company employees include:\n\n        1. John Smith is a 34-year-old software developer who lives at 123 Main St, Boston, USA\n           and has a vacation home at 456 Beach Road, Miami, USA.\n\n        2. Maria Garcia is 29 and works as a marketing specialist. She lives at\n           78 Park Avenue, New York, USA.\n\n        3. Ahmed Hassan, 41, is our senior data scientist who recently moved from\n           555 River St, Cairo, Egypt to 890 Tech Blvd, San Francisco, USA.\n        \"\"\"}\n    ]\n)\n\nfor person in people:\n    print(f\"{person.name}, {person.age} - {person.occupation}\")\n    for i, addr in enumerate(person.addresses, 1):\n        print(f\"  Address {i}: {addr.street}, {addr.city}, {addr.country}\")\n    print()\n\nimport instructor\nfrom openai import OpenAI\nfrom typing import List\nfrom pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    state: Optional[str] = None\n    country: str\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str = Field(description=\"The person's job or profession\")\n    addresses: List[Address] = Field(description=\"List of addresses associated with this person\")\n\npeople = client.chat.completions.create(\n    model=\"gpt-4\",  # More complex extraction works better with more capable models\n    response_model=List[Person],\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Our company employees include:\n\n        1. John Smith is a 34-year-old software developer who lives at 123 Main St, Boston, USA\n           and has a vacation home at 456 Beach Road, Miami, USA.\n\n        2. Maria Garcia is 29 and works as a marketing specialist. She lives at\n           78 Park Avenue, New York, USA.\n\n        3. Ahmed Hassan, 41, is our senior data scientist who recently moved from\n           555 River St, Cairo, Egypt to 890 Tech Blvd, San Francisco, USA.\n        \"\"\"}\n    ]\n)\n\nfor person in people:\n    print(f\"{person.name}, {person.age} - {person.occupation}\")\n    for i, addr in enumerate(person.addresses, 1):\n        print(f\"  Address {i}: {addr.street}, {addr.city}, {addr.country}\")\n    print()\n\nimport instructor\nfrom openai import OpenAI\nfrom typing import List\nfrom pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 59,
          "line_range": [
            59,
            108
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 109,
          "line_range": [
            109,
            109
          ],
          "target_line_range": [
            110,
            111
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 110,
          "line_range": [
            110,
            111
          ]
        },
        {
          "code": "# Extract with streaming using create_iterable\n",
          "display_code": "",
          "annotation": "Extract with streaming using create_iterable",
          "is_comment": true,
          "start_line": 112,
          "line_range": [
            112,
            112
          ],
          "target_line_range": [
            113,
            125
          ]
        },
        {
          "code": "people_stream = client.chat.completions.create_iterable(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,  # Note: no List wrapper here\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Extract all people mentioned in this text:\n        - John is 30 years old\n        - Mary is 25 years old\n        - Bob is 45 years old\n        \"\"\"}\n    ]\n)\n\n",
          "display_code": "people_stream = client.chat.completions.create_iterable(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,  # Note: no List wrapper here\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Extract all people mentioned in this text:\n        - John is 30 years old\n        - Mary is 25 years old\n        - Bob is 45 years old\n        \"\"\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 113,
          "line_range": [
            113,
            125
          ]
        },
        {
          "code": "# Process each item as it's completed\n",
          "display_code": "",
          "annotation": "Process each item as it's completed",
          "is_comment": true,
          "start_line": 126,
          "line_range": [
            126,
            126
          ],
          "target_line_range": [
            127,
            129
          ]
        },
        {
          "code": "for person in people_stream:\n    print(f\"Received: {person.name} is {person.age} years old\")\n\n",
          "display_code": "for person in people_stream:\n    print(f\"Received: {person.name} is {person.age} years old\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 127,
          "line_range": [
            127,
            129
          ]
        },
        {
          "code": "# Output will appear one at a time as each is completed:\n# Received: John is 30 years old\n# Received: Mary is 25 years old\n# Received: Bob is 45 years old\n",
          "display_code": "",
          "annotation": "Output will appear one at a time as each is completed:\nReceived: John is 30 years old\nReceived: Mary is 25 years old\nReceived: Bob is 45 years old",
          "is_comment": true,
          "start_line": 130,
          "line_range": [
            130,
            133
          ],
          "target_line_range": [
            134,
            134
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 134,
          "line_range": [
            134,
            134
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python list-extraction.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "003-basic-extraction",
      "section_title": "Basic Extraction Patterns"
    },
    {
      "id": "014-nested-structures",
      "title": "Nested Structures",
      "description": "",
      "order": 14,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Extract complex nested data structures from text using Instructor.\n",
          "display_code": "",
          "annotation": "Extract complex nested data structures from text using Instructor.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            27
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    state: Optional[str] = None\n    zip_code: Optional[str] = None\n    country: str\n\nclass PhoneNumber(BaseModel):\n    number: str\n    type: str  # e.g., \"home\", \"work\", \"mobile\"\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    addresses: List[Address]\n    phone_numbers: List[PhoneNumber]\n    email: Optional[str] = None\n\nimport instructor\nfrom openai import OpenAI\n\n",
          "display_code": "from pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    state: Optional[str] = None\n    zip_code: Optional[str] = None\n    country: str\n\nclass PhoneNumber(BaseModel):\n    number: str\n    type: str  # e.g., \"home\", \"work\", \"mobile\"\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    addresses: List[Address]\n    phone_numbers: List[PhoneNumber]\n    email: Optional[str] = None\n\nimport instructor\nfrom openai import OpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            27
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 28,
          "line_range": [
            28,
            28
          ],
          "target_line_range": [
            29,
            30
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 29,
          "line_range": [
            29,
            30
          ]
        },
        {
          "code": "# Extract nested data\n",
          "display_code": "",
          "annotation": "Extract nested data",
          "is_comment": true,
          "start_line": 31,
          "line_range": [
            31,
            31
          ],
          "target_line_range": [
            32,
            89
          ]
        },
        {
          "code": "person = client.chat.completions.create(\n    model=\"gpt-4\",  # Complex extraction works better with more capable models\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        John Smith is a 35-year-old professional. He has two addresses:\n        1. Home: 123 Main St, Austin, TX 78701, USA\n        2. Work: 456 Business Ave, Austin, TX 78702, USA\n\n        His phone numbers are:\n        - Mobile: (555) 123-4567\n        - Work: (555) 987-6543\n\n        You can reach him at john.smith@example.com\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {person.name}, Age: {person.age}\")\nprint(f\"Email: {person.email}\")\n\nprint(\"\\nAddresses:\")\nfor i, address in enumerate(person.addresses, 1):\n    print(f\"  {i}. {address.street}, {address.city}, {address.state} {address.zip_code}, {address.country}\")\n\nprint(\"\\nPhone Numbers:\")\nfor phone in person.phone_numbers:\n    print(f\"  {phone.type}: {phone.number}\")\n\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional, Dict\n\nclass Skill(BaseModel):\n    name: str\n    level: str  # e.g., \"beginner\", \"intermediate\", \"expert\"\n    years_of_experience: int\n\nclass Education(BaseModel):\n    degree: str\n    institution: str\n    year: int\n\nclass WorkExperience(BaseModel):\n    company: str\n    position: str\n    start_year: int\n    end_year: Optional[int] = None\n    is_current: bool\n    responsibilities: List[str]\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    skills: List[Skill]\n    education: List[Education]\n    work_experience: List[WorkExperience]\n    contact_info: Dict[str, str]  # e.g., \"email\", \"phone\", \"linkedin\"\n\n",
          "display_code": "person = client.chat.completions.create(\n    model=\"gpt-4\",  # Complex extraction works better with more capable models\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        John Smith is a 35-year-old professional. He has two addresses:\n        1. Home: 123 Main St, Austin, TX 78701, USA\n        2. Work: 456 Business Ave, Austin, TX 78702, USA\n\n        His phone numbers are:\n        - Mobile: (555) 123-4567\n        - Work: (555) 987-6543\n\n        You can reach him at john.smith@example.com\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {person.name}, Age: {person.age}\")\nprint(f\"Email: {person.email}\")\n\nprint(\"\\nAddresses:\")\nfor i, address in enumerate(person.addresses, 1):\n    print(f\"  {i}. {address.street}, {address.city}, {address.state} {address.zip_code}, {address.country}\")\n\nprint(\"\\nPhone Numbers:\")\nfor phone in person.phone_numbers:\n    print(f\"  {phone.type}: {phone.number}\")\n\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional, Dict\n\nclass Skill(BaseModel):\n    name: str\n    level: str  # e.g., \"beginner\", \"intermediate\", \"expert\"\n    years_of_experience: int\n\nclass Education(BaseModel):\n    degree: str\n    institution: str\n    year: int\n\nclass WorkExperience(BaseModel):\n    company: str\n    position: str\n    start_year: int\n    end_year: Optional[int] = None\n    is_current: bool\n    responsibilities: List[str]\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    skills: List[Skill]\n    education: List[Education]\n    work_experience: List[WorkExperience]\n    contact_info: Dict[str, str]  # e.g., \"email\", \"phone\", \"linkedin\"\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 32,
          "line_range": [
            32,
            89
          ]
        },
        {
          "code": "# Extract with a more capable model\n",
          "display_code": "",
          "annotation": "Extract with a more capable model",
          "is_comment": true,
          "start_line": 90,
          "line_range": [
            90,
            90
          ],
          "target_line_range": [
            91,
            163
          ]
        },
        {
          "code": "person = client.chat.completions.create(\n    model=\"gpt-4\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Resume: Sarah Johnson\n\n        Sarah is a 42-year-old software architect with 15 years in the industry.\n\n        Contact Information:\n        - Email: sarah.j@example.com\n        - Phone: (555) 234-5678\n        - LinkedIn: linkedin.com/in/sarahjohnson\n\n        Skills:\n        - Python (Expert, 12 years)\n        - JavaScript (Intermediate, 8 years)\n        - Cloud Architecture (Expert, 7 years)\n\n        Education:\n        - Master's in Computer Science, Stanford University, 2008\n        - Bachelor's in Software Engineering, MIT, 2006\n\n        Work Experience:\n        - TechCorp Inc.\n          Senior Software Architect\n          2018-Present\n          Responsibilities:\n          * Lead architecture design for cloud solutions\n          * Manage team of 12 developers\n          * Implement CI/CD pipelines\n\n        - DataSystems LLC\n          Software Developer\n          2012-2018\n          Responsibilities:\n          * Developed backend services in Python\n          * Optimized database performance\n          * Created RESTful APIs\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {person.name}, Age: {person.age}\")\n\nprint(\"\\nContact Info:\")\nfor key, value in person.contact_info.items():\n    print(f\"  {key}: {value}\")\n\nprint(\"\\nSkills:\")\nfor skill in person.skills:\n    print(f\"  {skill.name}: {skill.level} ({skill.years_of_experience} years)\")\n\nprint(\"\\nEducation:\")\nfor edu in person.education:\n    print(f\"  {edu.degree}, {edu.institution}, {edu.year}\")\n\nprint(\"\\nWork Experience:\")\nfor job in person.work_experience:\n    current = \"(Current)\" if job.is_current else f\"({job.start_year}-{job.end_year})\"\n    print(f\"  {job.position} at {job.company} {current}\")\n    print(\"  Responsibilities:\")\n    for resp in job.responsibilities:\n        print(f\"    - {resp}\")\n\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass Comment(BaseModel):\n    text: str\n    author: str\n    replies: List['Comment'] = []\n\n",
          "display_code": "person = client.chat.completions.create(\n    model=\"gpt-4\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Resume: Sarah Johnson\n\n        Sarah is a 42-year-old software architect with 15 years in the industry.\n\n        Contact Information:\n        - Email: sarah.j@example.com\n        - Phone: (555) 234-5678\n        - LinkedIn: linkedin.com/in/sarahjohnson\n\n        Skills:\n        - Python (Expert, 12 years)\n        - JavaScript (Intermediate, 8 years)\n        - Cloud Architecture (Expert, 7 years)\n\n        Education:\n        - Master's in Computer Science, Stanford University, 2008\n        - Bachelor's in Software Engineering, MIT, 2006\n\n        Work Experience:\n        - TechCorp Inc.\n          Senior Software Architect\n          2018-Present\n          Responsibilities:\n          * Lead architecture design for cloud solutions\n          * Manage team of 12 developers\n          * Implement CI/CD pipelines\n\n        - DataSystems LLC\n          Software Developer\n          2012-2018\n          Responsibilities:\n          * Developed backend services in Python\n          * Optimized database performance\n          * Created RESTful APIs\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {person.name}, Age: {person.age}\")\n\nprint(\"\\nContact Info:\")\nfor key, value in person.contact_info.items():\n    print(f\"  {key}: {value}\")\n\nprint(\"\\nSkills:\")\nfor skill in person.skills:\n    print(f\"  {skill.name}: {skill.level} ({skill.years_of_experience} years)\")\n\nprint(\"\\nEducation:\")\nfor edu in person.education:\n    print(f\"  {edu.degree}, {edu.institution}, {edu.year}\")\n\nprint(\"\\nWork Experience:\")\nfor job in person.work_experience:\n    current = \"(Current)\" if job.is_current else f\"({job.start_year}-{job.end_year})\"\n    print(f\"  {job.position} at {job.company} {current}\")\n    print(\"  Responsibilities:\")\n    for resp in job.responsibilities:\n        print(f\"    - {resp}\")\n\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass Comment(BaseModel):\n    text: str\n    author: str\n    replies: List['Comment'] = []\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 91,
          "line_range": [
            91,
            163
          ]
        },
        {
          "code": "# This is needed for recursive Pydantic models\n",
          "display_code": "",
          "annotation": "This is needed for recursive Pydantic models",
          "is_comment": true,
          "start_line": 164,
          "line_range": [
            164,
            164
          ],
          "target_line_range": [
            165,
            172
          ]
        },
        {
          "code": "Comment.model_rebuild()\n\nclass Post(BaseModel):\n    title: str\n    content: str\n    author: str\n    comments: List[Comment]\n\n",
          "display_code": "Comment.model_rebuild()\n\nclass Post(BaseModel):\n    title: str\n    content: str\n    author: str\n    comments: List[Comment]\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 165,
          "line_range": [
            165,
            172
          ]
        },
        {
          "code": "# Extract recursive structure\n",
          "display_code": "",
          "annotation": "Extract recursive structure",
          "is_comment": true,
          "start_line": 173,
          "line_range": [
            173,
            173
          ],
          "target_line_range": [
            174,
            208
          ]
        },
        {
          "code": "post = client.chat.completions.create(\n    model=\"gpt-4\",\n    response_model=Post,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Blog Post: \"Python Tips and Tricks\"\n        By: JohnDev\n\n        Python has many features that make it a versatile language. Here are some tips to improve your code...\n\n        Comments:\n        1. Comment by Alice: \"Great post! I especially liked the section on list comprehensions.\"\n          - Reply by JohnDev: \"Thanks Alice! Glad you found it useful.\"\n            - Reply by Bob: \"List comprehensions are my favorite too!\"\n               - Reply by Alice: \"They're so elegant compared to traditional loops.\"\n\n        2. Comment by Charlie: \"Could you do a follow-up on decorators?\"\n          - Reply by JohnDev: \"Great idea! I'll add it to my list of topics.\"\n        \"\"\"}\n    ]\n)\n\nprint(f\"Post: {post.title} by {post.author}\")\n\nfor i, comment in enumerate(post.comments, 1):\n    print(f\"\\nTop-level Comment {i}: {comment.author} said: '{comment.text}'\")\n\n    def print_replies(replies, indent=2):\n        for reply in replies:\n            print(f\"{'  ' * indent}{reply.author} replied: '{reply.text}'\")\n            if reply.replies:\n                print_replies(reply.replies, indent + 1)\n\n    print_replies(comment.replies)\n\n",
          "display_code": "post = client.chat.completions.create(\n    model=\"gpt-4\",\n    response_model=Post,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Blog Post: \"Python Tips and Tricks\"\n        By: JohnDev\n\n        Python has many features that make it a versatile language. Here are some tips to improve your code...\n\n        Comments:\n        1. Comment by Alice: \"Great post! I especially liked the section on list comprehensions.\"\n          - Reply by JohnDev: \"Thanks Alice! Glad you found it useful.\"\n            - Reply by Bob: \"List comprehensions are my favorite too!\"\n               - Reply by Alice: \"They're so elegant compared to traditional loops.\"\n\n        2. Comment by Charlie: \"Could you do a follow-up on decorators?\"\n          - Reply by JohnDev: \"Great idea! I'll add it to my list of topics.\"\n        \"\"\"}\n    ]\n)\n\nprint(f\"Post: {post.title} by {post.author}\")\n\nfor i, comment in enumerate(post.comments, 1):\n    print(f\"\\nTop-level Comment {i}: {comment.author} said: '{comment.text}'\")\n\n    def print_replies(replies, indent=2):\n        for reply in replies:\n            print(f\"{'  ' * indent}{reply.author} replied: '{reply.text}'\")\n            if reply.replies:\n                print_replies(reply.replies, indent + 1)\n\n    print_replies(comment.replies)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 174,
          "line_range": [
            174,
            208
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python nested-structures.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "003-basic-extraction",
      "section_title": "Basic Extraction Patterns"
    },
    {
      "id": "015-field-validation",
      "title": "Field Validation",
      "description": "",
      "order": 15,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Apply validation rules to ensure high-quality data extraction with Instructor.\n",
          "display_code": "",
          "annotation": "Apply validation rules to ensure high-quality data extraction with Instructor.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            7
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\n\n",
          "display_code": "from pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            7
          ]
        },
        {
          "code": "# Define a model with validation rules\n",
          "display_code": "",
          "annotation": "Define a model with validation rules",
          "is_comment": true,
          "start_line": 8,
          "line_range": [
            8,
            8
          ],
          "target_line_range": [
            9,
            14
          ]
        },
        {
          "code": "class Product(BaseModel):\n    name: str = Field(min_length=3, max_length=50)\n    price: float = Field(gt=0)  # must be greater than 0\n    quantity: int = Field(ge=0)  # must be greater than or equal to 0\n    category: str\n\n",
          "display_code": "class Product(BaseModel):\n    name: str = Field(min_length=3, max_length=50)\n    price: float = Field(gt=0)  # must be greater than 0\n    quantity: int = Field(ge=0)  # must be greater than or equal to 0\n    category: str\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 9,
          "line_range": [
            9,
            14
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 15,
          "line_range": [
            15,
            15
          ],
          "target_line_range": [
            16,
            17
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 16,
          "line_range": [
            16,
            17
          ]
        },
        {
          "code": "# Extract with validation\n",
          "display_code": "",
          "annotation": "Extract with validation",
          "is_comment": true,
          "start_line": 18,
          "line_range": [
            18,
            18
          ],
          "target_line_range": [
            19,
            40
          ]
        },
        {
          "code": "product = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Product,\n    messages=[\n        {\"role\": \"user\", \"content\": \"We sell a premium coffee mug for $12.99 and have 25 in stock in our kitchen category.\"}\n    ]\n)\n\nprint(f\"Name: {product.name}\")\nprint(f\"Price: ${product.price}\")\nprint(f\"Quantity: {product.quantity}\")\nprint(f\"Category: {product.category}\")\n\nfrom pydantic import BaseModel, Field\n\nclass PersonStats(BaseModel):\n    name: str\n    age: int = Field(ge=0, lt=120)  # 0 \u2264 age < 120\n    height: float = Field(gt=0, le=300)  # 0 < height \u2264 300 (cm)\n    weight: float = Field(gt=0, le=500)  # 0 < weight \u2264 500 (kg)\n    body_temperature: float = Field(ge=35, le=42)  # normal human range in Celsius\n\n",
          "display_code": "product = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Product,\n    messages=[\n        {\"role\": \"user\", \"content\": \"We sell a premium coffee mug for $12.99 and have 25 in stock in our kitchen category.\"}\n    ]\n)\n\nprint(f\"Name: {product.name}\")\nprint(f\"Price: ${product.price}\")\nprint(f\"Quantity: {product.quantity}\")\nprint(f\"Category: {product.category}\")\n\nfrom pydantic import BaseModel, Field\n\nclass PersonStats(BaseModel):\n    name: str\n    age: int = Field(ge=0, lt=120)  # 0 \u2264 age < 120\n    height: float = Field(gt=0, le=300)  # 0 < height \u2264 300 (cm)\n    weight: float = Field(gt=0, le=500)  # 0 < weight \u2264 500 (kg)\n    body_temperature: float = Field(ge=35, le=42)  # normal human range in Celsius\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 19,
          "line_range": [
            19,
            40
          ]
        },
        {
          "code": "# Extract with validation\n",
          "display_code": "",
          "annotation": "Extract with validation",
          "is_comment": true,
          "start_line": 41,
          "line_range": [
            41,
            41
          ],
          "target_line_range": [
            42,
            70
          ]
        },
        {
          "code": "person = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=PersonStats,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Patient: John Smith\n        Age: 35 years old\n        Height: 180 cm\n        Weight: 75 kg\n        Temperature: 37.2\u00b0C\n        \"\"\"}\n    ]\n)\n\nprint(f\"Patient: {person.name}\")\nprint(f\"Age: {person.age}\")\nprint(f\"Height: {person.height} cm\")\nprint(f\"Weight: {person.weight} kg\")\nprint(f\"Body Temperature: {person.body_temperature}\u00b0C\")\n\nfrom pydantic import BaseModel, Field, field_validator\nimport re\n\nclass ContactInfo(BaseModel):\n    name: str\n    email: str = Field(pattern=r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$')\n    phone: str = Field(pattern=r'^\\+?[1-9]\\d{1,14}$')  # E.164 phone format\n    website: str = Field(pattern=r'^https?://(?:www\\.)?[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}(?:/[^\\s]*)?$')\n\n",
          "display_code": "person = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=PersonStats,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Patient: John Smith\n        Age: 35 years old\n        Height: 180 cm\n        Weight: 75 kg\n        Temperature: 37.2\u00b0C\n        \"\"\"}\n    ]\n)\n\nprint(f\"Patient: {person.name}\")\nprint(f\"Age: {person.age}\")\nprint(f\"Height: {person.height} cm\")\nprint(f\"Weight: {person.weight} kg\")\nprint(f\"Body Temperature: {person.body_temperature}\u00b0C\")\n\nfrom pydantic import BaseModel, Field, field_validator\nimport re\n\nclass ContactInfo(BaseModel):\n    name: str\n    email: str = Field(pattern=r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$')\n    phone: str = Field(pattern=r'^\\+?[1-9]\\d{1,14}$')  # E.164 phone format\n    website: str = Field(pattern=r'^https?://(?:www\\.)?[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}(?:/[^\\s]*)?$')\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 42,
          "line_range": [
            42,
            70
          ]
        },
        {
          "code": "# Additional custom validation\n",
          "display_code": "",
          "annotation": "Additional custom validation",
          "is_comment": true,
          "start_line": 71,
          "line_range": [
            71,
            71
          ],
          "target_line_range": [
            72,
            77
          ]
        },
        {
          "code": "    @field_validator('name')\n    def validate_name(cls, v):\n        if len(v.split()) < 2:\n            raise ValueError('Name must include at least first and last name')\n        return v\n\n",
          "display_code": "    @field_validator('name')\n    def validate_name(cls, v):\n        if len(v.split()) < 2:\n            raise ValueError('Name must include at least first and last name')\n        return v\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 72,
          "line_range": [
            72,
            77
          ]
        },
        {
          "code": "# Extract with validation\n",
          "display_code": "",
          "annotation": "Extract with validation",
          "is_comment": true,
          "start_line": 78,
          "line_range": [
            78,
            78
          ],
          "target_line_range": [
            79,
            97
          ]
        },
        {
          "code": "contact = client.chat.completions.create(\n    model=\"gpt-4\",  # More capable for handling pattern constraints\n    response_model=ContactInfo,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Contact details for our new client:\n        Name: John A. Smith\n        Email: john.smith@example.com\n        Phone: +1-555-123-4567\n        Website: https://www.johnsmith.com\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {contact.name}\")\nprint(f\"Email: {contact.email}\")\nprint(f\"Phone: {contact.phone}\")\nprint(f\"Website: {contact.website}\")\n\n",
          "display_code": "contact = client.chat.completions.create(\n    model=\"gpt-4\",  # More capable for handling pattern constraints\n    response_model=ContactInfo,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Contact details for our new client:\n        Name: John A. Smith\n        Email: john.smith@example.com\n        Phone: +1-555-123-4567\n        Website: https://www.johnsmith.com\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {contact.name}\")\nprint(f\"Email: {contact.email}\")\nprint(f\"Phone: {contact.phone}\")\nprint(f\"Website: {contact.website}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 79,
          "line_range": [
            79,
            97
          ]
        },
        {
          "code": "# Instructor automatically retries with validation errors:\n",
          "display_code": "",
          "annotation": "Instructor automatically retries with validation errors:",
          "is_comment": true,
          "start_line": 98,
          "line_range": [
            98,
            98
          ],
          "target_line_range": [
            99,
            105
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\n\nclass User(BaseModel):\n    name: str\n    age: int = Field(ge=18, le=100)  # Must be between 18 and 100\n    email: str = Field(pattern=r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$')\n\n",
          "display_code": "from pydantic import BaseModel, Field\n\nclass User(BaseModel):\n    name: str\n    age: int = Field(ge=18, le=100)  # Must be between 18 and 100\n    email: str = Field(pattern=r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$')\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 99,
          "line_range": [
            99,
            105
          ]
        },
        {
          "code": "# This example has invalid data\n",
          "display_code": "",
          "annotation": "This example has invalid data",
          "is_comment": true,
          "start_line": 106,
          "line_range": [
            106,
            106
          ],
          "target_line_range": [
            107,
            115
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=User,\n    max_retries=2,  # Limit retries (default is 3)\n    messages=[\n        {\"role\": \"user\", \"content\": \"Sam is 16 years old and his email is sam@example\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=User,\n    max_retries=2,  # Limit retries (default is 3)\n    messages=[\n        {\"role\": \"user\", \"content\": \"Sam is 16 years old and his email is sam@example\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 107,
          "line_range": [
            107,
            115
          ]
        },
        {
          "code": "# Instructor will automatically retry with validation errors to get a fixed response\n",
          "display_code": "",
          "annotation": "Instructor will automatically retry with validation errors to get a fixed response",
          "is_comment": true,
          "start_line": 116,
          "line_range": [
            116,
            116
          ],
          "target_line_range": [
            117,
            147
          ]
        },
        {
          "code": "print(f\"Name: {user.name}\")\nprint(f\"Age: {user.age}\")  # Should be adjusted to valid range\nprint(f\"Email: {user.email}\")  # Should include a valid domain\n\nfrom pydantic import BaseModel, Field, field_validator\nfrom datetime import date\nfrom typing import Optional\n\nclass Reservation(BaseModel):\n    guest_name: str\n    check_in_date: date\n    check_out_date: date\n    room_type: str\n    num_guests: int = Field(gt=0)\n    special_requests: Optional[str] = None\n\n    @field_validator('check_out_date')\n    def validate_dates(cls, v, values):\n        if 'check_in_date' in values.data and v <= values.data['check_in_date']:\n            raise ValueError('check_out_date must be after check_in_date')\n        return v\n\n    @field_validator('num_guests')\n    def validate_guests(cls, v, values):\n        if 'room_type' in values.data:\n            if values.data['room_type'].lower() == 'single' and v > 1:\n                raise ValueError('Single rooms can only accommodate 1 guest')\n            elif values.data['room_type'].lower() == 'double' and v > 2:\n                raise ValueError('Double rooms can only accommodate 2 guests')\n        return v\n\n",
          "display_code": "print(f\"Name: {user.name}\")\nprint(f\"Age: {user.age}\")  # Should be adjusted to valid range\nprint(f\"Email: {user.email}\")  # Should include a valid domain\n\nfrom pydantic import BaseModel, Field, field_validator\nfrom datetime import date\nfrom typing import Optional\n\nclass Reservation(BaseModel):\n    guest_name: str\n    check_in_date: date\n    check_out_date: date\n    room_type: str\n    num_guests: int = Field(gt=0)\n    special_requests: Optional[str] = None\n\n    @field_validator('check_out_date')\n    def validate_dates(cls, v, values):\n        if 'check_in_date' in values.data and v <= values.data['check_in_date']:\n            raise ValueError('check_out_date must be after check_in_date')\n        return v\n\n    @field_validator('num_guests')\n    def validate_guests(cls, v, values):\n        if 'room_type' in values.data:\n            if values.data['room_type'].lower() == 'single' and v > 1:\n                raise ValueError('Single rooms can only accommodate 1 guest')\n            elif values.data['room_type'].lower() == 'double' and v > 2:\n                raise ValueError('Double rooms can only accommodate 2 guests')\n        return v\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 117,
          "line_range": [
            117,
            147
          ]
        },
        {
          "code": "# Extract with validation\n",
          "display_code": "",
          "annotation": "Extract with validation",
          "is_comment": true,
          "start_line": 148,
          "line_range": [
            148,
            148
          ],
          "target_line_range": [
            149,
            170
          ]
        },
        {
          "code": "reservation = client.chat.completions.create(\n    model=\"gpt-4\",\n    response_model=Reservation,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Hotel reservation details:\n        Guest: Maria Garcia\n        Check-in: 2023-11-15\n        Check-out: 2023-11-20\n        Room: Double\n        Guests: 2\n        Special requests: Early check-in if possible\n        \"\"\"}\n    ]\n)\n\nprint(f\"Guest: {reservation.guest_name}\")\nprint(f\"Stay: {reservation.check_in_date} to {reservation.check_out_date}\")\nprint(f\"Room: {reservation.room_type} for {reservation.num_guests} guests\")\nif reservation.special_requests:\n    print(f\"Special requests: {reservation.special_requests}\")\n\n",
          "display_code": "reservation = client.chat.completions.create(\n    model=\"gpt-4\",\n    response_model=Reservation,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Hotel reservation details:\n        Guest: Maria Garcia\n        Check-in: 2023-11-15\n        Check-out: 2023-11-20\n        Room: Double\n        Guests: 2\n        Special requests: Early check-in if possible\n        \"\"\"}\n    ]\n)\n\nprint(f\"Guest: {reservation.guest_name}\")\nprint(f\"Stay: {reservation.check_in_date} to {reservation.check_out_date}\")\nprint(f\"Room: {reservation.room_type} for {reservation.num_guests} guests\")\nif reservation.special_requests:\n    print(f\"Special requests: {reservation.special_requests}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 149,
          "line_range": [
            149,
            170
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python field-validation.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "003-basic-extraction",
      "section_title": "Basic Extraction Patterns"
    },
    {
      "id": "016-optional-fields",
      "title": "Optional Fields",
      "description": "",
      "order": 16,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Handle missing or optional data in your structured extractions with Instructor.\n",
          "display_code": "",
          "annotation": "Handle missing or optional data in your structured extractions with Instructor.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            11
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\nfrom typing import Optional\nimport instructor\nfrom openai import OpenAI\n\nclass Person(BaseModel):\n    name: str\n    age: int\n",
          "display_code": "from pydantic import BaseModel, Field\nfrom typing import Optional\nimport instructor\nfrom openai import OpenAI\n\nclass Person(BaseModel):\n    name: str\n    age: int\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            11
          ]
        },
        {
          "code": "    # Optional fields with default value of None\n",
          "display_code": "",
          "annotation": "Optional fields with default value of None",
          "is_comment": true,
          "start_line": 12,
          "line_range": [
            12,
            12
          ],
          "target_line_range": [
            13,
            16
          ]
        },
        {
          "code": "    email: Optional[str] = None\n    phone: Optional[str] = None\n    occupation: Optional[str] = None\n\n",
          "display_code": "    email: Optional[str] = None\n    phone: Optional[str] = None\n    occupation: Optional[str] = None\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 13,
          "line_range": [
            13,
            16
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 17,
          "line_range": [
            17,
            17
          ],
          "target_line_range": [
            18,
            19
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 18,
          "line_range": [
            18,
            19
          ]
        },
        {
          "code": "# Extract with optional fields\n",
          "display_code": "",
          "annotation": "Extract with optional fields",
          "is_comment": true,
          "start_line": 20,
          "line_range": [
            20,
            20
          ],
          "target_line_range": [
            21,
            40
          ]
        },
        {
          "code": "person = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John Smith is 35 years old and works as a software engineer.\"}\n    ]\n)\n\nprint(f\"Name: {person.name}\")\nprint(f\"Age: {person.age}\")\nprint(f\"Email: {person.email}\")  # None\nprint(f\"Phone: {person.phone}\")  # None\nprint(f\"Occupation: {person.occupation}\")  # \"software engineer\"\n\nfrom pydantic import BaseModel, Field\nfrom typing import Optional\n\nclass Product(BaseModel):\n    name: str\n    price: float\n",
          "display_code": "person = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John Smith is 35 years old and works as a software engineer.\"}\n    ]\n)\n\nprint(f\"Name: {person.name}\")\nprint(f\"Age: {person.age}\")\nprint(f\"Email: {person.email}\")  # None\nprint(f\"Phone: {person.phone}\")  # None\nprint(f\"Occupation: {person.occupation}\")  # \"software engineer\"\n\nfrom pydantic import BaseModel, Field\nfrom typing import Optional\n\nclass Product(BaseModel):\n    name: str\n    price: float\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 21,
          "line_range": [
            21,
            40
          ]
        },
        {
          "code": "    # Optional with custom defaults\n",
          "display_code": "",
          "annotation": "Optional with custom defaults",
          "is_comment": true,
          "start_line": 41,
          "line_range": [
            41,
            41
          ],
          "target_line_range": [
            42,
            67
          ]
        },
        {
          "code": "    currency: str = \"USD\"\n    in_stock: bool = True\n    category: Optional[str] = None\n    tags: list[str] = Field(default_factory=list)  # Empty list by default\n\nproduct = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Product,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Our new coffee mug costs 12.99 and is categorized under 'Kitchen'.\"}\n    ]\n)\n\nprint(f\"Product: {product.name}\")\nprint(f\"Price: {product.price} {product.currency}\")  # USD is the default\nprint(f\"In Stock: {product.in_stock}\")  # True is the default\nprint(f\"Category: {product.category}\")  # \"Kitchen\"\nprint(f\"Tags: {product.tags}\")  # Empty list by default\n\nfrom pydantic import BaseModel, Field\nfrom typing import Optional\n\nclass JobApplication(BaseModel):\n    name: str = Field(description=\"Applicant's full name\")\n    email: str = Field(description=\"Contact email address\")\n\n",
          "display_code": "    currency: str = \"USD\"\n    in_stock: bool = True\n    category: Optional[str] = None\n    tags: list[str] = Field(default_factory=list)  # Empty list by default\n\nproduct = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Product,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Our new coffee mug costs 12.99 and is categorized under 'Kitchen'.\"}\n    ]\n)\n\nprint(f\"Product: {product.name}\")\nprint(f\"Price: {product.price} {product.currency}\")  # USD is the default\nprint(f\"In Stock: {product.in_stock}\")  # True is the default\nprint(f\"Category: {product.category}\")  # \"Kitchen\"\nprint(f\"Tags: {product.tags}\")  # Empty list by default\n\nfrom pydantic import BaseModel, Field\nfrom typing import Optional\n\nclass JobApplication(BaseModel):\n    name: str = Field(description=\"Applicant's full name\")\n    email: str = Field(description=\"Contact email address\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 42,
          "line_range": [
            42,
            67
          ]
        },
        {
          "code": "    # Optional fields with descriptions\n",
          "display_code": "",
          "annotation": "Optional fields with descriptions",
          "is_comment": true,
          "start_line": 68,
          "line_range": [
            68,
            68
          ],
          "target_line_range": [
            69,
            101
          ]
        },
        {
          "code": "    phone: Optional[str] = Field(\n        None, description=\"Phone number in international format (optional)\"\n    )\n    years_experience: Optional[int] = Field(\n        None, description=\"Years of relevant work experience (optional)\"\n    )\n    portfolio_url: Optional[str] = Field(\n        None, description=\"Link to portfolio or personal website (optional)\"\n    )\n    cover_letter: Optional[str] = Field(\n        None, description=\"Brief cover letter or introduction (optional)\"\n    )\n\napplication = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=JobApplication,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Job application from Sarah Johnson:\n        I'm applying for the software developer position. My email is sarah.j@example.com\n        and I have 5 years of experience in frontend development. You can see my work\n        at https://sarahjohnson.dev\n        \"\"\"}\n    ]\n)\n\nprint(f\"Applicant: {application.name}\")\nprint(f\"Email: {application.email}\")\nprint(f\"Phone: {application.phone or 'Not provided'}\")  # None -> 'Not provided'\nprint(f\"Experience: {application.years_experience or 'Not specified'} years\")\nprint(f\"Portfolio: {application.portfolio_url or 'None provided'}\")\nprint(f\"Cover Letter: {application.cover_letter or 'Not included'}\")\n\n",
          "display_code": "    phone: Optional[str] = Field(\n        None, description=\"Phone number in international format (optional)\"\n    )\n    years_experience: Optional[int] = Field(\n        None, description=\"Years of relevant work experience (optional)\"\n    )\n    portfolio_url: Optional[str] = Field(\n        None, description=\"Link to portfolio or personal website (optional)\"\n    )\n    cover_letter: Optional[str] = Field(\n        None, description=\"Brief cover letter or introduction (optional)\"\n    )\n\napplication = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=JobApplication,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Job application from Sarah Johnson:\n        I'm applying for the software developer position. My email is sarah.j@example.com\n        and I have 5 years of experience in frontend development. You can see my work\n        at https://sarahjohnson.dev\n        \"\"\"}\n    ]\n)\n\nprint(f\"Applicant: {application.name}\")\nprint(f\"Email: {application.email}\")\nprint(f\"Phone: {application.phone or 'Not provided'}\")  # None -> 'Not provided'\nprint(f\"Experience: {application.years_experience or 'Not specified'} years\")\nprint(f\"Portfolio: {application.portfolio_url or 'None provided'}\")\nprint(f\"Cover Letter: {application.cover_letter or 'Not included'}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 69,
          "line_range": [
            69,
            101
          ]
        },
        {
          "code": "# Instructor provides a `Maybe` type that explicitly tracks whether fields were present in the source text:\n",
          "display_code": "",
          "annotation": "Instructor provides a `Maybe` type that explicitly tracks whether fields were present in the source text:",
          "is_comment": true,
          "start_line": 102,
          "line_range": [
            102,
            102
          ],
          "target_line_range": [
            103,
            110
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\nfrom instructor.dsl.maybe import Maybe\nimport instructor\nfrom openai import OpenAI\n\nclass Person(BaseModel):\n    name: str\n    age: int\n",
          "display_code": "from pydantic import BaseModel, Field\nfrom instructor.dsl.maybe import Maybe\nimport instructor\nfrom openai import OpenAI\n\nclass Person(BaseModel):\n    name: str\n    age: int\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 103,
          "line_range": [
            103,
            110
          ]
        },
        {
          "code": "    # Maybe fields track if the information was in the text\n",
          "display_code": "",
          "annotation": "Maybe fields track if the information was in the text",
          "is_comment": true,
          "start_line": 111,
          "line_range": [
            111,
            111
          ],
          "target_line_range": [
            112,
            115
          ]
        },
        {
          "code": "    occupation: Maybe[str] = Field(default=None)\n    email: Maybe[str] = Field(default=None)\n    location: Maybe[str] = Field(default=None)\n\n",
          "display_code": "    occupation: Maybe[str] = Field(default=None)\n    email: Maybe[str] = Field(default=None)\n    location: Maybe[str] = Field(default=None)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 112,
          "line_range": [
            112,
            115
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 116,
          "line_range": [
            116,
            116
          ],
          "target_line_range": [
            117,
            118
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 117,
          "line_range": [
            117,
            118
          ]
        },
        {
          "code": "# Extract with Maybe fields\n",
          "display_code": "",
          "annotation": "Extract with Maybe fields",
          "is_comment": true,
          "start_line": 119,
          "line_range": [
            119,
            119
          ],
          "target_line_range": [
            120,
            130
          ]
        },
        {
          "code": "person = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John Smith is 35 years old and works as a software engineer.\"}\n    ]\n)\n\nprint(f\"Name: {person.name}\")\nprint(f\"Age: {person.age}\")\n\n",
          "display_code": "person = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John Smith is 35 years old and works as a software engineer.\"}\n    ]\n)\n\nprint(f\"Name: {person.name}\")\nprint(f\"Age: {person.age}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 120,
          "line_range": [
            120,
            130
          ]
        },
        {
          "code": "# Check if occupation was present\n",
          "display_code": "",
          "annotation": "Check if occupation was present",
          "is_comment": true,
          "start_line": 131,
          "line_range": [
            131,
            131
          ],
          "target_line_range": [
            132,
            136
          ]
        },
        {
          "code": "if person.occupation.exists:\n    print(f\"Occupation: {person.occupation.value}\")\nelse:\n    print(\"Occupation: Not mentioned\")\n\n",
          "display_code": "if person.occupation.exists:\n    print(f\"Occupation: {person.occupation.value}\")\nelse:\n    print(\"Occupation: Not mentioned\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 132,
          "line_range": [
            132,
            136
          ]
        },
        {
          "code": "# Check if email was present\n",
          "display_code": "",
          "annotation": "Check if email was present",
          "is_comment": true,
          "start_line": 137,
          "line_range": [
            137,
            137
          ],
          "target_line_range": [
            138,
            142
          ]
        },
        {
          "code": "if person.email.exists:\n    print(f\"Email: {person.email.value}\")\nelse:\n    print(\"Email: Not mentioned\")\n\n",
          "display_code": "if person.email.exists:\n    print(f\"Email: {person.email.value}\")\nelse:\n    print(\"Email: Not mentioned\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 138,
          "line_range": [
            138,
            142
          ]
        },
        {
          "code": "# Check if location was present\n",
          "display_code": "",
          "annotation": "Check if location was present",
          "is_comment": true,
          "start_line": 143,
          "line_range": [
            143,
            143
          ],
          "target_line_range": [
            144,
            161
          ]
        },
        {
          "code": "if person.location.exists:\n    print(f\"Location: {person.location.value}\")\nelse:\n    print(\"Location: Not mentioned\")\n\nfrom pydantic import BaseModel, Field\nfrom typing import Optional, List\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    country: str\n    zip_code: Optional[str] = None\n\nclass ContactInfo(BaseModel):\n    email: Optional[str] = None\n    phone: Optional[str] = None\n\n",
          "display_code": "if person.location.exists:\n    print(f\"Location: {person.location.value}\")\nelse:\n    print(\"Location: Not mentioned\")\n\nfrom pydantic import BaseModel, Field\nfrom typing import Optional, List\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    country: str\n    zip_code: Optional[str] = None\n\nclass ContactInfo(BaseModel):\n    email: Optional[str] = None\n    phone: Optional[str] = None\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 144,
          "line_range": [
            144,
            161
          ]
        },
        {
          "code": "    # An optional nested object\n",
          "display_code": "",
          "annotation": "An optional nested object",
          "is_comment": true,
          "start_line": 162,
          "line_range": [
            162,
            162
          ],
          "target_line_range": [
            163,
            195
          ]
        },
        {
          "code": "    address: Optional[Address] = None\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    contact: Optional[ContactInfo] = None\n    hobbies: List[str] = Field(default_factory=list)\n\nperson = client.chat.completions.create(\n    model=\"gpt-4\",  # Better for complex structures\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Profile: Jane Smith, 42 years old.\n        She enjoys hiking, photography, and playing piano.\n        Contact her at jane.smith@example.com or at her home in\n        123 Maple Street, Toronto, Canada.\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {person.name}, Age: {person.age}\")\nprint(f\"Hobbies: {', '.join(person.hobbies)}\")\n\nif person.contact:\n    if person.contact.email:\n        print(f\"Email: {person.contact.email}\")\n    if person.contact.phone:\n        print(f\"Phone: {person.contact.phone}\")\n    if person.contact.address:\n        addr = person.contact.address\n        print(f\"Address: {addr.street}, {addr.city}, {addr.country}\")\n\n",
          "display_code": "    address: Optional[Address] = None\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    contact: Optional[ContactInfo] = None\n    hobbies: List[str] = Field(default_factory=list)\n\nperson = client.chat.completions.create(\n    model=\"gpt-4\",  # Better for complex structures\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Profile: Jane Smith, 42 years old.\n        She enjoys hiking, photography, and playing piano.\n        Contact her at jane.smith@example.com or at her home in\n        123 Maple Street, Toronto, Canada.\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {person.name}, Age: {person.age}\")\nprint(f\"Hobbies: {', '.join(person.hobbies)}\")\n\nif person.contact:\n    if person.contact.email:\n        print(f\"Email: {person.contact.email}\")\n    if person.contact.phone:\n        print(f\"Phone: {person.contact.phone}\")\n    if person.contact.address:\n        addr = person.contact.address\n        print(f\"Address: {addr.street}, {addr.city}, {addr.country}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 163,
          "line_range": [
            163,
            195
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python optional-fields.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "003-basic-extraction",
      "section_title": "Basic Extraction Patterns"
    },
    {
      "id": "017-working-with-enums",
      "title": "Working with Enums",
      "description": "",
      "order": 17,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Use enumerated types with Instructor for consistent, validated extractions. Enums help enforce a fixed set of allowed values.\n",
          "display_code": "",
          "annotation": "Use enumerated types with Instructor for consistent, validated extractions. Enums help enforce a fixed set of allowed values.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            8
          ]
        },
        {
          "code": "from enum import Enum\nfrom pydantic import BaseModel\nimport instructor\nfrom openai import OpenAI\n\n",
          "display_code": "from enum import Enum\nfrom pydantic import BaseModel\nimport instructor\nfrom openai import OpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            8
          ]
        },
        {
          "code": "# Define an enum for product categories\n",
          "display_code": "",
          "annotation": "Define an enum for product categories",
          "is_comment": true,
          "start_line": 9,
          "line_range": [
            9,
            9
          ],
          "target_line_range": [
            10,
            21
          ]
        },
        {
          "code": "class ProductCategory(str, Enum):\n    ELECTRONICS = \"electronics\"\n    CLOTHING = \"clothing\"\n    HOME = \"home\"\n    BOOKS = \"books\"\n    TOYS = \"toys\"\n\nclass Product(BaseModel):\n    name: str\n    price: float\n    category: ProductCategory\n\n",
          "display_code": "class ProductCategory(str, Enum):\n    ELECTRONICS = \"electronics\"\n    CLOTHING = \"clothing\"\n    HOME = \"home\"\n    BOOKS = \"books\"\n    TOYS = \"toys\"\n\nclass Product(BaseModel):\n    name: str\n    price: float\n    category: ProductCategory\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 10,
          "line_range": [
            10,
            21
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 22,
          "line_range": [
            22,
            22
          ],
          "target_line_range": [
            23,
            24
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 23,
          "line_range": [
            23,
            24
          ]
        },
        {
          "code": "# Extract with enum validation\n",
          "display_code": "",
          "annotation": "Extract with enum validation",
          "is_comment": true,
          "start_line": 25,
          "line_range": [
            25,
            25
          ],
          "target_line_range": [
            26,
            36
          ]
        },
        {
          "code": "product = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Product,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Our new wireless headphones cost $79.99 and belong in our electronics department.\"}\n    ]\n)\n\nprint(f\"Product: {product.name}\")\nprint(f\"Price: ${product.price}\")\nprint(f\"Category: {product.category}\")\n",
          "display_code": "product = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Product,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Our new wireless headphones cost $79.99 and belong in our electronics department.\"}\n    ]\n)\n\nprint(f\"Product: {product.name}\")\nprint(f\"Price: ${product.price}\")\nprint(f\"Category: {product.category}\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 26,
          "line_range": [
            26,
            36
          ]
        },
        {
          "code": "# Will be ProductCategory.ELECTRONICS, not just a string\n",
          "display_code": "",
          "annotation": "Will be ProductCategory.ELECTRONICS, not just a string",
          "is_comment": true,
          "start_line": 37,
          "line_range": [
            37,
            37
          ],
          "target_line_range": [
            38,
            38
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 38,
          "line_range": [
            38,
            38
          ]
        },
        {
          "code": "# You can use the enum for comparisons\n",
          "display_code": "",
          "annotation": "You can use the enum for comparisons",
          "is_comment": true,
          "start_line": 39,
          "line_range": [
            39,
            39
          ],
          "target_line_range": [
            40,
            46
          ]
        },
        {
          "code": "if product.category == ProductCategory.ELECTRONICS:\n    print(\"This is an electronic product.\")\n\nfrom enum import Enum, auto\nfrom pydantic import BaseModel\nfrom typing import List\n\n",
          "display_code": "if product.category == ProductCategory.ELECTRONICS:\n    print(\"This is an electronic product.\")\n\nfrom enum import Enum, auto\nfrom pydantic import BaseModel\nfrom typing import List\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 40,
          "line_range": [
            40,
            46
          ]
        },
        {
          "code": "# Define priority enum\n",
          "display_code": "",
          "annotation": "Define priority enum",
          "is_comment": true,
          "start_line": 47,
          "line_range": [
            47,
            47
          ],
          "target_line_range": [
            48,
            53
          ]
        },
        {
          "code": "class Priority(str, Enum):\n    LOW = \"low\"\n    MEDIUM = \"medium\"\n    HIGH = \"high\"\n    CRITICAL = \"critical\"\n\n",
          "display_code": "class Priority(str, Enum):\n    LOW = \"low\"\n    MEDIUM = \"medium\"\n    HIGH = \"high\"\n    CRITICAL = \"critical\"\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 48,
          "line_range": [
            48,
            53
          ]
        },
        {
          "code": "# Define status enum\n",
          "display_code": "",
          "annotation": "Define status enum",
          "is_comment": true,
          "start_line": 54,
          "line_range": [
            54,
            54
          ],
          "target_line_range": [
            55,
            88
          ]
        },
        {
          "code": "class Status(str, Enum):\n    TODO = \"todo\"\n    IN_PROGRESS = \"in_progress\"\n    REVIEW = \"review\"\n    DONE = \"done\"\n\nclass Task(BaseModel):\n    title: str\n    description: str\n    priority: Priority\n    status: Status\n    tags: List[str] = []\n\ntask = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Task,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Task Details:\n        Title: Fix login page bug\n        Description: Users report seeing errors when trying to log in with special characters\n        Priority: High\n        Status: In Progress\n        Tags: bug, authentication, frontend\n        \"\"\"}\n    ]\n)\n\nprint(f\"Task: {task.title}\")\nprint(f\"Description: {task.description}\")\nprint(f\"Priority: {task.priority}\")  # Priority.HIGH\nprint(f\"Status: {task.status}\")  # Status.IN_PROGRESS\nprint(f\"Tags: {', '.join(task.tags)}\")\n\n",
          "display_code": "class Status(str, Enum):\n    TODO = \"todo\"\n    IN_PROGRESS = \"in_progress\"\n    REVIEW = \"review\"\n    DONE = \"done\"\n\nclass Task(BaseModel):\n    title: str\n    description: str\n    priority: Priority\n    status: Status\n    tags: List[str] = []\n\ntask = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Task,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Task Details:\n        Title: Fix login page bug\n        Description: Users report seeing errors when trying to log in with special characters\n        Priority: High\n        Status: In Progress\n        Tags: bug, authentication, frontend\n        \"\"\"}\n    ]\n)\n\nprint(f\"Task: {task.title}\")\nprint(f\"Description: {task.description}\")\nprint(f\"Priority: {task.priority}\")  # Priority.HIGH\nprint(f\"Status: {task.status}\")  # Status.IN_PROGRESS\nprint(f\"Tags: {', '.join(task.tags)}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 55,
          "line_range": [
            55,
            88
          ]
        },
        {
          "code": "# Use enums for conditional logic\n",
          "display_code": "",
          "annotation": "Use enums for conditional logic",
          "is_comment": true,
          "start_line": 89,
          "line_range": [
            89,
            89
          ],
          "target_line_range": [
            90,
            98
          ]
        },
        {
          "code": "if task.priority in [Priority.HIGH, Priority.CRITICAL]:\n    print(\"This task requires immediate attention!\")\n\nif task.status == Status.IN_PROGRESS:\n    print(\"This task is being worked on.\")\n\nfrom enum import IntEnum\nfrom pydantic import BaseModel\n\n",
          "display_code": "if task.priority in [Priority.HIGH, Priority.CRITICAL]:\n    print(\"This task requires immediate attention!\")\n\nif task.status == Status.IN_PROGRESS:\n    print(\"This task is being worked on.\")\n\nfrom enum import IntEnum\nfrom pydantic import BaseModel\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 90,
          "line_range": [
            90,
            98
          ]
        },
        {
          "code": "# Define an integer-based enum\n",
          "display_code": "",
          "annotation": "Define an integer-based enum",
          "is_comment": true,
          "start_line": 99,
          "line_range": [
            99,
            99
          ],
          "target_line_range": [
            100,
            131
          ]
        },
        {
          "code": "class SeverityLevel(IntEnum):\n    LOW = 1\n    MODERATE = 2\n    HIGH = 3\n    SEVERE = 4\n    CRITICAL = 5\n\nclass SecurityIssue(BaseModel):\n    title: str\n    description: str\n    severity: SeverityLevel\n    affected_users: int\n\nissue = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=SecurityIssue,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Security Alert:\n        Issue: Database Exposure\n        Details: Customer database was partially exposed due to misconfigured firewall\n        Severity: 4 (Severe)\n        Affected Users: 5,230\n        \"\"\"}\n    ]\n)\n\nprint(f\"Issue: {issue.title}\")\nprint(f\"Description: {issue.description}\")\nprint(f\"Severity: {issue.severity.name} (Level {issue.severity.value})\")  # \"SEVERE (Level 4)\"\nprint(f\"Affected Users: {issue.affected_users}\")\n\n",
          "display_code": "class SeverityLevel(IntEnum):\n    LOW = 1\n    MODERATE = 2\n    HIGH = 3\n    SEVERE = 4\n    CRITICAL = 5\n\nclass SecurityIssue(BaseModel):\n    title: str\n    description: str\n    severity: SeverityLevel\n    affected_users: int\n\nissue = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=SecurityIssue,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Security Alert:\n        Issue: Database Exposure\n        Details: Customer database was partially exposed due to misconfigured firewall\n        Severity: 4 (Severe)\n        Affected Users: 5,230\n        \"\"\"}\n    ]\n)\n\nprint(f\"Issue: {issue.title}\")\nprint(f\"Description: {issue.description}\")\nprint(f\"Severity: {issue.severity.name} (Level {issue.severity.value})\")  # \"SEVERE (Level 4)\"\nprint(f\"Affected Users: {issue.affected_users}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 100,
          "line_range": [
            100,
            131
          ]
        },
        {
          "code": "# Use integer enum for thresholds\n",
          "display_code": "",
          "annotation": "Use integer enum for thresholds",
          "is_comment": true,
          "start_line": 132,
          "line_range": [
            132,
            132
          ],
          "target_line_range": [
            133,
            149
          ]
        },
        {
          "code": "if issue.severity >= SeverityLevel.HIGH and issue.affected_users > 1000:\n    print(\"This requires executive notification!\")\n\nfrom enum import Enum\nfrom pydantic import BaseModel, Field\n\nclass TicketType(str, Enum):\n    BUG = \"bug\"\n    FEATURE = \"feature\"\n    IMPROVEMENT = \"improvement\"\n    DOCUMENTATION = \"documentation\"\n    QUESTION = \"question\"\n\nclass Ticket(BaseModel):\n    title: str\n    description: str\n\n",
          "display_code": "if issue.severity >= SeverityLevel.HIGH and issue.affected_users > 1000:\n    print(\"This requires executive notification!\")\n\nfrom enum import Enum\nfrom pydantic import BaseModel, Field\n\nclass TicketType(str, Enum):\n    BUG = \"bug\"\n    FEATURE = \"feature\"\n    IMPROVEMENT = \"improvement\"\n    DOCUMENTATION = \"documentation\"\n    QUESTION = \"question\"\n\nclass Ticket(BaseModel):\n    title: str\n    description: str\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 133,
          "line_range": [
            133,
            149
          ]
        },
        {
          "code": "    # Add descriptions to help the LLM understand the enum\n",
          "display_code": "",
          "annotation": "Add descriptions to help the LLM understand the enum",
          "is_comment": true,
          "start_line": 150,
          "line_range": [
            150,
            150
          ],
          "target_line_range": [
            151,
            178
          ]
        },
        {
          "code": "    ticket_type: TicketType = Field(\n        description=\"\"\"Type of ticket with these options:\n        - bug: Something is not working correctly\n        - feature: A new capability is requested\n        - improvement: Enhancement to an existing feature\n        - documentation: Updates to documentation\n        - question: Question about functionality\"\"\"\n    )\n\nticket = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Ticket,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        New Ticket:\n        Title: Add dark mode to application\n        Description: Users would like a dark theme option to reduce eye strain when using the app at night\n        \"\"\"}\n    ]\n)\n\nprint(f\"Ticket: {ticket.title}\")\nprint(f\"Description: {ticket.description}\")\nprint(f\"Type: {ticket.ticket_type}\")  # Should be TicketType.IMPROVEMENT or TicketType.FEATURE\n\nfrom enum import Flag, auto\nfrom pydantic import BaseModel, Field\n\n",
          "display_code": "    ticket_type: TicketType = Field(\n        description=\"\"\"Type of ticket with these options:\n        - bug: Something is not working correctly\n        - feature: A new capability is requested\n        - improvement: Enhancement to an existing feature\n        - documentation: Updates to documentation\n        - question: Question about functionality\"\"\"\n    )\n\nticket = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Ticket,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        New Ticket:\n        Title: Add dark mode to application\n        Description: Users would like a dark theme option to reduce eye strain when using the app at night\n        \"\"\"}\n    ]\n)\n\nprint(f\"Ticket: {ticket.title}\")\nprint(f\"Description: {ticket.description}\")\nprint(f\"Type: {ticket.ticket_type}\")  # Should be TicketType.IMPROVEMENT or TicketType.FEATURE\n\nfrom enum import Flag, auto\nfrom pydantic import BaseModel, Field\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 151,
          "line_range": [
            151,
            178
          ]
        },
        {
          "code": "# Define a Flag enum for permissions\n",
          "display_code": "",
          "annotation": "Define a Flag enum for permissions",
          "is_comment": true,
          "start_line": 179,
          "line_range": [
            179,
            179
          ],
          "target_line_range": [
            180,
            186
          ]
        },
        {
          "code": "class Permissions(Flag):\n    NONE = 0\n    READ = auto()       # 1\n    WRITE = auto()      # 2\n    DELETE = auto()     # 4\n    ADMIN = auto()      # 8\n\n",
          "display_code": "class Permissions(Flag):\n    NONE = 0\n    READ = auto()       # 1\n    WRITE = auto()      # 2\n    DELETE = auto()     # 4\n    ADMIN = auto()      # 8\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 180,
          "line_range": [
            180,
            186
          ]
        },
        {
          "code": "    # Combinations\n",
          "display_code": "",
          "annotation": "Combinations",
          "is_comment": true,
          "start_line": 187,
          "line_range": [
            187,
            187
          ],
          "target_line_range": [
            188,
            220
          ]
        },
        {
          "code": "    READ_WRITE = READ | WRITE                # 3\n    STANDARD = READ | WRITE | DELETE         # 7\n    ALL = READ | WRITE | DELETE | ADMIN      # 15\n\nclass User(BaseModel):\n    name: str\n    role: str\n    permissions: Permissions = Field(\n        description=\"\"\"User permissions, can be a combination of:\n        - READ: Can view content\n        - WRITE: Can create and edit content\n        - DELETE: Can remove content\n        - ADMIN: Has administrative privileges\n        - Or predefined combinations like READ_WRITE, STANDARD, or ALL\"\"\"\n    )\n\nuser = client.chat.completions.create(\n    model=\"gpt-4\",  # Better for complex models\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        User Profile:\n        Name: Sarah Johnson\n        Role: Content Manager\n        Permissions: Can read, write, and delete content\n        \"\"\"}\n    ]\n)\n\nprint(f\"User: {user.name}\")\nprint(f\"Role: {user.role}\")\nprint(f\"Permissions: {user.permissions.name}\")  # Should be \"STANDARD\"\n\n",
          "display_code": "    READ_WRITE = READ | WRITE                # 3\n    STANDARD = READ | WRITE | DELETE         # 7\n    ALL = READ | WRITE | DELETE | ADMIN      # 15\n\nclass User(BaseModel):\n    name: str\n    role: str\n    permissions: Permissions = Field(\n        description=\"\"\"User permissions, can be a combination of:\n        - READ: Can view content\n        - WRITE: Can create and edit content\n        - DELETE: Can remove content\n        - ADMIN: Has administrative privileges\n        - Or predefined combinations like READ_WRITE, STANDARD, or ALL\"\"\"\n    )\n\nuser = client.chat.completions.create(\n    model=\"gpt-4\",  # Better for complex models\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        User Profile:\n        Name: Sarah Johnson\n        Role: Content Manager\n        Permissions: Can read, write, and delete content\n        \"\"\"}\n    ]\n)\n\nprint(f\"User: {user.name}\")\nprint(f\"Role: {user.role}\")\nprint(f\"Permissions: {user.permissions.name}\")  # Should be \"STANDARD\"\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 188,
          "line_range": [
            188,
            220
          ]
        },
        {
          "code": "# Check individual permissions\n",
          "display_code": "",
          "annotation": "Check individual permissions",
          "is_comment": true,
          "start_line": 221,
          "line_range": [
            221,
            221
          ],
          "target_line_range": [
            222,
            232
          ]
        },
        {
          "code": "if Permissions.READ in user.permissions:\n    print(\"User can read content\")\n\nif Permissions.WRITE in user.permissions:\n    print(\"User can write content\")\n\nif Permissions.ADMIN in user.permissions:\n    print(\"User has admin privileges\")\nelse:\n    print(\"User does not have admin privileges\")\n\n",
          "display_code": "if Permissions.READ in user.permissions:\n    print(\"User can read content\")\n\nif Permissions.WRITE in user.permissions:\n    print(\"User can write content\")\n\nif Permissions.ADMIN in user.permissions:\n    print(\"User has admin privileges\")\nelse:\n    print(\"User does not have admin privileges\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 222,
          "line_range": [
            222,
            232
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python working-with-enums.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "003-basic-extraction",
      "section_title": "Basic Extraction Patterns"
    },
    {
      "id": "018-simple-classification",
      "title": "Simple Classification",
      "description": "",
      "order": 18,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Perform single-label classification with Instructor and structured outputs.\n",
          "display_code": "",
          "annotation": "Perform single-label classification with Instructor and structured outputs.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            15
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\nfrom typing import Literal\nimport instructor\nfrom openai import OpenAI\n\nclass Classification(BaseModel):\n    \"\"\"A single-label classification for text as SPAM or NOT_SPAM\"\"\"\n\n    label: Literal[\"SPAM\", \"NOT_SPAM\"] = Field(\n        description=\"The classification label, either SPAM or NOT_SPAM\"\n    )\n\n",
          "display_code": "from pydantic import BaseModel, Field\nfrom typing import Literal\nimport instructor\nfrom openai import OpenAI\n\nclass Classification(BaseModel):\n    \"\"\"A single-label classification for text as SPAM or NOT_SPAM\"\"\"\n\n    label: Literal[\"SPAM\", \"NOT_SPAM\"] = Field(\n        description=\"The classification label, either SPAM or NOT_SPAM\"\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            15
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 16,
          "line_range": [
            16,
            16
          ],
          "target_line_range": [
            17,
            43
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\ndef classify_text(text: str) -> Classification:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=Classification,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"\"\"\n                You are an email spam classifier. Classify the provided text as either SPAM or NOT_SPAM.\n\n                Examples of SPAM:\n                - \"Claim your free prize now!\"\n                - \"Make $1000 a day working from home\"\n                - \"Limited time offer - 90% discount\"\n\n                Examples of NOT_SPAM:\n                - \"Can we schedule a meeting tomorrow?\"\n                - \"Here's the report you requested\"\n                - \"Please review the attached document\"\n                \"\"\"\n            },\n            {\"role\": \"user\", \"content\": f\"Classify this text: {text}\"}\n        ]\n    )\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\ndef classify_text(text: str) -> Classification:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=Classification,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"\"\"\n                You are an email spam classifier. Classify the provided text as either SPAM or NOT_SPAM.\n\n                Examples of SPAM:\n                - \"Claim your free prize now!\"\n                - \"Make $1000 a day working from home\"\n                - \"Limited time offer - 90% discount\"\n\n                Examples of NOT_SPAM:\n                - \"Can we schedule a meeting tomorrow?\"\n                - \"Here's the report you requested\"\n                - \"Please review the attached document\"\n                \"\"\"\n            },\n            {\"role\": \"user\", \"content\": f\"Classify this text: {text}\"}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 17,
          "line_range": [
            17,
            43
          ]
        },
        {
          "code": "# Test with examples\n",
          "display_code": "",
          "annotation": "Test with examples",
          "is_comment": true,
          "start_line": 44,
          "line_range": [
            44,
            44
          ],
          "target_line_range": [
            45,
            52
          ]
        },
        {
          "code": "spam_text = \"URGENT: Your account has been compromised. Click here to verify details!\"\nlegit_text = \"Please review the meeting notes and provide your feedback by Friday.\"\n\nspam_result = classify_text(spam_text)\nlegit_result = classify_text(legit_text)\n\nprint(f\"Text: '{spam_text}'\")\nprint(f\"Classification: {spam_result.label}\")\n",
          "display_code": "spam_text = \"URGENT: Your account has been compromised. Click here to verify details!\"\nlegit_text = \"Please review the meeting notes and provide your feedback by Friday.\"\n\nspam_result = classify_text(spam_text)\nlegit_result = classify_text(legit_text)\n\nprint(f\"Text: '{spam_text}'\")\nprint(f\"Classification: {spam_result.label}\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 45,
          "line_range": [
            45,
            52
          ]
        },
        {
          "code": "# Output: Classification: SPAM\n",
          "display_code": "",
          "annotation": "Output: Classification: SPAM",
          "is_comment": true,
          "start_line": 53,
          "line_range": [
            53,
            53
          ],
          "target_line_range": [
            54,
            56
          ]
        },
        {
          "code": "\nprint(f\"\\nText: '{legit_text}'\")\nprint(f\"Classification: {legit_result.label}\")\n",
          "display_code": "\nprint(f\"\\nText: '{legit_text}'\")\nprint(f\"Classification: {legit_result.label}\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 54,
          "line_range": [
            54,
            56
          ]
        },
        {
          "code": "# Output: Classification: NOT_SPAM\n",
          "display_code": "",
          "annotation": "Output: Classification: NOT_SPAM",
          "is_comment": true,
          "start_line": 57,
          "line_range": [
            57,
            57
          ],
          "target_line_range": [
            58,
            87
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field\nfrom typing import Literal\n\nclass ClassificationWithConfidence(BaseModel):\n    label: Literal[\"SPAM\", \"NOT_SPAM\"]\n    confidence: float = Field(\n        gt=0, le=1,  # Greater than 0, less than or equal to 1\n        description=\"Confidence score between 0 and 1 (higher = more confident)\"\n    )\n\ndef classify_with_confidence(text: str) -> ClassificationWithConfidence:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=ClassificationWithConfidence,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Classify the text as SPAM or NOT_SPAM with a confidence score.\"\n            },\n            {\"role\": \"user\", \"content\": f\"Classify this text: {text}\"}\n        ]\n    )\n\nborderline_text = \"Get your free account upgrade today. Limited availability.\"\nresult = classify_with_confidence(borderline_text)\n\nprint(f\"Text: '{borderline_text}'\")\nprint(f\"Classification: {result.label}\")\nprint(f\"Confidence: {result.confidence:.2f}\")\n",
          "display_code": "\nfrom pydantic import BaseModel, Field\nfrom typing import Literal\n\nclass ClassificationWithConfidence(BaseModel):\n    label: Literal[\"SPAM\", \"NOT_SPAM\"]\n    confidence: float = Field(\n        gt=0, le=1,  # Greater than 0, less than or equal to 1\n        description=\"Confidence score between 0 and 1 (higher = more confident)\"\n    )\n\ndef classify_with_confidence(text: str) -> ClassificationWithConfidence:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=ClassificationWithConfidence,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Classify the text as SPAM or NOT_SPAM with a confidence score.\"\n            },\n            {\"role\": \"user\", \"content\": f\"Classify this text: {text}\"}\n        ]\n    )\n\nborderline_text = \"Get your free account upgrade today. Limited availability.\"\nresult = classify_with_confidence(borderline_text)\n\nprint(f\"Text: '{borderline_text}'\")\nprint(f\"Classification: {result.label}\")\nprint(f\"Confidence: {result.confidence:.2f}\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 58,
          "line_range": [
            58,
            87
          ]
        },
        {
          "code": "# Example Output:\n# Classification: SPAM\n# Confidence: 0.75\n",
          "display_code": "",
          "annotation": "Example Output:\nClassification: SPAM\nConfidence: 0.75",
          "is_comment": true,
          "start_line": 88,
          "line_range": [
            88,
            90
          ],
          "target_line_range": [
            91,
            127
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field\nfrom typing import Literal\n\nclass DetailedClassification(BaseModel):\n    label: Literal[\"SPAM\", \"NOT_SPAM\"]\n    explanation: str = Field(\n        description=\"Detailed reasoning for this classification\"\n    )\n    spam_indicators: list[str] = Field(\n        default_factory=list,\n        description=\"List of specific elements that indicate spam, if any\"\n    )\n\ndef classify_with_details(text: str) -> DetailedClassification:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=DetailedClassification,\n        messages=[\n            {\"role\": \"system\", \"content\": \"Classify the text and provide a detailed explanation.\"},\n            {\"role\": \"user\", \"content\": f\"Classify this text: {text}\"}\n        ]\n    )\n\ntext = \"CONGRATULATIONS! You've been selected to receive a free iPhone! Click now to claim: bit.ly/claim-prize\"\nresult = classify_with_details(text)\n\nprint(f\"Text: '{text}'\")\nprint(f\"Classification: {result.label}\")\nprint(f\"Explanation: {result.explanation}\")\nprint(\"Spam indicators:\")\nfor indicator in result.spam_indicators:\n    print(f\"- {indicator}\")\n\nfrom typing import List\n\ndef classify_batch(texts: List[str]) -> List[Classification]:\n",
          "display_code": "\nfrom pydantic import BaseModel, Field\nfrom typing import Literal\n\nclass DetailedClassification(BaseModel):\n    label: Literal[\"SPAM\", \"NOT_SPAM\"]\n    explanation: str = Field(\n        description=\"Detailed reasoning for this classification\"\n    )\n    spam_indicators: list[str] = Field(\n        default_factory=list,\n        description=\"List of specific elements that indicate spam, if any\"\n    )\n\ndef classify_with_details(text: str) -> DetailedClassification:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=DetailedClassification,\n        messages=[\n            {\"role\": \"system\", \"content\": \"Classify the text and provide a detailed explanation.\"},\n            {\"role\": \"user\", \"content\": f\"Classify this text: {text}\"}\n        ]\n    )\n\ntext = \"CONGRATULATIONS! You've been selected to receive a free iPhone! Click now to claim: bit.ly/claim-prize\"\nresult = classify_with_details(text)\n\nprint(f\"Text: '{text}'\")\nprint(f\"Classification: {result.label}\")\nprint(f\"Explanation: {result.explanation}\")\nprint(\"Spam indicators:\")\nfor indicator in result.spam_indicators:\n    print(f\"- {indicator}\")\n\nfrom typing import List\n\ndef classify_batch(texts: List[str]) -> List[Classification]:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 91,
          "line_range": [
            91,
            127
          ]
        },
        {
          "code": "    # Use a batch prompt to classify multiple texts at once\n",
          "display_code": "",
          "annotation": "Use a batch prompt to classify multiple texts at once",
          "is_comment": true,
          "start_line": 128,
          "line_range": [
            128,
            128
          ],
          "target_line_range": [
            129,
            139
          ]
        },
        {
          "code": "    formatted_texts = \"\\n\\n\".join([f\"Text {i+1}: {text}\" for i, text in enumerate(texts)])\n\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=List[Classification],\n        messages=[\n            {\"role\": \"system\", \"content\": \"Classify each text as SPAM or NOT_SPAM.\"},\n            {\"role\": \"user\", \"content\": f\"Classify these texts:\\n\\n{formatted_texts}\"}\n        ]\n    )\n\n",
          "display_code": "    formatted_texts = \"\\n\\n\".join([f\"Text {i+1}: {text}\" for i, text in enumerate(texts)])\n\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=List[Classification],\n        messages=[\n            {\"role\": \"system\", \"content\": \"Classify each text as SPAM or NOT_SPAM.\"},\n            {\"role\": \"user\", \"content\": f\"Classify these texts:\\n\\n{formatted_texts}\"}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 129,
          "line_range": [
            129,
            139
          ]
        },
        {
          "code": "# Test with a batch of texts\n",
          "display_code": "",
          "annotation": "Test with a batch of texts",
          "is_comment": true,
          "start_line": 140,
          "line_range": [
            140,
            140
          ],
          "target_line_range": [
            141,
            152
          ]
        },
        {
          "code": "texts = [\n    \"Your application has been approved. Sign the documents at your earliest convenience.\",\n    \"WINNER! You've been selected to receive $1000! Send your bank details now!\",\n    \"Meeting rescheduled to 3PM tomorrow. Same Zoom link.\"\n]\n\nresults = classify_batch(texts)\n\nfor i, (text, result) in enumerate(zip(texts, results)):\n    print(f\"Text {i+1}: '{text}'\")\n    print(f\"Classification: {result.label}\\n\")\n\n",
          "display_code": "texts = [\n    \"Your application has been approved. Sign the documents at your earliest convenience.\",\n    \"WINNER! You've been selected to receive $1000! Send your bank details now!\",\n    \"Meeting rescheduled to 3PM tomorrow. Same Zoom link.\"\n]\n\nresults = classify_batch(texts)\n\nfor i, (text, result) in enumerate(zip(texts, results)):\n    print(f\"Text {i+1}: '{text}'\")\n    print(f\"Classification: {result.label}\\n\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 141,
          "line_range": [
            141,
            152
          ]
        },
        {
          "code": "# Output:\n# Text 1: 'Your application has been approved. Sign the documents at your earliest convenience.'\n# Classification: NOT_SPAM\n#\n# Text 2: 'WINNER! You've been selected to receive $1000! Send your bank details now!'\n# Classification: SPAM\n#\n# Text 3: 'Meeting rescheduled to 3PM tomorrow. Same Zoom link.'\n# Classification: NOT_SPAM\n",
          "display_code": "",
          "annotation": "Output:\nText 1: 'Your application has been approved. Sign the documents at your earliest convenience.'\nClassification: NOT_SPAM\n\nText 2: 'WINNER! You've been selected to receive $1000! Send your bank details now!'\nClassification: SPAM\n\nText 3: 'Meeting rescheduled to 3PM tomorrow. Same Zoom link.'\nClassification: NOT_SPAM",
          "is_comment": true,
          "start_line": 153,
          "line_range": [
            153,
            161
          ],
          "target_line_range": [
            162,
            162
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 162,
          "line_range": [
            162,
            162
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python simple-classification.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "004-classification",
      "section_title": "Classification and Analysis"
    },
    {
      "id": "019-multi-label-classification",
      "title": "Multi-label Classification",
      "description": "",
      "order": 19,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Extract multiple labels from text using Instructor.\n",
          "display_code": "",
          "annotation": "Extract multiple labels from text using Instructor.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            15
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\nfrom typing import List\nimport instructor\nfrom openai import OpenAI\n\nclass MultiLabelClassification(BaseModel):\n    \"\"\"Multi-label classification of text content\"\"\"\n\n    labels: List[str] = Field(\n        description=\"List of applicable category labels for the text\"\n    )\n\n",
          "display_code": "from pydantic import BaseModel, Field\nfrom typing import List\nimport instructor\nfrom openai import OpenAI\n\nclass MultiLabelClassification(BaseModel):\n    \"\"\"Multi-label classification of text content\"\"\"\n\n    labels: List[str] = Field(\n        description=\"List of applicable category labels for the text\"\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            15
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 16,
          "line_range": [
            16,
            16
          ],
          "target_line_range": [
            17,
            43
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\ndef classify_text(text: str) -> MultiLabelClassification:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=MultiLabelClassification,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"\"\"\n                Classify the text into one or more of these categories:\n                - Technology\n                - Finance\n                - Health\n                - Sports\n                - Entertainment\n                - Politics\n                - Science\n                - Education\n\n                Return all categories that apply to the text.\n                \"\"\"\n            },\n            {\"role\": \"user\", \"content\": f\"Text for classification: {text}\"}\n        ]\n    )\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\ndef classify_text(text: str) -> MultiLabelClassification:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=MultiLabelClassification,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"\"\"\n                Classify the text into one or more of these categories:\n                - Technology\n                - Finance\n                - Health\n                - Sports\n                - Entertainment\n                - Politics\n                - Science\n                - Education\n\n                Return all categories that apply to the text.\n                \"\"\"\n            },\n            {\"role\": \"user\", \"content\": f\"Text for classification: {text}\"}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 17,
          "line_range": [
            17,
            43
          ]
        },
        {
          "code": "# Test with an example\n",
          "display_code": "",
          "annotation": "Test with an example",
          "is_comment": true,
          "start_line": 44,
          "line_range": [
            44,
            44
          ],
          "target_line_range": [
            45,
            54
          ]
        },
        {
          "code": "article = \"\"\"\n    Bitcoin prices surged to a new all-time high today as several tech companies announced\n    plans to add the cryptocurrency to their balance sheets. Health officials warned that\n    the excitement might cause stress for some investors.\n\"\"\"\n\nresult = classify_text(article)\n\nprint(f\"Text: '{article}'\")\nprint(f\"Labels: {', '.join(result.labels)}\")\n",
          "display_code": "article = \"\"\"\n    Bitcoin prices surged to a new all-time high today as several tech companies announced\n    plans to add the cryptocurrency to their balance sheets. Health officials warned that\n    the excitement might cause stress for some investors.\n\"\"\"\n\nresult = classify_text(article)\n\nprint(f\"Text: '{article}'\")\nprint(f\"Labels: {', '.join(result.labels)}\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 45,
          "line_range": [
            45,
            54
          ]
        },
        {
          "code": "# Example Output: Labels: Technology, Finance, Health\n",
          "display_code": "",
          "annotation": "Example Output: Labels: Technology, Finance, Health",
          "is_comment": true,
          "start_line": 55,
          "line_range": [
            55,
            55
          ],
          "target_line_range": [
            56,
            60
          ]
        },
        {
          "code": "\nfrom enum import Enum\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\n",
          "display_code": "\nfrom enum import Enum\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 56,
          "line_range": [
            56,
            60
          ]
        },
        {
          "code": "# Define fixed categories as an enum\n",
          "display_code": "",
          "annotation": "Define fixed categories as an enum",
          "is_comment": true,
          "start_line": 61,
          "line_range": [
            61,
            61
          ],
          "target_line_range": [
            62,
            97
          ]
        },
        {
          "code": "class Category(str, Enum):\n    BUSINESS = \"business\"\n    TECHNOLOGY = \"technology\"\n    POLITICS = \"politics\"\n    HEALTH = \"health\"\n    ENTERTAINMENT = \"entertainment\"\n    SPORTS = \"sports\"\n    SCIENCE = \"science\"\n    EDUCATION = \"education\"\n\nclass EnumMultiLabelClassification(BaseModel):\n    \"\"\"Multi-label classification using predefined categories\"\"\"\n\n    categories: List[Category] = Field(\n        description=\"List of applicable categories from the predefined set\"\n    )\n\ndef classify_with_enums(text: str) -> EnumMultiLabelClassification:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=EnumMultiLabelClassification,\n        messages=[\n            {\"role\": \"system\", \"content\": \"Classify the text into one or more predefined categories.\"},\n            {\"role\": \"user\", \"content\": f\"Text for classification: {text}\"}\n        ]\n    )\n\narticle = \"\"\"\n    New educational technology is transforming classrooms across the country.\n    Students are using AI-powered tools to enhance their learning experiences.\n\"\"\"\n\nresult = classify_with_enums(article)\n\nprint(f\"Text: '{article}'\")\nprint(f\"Categories: {', '.join([c.value for c in result.categories])}\")\n",
          "display_code": "class Category(str, Enum):\n    BUSINESS = \"business\"\n    TECHNOLOGY = \"technology\"\n    POLITICS = \"politics\"\n    HEALTH = \"health\"\n    ENTERTAINMENT = \"entertainment\"\n    SPORTS = \"sports\"\n    SCIENCE = \"science\"\n    EDUCATION = \"education\"\n\nclass EnumMultiLabelClassification(BaseModel):\n    \"\"\"Multi-label classification using predefined categories\"\"\"\n\n    categories: List[Category] = Field(\n        description=\"List of applicable categories from the predefined set\"\n    )\n\ndef classify_with_enums(text: str) -> EnumMultiLabelClassification:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=EnumMultiLabelClassification,\n        messages=[\n            {\"role\": \"system\", \"content\": \"Classify the text into one or more predefined categories.\"},\n            {\"role\": \"user\", \"content\": f\"Text for classification: {text}\"}\n        ]\n    )\n\narticle = \"\"\"\n    New educational technology is transforming classrooms across the country.\n    Students are using AI-powered tools to enhance their learning experiences.\n\"\"\"\n\nresult = classify_with_enums(article)\n\nprint(f\"Text: '{article}'\")\nprint(f\"Categories: {', '.join([c.value for c in result.categories])}\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 62,
          "line_range": [
            62,
            97
          ]
        },
        {
          "code": "# Example Output: Categories: technology, education\n",
          "display_code": "",
          "annotation": "Example Output: Categories: technology, education",
          "is_comment": true,
          "start_line": 98,
          "line_range": [
            98,
            98
          ],
          "target_line_range": [
            99,
            144
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Dict\n\nclass LabelWithConfidence(BaseModel):\n    label: str\n    confidence: float = Field(gt=0, le=1)  # Between 0 and 1\n\nclass ConfidenceClassification(BaseModel):\n    labels: List[LabelWithConfidence] = Field(\n        description=\"List of applicable labels with confidence scores\"\n    )\n\ndef classify_with_confidence(text: str) -> ConfidenceClassification:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=ConfidenceClassification,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"\"\"\n                Classify the text into these categories and provide confidence scores (0-1):\n                - Technology\n                - Finance\n                - Health\n                - Sports\n                - Entertainment\n                Only include categories that apply with a confidence score over 0.4.\n                \"\"\"\n            },\n            {\"role\": \"user\", \"content\": f\"Text for classification: {text}\"}\n        ]\n    )\n\narticle = \"\"\"\n    The new smartphone features a built-in heart rate monitor that can alert users\n    about potential cardiac issues while they exercise.\n\"\"\"\n\nresult = classify_with_confidence(article)\n\nprint(f\"Text: '{article}'\")\nprint(\"Labels with confidence:\")\nfor label in result.labels:\n    print(f\"- {label.label}: {label.confidence:.2f}\")\n\n",
          "display_code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Dict\n\nclass LabelWithConfidence(BaseModel):\n    label: str\n    confidence: float = Field(gt=0, le=1)  # Between 0 and 1\n\nclass ConfidenceClassification(BaseModel):\n    labels: List[LabelWithConfidence] = Field(\n        description=\"List of applicable labels with confidence scores\"\n    )\n\ndef classify_with_confidence(text: str) -> ConfidenceClassification:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=ConfidenceClassification,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"\"\"\n                Classify the text into these categories and provide confidence scores (0-1):\n                - Technology\n                - Finance\n                - Health\n                - Sports\n                - Entertainment\n                Only include categories that apply with a confidence score over 0.4.\n                \"\"\"\n            },\n            {\"role\": \"user\", \"content\": f\"Text for classification: {text}\"}\n        ]\n    )\n\narticle = \"\"\"\n    The new smartphone features a built-in heart rate monitor that can alert users\n    about potential cardiac issues while they exercise.\n\"\"\"\n\nresult = classify_with_confidence(article)\n\nprint(f\"Text: '{article}'\")\nprint(\"Labels with confidence:\")\nfor label in result.labels:\n    print(f\"- {label.label}: {label.confidence:.2f}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 99,
          "line_range": [
            99,
            144
          ]
        },
        {
          "code": "# Example Output:\n# Labels with confidence:\n# - Technology: 0.95\n# - Health: 0.85\n# - Sports: 0.62\n",
          "display_code": "",
          "annotation": "Example Output:\nLabels with confidence:\n- Technology: 0.95\n- Health: 0.85\n- Sports: 0.62",
          "is_comment": true,
          "start_line": 145,
          "line_range": [
            145,
            149
          ],
          "target_line_range": [
            150,
            204
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass SubCategory(BaseModel):\n    name: str\n    confidence: float = Field(gt=0, le=1)\n\nclass MainCategory(BaseModel):\n    name: str\n    confidence: float = Field(gt=0, le=1)\n    subcategories: List[SubCategory] = []\n\nclass HierarchicalClassification(BaseModel):\n    categories: List[MainCategory] = Field(\n        description=\"Hierarchical categories with confidence scores\"\n    )\n\ndef classify_hierarchical(text: str) -> HierarchicalClassification:\n    return client.chat.completions.create(\n        model=\"gpt-4\",  # More complex tasks work better with GPT-4\n        response_model=HierarchicalClassification,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"\"\"\n                Classify the text into main categories and subcategories:\n\n                Main categories:\n                - Technology (subcategories: Hardware, Software, AI, Internet)\n                - Science (subcategories: Physics, Biology, Chemistry, Astronomy)\n                - Health (subcategories: Fitness, Nutrition, Medical, Mental Health)\n\n                Return only relevant categories with confidence scores.\n                \"\"\"\n            },\n            {\"role\": \"user\", \"content\": f\"Text for classification: {text}\"}\n        ]\n    )\n\narticle = \"\"\"\n    Researchers have developed a new AI algorithm that can detect early signs of\n    Alzheimer's disease from brain scans with 94% accuracy. The deep learning software\n    could help doctors diagnose patients years earlier than current methods.\n\"\"\"\n\nresult = classify_hierarchical(article)\n\nprint(f\"Text: '{article}'\")\nprint(\"Classification:\")\nfor category in result.categories:\n    print(f\"- {category.name} ({category.confidence:.2f})\")\n    for subcategory in category.subcategories:\n        print(f\"  - {subcategory.name} ({subcategory.confidence:.2f})\")\n\n",
          "display_code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass SubCategory(BaseModel):\n    name: str\n    confidence: float = Field(gt=0, le=1)\n\nclass MainCategory(BaseModel):\n    name: str\n    confidence: float = Field(gt=0, le=1)\n    subcategories: List[SubCategory] = []\n\nclass HierarchicalClassification(BaseModel):\n    categories: List[MainCategory] = Field(\n        description=\"Hierarchical categories with confidence scores\"\n    )\n\ndef classify_hierarchical(text: str) -> HierarchicalClassification:\n    return client.chat.completions.create(\n        model=\"gpt-4\",  # More complex tasks work better with GPT-4\n        response_model=HierarchicalClassification,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"\"\"\n                Classify the text into main categories and subcategories:\n\n                Main categories:\n                - Technology (subcategories: Hardware, Software, AI, Internet)\n                - Science (subcategories: Physics, Biology, Chemistry, Astronomy)\n                - Health (subcategories: Fitness, Nutrition, Medical, Mental Health)\n\n                Return only relevant categories with confidence scores.\n                \"\"\"\n            },\n            {\"role\": \"user\", \"content\": f\"Text for classification: {text}\"}\n        ]\n    )\n\narticle = \"\"\"\n    Researchers have developed a new AI algorithm that can detect early signs of\n    Alzheimer's disease from brain scans with 94% accuracy. The deep learning software\n    could help doctors diagnose patients years earlier than current methods.\n\"\"\"\n\nresult = classify_hierarchical(article)\n\nprint(f\"Text: '{article}'\")\nprint(\"Classification:\")\nfor category in result.categories:\n    print(f\"- {category.name} ({category.confidence:.2f})\")\n    for subcategory in category.subcategories:\n        print(f\"  - {subcategory.name} ({subcategory.confidence:.2f})\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 150,
          "line_range": [
            150,
            204
          ]
        },
        {
          "code": "# Example Output:\n# Classification:\n# - Technology (0.90)\n#   - AI (0.95)\n#   - Software (0.80)\n# - Health (0.85)\n#   - Medical (0.90)\n# - Science (0.75)\n#   - Biology (0.70)\n",
          "display_code": "",
          "annotation": "Example Output:\nClassification:\n- Technology (0.90)\n- AI (0.95)\n- Software (0.80)\n- Health (0.85)\n- Medical (0.90)\n- Science (0.75)\n- Biology (0.70)",
          "is_comment": true,
          "start_line": 205,
          "line_range": [
            205,
            213
          ],
          "target_line_range": [
            214,
            214
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 214,
          "line_range": [
            214,
            214
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python multi-label-classification.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "004-classification",
      "section_title": "Classification and Analysis"
    },
    {
      "id": "023-streaming-basics",
      "title": "Streaming Basics",
      "description": "",
      "order": 23,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Get started with streaming responses in Instructor for real-time processing.\n# \n# Streaming allows you to receive partial responses from LLMs as they're being generated, \n# rather than waiting for the complete response.\n#\n# Instructor offers two main ways to stream structured data:\n# \n# 1. Partial: Stream a single object as it's being populated field by field\n# 2. Iterable: Stream multiple complete objects one at a time\n",
          "display_code": "",
          "annotation": "Get started with streaming responses in Instructor for real-time processing.\n\nStreaming allows you to receive partial responses from LLMs as they're being generated,\nrather than waiting for the complete response.\n\nInstructor offers two main ways to stream structured data:\n\n1. Partial: Stream a single object as it's being populated field by field\n2. Iterable: Stream multiple complete objects one at a time",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            11
          ],
          "target_line_range": [
            12,
            20
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n    bio: str\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n    bio: str\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            20
          ]
        },
        {
          "code": "# Patch the OpenAI client\n",
          "display_code": "",
          "annotation": "Patch the OpenAI client",
          "is_comment": true,
          "start_line": 21,
          "line_range": [
            21,
            21
          ],
          "target_line_range": [
            22,
            23
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 22,
          "line_range": [
            22,
            23
          ]
        },
        {
          "code": "# Create a basic streaming response and process the chunks\n",
          "display_code": "",
          "annotation": "Create a basic streaming response and process the chunks",
          "is_comment": true,
          "start_line": 24,
          "line_range": [
            24,
            24
          ],
          "target_line_range": [
            25,
            34
          ]
        },
        {
          "code": "def stream_user_info():\n    stream = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        stream=True,  # Enable streaming\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate a profile for a fictional user named Alice who is 28 years old.\"}\n        ]\n    )\n\n",
          "display_code": "def stream_user_info():\n    stream = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        stream=True,  # Enable streaming\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate a profile for a fictional user named Alice who is 28 years old.\"}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 25,
          "line_range": [
            25,
            34
          ]
        },
        {
          "code": "    # Each chunk contains the partial model constructed so far\n",
          "display_code": "",
          "annotation": "Each chunk contains the partial model constructed so far",
          "is_comment": true,
          "start_line": 35,
          "line_range": [
            35,
            35
          ],
          "target_line_range": [
            36,
            38
          ]
        },
        {
          "code": "    for chunk in stream:\n        print(f\"Received chunk: {chunk}\")\n        \n",
          "display_code": "    for chunk in stream:\n        print(f\"Received chunk: {chunk}\")\n        \n",
          "annotation": "",
          "is_comment": false,
          "start_line": 36,
          "line_range": [
            36,
            38
          ]
        },
        {
          "code": "    # Return the final complete object\n",
          "display_code": "",
          "annotation": "Return the final complete object",
          "is_comment": true,
          "start_line": 39,
          "line_range": [
            39,
            39
          ],
          "target_line_range": [
            40,
            46
          ]
        },
        {
          "code": "    return chunk\n\nuser = stream_user_info()\nprint(f\"\\nFinal result: {user}\")\n\nfrom instructor import Partial\n\n",
          "display_code": "    return chunk\n\nuser = stream_user_info()\nprint(f\"\\nFinal result: {user}\")\n\nfrom instructor import Partial\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 40,
          "line_range": [
            40,
            46
          ]
        },
        {
          "code": "# Stream with Partial objects for field-by-field progress tracking\n",
          "display_code": "",
          "annotation": "Stream with Partial objects for field-by-field progress tracking",
          "is_comment": true,
          "start_line": 47,
          "line_range": [
            47,
            47
          ],
          "target_line_range": [
            48,
            56
          ]
        },
        {
          "code": "def stream_user_with_partial():\n    user_stream = client.chat.completions.create_partial(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate a profile for a fictional user named Bob who is 35 years old and works as a software developer.\"}\n        ]\n    )\n\n",
          "display_code": "def stream_user_with_partial():\n    user_stream = client.chat.completions.create_partial(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate a profile for a fictional user named Bob who is 35 years old and works as a software developer.\"}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 48,
          "line_range": [
            48,
            56
          ]
        },
        {
          "code": "    # Show progress as each field gets filled in\n",
          "display_code": "",
          "annotation": "Show progress as each field gets filled in",
          "is_comment": true,
          "start_line": 57,
          "line_range": [
            57,
            57
          ],
          "target_line_range": [
            58,
            60
          ]
        },
        {
          "code": "    print(\"Streaming user data:\")\n\n    for partial_user in user_stream:\n",
          "display_code": "    print(\"Streaming user data:\")\n\n    for partial_user in user_stream:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 58,
          "line_range": [
            58,
            60
          ]
        },
        {
          "code": "        # Fields appear as they're generated by the model\n",
          "display_code": "",
          "annotation": "Fields appear as they're generated by the model",
          "is_comment": true,
          "start_line": 61,
          "line_range": [
            61,
            61
          ],
          "target_line_range": [
            62,
            63
          ]
        },
        {
          "code": "        print(f\"Current state: name={partial_user.name}, age={partial_user.age}, bio={partial_user.bio!r}\")\n\n",
          "display_code": "        print(f\"Current state: name={partial_user.name}, age={partial_user.age}, bio={partial_user.bio!r}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 62,
          "line_range": [
            62,
            63
          ]
        },
        {
          "code": "# Example output:\n# Current state: name=None, age=None, bio=None\n# Current state: name='Bob', age=None, bio=None\n# Current state: name='Bob', age=35, bio=None\n# Current state: name='Bob', age=35, bio='Software developer with 10 years of experience...'\n",
          "display_code": "",
          "annotation": "Example output:\nCurrent state: name=None, age=None, bio=None\nCurrent state: name='Bob', age=None, bio=None\nCurrent state: name='Bob', age=35, bio=None\nCurrent state: name='Bob', age=35, bio='Software developer with 10 years of experience...'",
          "is_comment": true,
          "start_line": 64,
          "line_range": [
            64,
            68
          ],
          "target_line_range": [
            69,
            75
          ]
        },
        {
          "code": "\nfrom typing import Dict, Any\n\nclass ProgressTracker:\n    def __init__(self):\n        self.progress = {}\n\n",
          "display_code": "\nfrom typing import Dict, Any\n\nclass ProgressTracker:\n    def __init__(self):\n        self.progress = {}\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 69,
          "line_range": [
            69,
            75
          ]
        },
        {
          "code": "# Monitor completion percentage and track field updates\n",
          "display_code": "",
          "annotation": "Monitor completion percentage and track field updates",
          "is_comment": true,
          "start_line": 76,
          "line_range": [
            76,
            76
          ],
          "target_line_range": [
            77,
            77
          ]
        },
        {
          "code": "    def update(self, partial_user: Partial[User]):\n",
          "display_code": "    def update(self, partial_user: Partial[User]):\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 77,
          "line_range": [
            77,
            77
          ]
        },
        {
          "code": "        # Calculate what percentage of fields are now populated\n",
          "display_code": "",
          "annotation": "Calculate what percentage of fields are now populated",
          "is_comment": true,
          "start_line": 78,
          "line_range": [
            78,
            78
          ],
          "target_line_range": [
            79,
            82
          ]
        },
        {
          "code": "        total_fields = len(User.model_fields)\n        populated = sum(1 for v in [partial_user.name, partial_user.age, partial_user.bio] if v is not None)\n        completion = int(populated / total_fields * 100)\n        \n",
          "display_code": "        total_fields = len(User.model_fields)\n        populated = sum(1 for v in [partial_user.name, partial_user.age, partial_user.bio] if v is not None)\n        completion = int(populated / total_fields * 100)\n        \n",
          "annotation": "",
          "is_comment": false,
          "start_line": 79,
          "line_range": [
            79,
            82
          ]
        },
        {
          "code": "        # Build a dictionary of only the fields that have values\n",
          "display_code": "",
          "annotation": "Build a dictionary of only the fields that have values",
          "is_comment": true,
          "start_line": 83,
          "line_range": [
            83,
            83
          ],
          "target_line_range": [
            84,
            113
          ]
        },
        {
          "code": "        data = {}\n        if partial_user.name is not None:\n            data[\"name\"] = partial_user.name\n        if partial_user.age is not None:\n            data[\"age\"] = partial_user.age\n        if partial_user.bio is not None:\n            data[\"bio\"] = partial_user.bio\n\n        self.progress = {\n            \"completion\": f\"{completion}%\",\n            \"data\": data\n        }\n\n        return self.progress\n\ndef stream_with_progress():\n    tracker = ProgressTracker()\n\n    user_stream = client.chat.completions.create_partial(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate a profile for a fictional user named Carol who is 42 years old.\"}\n        ]\n    )\n\n    for partial_user in user_stream:\n        progress = tracker.update(partial_user)\n        print(f\"Progress: {progress['completion']} - Current data: {progress['data']}\")\n\n",
          "display_code": "        data = {}\n        if partial_user.name is not None:\n            data[\"name\"] = partial_user.name\n        if partial_user.age is not None:\n            data[\"age\"] = partial_user.age\n        if partial_user.bio is not None:\n            data[\"bio\"] = partial_user.bio\n\n        self.progress = {\n            \"completion\": f\"{completion}%\",\n            \"data\": data\n        }\n\n        return self.progress\n\ndef stream_with_progress():\n    tracker = ProgressTracker()\n\n    user_stream = client.chat.completions.create_partial(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate a profile for a fictional user named Carol who is 42 years old.\"}\n        ]\n    )\n\n    for partial_user in user_stream:\n        progress = tracker.update(partial_user)\n        print(f\"Progress: {progress['completion']} - Current data: {progress['data']}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 84,
          "line_range": [
            84,
            113
          ]
        },
        {
          "code": "# Example output:\n# Progress: 33% - Current data: {'name': 'Carol'}\n# Progress: 66% - Current data: {'name': 'Carol', 'age': 42}\n# Progress: 100% - Current data: {'name': 'Carol', 'age': 42, 'bio': 'Carol is a passionate...'}\n",
          "display_code": "",
          "annotation": "Example output:\nProgress: 33% - Current data: {'name': 'Carol'}\nProgress: 66% - Current data: {'name': 'Carol', 'age': 42}\nProgress: 100% - Current data: {'name': 'Carol', 'age': 42, 'bio': 'Carol is a passionate...'}",
          "is_comment": true,
          "start_line": 114,
          "line_range": [
            114,
            117
          ],
          "target_line_range": [
            118,
            121
          ]
        },
        {
          "code": "\nimport asyncio\nfrom openai import AsyncOpenAI\n\n",
          "display_code": "\nimport asyncio\nfrom openai import AsyncOpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 118,
          "line_range": [
            118,
            121
          ]
        },
        {
          "code": "# Demonstrate async streaming with await syntax\n",
          "display_code": "",
          "annotation": "Demonstrate async streaming with await syntax",
          "is_comment": true,
          "start_line": 122,
          "line_range": [
            122,
            122
          ],
          "target_line_range": [
            123,
            125
          ]
        },
        {
          "code": "async def stream_async():\n    async_client = instructor.from_openai(AsyncOpenAI())\n\n",
          "display_code": "async def stream_async():\n    async_client = instructor.from_openai(AsyncOpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 123,
          "line_range": [
            123,
            125
          ]
        },
        {
          "code": "    # Use async/await pattern for non-blocking streaming\n",
          "display_code": "",
          "annotation": "Use async/await pattern for non-blocking streaming",
          "is_comment": true,
          "start_line": 126,
          "line_range": [
            126,
            126
          ],
          "target_line_range": [
            127,
            134
          ]
        },
        {
          "code": "    user_stream = await async_client.chat.completions.create_partial(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate a profile for a fictional user named Dave who is 31 years old.\"}\n        ]\n    )\n\n",
          "display_code": "    user_stream = await async_client.chat.completions.create_partial(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate a profile for a fictional user named Dave who is 31 years old.\"}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 127,
          "line_range": [
            127,
            134
          ]
        },
        {
          "code": "    # Process stream with async for loop\n",
          "display_code": "",
          "annotation": "Process stream with async for loop",
          "is_comment": true,
          "start_line": 135,
          "line_range": [
            135,
            135
          ],
          "target_line_range": [
            136,
            138
          ]
        },
        {
          "code": "    async for partial_user in user_stream:\n        print(f\"Async stream update: {partial_user}\")\n\n",
          "display_code": "    async for partial_user in user_stream:\n        print(f\"Async stream update: {partial_user}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 136,
          "line_range": [
            136,
            138
          ]
        },
        {
          "code": "# Run the async function\n",
          "display_code": "",
          "annotation": "Run the async function",
          "is_comment": true,
          "start_line": 139,
          "line_range": [
            139,
            139
          ],
          "target_line_range": [
            140,
            141
          ]
        },
        {
          "code": "asyncio.run(stream_async())\n\n",
          "display_code": "asyncio.run(stream_async())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 140,
          "line_range": [
            140,
            141
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python streaming-basics.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "005-streaming",
      "section_title": "Streaming"
    },
    {
      "id": "025-streaming-lists",
      "title": "Streaming Lists",
      "description": "",
      "order": 25,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Stream collections of objects one at a time with Instructor.\n",
          "display_code": "",
          "annotation": "Stream collections of objects one at a time with Instructor.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            13
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\nfrom typing import List\nimport instructor\nfrom openai import OpenAI\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\n",
          "display_code": "from pydantic import BaseModel, Field\nfrom typing import List\nimport instructor\nfrom openai import OpenAI\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            13
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            16
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            16
          ]
        },
        {
          "code": "# Create a streaming iterable\n",
          "display_code": "",
          "annotation": "Create a streaming iterable",
          "is_comment": true,
          "start_line": 17,
          "line_range": [
            17,
            17
          ],
          "target_line_range": [
            18,
            30
          ]
        },
        {
          "code": "people_stream = client.chat.completions.create_iterable(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,  # Note: no List[] wrapper needed here\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n            Generate profiles for three different people:\n            1. A software engineer in their 30s\n            2. A teacher in their 40s\n            3. A doctor in their 50s\n        \"\"\"}\n    ]\n)\n\n",
          "display_code": "people_stream = client.chat.completions.create_iterable(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,  # Note: no List[] wrapper needed here\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n            Generate profiles for three different people:\n            1. A software engineer in their 30s\n            2. A teacher in their 40s\n            3. A doctor in their 50s\n        \"\"\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 18,
          "line_range": [
            18,
            30
          ]
        },
        {
          "code": "# Process each person as they are completed\n",
          "display_code": "",
          "annotation": "Process each person as they are completed",
          "is_comment": true,
          "start_line": 31,
          "line_range": [
            31,
            31
          ],
          "target_line_range": [
            32,
            37
          ]
        },
        {
          "code": "print(\"Receiving people one at a time:\")\nfor i, person in enumerate(people_stream, 1):\n    print(f\"\\nPerson {i}:\")\n    print(f\"Name: {person.name}\")\n    print(f\"Age: {person.age}\")\n    print(f\"Occupation: {person.occupation}\")\n",
          "display_code": "print(\"Receiving people one at a time:\")\nfor i, person in enumerate(people_stream, 1):\n    print(f\"\\nPerson {i}:\")\n    print(f\"Name: {person.name}\")\n    print(f\"Age: {person.age}\")\n    print(f\"Occupation: {person.occupation}\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 32,
          "line_range": [
            32,
            37
          ]
        },
        {
          "code": "    # Note: Each person is fully complete when received\n",
          "display_code": "",
          "annotation": "Note: Each person is fully complete when received",
          "is_comment": true,
          "start_line": 38,
          "line_range": [
            38,
            38
          ],
          "target_line_range": [
            39,
            39
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 39,
          "line_range": [
            39,
            39
          ]
        },
        {
          "code": "# Example output:\n# Receiving people one at a time:\n#\n# Person 1:\n# Name: Michael Chen\n# Age: 34\n# Occupation: software engineer\n#\n# Person 2:\n# Name: Sarah Johnson\n# Age: 42\n# Occupation: teacher\n#\n# Person 3:\n# Name: Robert Garcia\n# Age: 56\n# Occupation: doctor\n",
          "display_code": "",
          "annotation": "Example output:\nReceiving people one at a time:\n\nPerson 1:\nName: Michael Chen\nAge: 34\nOccupation: software engineer\n\nPerson 2:\nName: Sarah Johnson\nAge: 42\nOccupation: teacher\n\nPerson 3:\nName: Robert Garcia\nAge: 56\nOccupation: doctor",
          "is_comment": true,
          "start_line": 40,
          "line_range": [
            40,
            56
          ],
          "target_line_range": [
            57,
            68
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass Book(BaseModel):\n    title: str\n    author: str\n    year: int\n    genre: str\n    summary: str = Field(description=\"Brief summary of the book's plot\")\n    rating: Optional[float] = Field(None, ge=0, le=5, description=\"Rating from 0-5 stars\")\n\n",
          "display_code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass Book(BaseModel):\n    title: str\n    author: str\n    year: int\n    genre: str\n    summary: str = Field(description=\"Brief summary of the book's plot\")\n    rating: Optional[float] = Field(None, ge=0, le=5, description=\"Rating from 0-5 stars\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 57,
          "line_range": [
            57,
            68
          ]
        },
        {
          "code": "# Create a streaming iterable for complex objects\n",
          "display_code": "",
          "annotation": "Create a streaming iterable for complex objects",
          "is_comment": true,
          "start_line": 69,
          "line_range": [
            69,
            69
          ],
          "target_line_range": [
            70,
            81
          ]
        },
        {
          "code": "books_stream = client.chat.completions.create_iterable(\n    model=\"gpt-3.5-turbo\",\n    response_model=Book,\n    messages=[\n        {\"role\": \"system\", \"content\": \"Generate detailed book entries with accurate information.\"},\n        {\"role\": \"user\", \"content\": \"\"\"\n            Generate entries for three classic science fiction books.\n            Include their titles, authors, publication years, and summaries.\n        \"\"\"}\n    ]\n)\n\n",
          "display_code": "books_stream = client.chat.completions.create_iterable(\n    model=\"gpt-3.5-turbo\",\n    response_model=Book,\n    messages=[\n        {\"role\": \"system\", \"content\": \"Generate detailed book entries with accurate information.\"},\n        {\"role\": \"user\", \"content\": \"\"\"\n            Generate entries for three classic science fiction books.\n            Include their titles, authors, publication years, and summaries.\n        \"\"\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 70,
          "line_range": [
            70,
            81
          ]
        },
        {
          "code": "# Process each book as it's generated\n",
          "display_code": "",
          "annotation": "Process each book as it's generated",
          "is_comment": true,
          "start_line": 82,
          "line_range": [
            82,
            82
          ],
          "target_line_range": [
            83,
            99
          ]
        },
        {
          "code": "print(\"Streaming book data:\")\nfor i, book in enumerate(books_stream, 1):\n    print(f\"\\nBook {i}: {book.title} ({book.year})\")\n    print(f\"Author: {book.author}\")\n    print(f\"Genre: {book.genre}\")\n    print(f\"Rating: {book.rating if book.rating is not None else 'Not rated'}\")\n    print(f\"Summary: {book.summary}\")\n\nfrom typing import List, Dict, Any\nimport time\n\nclass Task(BaseModel):\n    title: str\n    priority: str\n    estimated_hours: float\n    assigned_to: Optional[str] = None\n\n",
          "display_code": "print(\"Streaming book data:\")\nfor i, book in enumerate(books_stream, 1):\n    print(f\"\\nBook {i}: {book.title} ({book.year})\")\n    print(f\"Author: {book.author}\")\n    print(f\"Genre: {book.genre}\")\n    print(f\"Rating: {book.rating if book.rating is not None else 'Not rated'}\")\n    print(f\"Summary: {book.summary}\")\n\nfrom typing import List, Dict, Any\nimport time\n\nclass Task(BaseModel):\n    title: str\n    priority: str\n    estimated_hours: float\n    assigned_to: Optional[str] = None\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 83,
          "line_range": [
            83,
            99
          ]
        },
        {
          "code": "# Setup for real-time processing\n",
          "display_code": "",
          "annotation": "Setup for real-time processing",
          "is_comment": true,
          "start_line": 100,
          "line_range": [
            100,
            100
          ],
          "target_line_range": [
            101,
            105
          ]
        },
        {
          "code": "all_tasks = []\ntotal_hours = 0\nby_priority = {\"high\": 0, \"medium\": 0, \"low\": 0}\nby_assignee = {}\n\n",
          "display_code": "all_tasks = []\ntotal_hours = 0\nby_priority = {\"high\": 0, \"medium\": 0, \"low\": 0}\nby_assignee = {}\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 101,
          "line_range": [
            101,
            105
          ]
        },
        {
          "code": "# Create a streaming iterable\n",
          "display_code": "",
          "annotation": "Create a streaming iterable",
          "is_comment": true,
          "start_line": 106,
          "line_range": [
            106,
            106
          ],
          "target_line_range": [
            107,
            118
          ]
        },
        {
          "code": "tasks_stream = client.chat.completions.create_iterable(\n    model=\"gpt-3.5-turbo\",\n    response_model=Task,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n            Generate 5 tasks for a software development sprint.\n            Include high, medium, and low priority tasks.\n            Assign team members: Alex, Jamie, Taylor, and Morgan.\n        \"\"\"}\n    ]\n)\n\n",
          "display_code": "tasks_stream = client.chat.completions.create_iterable(\n    model=\"gpt-3.5-turbo\",\n    response_model=Task,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n            Generate 5 tasks for a software development sprint.\n            Include high, medium, and low priority tasks.\n            Assign team members: Alex, Jamie, Taylor, and Morgan.\n        \"\"\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 107,
          "line_range": [
            107,
            118
          ]
        },
        {
          "code": "# Process tasks in real-time\n",
          "display_code": "",
          "annotation": "Process tasks in real-time",
          "is_comment": true,
          "start_line": 119,
          "line_range": [
            119,
            119
          ],
          "target_line_range": [
            120,
            123
          ]
        },
        {
          "code": "print(\"Project task planning:\")\nprint(\"---------------------\")\n\nfor task in tasks_stream:\n",
          "display_code": "print(\"Project task planning:\")\nprint(\"---------------------\")\n\nfor task in tasks_stream:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 120,
          "line_range": [
            120,
            123
          ]
        },
        {
          "code": "    # Update statistics\n",
          "display_code": "",
          "annotation": "Update statistics",
          "is_comment": true,
          "start_line": 124,
          "line_range": [
            124,
            124
          ],
          "target_line_range": [
            125,
            131
          ]
        },
        {
          "code": "    all_tasks.append(task)\n    total_hours += task.estimated_hours\n    by_priority[task.priority.lower()] += 1\n\n    if task.assigned_to:\n        by_assignee[task.assigned_to] = by_assignee.get(task.assigned_to, 0) + 1\n\n",
          "display_code": "    all_tasks.append(task)\n    total_hours += task.estimated_hours\n    by_priority[task.priority.lower()] += 1\n\n    if task.assigned_to:\n        by_assignee[task.assigned_to] = by_assignee.get(task.assigned_to, 0) + 1\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 125,
          "line_range": [
            125,
            131
          ]
        },
        {
          "code": "    # Print the task\n",
          "display_code": "",
          "annotation": "Print the task",
          "is_comment": true,
          "start_line": 132,
          "line_range": [
            132,
            132
          ],
          "target_line_range": [
            133,
            137
          ]
        },
        {
          "code": "    print(f\"\\nNew Task: {task.title}\")\n    print(f\"Priority: {task.priority}\")\n    print(f\"Estimate: {task.estimated_hours} hours\")\n    print(f\"Assigned to: {task.assigned_to or 'Unassigned'}\")\n\n",
          "display_code": "    print(f\"\\nNew Task: {task.title}\")\n    print(f\"Priority: {task.priority}\")\n    print(f\"Estimate: {task.estimated_hours} hours\")\n    print(f\"Assigned to: {task.assigned_to or 'Unassigned'}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 133,
          "line_range": [
            133,
            137
          ]
        },
        {
          "code": "    # Print current statistics\n",
          "display_code": "",
          "annotation": "Print current statistics",
          "is_comment": true,
          "start_line": 138,
          "line_range": [
            138,
            138
          ],
          "target_line_range": [
            139,
            144
          ]
        },
        {
          "code": "    print(\"\\nCurrent Sprint Stats:\")\n    print(f\"Tasks planned: {len(all_tasks)}\")\n    print(f\"Total hours: {total_hours:.1f}\")\n    print(f\"By priority: {by_priority}\")\n    print(f\"By assignee: {by_assignee}\")\n\n",
          "display_code": "    print(\"\\nCurrent Sprint Stats:\")\n    print(f\"Tasks planned: {len(all_tasks)}\")\n    print(f\"Total hours: {total_hours:.1f}\")\n    print(f\"By priority: {by_priority}\")\n    print(f\"By assignee: {by_assignee}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 139,
          "line_range": [
            139,
            144
          ]
        },
        {
          "code": "    # Simulate a pause for real-time updates\n",
          "display_code": "",
          "annotation": "Simulate a pause for real-time updates",
          "is_comment": true,
          "start_line": 145,
          "line_range": [
            145,
            145
          ],
          "target_line_range": [
            146,
            167
          ]
        },
        {
          "code": "    time.sleep(0.5)\n\nprint(\"\\nSprint planning complete!\")\n\nfrom typing import Dict, List, Any, Generator, TypeVar, Generic\n\nT = TypeVar('T')\n\ndef combine_streams(streams: Dict[str, Generator[T, None, None]]) -> Generator[Dict[str, T], None, None]:\n    \"\"\"Combine multiple iterables with identification.\"\"\"\n    active_streams = streams.copy()\n    results = {key: None for key in streams}\n\n    while active_streams:\n        for key, stream in list(active_streams.items()):\n            try:\n                value = next(stream)\n                results[key] = value\n                yield results.copy()\n            except StopIteration:\n                del active_streams[key]\n\n",
          "display_code": "    time.sleep(0.5)\n\nprint(\"\\nSprint planning complete!\")\n\nfrom typing import Dict, List, Any, Generator, TypeVar, Generic\n\nT = TypeVar('T')\n\ndef combine_streams(streams: Dict[str, Generator[T, None, None]]) -> Generator[Dict[str, T], None, None]:\n    \"\"\"Combine multiple iterables with identification.\"\"\"\n    active_streams = streams.copy()\n    results = {key: None for key in streams}\n\n    while active_streams:\n        for key, stream in list(active_streams.items()):\n            try:\n                value = next(stream)\n                results[key] = value\n                yield results.copy()\n            except StopIteration:\n                del active_streams[key]\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 146,
          "line_range": [
            146,
            167
          ]
        },
        {
          "code": "# Create multiple document iterables\n",
          "display_code": "",
          "annotation": "Create multiple document iterables",
          "is_comment": true,
          "start_line": 168,
          "line_range": [
            168,
            168
          ],
          "target_line_range": [
            169,
            174
          ]
        },
        {
          "code": "class DocumentSummary(BaseModel):\n    title: str\n    content_type: str\n    key_points: List[str]\n    word_count: int\n\n",
          "display_code": "class DocumentSummary(BaseModel):\n    title: str\n    content_type: str\n    key_points: List[str]\n    word_count: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 169,
          "line_range": [
            169,
            174
          ]
        },
        {
          "code": "# Generate different types of documents\n",
          "display_code": "",
          "annotation": "Generate different types of documents",
          "is_comment": true,
          "start_line": 175,
          "line_range": [
            175,
            175
          ],
          "target_line_range": [
            176,
            181
          ]
        },
        {
          "code": "prompts = {\n    \"emails\": \"Generate summaries for 3 important emails about project deadlines\",\n    \"reports\": \"Generate summaries for 2 financial reports about quarterly earnings\",\n    \"articles\": \"Generate summaries for 2 news articles about technology trends\"\n}\n\n",
          "display_code": "prompts = {\n    \"emails\": \"Generate summaries for 3 important emails about project deadlines\",\n    \"reports\": \"Generate summaries for 2 financial reports about quarterly earnings\",\n    \"articles\": \"Generate summaries for 2 news articles about technology trends\"\n}\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 176,
          "line_range": [
            176,
            181
          ]
        },
        {
          "code": "# Create multiple streams\n",
          "display_code": "",
          "annotation": "Create multiple streams",
          "is_comment": true,
          "start_line": 182,
          "line_range": [
            182,
            182
          ],
          "target_line_range": [
            183,
            190
          ]
        },
        {
          "code": "streams = {}\nfor category, prompt in prompts.items():\n    streams[category] = client.chat.completions.create_iterable(\n        model=\"gpt-3.5-turbo\",\n        response_model=DocumentSummary,\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n\n",
          "display_code": "streams = {}\nfor category, prompt in prompts.items():\n    streams[category] = client.chat.completions.create_iterable(\n        model=\"gpt-3.5-turbo\",\n        response_model=DocumentSummary,\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 183,
          "line_range": [
            183,
            190
          ]
        },
        {
          "code": "# Process combined streams as they arrive\n",
          "display_code": "",
          "annotation": "Process combined streams as they arrive",
          "is_comment": true,
          "start_line": 191,
          "line_range": [
            191,
            191
          ],
          "target_line_range": [
            192,
            209
          ]
        },
        {
          "code": "for i, result in enumerate(combine_streams(streams), 1):\n    print(f\"\\nUpdate {i}:\")\n    for category, doc in result.items():\n        if doc:\n            print(f\"  {category.upper()}: {doc.title}\")\n        else:\n            print(f\"  {category.upper()}: No documents yet\")\n\nfrom typing import List, Optional, Iterator\nimport itertools\n\nclass NewsHeadline(BaseModel):\n    title: str\n    source: str\n    category: str\n    publish_date: str\n    summary: str\n\n",
          "display_code": "for i, result in enumerate(combine_streams(streams), 1):\n    print(f\"\\nUpdate {i}:\")\n    for category, doc in result.items():\n        if doc:\n            print(f\"  {category.upper()}: {doc.title}\")\n        else:\n            print(f\"  {category.upper()}: No documents yet\")\n\nfrom typing import List, Optional, Iterator\nimport itertools\n\nclass NewsHeadline(BaseModel):\n    title: str\n    source: str\n    category: str\n    publish_date: str\n    summary: str\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 192,
          "line_range": [
            192,
            209
          ]
        },
        {
          "code": "# Generate a potentially large stream of headlines\n",
          "display_code": "",
          "annotation": "Generate a potentially large stream of headlines",
          "is_comment": true,
          "start_line": 210,
          "line_range": [
            210,
            210
          ],
          "target_line_range": [
            211,
            218
          ]
        },
        {
          "code": "headlines_stream = client.chat.completions.create_iterable(\n    model=\"gpt-3.5-turbo\",\n    response_model=NewsHeadline,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Generate 10 fictional technology news headlines from the past week.\"}\n    ]\n)\n\n",
          "display_code": "headlines_stream = client.chat.completions.create_iterable(\n    model=\"gpt-3.5-turbo\",\n    response_model=NewsHeadline,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Generate 10 fictional technology news headlines from the past week.\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 211,
          "line_range": [
            211,
            218
          ]
        },
        {
          "code": "# Get only the first 3 headlines\n",
          "display_code": "",
          "annotation": "Get only the first 3 headlines",
          "is_comment": true,
          "start_line": 219,
          "line_range": [
            219,
            219
          ],
          "target_line_range": [
            220,
            227
          ]
        },
        {
          "code": "print(\"Top Headlines:\")\nfor i, headline in enumerate(itertools.islice(headlines_stream, 3)):\n    print(f\"\\nHeadline {i+1}: {headline.title}\")\n    print(f\"Source: {headline.source}\")\n    print(f\"Category: {headline.category}\")\n    print(f\"Date: {headline.publish_date}\")\n    print(f\"Summary: {headline.summary}\")\n\n",
          "display_code": "print(\"Top Headlines:\")\nfor i, headline in enumerate(itertools.islice(headlines_stream, 3)):\n    print(f\"\\nHeadline {i+1}: {headline.title}\")\n    print(f\"Source: {headline.source}\")\n    print(f\"Category: {headline.category}\")\n    print(f\"Date: {headline.publish_date}\")\n    print(f\"Summary: {headline.summary}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 220,
          "line_range": [
            220,
            227
          ]
        },
        {
          "code": "# Note: The rest of the stream is not processed, which saves tokens\n",
          "display_code": "",
          "annotation": "Note: The rest of the stream is not processed, which saves tokens",
          "is_comment": true,
          "start_line": 228,
          "line_range": [
            228,
            228
          ],
          "target_line_range": [
            229,
            230
          ]
        },
        {
          "code": "print(\"\\nShowing only the first 3 headlines.\")\n\n",
          "display_code": "print(\"\\nShowing only the first 3 headlines.\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 229,
          "line_range": [
            229,
            230
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python streaming-lists.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "005-streaming",
      "section_title": "Streaming"
    },
    {
      "id": "028-recursive-structures",
      "title": "Recursive Structures",
      "description": "",
      "order": 28,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Create and work with self-referential data structures using Instructor. Enables extraction of hierarchical data like organizational charts and family trees.\n",
          "display_code": "",
          "annotation": "Create and work with self-referential data structures using Instructor. Enables extraction of hierarchical data like organizational charts and family trees.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor supports defining and extracting recursive data structures, where a model can reference itself in its definition. This is particularly useful for representing hierarchical data like file systems, org charts, or nested comments.\n",
          "display_code": "",
          "annotation": "Instructor supports defining and extracting recursive data structures, where a model can reference itself in its definition. This is particularly useful for representing hierarchical data like file systems, org charts, or nested comments.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nimport enum\nfrom pydantic import BaseModel, Field\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nimport enum\nfrom pydantic import BaseModel, Field\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define the node type enum\n",
          "display_code": "",
          "annotation": "Define the node type enum",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            18
          ]
        },
        {
          "code": "class NodeType(str, enum.Enum):\n    FILE = \"file\"\n    FOLDER = \"folder\"\n\n",
          "display_code": "class NodeType(str, enum.Enum):\n    FILE = \"file\"\n    FOLDER = \"folder\"\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            18
          ]
        },
        {
          "code": "# Define the Node class with a self-reference for children\n",
          "display_code": "",
          "annotation": "Define the Node class with a self-reference for children",
          "is_comment": true,
          "start_line": 19,
          "line_range": [
            19,
            19
          ],
          "target_line_range": [
            20,
            30
          ]
        },
        {
          "code": "class Node(BaseModel):\n    name: str = Field(..., description=\"Name of the node\")\n    children: list[\"Node\"] = Field(\n        default_factory=list,\n        description=\"List of children nodes, only applicable for folders\"\n    )\n    node_type: NodeType = Field(\n        default=NodeType.FILE,\n        description=\"Either a file or folder\"\n    )\n\n",
          "display_code": "class Node(BaseModel):\n    name: str = Field(..., description=\"Name of the node\")\n    children: list[\"Node\"] = Field(\n        default_factory=list,\n        description=\"List of children nodes, only applicable for folders\"\n    )\n    node_type: NodeType = Field(\n        default=NodeType.FILE,\n        description=\"Either a file or folder\"\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 20,
          "line_range": [
            20,
            30
          ]
        },
        {
          "code": "# Important! For recursive models, we need to rebuild the model\n",
          "display_code": "",
          "annotation": "Important! For recursive models, we need to rebuild the model",
          "is_comment": true,
          "start_line": 31,
          "line_range": [
            31,
            31
          ],
          "target_line_range": [
            32,
            33
          ]
        },
        {
          "code": "Node.model_rebuild()\n\n",
          "display_code": "Node.model_rebuild()\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 32,
          "line_range": [
            32,
            33
          ]
        },
        {
          "code": "# Create a container model for the root node\n",
          "display_code": "",
          "annotation": "Create a container model for the root node",
          "is_comment": true,
          "start_line": 34,
          "line_range": [
            34,
            34
          ],
          "target_line_range": [
            35,
            37
          ]
        },
        {
          "code": "class DirectoryTree(BaseModel):\n    root: Node = Field(..., description=\"Root folder of the directory tree\")\n\n",
          "display_code": "class DirectoryTree(BaseModel):\n    root: Node = Field(..., description=\"Root folder of the directory tree\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 35,
          "line_range": [
            35,
            37
          ]
        },
        {
          "code": "# Extract a directory tree from text representation\n",
          "display_code": "",
          "annotation": "Extract a directory tree from text representation",
          "is_comment": true,
          "start_line": 38,
          "line_range": [
            38,
            38
          ],
          "target_line_range": [
            39,
            54
          ]
        },
        {
          "code": "def parse_directory_structure(text_representation: str) -> DirectoryTree:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=DirectoryTree,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Parse the following directory structure into a tree.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": f\"Parse this directory structure:\\n{text_representation}\"\n            }\n        ]\n    )\n\n",
          "display_code": "def parse_directory_structure(text_representation: str) -> DirectoryTree:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=DirectoryTree,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Parse the following directory structure into a tree.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": f\"Parse this directory structure:\\n{text_representation}\"\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 39,
          "line_range": [
            39,
            54
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 55,
          "line_range": [
            55,
            55
          ],
          "target_line_range": [
            56,
            68
          ]
        },
        {
          "code": "directory_structure = '''\nroot\n\u251c\u2500\u2500 images\n\u2502   \u251c\u2500\u2500 logo.png\n\u2502   \u2514\u2500\u2500 banner.jpg\n\u2514\u2500\u2500 docs\n    \u251c\u2500\u2500 readme.md\n    \u2514\u2500\u2500 config\n        \u2514\u2500\u2500 settings.json\n'''\n\nresult = parse_directory_structure(directory_structure)\n\n",
          "display_code": "directory_structure = '''\nroot\n\u251c\u2500\u2500 images\n\u2502   \u251c\u2500\u2500 logo.png\n\u2502   \u2514\u2500\u2500 banner.jpg\n\u2514\u2500\u2500 docs\n    \u251c\u2500\u2500 readme.md\n    \u2514\u2500\u2500 config\n        \u2514\u2500\u2500 settings.json\n'''\n\nresult = parse_directory_structure(directory_structure)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 56,
          "line_range": [
            56,
            68
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python recursive-structures.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "006-advanced-structures",
      "section_title": "Advanced Structures"
    },
    {
      "id": "029-knowledge-graphs",
      "title": "Knowledge Graphs",
      "description": "",
      "order": 29,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Extract interconnected knowledge graphs from text using Instructor. This approach helps visualize relationships between concepts and entities.\n",
          "display_code": "",
          "annotation": "Extract interconnected knowledge graphs from text using Instructor. This approach helps visualize relationships between concepts and entities.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor can be used to extract structured knowledge graphs from text. A knowledge graph represents entities and their relationships, making complex information easier to understand and visualize.\n",
          "display_code": "",
          "annotation": "Instructor can be used to extract structured knowledge graphs from text. A knowledge graph represents entities and their relationships, making complex information easier to understand and visualize.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            9
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            9
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 10,
          "line_range": [
            10,
            10
          ],
          "target_line_range": [
            11,
            12
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 11,
          "line_range": [
            11,
            12
          ]
        },
        {
          "code": "# Define the node structure\n",
          "display_code": "",
          "annotation": "Define the node structure",
          "is_comment": true,
          "start_line": 13,
          "line_range": [
            13,
            13
          ],
          "target_line_range": [
            14,
            18
          ]
        },
        {
          "code": "class Node(BaseModel):\n    id: int\n    label: str\n    color: str\n\n",
          "display_code": "class Node(BaseModel):\n    id: int\n    label: str\n    color: str\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 14,
          "line_range": [
            14,
            18
          ]
        },
        {
          "code": "# Define the edge structure\n",
          "display_code": "",
          "annotation": "Define the edge structure",
          "is_comment": true,
          "start_line": 19,
          "line_range": [
            19,
            19
          ],
          "target_line_range": [
            20,
            25
          ]
        },
        {
          "code": "class Edge(BaseModel):\n    source: int\n    target: int\n    label: str\n    color: str = \"black\"\n\n",
          "display_code": "class Edge(BaseModel):\n    source: int\n    target: int\n    label: str\n    color: str = \"black\"\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 20,
          "line_range": [
            20,
            25
          ]
        },
        {
          "code": "# Define the knowledge graph structure\n",
          "display_code": "",
          "annotation": "Define the knowledge graph structure",
          "is_comment": true,
          "start_line": 26,
          "line_range": [
            26,
            26
          ],
          "target_line_range": [
            27,
            30
          ]
        },
        {
          "code": "class KnowledgeGraph(BaseModel):\n    nodes: list[Node] = Field(..., default_factory=list)\n    edges: list[Edge] = Field(..., default_factory=list)\n\n",
          "display_code": "class KnowledgeGraph(BaseModel):\n    nodes: list[Node] = Field(..., default_factory=list)\n    edges: list[Edge] = Field(..., default_factory=list)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 27,
          "line_range": [
            27,
            30
          ]
        },
        {
          "code": "# Extract a knowledge graph from text\n",
          "display_code": "",
          "annotation": "Extract a knowledge graph from text",
          "is_comment": true,
          "start_line": 31,
          "line_range": [
            31,
            31
          ],
          "target_line_range": [
            32,
            43
          ]
        },
        {
          "code": "def generate_knowledge_graph(input_text: str) -> KnowledgeGraph:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Create a detailed knowledge graph for: {input_text}\"\n            }\n        ],\n        response_model=KnowledgeGraph\n    )\n\n",
          "display_code": "def generate_knowledge_graph(input_text: str) -> KnowledgeGraph:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Create a detailed knowledge graph for: {input_text}\"\n            }\n        ],\n        response_model=KnowledgeGraph\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 32,
          "line_range": [
            32,
            43
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 44,
          "line_range": [
            44,
            44
          ],
          "target_line_range": [
            45,
            46
          ]
        },
        {
          "code": "graph = generate_knowledge_graph(\"Quantum mechanics and its applications\")\n\n",
          "display_code": "graph = generate_knowledge_graph(\"Quantum mechanics and its applications\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 45,
          "line_range": [
            45,
            46
          ]
        },
        {
          "code": "# Print the nodes and edges\n",
          "display_code": "",
          "annotation": "Print the nodes and edges",
          "is_comment": true,
          "start_line": 47,
          "line_range": [
            47,
            47
          ],
          "target_line_range": [
            48,
            53
          ]
        },
        {
          "code": "for node in graph.nodes:\n    print(f\"Node {node.id}: {node.label} ({node.color})\")\n\nfor edge in graph.edges:\n    print(f\"Edge: {edge.source} --({edge.label})--> {edge.target}\")\n\n",
          "display_code": "for node in graph.nodes:\n    print(f\"Node {node.id}: {node.label} ({node.color})\")\n\nfor edge in graph.edges:\n    print(f\"Edge: {edge.source} --({edge.label})--> {edge.target}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 48,
          "line_range": [
            48,
            53
          ]
        },
        {
          "code": "# To visualize the knowledge graph, you can use libraries like graphviz:\n",
          "display_code": "",
          "annotation": "To visualize the knowledge graph, you can use libraries like graphviz:",
          "is_comment": true,
          "start_line": 54,
          "line_range": [
            54,
            54
          ],
          "target_line_range": [
            55,
            59
          ]
        },
        {
          "code": "from graphviz import Digraph\n\ndef visualize_knowledge_graph(kg: KnowledgeGraph):\n    dot = Digraph(comment=\"Knowledge Graph\")\n\n",
          "display_code": "from graphviz import Digraph\n\ndef visualize_knowledge_graph(kg: KnowledgeGraph):\n    dot = Digraph(comment=\"Knowledge Graph\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 55,
          "line_range": [
            55,
            59
          ]
        },
        {
          "code": "    # Add nodes\n",
          "display_code": "",
          "annotation": "Add nodes",
          "is_comment": true,
          "start_line": 60,
          "line_range": [
            60,
            60
          ],
          "target_line_range": [
            61,
            63
          ]
        },
        {
          "code": "    for node in kg.nodes:\n        dot.node(str(node.id), node.label, color=node.color)\n\n",
          "display_code": "    for node in kg.nodes:\n        dot.node(str(node.id), node.label, color=node.color)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 61,
          "line_range": [
            61,
            63
          ]
        },
        {
          "code": "    # Add edges\n",
          "display_code": "",
          "annotation": "Add edges",
          "is_comment": true,
          "start_line": 64,
          "line_range": [
            64,
            64
          ],
          "target_line_range": [
            65,
            68
          ]
        },
        {
          "code": "    for edge in kg.edges:\n        dot.edge(str(edge.source), str(edge.target),\n                 label=edge.label, color=edge.color)\n\n",
          "display_code": "    for edge in kg.edges:\n        dot.edge(str(edge.source), str(edge.target),\n                 label=edge.label, color=edge.color)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 65,
          "line_range": [
            65,
            68
          ]
        },
        {
          "code": "    # Render the graph\n",
          "display_code": "",
          "annotation": "Render the graph",
          "is_comment": true,
          "start_line": 69,
          "line_range": [
            69,
            69
          ],
          "target_line_range": [
            70,
            71
          ]
        },
        {
          "code": "    dot.render(\"knowledge_graph.gv\", view=True)\n\n",
          "display_code": "    dot.render(\"knowledge_graph.gv\", view=True)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 70,
          "line_range": [
            70,
            71
          ]
        },
        {
          "code": "# Visualize the graph\n",
          "display_code": "",
          "annotation": "Visualize the graph",
          "is_comment": true,
          "start_line": 72,
          "line_range": [
            72,
            72
          ],
          "target_line_range": [
            73,
            74
          ]
        },
        {
          "code": "visualize_knowledge_graph(graph)\n\n",
          "display_code": "visualize_knowledge_graph(graph)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 73,
          "line_range": [
            73,
            74
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python knowledge-graphs.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "006-advanced-structures",
      "section_title": "Advanced Structures"
    },
    {
      "id": "030-dependency-trees",
      "title": "Dependency Trees",
      "description": "",
      "order": 30,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Model hierarchical dependencies using Instructor. This technique helps identify bottlenecks and critical paths in processes and systems.\n",
          "display_code": "",
          "annotation": "Model hierarchical dependencies using Instructor. This technique helps identify bottlenecks and critical paths in processes and systems.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Dependency trees represent relationships where some items depend on others. Instructor can extract these structures for tasks like workflow management, build systems, or data processing pipelines.\n",
          "display_code": "",
          "annotation": "Dependency trees represent relationships where some items depend on others. Instructor can extract these structures for tasks like workflow management, build systems, or data processing pipelines.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            9
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            9
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 10,
          "line_range": [
            10,
            10
          ],
          "target_line_range": [
            11,
            12
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 11,
          "line_range": [
            11,
            12
          ]
        },
        {
          "code": "# Define a dependency node\n",
          "display_code": "",
          "annotation": "Define a dependency node",
          "is_comment": true,
          "start_line": 13,
          "line_range": [
            13,
            13
          ],
          "target_line_range": [
            14,
            19
          ]
        },
        {
          "code": "class DependencyNode(BaseModel):\n    id: str\n    description: str\n    dependencies: list[str] = Field(default_factory=list,\n                                   description=\"IDs of nodes this node depends on\")\n\n",
          "display_code": "class DependencyNode(BaseModel):\n    id: str\n    description: str\n    dependencies: list[str] = Field(default_factory=list,\n                                   description=\"IDs of nodes this node depends on\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 14,
          "line_range": [
            14,
            19
          ]
        },
        {
          "code": "# Define the dependency tree\n",
          "display_code": "",
          "annotation": "Define the dependency tree",
          "is_comment": true,
          "start_line": 20,
          "line_range": [
            20,
            20
          ],
          "target_line_range": [
            21,
            25
          ]
        },
        {
          "code": "class DependencyTree(BaseModel):\n    nodes: list[DependencyNode]\n\n    def get_execution_order(self) -> list[str]:\n        \"\"\"Returns topologically sorted execution order.\"\"\"\n",
          "display_code": "class DependencyTree(BaseModel):\n    nodes: list[DependencyNode]\n\n    def get_execution_order(self) -> list[str]:\n        \"\"\"Returns topologically sorted execution order.\"\"\"\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 21,
          "line_range": [
            21,
            25
          ]
        },
        {
          "code": "        # Build dependency graph\n",
          "display_code": "",
          "annotation": "Build dependency graph",
          "is_comment": true,
          "start_line": 26,
          "line_range": [
            26,
            26
          ],
          "target_line_range": [
            27,
            29
          ]
        },
        {
          "code": "        dep_graph = {node.id: set(node.dependencies) for node in self.nodes}\n        result = []\n\n",
          "display_code": "        dep_graph = {node.id: set(node.dependencies) for node in self.nodes}\n        result = []\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 27,
          "line_range": [
            27,
            29
          ]
        },
        {
          "code": "        # Find nodes with no dependencies\n",
          "display_code": "",
          "annotation": "Find nodes with no dependencies",
          "is_comment": true,
          "start_line": 30,
          "line_range": [
            30,
            30
          ],
          "target_line_range": [
            31,
            31
          ]
        },
        {
          "code": "        while dep_graph:\n",
          "display_code": "        while dep_graph:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 31,
          "line_range": [
            31,
            31
          ]
        },
        {
          "code": "            # Find nodes with no dependencies\n",
          "display_code": "",
          "annotation": "Find nodes with no dependencies",
          "is_comment": true,
          "start_line": 32,
          "line_range": [
            32,
            32
          ],
          "target_line_range": [
            33,
            36
          ]
        },
        {
          "code": "            roots = {node for node, deps in dep_graph.items() if not deps}\n            if not roots:\n                raise ValueError(\"Circular dependency detected\")\n\n",
          "display_code": "            roots = {node for node, deps in dep_graph.items() if not deps}\n            if not roots:\n                raise ValueError(\"Circular dependency detected\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 33,
          "line_range": [
            33,
            36
          ]
        },
        {
          "code": "            # Add these nodes to the result\n",
          "display_code": "",
          "annotation": "Add these nodes to the result",
          "is_comment": true,
          "start_line": 37,
          "line_range": [
            37,
            37
          ],
          "target_line_range": [
            38,
            39
          ]
        },
        {
          "code": "            result.extend(sorted(roots))\n\n",
          "display_code": "            result.extend(sorted(roots))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 38,
          "line_range": [
            38,
            39
          ]
        },
        {
          "code": "            # Remove these nodes from the graph\n",
          "display_code": "",
          "annotation": "Remove these nodes from the graph",
          "is_comment": true,
          "start_line": 40,
          "line_range": [
            40,
            40
          ],
          "target_line_range": [
            41,
            48
          ]
        },
        {
          "code": "            dep_graph = {\n                node: (deps - roots)\n                for node, deps in dep_graph.items()\n                if node not in roots\n            }\n\n        return result\n\n",
          "display_code": "            dep_graph = {\n                node: (deps - roots)\n                for node, deps in dep_graph.items()\n                if node not in roots\n            }\n\n        return result\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 41,
          "line_range": [
            41,
            48
          ]
        },
        {
          "code": "# Extract dependencies from a project description\n",
          "display_code": "",
          "annotation": "Extract dependencies from a project description",
          "is_comment": true,
          "start_line": 49,
          "line_range": [
            49,
            49
          ],
          "target_line_range": [
            50,
            65
          ]
        },
        {
          "code": "def extract_dependencies(project_description: str) -> DependencyTree:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract the dependencies between tasks in this project.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": project_description\n            }\n        ],\n        response_model=DependencyTree\n    )\n\n",
          "display_code": "def extract_dependencies(project_description: str) -> DependencyTree:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract the dependencies between tasks in this project.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": project_description\n            }\n        ],\n        response_model=DependencyTree\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 50,
          "line_range": [
            50,
            65
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 66,
          "line_range": [
            66,
            66
          ],
          "target_line_range": [
            67,
            80
          ]
        },
        {
          "code": "project = \"\"\"\nBuilding a web application requires:\n1. Setup development environment\n2. Design database schema (after setup)\n3. Create API endpoints (after database schema)\n4. Build frontend UI (after API design)\n5. Write tests (after API and UI)\n6. Deploy application (after tests pass)\n\"\"\"\n\ndependencies = extract_dependencies(project)\nexecution_order = dependencies.get_execution_order()\nprint(\"Execution order:\", execution_order)\n\n",
          "display_code": "project = \"\"\"\nBuilding a web application requires:\n1. Setup development environment\n2. Design database schema (after setup)\n3. Create API endpoints (after database schema)\n4. Build frontend UI (after API design)\n5. Write tests (after API and UI)\n6. Deploy application (after tests pass)\n\"\"\"\n\ndependencies = extract_dependencies(project)\nexecution_order = dependencies.get_execution_order()\nprint(\"Execution order:\", execution_order)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 67,
          "line_range": [
            67,
            80
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python dependency-trees.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "006-advanced-structures",
      "section_title": "Advanced Structures"
    },
    {
      "id": "031-task-planning",
      "title": "Task Planning",
      "description": "",
      "order": 31,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Generate structured task plans from natural language prompts. Instructor helps create step-by-step solutions with dependencies and execution order.\n",
          "display_code": "",
          "annotation": "Generate structured task plans from natural language prompts. Instructor helps create step-by-step solutions with dependencies and execution order.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor can be used to create sophisticated task planning systems that break down complex problems into manageable subtasks. This example shows how to implement a task planner with dependencies and execute them in the correct order.\n",
          "display_code": "",
          "annotation": "Instructor can be used to create sophisticated task planning systems that break down complex problems into manageable subtasks. This example shows how to implement a task planner with dependencies and execute them in the correct order.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "import asyncio\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\n\n",
          "display_code": "import asyncio\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define models for task results\n",
          "display_code": "",
          "annotation": "Define models for task results",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            21
          ]
        },
        {
          "code": "class TaskResult(BaseModel):\n    task_id: int\n    result: str\n\nclass TaskResults(BaseModel):\n    results: list[TaskResult]\n\n",
          "display_code": "class TaskResult(BaseModel):\n    task_id: int\n    result: str\n\nclass TaskResults(BaseModel):\n    results: list[TaskResult]\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            21
          ]
        },
        {
          "code": "# Define the Task model\n",
          "display_code": "",
          "annotation": "Define the Task model",
          "is_comment": true,
          "start_line": 22,
          "line_range": [
            22,
            22
          ],
          "target_line_range": [
            23,
            30
          ]
        },
        {
          "code": "class Task(BaseModel):\n    id: int = Field(..., description=\"Unique id of the task\")\n    task: str = Field(..., description=\"The task to be performed\")\n    subtasks: list[int] = Field(\n        default_factory=list,\n        description=\"IDs of subtasks that must be completed before this task\"\n    )\n\n",
          "display_code": "class Task(BaseModel):\n    id: int = Field(..., description=\"Unique id of the task\")\n    task: str = Field(..., description=\"The task to be performed\")\n    subtasks: list[int] = Field(\n        default_factory=list,\n        description=\"IDs of subtasks that must be completed before this task\"\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 23,
          "line_range": [
            23,
            30
          ]
        },
        {
          "code": "# This method executes a single task and returns its result\n# In a real implementation, this would perform actual work rather than return a placeholder\n",
          "display_code": "",
          "annotation": "This method executes a single task and returns its result\nIn a real implementation, this would perform actual work rather than return a placeholder",
          "is_comment": true,
          "start_line": 31,
          "line_range": [
            31,
            32
          ],
          "target_line_range": [
            33,
            36
          ]
        },
        {
          "code": "    async def execute(self, with_results: TaskResults) -> TaskResult:\n        \"\"\"Execute this task and return the result.\"\"\"\n        return TaskResult(task_id=self.id, result=f\"Result for task: {self.task}\")\n\n",
          "display_code": "    async def execute(self, with_results: TaskResults) -> TaskResult:\n        \"\"\"Execute this task and return the result.\"\"\"\n        return TaskResult(task_id=self.id, result=f\"Result for task: {self.task}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 33,
          "line_range": [
            33,
            36
          ]
        },
        {
          "code": "# Define the TaskPlan model\n",
          "display_code": "",
          "annotation": "Define the TaskPlan model",
          "is_comment": true,
          "start_line": 37,
          "line_range": [
            37,
            37
          ],
          "target_line_range": [
            38,
            48
          ]
        },
        {
          "code": "class TaskPlan(BaseModel):\n    task_graph: list[Task] = Field(\n        ...,\n        description=\"List of tasks and their dependencies\"\n    )\n\n    def _get_execution_order(self) -> list[int]:\n        \"\"\"Compute topological sort of tasks based on dependencies.\"\"\"\n        dep_graph = {task.id: set(task.subtasks) for task in self.task_graph}\n        result = []\n\n",
          "display_code": "class TaskPlan(BaseModel):\n    task_graph: list[Task] = Field(\n        ...,\n        description=\"List of tasks and their dependencies\"\n    )\n\n    def _get_execution_order(self) -> list[int]:\n        \"\"\"Compute topological sort of tasks based on dependencies.\"\"\"\n        dep_graph = {task.id: set(task.subtasks) for task in self.task_graph}\n        result = []\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 38,
          "line_range": [
            38,
            48
          ]
        },
        {
          "code": "# Find and order tasks based on their dependencies\n",
          "display_code": "",
          "annotation": "Find and order tasks based on their dependencies",
          "is_comment": true,
          "start_line": 49,
          "line_range": [
            49,
            49
          ],
          "target_line_range": [
            50,
            56
          ]
        },
        {
          "code": "        while dep_graph:\n            available = {task_id for task_id, deps in dep_graph.items() if not deps}  # Tasks with no dependencies\n            if not available:\n                raise ValueError(\"Circular dependency detected in tasks\")\n\n            result.extend(sorted(available))  # Add to execution order\n\n",
          "display_code": "        while dep_graph:\n            available = {task_id for task_id, deps in dep_graph.items() if not deps}  # Tasks with no dependencies\n            if not available:\n                raise ValueError(\"Circular dependency detected in tasks\")\n\n            result.extend(sorted(available))  # Add to execution order\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 50,
          "line_range": [
            50,
            56
          ]
        },
        {
          "code": "            # Update dependency graph by removing completed tasks\n",
          "display_code": "",
          "annotation": "Update dependency graph by removing completed tasks",
          "is_comment": true,
          "start_line": 57,
          "line_range": [
            57,
            57
          ],
          "target_line_range": [
            58,
            71
          ]
        },
        {
          "code": "            dep_graph = {\n                task_id: (deps - available)\n                for task_id, deps in dep_graph.items()\n                if task_id not in available\n            }\n\n        return result\n\n    async def execute(self) -> dict[int, TaskResult]:\n        \"\"\"Execute all tasks in dependency order.\"\"\"\n        execution_order = self._get_execution_order()\n        tasks_by_id = {task.id: task for task in self.task_graph}\n        results = {}\n\n",
          "display_code": "            dep_graph = {\n                task_id: (deps - available)\n                for task_id, deps in dep_graph.items()\n                if task_id not in available\n            }\n\n        return result\n\n    async def execute(self) -> dict[int, TaskResult]:\n        \"\"\"Execute all tasks in dependency order.\"\"\"\n        execution_order = self._get_execution_order()\n        tasks_by_id = {task.id: task for task in self.task_graph}\n        results = {}\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 58,
          "line_range": [
            58,
            71
          ]
        },
        {
          "code": "# Execute tasks in dependency order, processing parallel tasks when possible\n",
          "display_code": "",
          "annotation": "Execute tasks in dependency order, processing parallel tasks when possible",
          "is_comment": true,
          "start_line": 72,
          "line_range": [
            72,
            72
          ],
          "target_line_range": [
            73,
            73
          ]
        },
        {
          "code": "        while len(results) < len(self.task_graph):\n",
          "display_code": "        while len(results) < len(self.task_graph):\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 73,
          "line_range": [
            73,
            73
          ]
        },
        {
          "code": "            # Identify tasks whose dependencies are all satisfied\n",
          "display_code": "",
          "annotation": "Identify tasks whose dependencies are all satisfied",
          "is_comment": true,
          "start_line": 74,
          "line_range": [
            74,
            74
          ],
          "target_line_range": [
            75,
            81
          ]
        },
        {
          "code": "            ready_tasks = [\n                tasks_by_id[task_id]\n                for task_id in execution_order\n                if task_id not in results and\n                all(dep_id in results for dep_id in tasks_by_id[task_id].subtasks)\n            ]\n\n",
          "display_code": "            ready_tasks = [\n                tasks_by_id[task_id]\n                for task_id in execution_order\n                if task_id not in results and\n                all(dep_id in results for dep_id in tasks_by_id[task_id].subtasks)\n            ]\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 75,
          "line_range": [
            75,
            81
          ]
        },
        {
          "code": "            # Process all ready tasks concurrently\n",
          "display_code": "",
          "annotation": "Process all ready tasks concurrently",
          "is_comment": true,
          "start_line": 82,
          "line_range": [
            82,
            82
          ],
          "target_line_range": [
            83,
            94
          ]
        },
        {
          "code": "            new_results = await asyncio.gather(*[\n                task.execute(\n                    with_results=TaskResults(\n                        results=[\n                            results[dep_id]\n                            for dep_id in task.subtasks\n                        ]\n                    )\n                )\n                for task in ready_tasks\n            ])\n\n",
          "display_code": "            new_results = await asyncio.gather(*[\n                task.execute(\n                    with_results=TaskResults(\n                        results=[\n                            results[dep_id]\n                            for dep_id in task.subtasks\n                        ]\n                    )\n                )\n                for task in ready_tasks\n            ])\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 83,
          "line_range": [
            83,
            94
          ]
        },
        {
          "code": "            # Save results for dependent tasks to use\n",
          "display_code": "",
          "annotation": "Save results for dependent tasks to use",
          "is_comment": true,
          "start_line": 95,
          "line_range": [
            95,
            95
          ],
          "target_line_range": [
            96,
            100
          ]
        },
        {
          "code": "            for result in new_results:\n                results[result.task_id] = result\n\n        return results\n\n",
          "display_code": "            for result in new_results:\n                results[result.task_id] = result\n\n        return results\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 96,
          "line_range": [
            96,
            100
          ]
        },
        {
          "code": "# Generate a task plan for a complex question\n",
          "display_code": "",
          "annotation": "Generate a task plan for a complex question",
          "is_comment": true,
          "start_line": 101,
          "line_range": [
            101,
            101
          ],
          "target_line_range": [
            102,
            117
          ]
        },
        {
          "code": "def create_task_plan(question: str) -> TaskPlan:\n    return client.chat.completions.create(\n        model=\"gpt-4\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Create a detailed task plan to answer the user's question. Break down the problem into smaller, dependent tasks.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": question\n            }\n        ],\n        response_model=TaskPlan\n    )\n\n",
          "display_code": "def create_task_plan(question: str) -> TaskPlan:\n    return client.chat.completions.create(\n        model=\"gpt-4\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Create a detailed task plan to answer the user's question. Break down the problem into smaller, dependent tasks.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": question\n            }\n        ],\n        response_model=TaskPlan\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 102,
          "line_range": [
            102,
            117
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 118,
          "line_range": [
            118,
            118
          ],
          "target_line_range": [
            119,
            134
          ]
        },
        {
          "code": "async def main():\n    plan = create_task_plan(\n        \"What is the economic impact of renewable energy adoption in developing countries?\"\n    )\n    print(\"Task Plan:\")\n    for task in plan.task_graph:\n        deps = f\" (depends on: {task.subtasks})\" if task.subtasks else \"\"\n        print(f\"Task {task.id}: {task.task}{deps}\")\n\n    print(\"\\nExecuting plan...\")\n    results = await plan.execute()\n\n    print(\"\\nResults:\")\n    for task_id, result in sorted(results.items()):\n        print(f\"Task {task_id}: {result.result}\")\n\n",
          "display_code": "async def main():\n    plan = create_task_plan(\n        \"What is the economic impact of renewable energy adoption in developing countries?\"\n    )\n    print(\"Task Plan:\")\n    for task in plan.task_graph:\n        deps = f\" (depends on: {task.subtasks})\" if task.subtasks else \"\"\n        print(f\"Task {task.id}: {task.task}{deps}\")\n\n    print(\"\\nExecuting plan...\")\n    results = await plan.execute()\n\n    print(\"\\nResults:\")\n    for task_id, result in sorted(results.items()):\n        print(f\"Task {task_id}: {result.result}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 119,
          "line_range": [
            119,
            134
          ]
        },
        {
          "code": "# Run the example\n",
          "display_code": "",
          "annotation": "Run the example",
          "is_comment": true,
          "start_line": 135,
          "line_range": [
            135,
            135
          ],
          "target_line_range": [
            136,
            138
          ]
        },
        {
          "code": "if __name__ == \"__main__\":\n    asyncio.run(main())\n\n",
          "display_code": "if __name__ == \"__main__\":\n    asyncio.run(main())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 136,
          "line_range": [
            136,
            138
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python task-planning.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "006-advanced-structures",
      "section_title": "Advanced Structures"
    },
    {
      "id": "032-document-structure",
      "title": "Document Structure",
      "description": "",
      "order": 32,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Extract document structure and organization using Instructor. Helps with document classification, section analysis, and content organization.\n",
          "display_code": "",
          "annotation": "Extract document structure and organization using Instructor. Helps with document classification, section analysis, and content organization.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor can extract structured representations of documents, such as articles, papers, or reports. This approach helps convert unstructured text into structured data that can be analyzed and processed.\n",
          "display_code": "",
          "annotation": "Instructor can extract structured representations of documents, such as articles, papers, or reports. This approach helps convert unstructured text into structured data that can be analyzed and processed.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import Optional, List\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import Optional, List\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define section structure\n",
          "display_code": "",
          "annotation": "Define section structure",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            19
          ]
        },
        {
          "code": "class Section(BaseModel):\n    heading: str\n    content: str\n    subsections: List[\"Section\"] = Field(default_factory=list)\n\n",
          "display_code": "class Section(BaseModel):\n    heading: str\n    content: str\n    subsections: List[\"Section\"] = Field(default_factory=list)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            19
          ]
        },
        {
          "code": "# Important! For recursive models, we need to rebuild the model\n",
          "display_code": "",
          "annotation": "Important! For recursive models, we need to rebuild the model",
          "is_comment": true,
          "start_line": 20,
          "line_range": [
            20,
            20
          ],
          "target_line_range": [
            21,
            22
          ]
        },
        {
          "code": "Section.model_rebuild()\n\n",
          "display_code": "Section.model_rebuild()\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 21,
          "line_range": [
            21,
            22
          ]
        },
        {
          "code": "# Define document structure\n",
          "display_code": "",
          "annotation": "Define document structure",
          "is_comment": true,
          "start_line": 23,
          "line_range": [
            23,
            23
          ],
          "target_line_range": [
            24,
            30
          ]
        },
        {
          "code": "class Document(BaseModel):\n    title: str\n    abstract: Optional[str] = None\n    authors: List[str] = Field(default_factory=list)\n    sections: List[Section] = Field(default_factory=list)\n    keywords: List[str] = Field(default_factory=list)\n\n",
          "display_code": "class Document(BaseModel):\n    title: str\n    abstract: Optional[str] = None\n    authors: List[str] = Field(default_factory=list)\n    sections: List[Section] = Field(default_factory=list)\n    keywords: List[str] = Field(default_factory=list)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 24,
          "line_range": [
            24,
            30
          ]
        },
        {
          "code": "# Extract document structure from text\n",
          "display_code": "",
          "annotation": "Extract document structure from text",
          "is_comment": true,
          "start_line": 31,
          "line_range": [
            31,
            31
          ],
          "target_line_range": [
            32,
            47
          ]
        },
        {
          "code": "def extract_document_structure(text: str) -> Document:\n    return client.chat.completions.create(\n        model=\"gpt-4\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract the structured representation of this document, including all sections and subsections.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": text\n            }\n        ],\n        response_model=Document\n    )\n\n",
          "display_code": "def extract_document_structure(text: str) -> Document:\n    return client.chat.completions.create(\n        model=\"gpt-4\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract the structured representation of this document, including all sections and subsections.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": text\n            }\n        ],\n        response_model=Document\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 32,
          "line_range": [
            32,
            47
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 48,
          "line_range": [
            48,
            48
          ],
          "target_line_range": [
            49,
            49
          ]
        },
        {
          "code": "document_text = \"\"\"\n",
          "display_code": "document_text = \"\"\"\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 49,
          "line_range": [
            49,
            49
          ]
        },
        {
          "code": "# Machine Learning in Healthcare\n## Authors: Jane Smith, John Doe\n",
          "display_code": "",
          "annotation": "Machine Learning in Healthcare\nAuthors: Jane Smith, John Doe",
          "is_comment": true,
          "start_line": 50,
          "line_range": [
            50,
            51
          ],
          "target_line_range": [
            52,
            52
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 52,
          "line_range": [
            52,
            52
          ]
        },
        {
          "code": "### Abstract\n",
          "display_code": "",
          "annotation": "Abstract",
          "is_comment": true,
          "start_line": 53,
          "line_range": [
            53,
            53
          ],
          "target_line_range": [
            54,
            55
          ]
        },
        {
          "code": "This paper explores the applications of machine learning in healthcare settings.\n\n",
          "display_code": "This paper explores the applications of machine learning in healthcare settings.\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 54,
          "line_range": [
            54,
            55
          ]
        },
        {
          "code": "### Keywords\n",
          "display_code": "",
          "annotation": "Keywords",
          "is_comment": true,
          "start_line": 56,
          "line_range": [
            56,
            56
          ],
          "target_line_range": [
            57,
            58
          ]
        },
        {
          "code": "machine learning, healthcare, AI, medical diagnosis\n\n",
          "display_code": "machine learning, healthcare, AI, medical diagnosis\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 57,
          "line_range": [
            57,
            58
          ]
        },
        {
          "code": "## Introduction\n",
          "display_code": "",
          "annotation": "Introduction",
          "is_comment": true,
          "start_line": 59,
          "line_range": [
            59,
            59
          ],
          "target_line_range": [
            60,
            61
          ]
        },
        {
          "code": "Machine learning has shown promising results in healthcare applications.\n\n",
          "display_code": "Machine learning has shown promising results in healthcare applications.\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 60,
          "line_range": [
            60,
            61
          ]
        },
        {
          "code": "### Background\n",
          "display_code": "",
          "annotation": "Background",
          "is_comment": true,
          "start_line": 62,
          "line_range": [
            62,
            62
          ],
          "target_line_range": [
            63,
            64
          ]
        },
        {
          "code": "Healthcare has historically been slow to adopt new technologies.\n\n",
          "display_code": "Healthcare has historically been slow to adopt new technologies.\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 63,
          "line_range": [
            63,
            64
          ]
        },
        {
          "code": "### Current Challenges\n",
          "display_code": "",
          "annotation": "Current Challenges",
          "is_comment": true,
          "start_line": 65,
          "line_range": [
            65,
            65
          ],
          "target_line_range": [
            66,
            67
          ]
        },
        {
          "code": "Data privacy and model interpretability remain significant challenges.\n\n",
          "display_code": "Data privacy and model interpretability remain significant challenges.\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 66,
          "line_range": [
            66,
            67
          ]
        },
        {
          "code": "## Methods\n",
          "display_code": "",
          "annotation": "Methods",
          "is_comment": true,
          "start_line": 68,
          "line_range": [
            68,
            68
          ],
          "target_line_range": [
            69,
            70
          ]
        },
        {
          "code": "We employed a mixed-methods approach.\n\n",
          "display_code": "We employed a mixed-methods approach.\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 69,
          "line_range": [
            69,
            70
          ]
        },
        {
          "code": "## Results\n",
          "display_code": "",
          "annotation": "Results",
          "is_comment": true,
          "start_line": 71,
          "line_range": [
            71,
            71
          ],
          "target_line_range": [
            72,
            73
          ]
        },
        {
          "code": "Our findings indicate a 30% improvement in diagnostic accuracy.\n\n",
          "display_code": "Our findings indicate a 30% improvement in diagnostic accuracy.\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 72,
          "line_range": [
            72,
            73
          ]
        },
        {
          "code": "## Discussion\n",
          "display_code": "",
          "annotation": "Discussion",
          "is_comment": true,
          "start_line": 74,
          "line_range": [
            74,
            74
          ],
          "target_line_range": [
            75,
            76
          ]
        },
        {
          "code": "These results have significant implications for clinical practice.\n\n",
          "display_code": "These results have significant implications for clinical practice.\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 75,
          "line_range": [
            75,
            76
          ]
        },
        {
          "code": "## Conclusion\n",
          "display_code": "",
          "annotation": "Conclusion",
          "is_comment": true,
          "start_line": 77,
          "line_range": [
            77,
            77
          ],
          "target_line_range": [
            78,
            82
          ]
        },
        {
          "code": "Machine learning will continue to transform healthcare delivery.\n\"\"\"\n\ndoc_structure = extract_document_structure(document_text)\n\n",
          "display_code": "Machine learning will continue to transform healthcare delivery.\n\"\"\"\n\ndoc_structure = extract_document_structure(document_text)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 78,
          "line_range": [
            78,
            82
          ]
        },
        {
          "code": "# Print the document structure\n",
          "display_code": "",
          "annotation": "Print the document structure",
          "is_comment": true,
          "start_line": 83,
          "line_range": [
            83,
            83
          ],
          "target_line_range": [
            84,
            94
          ]
        },
        {
          "code": "print(f\"Title: {doc_structure.title}\")\nprint(f\"Authors: {', '.join(doc_structure.authors)}\")\nif doc_structure.abstract:\n    print(f\"Abstract: {doc_structure.abstract}\")\nprint(f\"Keywords: {', '.join(doc_structure.keywords)}\")\nprint(\"\\nSections:\")\nfor section in doc_structure.sections:\n    print(f\"- {section.heading}\")\n    for subsection in section.subsections:\n        print(f\"  - {subsection.heading}\")\n\n",
          "display_code": "print(f\"Title: {doc_structure.title}\")\nprint(f\"Authors: {', '.join(doc_structure.authors)}\")\nif doc_structure.abstract:\n    print(f\"Abstract: {doc_structure.abstract}\")\nprint(f\"Keywords: {', '.join(doc_structure.keywords)}\")\nprint(\"\\nSections:\")\nfor section in doc_structure.sections:\n    print(f\"- {section.heading}\")\n    for subsection in section.subsections:\n        print(f\"  - {subsection.heading}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 84,
          "line_range": [
            84,
            94
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python document-structure.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "006-advanced-structures",
      "section_title": "Advanced Structures"
    },
    {
      "id": "033-validation-basics",
      "title": "Validation Basics",
      "description": "",
      "order": 33,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Learn the fundamentals of validation in Instructor. Understand the automatic validation and retry process for ensuring data quality.\n",
          "display_code": "",
          "annotation": "Learn the fundamentals of validation in Instructor. Understand the automatic validation and retry process for ensuring data quality.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor leverages Pydantic's validation framework to ensure that outputs from LLMs match your expected schema. This is crucial for building reliable applications.\n",
          "display_code": "",
          "annotation": "Instructor leverages Pydantic's validation framework to ensure that outputs from LLMs match your expected schema. This is crucial for building reliable applications.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            9
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            9
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 10,
          "line_range": [
            10,
            10
          ],
          "target_line_range": [
            11,
            12
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 11,
          "line_range": [
            11,
            12
          ]
        },
        {
          "code": "# Define a model with basic validation\n",
          "display_code": "",
          "annotation": "Define a model with basic validation",
          "is_comment": true,
          "start_line": 13,
          "line_range": [
            13,
            13
          ],
          "target_line_range": [
            14,
            20
          ]
        },
        {
          "code": "class User(BaseModel):\n    name: str = Field(..., description=\"User's full name\")\n    age: int = Field(...,\n                    description=\"User's age in years\",\n                    ge=0, le=120)  # Must be between 0 and 120\n    email: str = Field(..., description=\"User's email address\")\n\n",
          "display_code": "class User(BaseModel):\n    name: str = Field(..., description=\"User's full name\")\n    age: int = Field(...,\n                    description=\"User's age in years\",\n                    ge=0, le=120)  # Must be between 0 and 120\n    email: str = Field(..., description=\"User's email address\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 14,
          "line_range": [
            14,
            20
          ]
        },
        {
          "code": "# Extract user information with validation\n",
          "display_code": "",
          "annotation": "Extract user information with validation",
          "is_comment": true,
          "start_line": 21,
          "line_range": [
            21,
            21
          ],
          "target_line_range": [
            22,
            33
          ]
        },
        {
          "code": "def extract_user(text: str) -> User:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Extract user information from this text: {text}\"\n            }\n        ],\n        response_model=User\n    )\n\n",
          "display_code": "def extract_user(text: str) -> User:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Extract user information from this text: {text}\"\n            }\n        ],\n        response_model=User\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 22,
          "line_range": [
            22,
            33
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 34,
          "line_range": [
            34,
            34
          ],
          "target_line_range": [
            35,
            38
          ]
        },
        {
          "code": "text = \"John Doe is 25 years old and his email is john.doe@example.com.\"\nuser = extract_user(text)\nprint(user.model_dump_json(indent=2))\n\n",
          "display_code": "text = \"John Doe is 25 years old and his email is john.doe@example.com.\"\nuser = extract_user(text)\nprint(user.model_dump_json(indent=2))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 35,
          "line_range": [
            35,
            38
          ]
        },
        {
          "code": "# When an LLM output fails validation, Instructor can automatically retry the request with the validation error message:\n",
          "display_code": "",
          "annotation": "When an LLM output fails validation, Instructor can automatically retry the request with the validation error message:",
          "is_comment": true,
          "start_line": 39,
          "line_range": [
            39,
            39
          ],
          "target_line_range": [
            40,
            43
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, field_validator\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, field_validator\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 40,
          "line_range": [
            40,
            43
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 44,
          "line_range": [
            44,
            44
          ],
          "target_line_range": [
            45,
            46
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 45,
          "line_range": [
            45,
            46
          ]
        },
        {
          "code": "# Define a model with custom validation\n",
          "display_code": "",
          "annotation": "Define a model with custom validation",
          "is_comment": true,
          "start_line": 47,
          "line_range": [
            47,
            47
          ],
          "target_line_range": [
            48,
            57
          ]
        },
        {
          "code": "class User(BaseModel):\n    name: str\n    age: int\n\n    @field_validator(\"age\")\n    def validate_age(cls, v):\n        if v < 0 or v > 120:\n            raise ValueError(\"Age must be between 0 and 120\")\n        return v\n\n",
          "display_code": "class User(BaseModel):\n    name: str\n    age: int\n\n    @field_validator(\"age\")\n    def validate_age(cls, v):\n        if v < 0 or v > 120:\n            raise ValueError(\"Age must be between 0 and 120\")\n        return v\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 48,
          "line_range": [
            48,
            57
          ]
        },
        {
          "code": "# Extract with automatic retries\n",
          "display_code": "",
          "annotation": "Extract with automatic retries",
          "is_comment": true,
          "start_line": 58,
          "line_range": [
            58,
            58
          ],
          "target_line_range": [
            59,
            72
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract: John Doe, age: 150\"\n        }\n    ],\n    response_model=User,\n    max_retries=2  # Try up to 2 more times if validation fails\n)\n\nprint(user.model_dump_json(indent=2))\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract: John Doe, age: 150\"\n        }\n    ],\n    response_model=User,\n    max_retries=2  # Try up to 2 more times if validation fails\n)\n\nprint(user.model_dump_json(indent=2))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 59,
          "line_range": [
            59,
            72
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python validation-basics.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "007-validation",
      "section_title": "Validation"
    },
    {
      "id": "034-custom-validators",
      "title": "Custom Validators",
      "description": "",
      "order": 34,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Implement custom validators for domain-specific validation rules with Instructor. Enables context-dependent validation for complex business logic.\n",
          "display_code": "",
          "annotation": "Implement custom validators for domain-specific validation rules with Instructor. Enables context-dependent validation for complex business logic.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor allows you to create custom validators to enforce specific rules on LLM outputs. These can range from simple format checks to complex business logic.\n",
          "display_code": "",
          "annotation": "Instructor allows you to create custom validators to enforce specific rules on LLM outputs. These can range from simple format checks to complex business logic.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            9
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, field_validator\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, field_validator\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            9
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 10,
          "line_range": [
            10,
            10
          ],
          "target_line_range": [
            11,
            12
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 11,
          "line_range": [
            11,
            12
          ]
        },
        {
          "code": "# Define a model with a custom validator\n",
          "display_code": "",
          "annotation": "Define a model with a custom validator",
          "is_comment": true,
          "start_line": 13,
          "line_range": [
            13,
            13
          ],
          "target_line_range": [
            14,
            26
          ]
        },
        {
          "code": "class Contact(BaseModel):\n    name: str = Field(description=\"Person's full name\")\n    email: str = Field(description=\"Person's email address\")\n    phone: str = Field(description=\"Person's phone number\")\n\n    @field_validator(\"email\")\n    def validate_email(cls, v):\n        if \"@\" not in v:\n            raise ValueError(\"Email must contain @ symbol\")\n        return v\n\n    @field_validator(\"phone\")\n    def validate_phone(cls, v):\n",
          "display_code": "class Contact(BaseModel):\n    name: str = Field(description=\"Person's full name\")\n    email: str = Field(description=\"Person's email address\")\n    phone: str = Field(description=\"Person's phone number\")\n\n    @field_validator(\"email\")\n    def validate_email(cls, v):\n        if \"@\" not in v:\n            raise ValueError(\"Email must contain @ symbol\")\n        return v\n\n    @field_validator(\"phone\")\n    def validate_phone(cls, v):\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 14,
          "line_range": [
            14,
            26
          ]
        },
        {
          "code": "        # Remove all non-numeric characters\n",
          "display_code": "",
          "annotation": "Remove all non-numeric characters",
          "is_comment": true,
          "start_line": 27,
          "line_range": [
            27,
            27
          ],
          "target_line_range": [
            28,
            32
          ]
        },
        {
          "code": "        digits = ''.join(c for c in v if c.isdigit())\n        if len(digits) < 10:\n            raise ValueError(\"Phone number must have at least 10 digits\")\n        return v\n\n",
          "display_code": "        digits = ''.join(c for c in v if c.isdigit())\n        if len(digits) < 10:\n            raise ValueError(\"Phone number must have at least 10 digits\")\n        return v\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 28,
          "line_range": [
            28,
            32
          ]
        },
        {
          "code": "# Extract contact information with validation\n",
          "display_code": "",
          "annotation": "Extract contact information with validation",
          "is_comment": true,
          "start_line": 33,
          "line_range": [
            33,
            33
          ],
          "target_line_range": [
            34,
            47
          ]
        },
        {
          "code": "contact = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract: John Doe, email: johndoe.example.com, phone: 555-1234\"\n        }\n    ],\n    response_model=Contact,\n    max_retries=2\n)\n\nprint(contact.model_dump_json(indent=2))\n\n",
          "display_code": "contact = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract: John Doe, email: johndoe.example.com, phone: 555-1234\"\n        }\n    ],\n    response_model=Contact,\n    max_retries=2\n)\n\nprint(contact.model_dump_json(indent=2))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 34,
          "line_range": [
            34,
            47
          ]
        },
        {
          "code": "# You can also use validation with annotated types:\n",
          "display_code": "",
          "annotation": "You can also use validation with annotated types:",
          "is_comment": true,
          "start_line": 48,
          "line_range": [
            48,
            48
          ],
          "target_line_range": [
            49,
            51
          ]
        },
        {
          "code": "from typing_extensions import Annotated\nfrom pydantic import AfterValidator\n\n",
          "display_code": "from typing_extensions import Annotated\nfrom pydantic import AfterValidator\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 49,
          "line_range": [
            49,
            51
          ]
        },
        {
          "code": "# Define a validation function\n",
          "display_code": "",
          "annotation": "Define a validation function",
          "is_comment": true,
          "start_line": 52,
          "line_range": [
            52,
            52
          ],
          "target_line_range": [
            53,
            57
          ]
        },
        {
          "code": "def validate_uppercase(v: str) -> str:\n    if v != v.upper():\n        raise ValueError(\"String must be uppercase\")\n    return v\n\n",
          "display_code": "def validate_uppercase(v: str) -> str:\n    if v != v.upper():\n        raise ValueError(\"String must be uppercase\")\n    return v\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 53,
          "line_range": [
            53,
            57
          ]
        },
        {
          "code": "# Define a model with annotated validation\n",
          "display_code": "",
          "annotation": "Define a model with annotated validation",
          "is_comment": true,
          "start_line": 58,
          "line_range": [
            58,
            58
          ],
          "target_line_range": [
            59,
            68
          ]
        },
        {
          "code": "class Document(BaseModel):\n    title: Annotated[str, AfterValidator(validate_uppercase)]\n    content: str\n\n    @field_validator(\"content\")\n    def validate_content_length(cls, v):\n        if len(v.split()) < 5:\n            raise ValueError(\"Content must be at least 5 words long\")\n        return v\n\n",
          "display_code": "class Document(BaseModel):\n    title: Annotated[str, AfterValidator(validate_uppercase)]\n    content: str\n\n    @field_validator(\"content\")\n    def validate_content_length(cls, v):\n        if len(v.split()) < 5:\n            raise ValueError(\"Content must be at least 5 words long\")\n        return v\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 59,
          "line_range": [
            59,
            68
          ]
        },
        {
          "code": "# For even more advanced validation, you can use LLM-based validators:\n",
          "display_code": "",
          "annotation": "For even more advanced validation, you can use LLM-based validators:",
          "is_comment": true,
          "start_line": 69,
          "line_range": [
            69,
            69
          ],
          "target_line_range": [
            70,
            75
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, BeforeValidator\nfrom typing_extensions import Annotated\nfrom instructor import llm_validator\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, BeforeValidator\nfrom typing_extensions import Annotated\nfrom instructor import llm_validator\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 70,
          "line_range": [
            70,
            75
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 76,
          "line_range": [
            76,
            76
          ],
          "target_line_range": [
            77,
            78
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 77,
          "line_range": [
            77,
            78
          ]
        },
        {
          "code": "# Define a model with LLM-based validation\n",
          "display_code": "",
          "annotation": "Define a model with LLM-based validation",
          "is_comment": true,
          "start_line": 79,
          "line_range": [
            79,
            79
          ],
          "target_line_range": [
            80,
            87
          ]
        },
        {
          "code": "class Review(BaseModel):\n    product: str\n    content: Annotated[\n        str,\n        BeforeValidator(llm_validator(\"must be positive and respectful\", client=client))\n    ]\n    rating: int\n\n",
          "display_code": "class Review(BaseModel):\n    product: str\n    content: Annotated[\n        str,\n        BeforeValidator(llm_validator(\"must be positive and respectful\", client=client))\n    ]\n    rating: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 80,
          "line_range": [
            80,
            87
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 88,
          "line_range": [
            88,
            88
          ],
          "target_line_range": [
            89,
            100
          ]
        },
        {
          "code": "review = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract: iPhone 14, content: This product is terrible and I hate it, rating: 1\"\n        }\n    ],\n    response_model=Review,\n    max_retries=2\n)\n\n",
          "display_code": "review = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract: iPhone 14, content: This product is terrible and I hate it, rating: 1\"\n        }\n    ],\n    response_model=Review,\n    max_retries=2\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 89,
          "line_range": [
            89,
            100
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python custom-validators.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "007-validation",
      "section_title": "Validation"
    },
    {
      "id": "035-retry-mechanisms",
      "title": "Retry Mechanisms",
      "description": "",
      "order": 35,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Build robust extraction pipelines with automatic retry mechanisms. Instructor provides tools for creating reliable production applications.\n",
          "display_code": "",
          "annotation": "Build robust extraction pipelines with automatic retry mechanisms. Instructor provides tools for creating reliable production applications.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor provides flexible retry mechanisms for handling validation failures. This helps create more robust applications that can recover from parsing errors or validation issues.\n",
          "display_code": "",
          "annotation": "Instructor provides flexible retry mechanisms for handling validation failures. This helps create more robust applications that can recover from parsing errors or validation issues.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            9
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, field_validator\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, field_validator\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            9
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 10,
          "line_range": [
            10,
            10
          ],
          "target_line_range": [
            11,
            12
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 11,
          "line_range": [
            11,
            12
          ]
        },
        {
          "code": "# Define a model with validation\n",
          "display_code": "",
          "annotation": "Define a model with validation",
          "is_comment": true,
          "start_line": 13,
          "line_range": [
            13,
            13
          ],
          "target_line_range": [
            14,
            23
          ]
        },
        {
          "code": "class Profile(BaseModel):\n    username: str = Field(description=\"Username without spaces\")\n    age: int = Field(description=\"Age in years\", ge=13)\n\n    @field_validator(\"username\")\n    def validate_username(cls, v):\n        if \" \" in v:\n            raise ValueError(\"Username cannot contain spaces\")\n        return v\n\n",
          "display_code": "class Profile(BaseModel):\n    username: str = Field(description=\"Username without spaces\")\n    age: int = Field(description=\"Age in years\", ge=13)\n\n    @field_validator(\"username\")\n    def validate_username(cls, v):\n        if \" \" in v:\n            raise ValueError(\"Username cannot contain spaces\")\n        return v\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 14,
          "line_range": [
            14,
            23
          ]
        },
        {
          "code": "# Basic retry approach - specify max_retries\n",
          "display_code": "",
          "annotation": "Basic retry approach - specify max_retries",
          "is_comment": true,
          "start_line": 24,
          "line_range": [
            24,
            24
          ],
          "target_line_range": [
            25,
            38
          ]
        },
        {
          "code": "profile = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract: username: John Doe, age: 25\"\n        }\n    ],\n    response_model=Profile,\n    max_retries=3  # Try up to 3 more times if validation fails\n)\n\nprint(profile.model_dump_json(indent=2))\n\n",
          "display_code": "profile = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract: username: John Doe, age: 25\"\n        }\n    ],\n    response_model=Profile,\n    max_retries=3  # Try up to 3 more times if validation fails\n)\n\nprint(profile.model_dump_json(indent=2))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 25,
          "line_range": [
            25,
            38
          ]
        },
        {
          "code": "# For more advanced retry logic, you can use the Tenacity library:\n",
          "display_code": "",
          "annotation": "For more advanced retry logic, you can use the Tenacity library:",
          "is_comment": true,
          "start_line": 39,
          "line_range": [
            39,
            39
          ],
          "target_line_range": [
            40,
            44
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, field_validator\nfrom tenacity import Retrying, stop_after_attempt, wait_fixed\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, field_validator\nfrom tenacity import Retrying, stop_after_attempt, wait_fixed\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 40,
          "line_range": [
            40,
            44
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 45,
          "line_range": [
            45,
            45
          ],
          "target_line_range": [
            46,
            47
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 46,
          "line_range": [
            46,
            47
          ]
        },
        {
          "code": "# Define a model with validation\n",
          "display_code": "",
          "annotation": "Define a model with validation",
          "is_comment": true,
          "start_line": 48,
          "line_range": [
            48,
            48
          ],
          "target_line_range": [
            49,
            58
          ]
        },
        {
          "code": "class User(BaseModel):\n    name: str\n    age: int\n\n    @field_validator(\"name\")\n    def validate_name(cls, v):\n        if not v.isupper():\n            raise ValueError(\"Name must be uppercase\")\n        return v\n\n",
          "display_code": "class User(BaseModel):\n    name: str\n    age: int\n\n    @field_validator(\"name\")\n    def validate_name(cls, v):\n        if not v.isupper():\n            raise ValueError(\"Name must be uppercase\")\n        return v\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 49,
          "line_range": [
            49,
            58
          ]
        },
        {
          "code": "# Use tenacity for advanced retry configuration\n",
          "display_code": "",
          "annotation": "Use tenacity for advanced retry configuration",
          "is_comment": true,
          "start_line": 59,
          "line_range": [
            59,
            59
          ],
          "target_line_range": [
            60,
            76
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract: John is 30 years old\"\n        }\n    ],\n    response_model=User,\n    max_retries=Retrying(\n        stop=stop_after_attempt(3),  # Stop after 3 attempts\n        wait=wait_fixed(1),  # Wait 1 second between attempts\n    )\n)\n\nprint(user.model_dump_json(indent=2))\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract: John is 30 years old\"\n        }\n    ],\n    response_model=User,\n    max_retries=Retrying(\n        stop=stop_after_attempt(3),  # Stop after 3 attempts\n        wait=wait_fixed(1),  # Wait 1 second between attempts\n    )\n)\n\nprint(user.model_dump_json(indent=2))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 60,
          "line_range": [
            60,
            76
          ]
        },
        {
          "code": "# You can also catch retry exceptions to handle persistent failures:\n",
          "display_code": "",
          "annotation": "You can also catch retry exceptions to handle persistent failures:",
          "is_comment": true,
          "start_line": 77,
          "line_range": [
            77,
            77
          ],
          "target_line_range": [
            78,
            82
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, field_validator\nfrom instructor.exceptions import InstructorRetryException\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, field_validator\nfrom instructor.exceptions import InstructorRetryException\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 78,
          "line_range": [
            78,
            82
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 83,
          "line_range": [
            83,
            83
          ],
          "target_line_range": [
            84,
            85
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 84,
          "line_range": [
            84,
            85
          ]
        },
        {
          "code": "# Define a model with validation that will always fail\n",
          "display_code": "",
          "annotation": "Define a model with validation that will always fail",
          "is_comment": true,
          "start_line": 86,
          "line_range": [
            86,
            86
          ],
          "target_line_range": [
            87,
            94
          ]
        },
        {
          "code": "class ImpossibleModel(BaseModel):\n    name: str\n    age: int\n\n    @field_validator(\"age\")\n    def validate_age(cls, v):\n        raise ValueError(\"This validator will always fail\")\n\n",
          "display_code": "class ImpossibleModel(BaseModel):\n    name: str\n    age: int\n\n    @field_validator(\"age\")\n    def validate_age(cls, v):\n        raise ValueError(\"This validator will always fail\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 87,
          "line_range": [
            87,
            94
          ]
        },
        {
          "code": "# Handle retry exceptions\n",
          "display_code": "",
          "annotation": "Handle retry exceptions",
          "is_comment": true,
          "start_line": 95,
          "line_range": [
            95,
            95
          ],
          "target_line_range": [
            96,
            111
          ]
        },
        {
          "code": "try:\n    result = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": \"Extract: Jane is 25 years old\"\n            }\n        ],\n        response_model=ImpossibleModel,\n        max_retries=2\n    )\nexcept InstructorRetryException as e:\n    print(f\"Failed after {e.n_attempts} attempts\")\n    print(f\"Last error message: {e.messages[-1]['content']}\")\n\n",
          "display_code": "try:\n    result = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": \"Extract: Jane is 25 years old\"\n            }\n        ],\n        response_model=ImpossibleModel,\n        max_retries=2\n    )\nexcept InstructorRetryException as e:\n    print(f\"Failed after {e.n_attempts} attempts\")\n    print(f\"Last error message: {e.messages[-1]['content']}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 96,
          "line_range": [
            96,
            111
          ]
        },
        {
          "code": "    # Implement fallback strategy here\n",
          "display_code": "",
          "annotation": "Implement fallback strategy here",
          "is_comment": true,
          "start_line": 112,
          "line_range": [
            112,
            112
          ],
          "target_line_range": [
            113,
            115
          ]
        },
        {
          "code": "    fallback_result = {\"name\": \"Jane\", \"age\": 0}\n    print(f\"Using fallback: {fallback_result}\")\n\n",
          "display_code": "    fallback_result = {\"name\": \"Jane\", \"age\": 0}\n    print(f\"Using fallback: {fallback_result}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 113,
          "line_range": [
            113,
            115
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python retry-mechanisms.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "007-validation",
      "section_title": "Validation"
    },
    {
      "id": "036-fallback-strategies",
      "title": "Fallback Strategies",
      "description": "",
      "order": 36,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Implement fallback strategies for handling missing or invalid information. Instructor helps provide default values when extraction is uncertain.\n",
          "display_code": "",
          "annotation": "Implement fallback strategies for handling missing or invalid information. Instructor helps provide default values when extraction is uncertain.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# When working with LLMs, it's important to have fallback strategies for handling persistent failures or unexpected issues. Instructor provides several ways to implement robust fallback mechanisms.\n",
          "display_code": "",
          "annotation": "When working with LLMs, it's important to have fallback strategies for handling persistent failures or unexpected issues. Instructor provides several ways to implement robust fallback mechanisms.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, ValidationError\nfrom instructor.exceptions import InstructorRetryException\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, ValidationError\nfrom instructor.exceptions import InstructorRetryException\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define primary model with strict validation\n",
          "display_code": "",
          "annotation": "Define primary model with strict validation",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            21
          ]
        },
        {
          "code": "class DetailedUserProfile(BaseModel):\n    name: str = Field(description=\"User's full name\")\n    age: int = Field(description=\"User's age in years\", ge=18)\n    occupation: str = Field(description=\"User's job or profession\")\n    income: int = Field(description=\"User's annual income in USD\", ge=0)\n    education: str = Field(description=\"User's highest education level\")\n\n",
          "display_code": "class DetailedUserProfile(BaseModel):\n    name: str = Field(description=\"User's full name\")\n    age: int = Field(description=\"User's age in years\", ge=18)\n    occupation: str = Field(description=\"User's job or profession\")\n    income: int = Field(description=\"User's annual income in USD\", ge=0)\n    education: str = Field(description=\"User's highest education level\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            21
          ]
        },
        {
          "code": "# Define simpler fallback model\n",
          "display_code": "",
          "annotation": "Define simpler fallback model",
          "is_comment": true,
          "start_line": 22,
          "line_range": [
            22,
            22
          ],
          "target_line_range": [
            23,
            26
          ]
        },
        {
          "code": "class BasicUserProfile(BaseModel):\n    name: str = Field(description=\"User's name\")\n    age: int = Field(description=\"User's age\", ge=0)\n\n",
          "display_code": "class BasicUserProfile(BaseModel):\n    name: str = Field(description=\"User's name\")\n    age: int = Field(description=\"User's age\", ge=0)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 23,
          "line_range": [
            23,
            26
          ]
        },
        {
          "code": "# Try extraction with fallback strategy\n",
          "display_code": "",
          "annotation": "Try extraction with fallback strategy",
          "is_comment": true,
          "start_line": 27,
          "line_range": [
            27,
            27
          ],
          "target_line_range": [
            28,
            54
          ]
        },
        {
          "code": "def extract_user_with_fallback(text: str):\n    try:\n        return client.chat.completions.create(  # First attempt with detailed model\n            model=\"gpt-3.5-turbo\",\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Extract user information: {text}\"\n                }\n            ],\n            response_model=DetailedUserProfile,\n            max_retries=2\n        )\n    except InstructorRetryException:\n        print(\"Detailed extraction failed, falling back to basic profile\")\n        return client.chat.completions.create(  # Fall back to simpler model\n            model=\"gpt-3.5-turbo\",\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Extract basic user information: {text}\"\n                }\n            ],\n            response_model=BasicUserProfile,\n            max_retries=1\n        )\n\n",
          "display_code": "def extract_user_with_fallback(text: str):\n    try:\n        return client.chat.completions.create(  # First attempt with detailed model\n            model=\"gpt-3.5-turbo\",\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Extract user information: {text}\"\n                }\n            ],\n            response_model=DetailedUserProfile,\n            max_retries=2\n        )\n    except InstructorRetryException:\n        print(\"Detailed extraction failed, falling back to basic profile\")\n        return client.chat.completions.create(  # Fall back to simpler model\n            model=\"gpt-3.5-turbo\",\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Extract basic user information: {text}\"\n                }\n            ],\n            response_model=BasicUserProfile,\n            max_retries=1\n        )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 28,
          "line_range": [
            28,
            54
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 55,
          "line_range": [
            55,
            55
          ],
          "target_line_range": [
            56,
            59
          ]
        },
        {
          "code": "text = \"John is 25 years old\"\nuser = extract_user_with_fallback(text)\nprint(user.model_dump_json(indent=2))\n\n",
          "display_code": "text = \"John is 25 years old\"\nuser = extract_user_with_fallback(text)\nprint(user.model_dump_json(indent=2))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 56,
          "line_range": [
            56,
            59
          ]
        },
        {
          "code": "# Another approach is to use optional fields for less reliable information:\n",
          "display_code": "",
          "annotation": "Another approach is to use optional fields for less reliable information:",
          "is_comment": true,
          "start_line": 60,
          "line_range": [
            60,
            60
          ],
          "target_line_range": [
            61,
            65
          ]
        },
        {
          "code": "from typing import Optional\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\n\n",
          "display_code": "from typing import Optional\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 61,
          "line_range": [
            61,
            65
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 66,
          "line_range": [
            66,
            66
          ],
          "target_line_range": [
            67,
            68
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 67,
          "line_range": [
            67,
            68
          ]
        },
        {
          "code": "# Define model with optional fields\n",
          "display_code": "",
          "annotation": "Define model with optional fields",
          "is_comment": true,
          "start_line": 69,
          "line_range": [
            69,
            69
          ],
          "target_line_range": [
            70,
            75
          ]
        },
        {
          "code": "class FlexibleProfile(BaseModel):\n    name: str = Field(description=\"Person's name\")\n    age: Optional[int] = Field(None, description=\"Person's age if mentioned\")\n    location: Optional[str] = Field(None, description=\"Person's location if mentioned\")\n    occupation: Optional[str] = Field(None, description=\"Person's job if mentioned\")\n\n",
          "display_code": "class FlexibleProfile(BaseModel):\n    name: str = Field(description=\"Person's name\")\n    age: Optional[int] = Field(None, description=\"Person's age if mentioned\")\n    location: Optional[str] = Field(None, description=\"Person's location if mentioned\")\n    occupation: Optional[str] = Field(None, description=\"Person's job if mentioned\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 70,
          "line_range": [
            70,
            75
          ]
        },
        {
          "code": "# Extract what's available without failing\n",
          "display_code": "",
          "annotation": "Extract what's available without failing",
          "is_comment": true,
          "start_line": 76,
          "line_range": [
            76,
            76
          ],
          "target_line_range": [
            77,
            89
          ]
        },
        {
          "code": "profile = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Sarah is a software engineer from Boston\"\n        }\n    ],\n    response_model=FlexibleProfile\n)\n\nprint(profile.model_dump_json(indent=2))\n\n",
          "display_code": "profile = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Sarah is a software engineer from Boston\"\n        }\n    ],\n    response_model=FlexibleProfile\n)\n\nprint(profile.model_dump_json(indent=2))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 77,
          "line_range": [
            77,
            89
          ]
        },
        {
          "code": "# For critical applications, you can implement a more comprehensive fallback strategy:\n",
          "display_code": "",
          "annotation": "For critical applications, you can implement a more comprehensive fallback strategy:",
          "is_comment": true,
          "start_line": 90,
          "line_range": [
            90,
            90
          ],
          "target_line_range": [
            91,
            95
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, ValidationError\nfrom enum import Enum\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, ValidationError\nfrom enum import Enum\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 91,
          "line_range": [
            91,
            95
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 96,
          "line_range": [
            96,
            96
          ],
          "target_line_range": [
            97,
            98
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 97,
          "line_range": [
            97,
            98
          ]
        },
        {
          "code": "# Define extraction result status\n",
          "display_code": "",
          "annotation": "Define extraction result status",
          "is_comment": true,
          "start_line": 99,
          "line_range": [
            99,
            99
          ],
          "target_line_range": [
            100,
            104
          ]
        },
        {
          "code": "class ExtractionStatus(str, Enum):\n    SUCCESS = \"success\"\n    PARTIAL = \"partial\"\n    FAILED = \"failed\"\n\n",
          "display_code": "class ExtractionStatus(str, Enum):\n    SUCCESS = \"success\"\n    PARTIAL = \"partial\"\n    FAILED = \"failed\"\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 100,
          "line_range": [
            100,
            104
          ]
        },
        {
          "code": "# Define target model\n",
          "display_code": "",
          "annotation": "Define target model",
          "is_comment": true,
          "start_line": 105,
          "line_range": [
            105,
            105
          ],
          "target_line_range": [
            106,
            110
          ]
        },
        {
          "code": "class Contact(BaseModel):\n    name: str\n    email: str\n    phone: str\n\n",
          "display_code": "class Contact(BaseModel):\n    name: str\n    email: str\n    phone: str\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 106,
          "line_range": [
            106,
            110
          ]
        },
        {
          "code": "# Define wrapper for extraction result\n",
          "display_code": "",
          "annotation": "Define wrapper for extraction result",
          "is_comment": true,
          "start_line": 111,
          "line_range": [
            111,
            111
          ],
          "target_line_range": [
            112,
            116
          ]
        },
        {
          "code": "class ExtractionResult(BaseModel):\n    status: ExtractionStatus\n    data: dict\n    error_message: str = \"\"\n\n",
          "display_code": "class ExtractionResult(BaseModel):\n    status: ExtractionStatus\n    data: dict\n    error_message: str = \"\"\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 112,
          "line_range": [
            112,
            116
          ]
        },
        {
          "code": "# Robust extraction function with fallbacks\n",
          "display_code": "",
          "annotation": "Robust extraction function with fallbacks",
          "is_comment": true,
          "start_line": 117,
          "line_range": [
            117,
            117
          ],
          "target_line_range": [
            118,
            129
          ]
        },
        {
          "code": "def extract_with_robustness(text: str) -> ExtractionResult:\n    try:\n        result = client.chat.completions.create(  # Primary extraction attempt\n            model=\"gpt-3.5-turbo\",\n            messages=[{\"role\": \"user\", \"content\": f\"Extract contact info: {text}\"}],\n            response_model=Contact,\n            max_retries=2\n        )\n        return ExtractionResult(\n            status=ExtractionStatus.SUCCESS,\n            data=result.model_dump()\n        )\n",
          "display_code": "def extract_with_robustness(text: str) -> ExtractionResult:\n    try:\n        result = client.chat.completions.create(  # Primary extraction attempt\n            model=\"gpt-3.5-turbo\",\n            messages=[{\"role\": \"user\", \"content\": f\"Extract contact info: {text}\"}],\n            response_model=Contact,\n            max_retries=2\n        )\n        return ExtractionResult(\n            status=ExtractionStatus.SUCCESS,\n            data=result.model_dump()\n        )\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 118,
          "line_range": [
            118,
            129
          ]
        },
        {
          "code": "# Attempt to salvage partial data when extraction fails\n",
          "display_code": "",
          "annotation": "Attempt to salvage partial data when extraction fails",
          "is_comment": true,
          "start_line": 130,
          "line_range": [
            130,
            130
          ],
          "target_line_range": [
            131,
            162
          ]
        },
        {
          "code": "    except InstructorRetryException as e:\n        try:\n            partial_data = {}\n            error_msg = e.messages[-1][\"content\"]  # Parse the error message\n            text_lines = text.split('\\n')\n            for line in text_lines:\n                if \"name:\" in line.lower():\n                    partial_data[\"name\"] = line.split(\"name:\")[1].strip()\n                if \"email:\" in line.lower():\n                    partial_data[\"email\"] = line.split(\"email:\")[1].strip()\n                if \"phone:\" in line.lower():\n                    partial_data[\"phone\"] = line.split(\"phone:\")[1].strip()\n\n            if partial_data:\n                return ExtractionResult(\n                    status=ExtractionStatus.PARTIAL,\n                    data=partial_data,\n                    error_message=error_msg\n                )\n            else:\n                return ExtractionResult(\n                    status=ExtractionStatus.FAILED,\n                    data={},\n                    error_message=error_msg\n                )\n        except Exception as nested_error:\n            return ExtractionResult(\n                status=ExtractionStatus.FAILED,\n                data={},\n                error_message=f\"Complete extraction failure: {str(nested_error)}\"\n            )\n\n",
          "display_code": "    except InstructorRetryException as e:\n        try:\n            partial_data = {}\n            error_msg = e.messages[-1][\"content\"]  # Parse the error message\n            text_lines = text.split('\\n')\n            for line in text_lines:\n                if \"name:\" in line.lower():\n                    partial_data[\"name\"] = line.split(\"name:\")[1].strip()\n                if \"email:\" in line.lower():\n                    partial_data[\"email\"] = line.split(\"email:\")[1].strip()\n                if \"phone:\" in line.lower():\n                    partial_data[\"phone\"] = line.split(\"phone:\")[1].strip()\n\n            if partial_data:\n                return ExtractionResult(\n                    status=ExtractionStatus.PARTIAL,\n                    data=partial_data,\n                    error_message=error_msg\n                )\n            else:\n                return ExtractionResult(\n                    status=ExtractionStatus.FAILED,\n                    data={},\n                    error_message=error_msg\n                )\n        except Exception as nested_error:\n            return ExtractionResult(\n                status=ExtractionStatus.FAILED,\n                data={},\n                error_message=f\"Complete extraction failure: {str(nested_error)}\"\n            )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 131,
          "line_range": [
            131,
            162
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python fallback-strategies.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "007-validation",
      "section_title": "Validation"
    },
    {
      "id": "037-field-level-validation",
      "title": "Field-level Validation",
      "description": "",
      "order": 37,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Apply field-level validation rules to enforce domain-specific business logic. Instructor allows fine-grained control over data validation.\n",
          "display_code": "",
          "annotation": "Apply field-level validation rules to enforce domain-specific business logic. Instructor allows fine-grained control over data validation.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor supports detailed field-level validation to ensure that specific parts of the LLM output meet your requirements. This allows for fine-grained control over the extracted data.\n",
          "display_code": "",
          "annotation": "Instructor supports detailed field-level validation to ensure that specific parts of the LLM output meet your requirements. This allows for fine-grained control over the extracted data.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, field_validator\nimport re\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, field_validator\nimport re\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define a model with field-level validation\n",
          "display_code": "",
          "annotation": "Define a model with field-level validation",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            42
          ]
        },
        {
          "code": "class UserProfile(BaseModel):\n    username: str = Field(\n        description=\"Username (lowercase, no spaces)\",\n        min_length=3,\n        max_length=20\n    )\n    email: str = Field(\n        description=\"Valid email address\"\n    )\n    age: int = Field(\n        description=\"Age in years\",\n        ge=13,  # Greater than or equal to 13\n        le=120  # Less than or equal to 120\n    )\n\n    @field_validator(\"username\")\n    def validate_username(cls, v):\n        if not v.islower() or \" \" in v:\n            raise ValueError(\"Username must be lowercase and contain no spaces\")\n        return v\n\n    @field_validator(\"email\")\n    def validate_email(cls, v):\n        pattern = r\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\"\n        if not re.match(pattern, v):\n            raise ValueError(\"Invalid email format\")\n        return v\n\n",
          "display_code": "class UserProfile(BaseModel):\n    username: str = Field(\n        description=\"Username (lowercase, no spaces)\",\n        min_length=3,\n        max_length=20\n    )\n    email: str = Field(\n        description=\"Valid email address\"\n    )\n    age: int = Field(\n        description=\"Age in years\",\n        ge=13,  # Greater than or equal to 13\n        le=120  # Less than or equal to 120\n    )\n\n    @field_validator(\"username\")\n    def validate_username(cls, v):\n        if not v.islower() or \" \" in v:\n            raise ValueError(\"Username must be lowercase and contain no spaces\")\n        return v\n\n    @field_validator(\"email\")\n    def validate_email(cls, v):\n        pattern = r\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\"\n        if not re.match(pattern, v):\n            raise ValueError(\"Invalid email format\")\n        return v\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            42
          ]
        },
        {
          "code": "# Extract user profile with validation\n",
          "display_code": "",
          "annotation": "Extract user profile with validation",
          "is_comment": true,
          "start_line": 43,
          "line_range": [
            43,
            43
          ],
          "target_line_range": [
            44,
            57
          ]
        },
        {
          "code": "profile = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract user profile: John Doe, john.doe@example.com, 25 years old\"\n        }\n    ],\n    response_model=UserProfile,\n    max_retries=2\n)\n\nprint(profile.model_dump_json(indent=2))\n\n",
          "display_code": "profile = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract user profile: John Doe, john.doe@example.com, 25 years old\"\n        }\n    ],\n    response_model=UserProfile,\n    max_retries=2\n)\n\nprint(profile.model_dump_json(indent=2))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 44,
          "line_range": [
            44,
            57
          ]
        },
        {
          "code": "# You can also use Pydantic's Field parameters for basic constraints:\n",
          "display_code": "",
          "annotation": "You can also use Pydantic's Field parameters for basic constraints:",
          "is_comment": true,
          "start_line": 58,
          "line_range": [
            58,
            58
          ],
          "target_line_range": [
            59,
            63
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 59,
          "line_range": [
            59,
            63
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 64,
          "line_range": [
            64,
            64
          ],
          "target_line_range": [
            65,
            66
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 65,
          "line_range": [
            65,
            66
          ]
        },
        {
          "code": "# Define a model with Field constraints\n",
          "display_code": "",
          "annotation": "Define a model with Field constraints",
          "is_comment": true,
          "start_line": 67,
          "line_range": [
            67,
            67
          ],
          "target_line_range": [
            68,
            88
          ]
        },
        {
          "code": "class Product(BaseModel):\n    name: str = Field(\n        description=\"Product name\",\n        min_length=2,\n        max_length=100\n    )\n    price: float = Field(\n        description=\"Product price in USD\",\n        gt=0  # Greater than 0\n    )\n    description: str = Field(\n        description=\"Product description\",\n        min_length=10,\n        max_length=1000\n    )\n    tags: List[str] = Field(\n        description=\"Product tags\",\n        min_length=1,  # At least one tag\n        max_length=10  # At most 10 tags\n    )\n\n",
          "display_code": "class Product(BaseModel):\n    name: str = Field(\n        description=\"Product name\",\n        min_length=2,\n        max_length=100\n    )\n    price: float = Field(\n        description=\"Product price in USD\",\n        gt=0  # Greater than 0\n    )\n    description: str = Field(\n        description=\"Product description\",\n        min_length=10,\n        max_length=1000\n    )\n    tags: List[str] = Field(\n        description=\"Product tags\",\n        min_length=1,  # At least one tag\n        max_length=10  # At most 10 tags\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 68,
          "line_range": [
            68,
            88
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 89,
          "line_range": [
            89,
            89
          ],
          "target_line_range": [
            90,
            102
          ]
        },
        {
          "code": "product = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract product info: iPhone, $999, Latest smartphone with advanced features, tags: electronics, smartphone, apple\"\n        }\n    ],\n    response_model=Product\n)\n\nprint(product.model_dump_json(indent=2))\n\n",
          "display_code": "product = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract product info: iPhone, $999, Latest smartphone with advanced features, tags: electronics, smartphone, apple\"\n        }\n    ],\n    response_model=Product\n)\n\nprint(product.model_dump_json(indent=2))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 90,
          "line_range": [
            90,
            102
          ]
        },
        {
          "code": "# For more complex validation, you can use annotated types:\n",
          "display_code": "",
          "annotation": "For more complex validation, you can use annotated types:",
          "is_comment": true,
          "start_line": 103,
          "line_range": [
            103,
            103
          ],
          "target_line_range": [
            104,
            109
          ]
        },
        {
          "code": "from typing_extensions import Annotated\nfrom pydantic import AfterValidator\nimport re\n\ndef validate_phone_number(v: str) -> str:\n    \"\"\"Validate phone number format.\"\"\"\n",
          "display_code": "from typing_extensions import Annotated\nfrom pydantic import AfterValidator\nimport re\n\ndef validate_phone_number(v: str) -> str:\n    \"\"\"Validate phone number format.\"\"\"\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 104,
          "line_range": [
            104,
            109
          ]
        },
        {
          "code": "    # Remove all non-numeric characters\n",
          "display_code": "",
          "annotation": "Remove all non-numeric characters",
          "is_comment": true,
          "start_line": 110,
          "line_range": [
            110,
            110
          ],
          "target_line_range": [
            111,
            129
          ]
        },
        {
          "code": "    digits = ''.join(c for c in v if c.isdigit())\n    if len(digits) < 10:\n        raise ValueError(\"Phone number must have at least 10 digits\")\n    return v\n\ndef validate_zip_code(v: str) -> str:\n    \"\"\"Validate US zip code format.\"\"\"\n    pattern = r\"^\\d{5}(-\\d{4})?$\"\n    if not re.match(pattern, v):\n        raise ValueError(\"Invalid zip code format (must be 12345 or 12345-6789)\")\n    return v\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    state: str\n    zip_code: Annotated[str, AfterValidator(validate_zip_code)]\n    phone: Annotated[str, AfterValidator(validate_phone_number)]\n\n",
          "display_code": "    digits = ''.join(c for c in v if c.isdigit())\n    if len(digits) < 10:\n        raise ValueError(\"Phone number must have at least 10 digits\")\n    return v\n\ndef validate_zip_code(v: str) -> str:\n    \"\"\"Validate US zip code format.\"\"\"\n    pattern = r\"^\\d{5}(-\\d{4})?$\"\n    if not re.match(pattern, v):\n        raise ValueError(\"Invalid zip code format (must be 12345 or 12345-6789)\")\n    return v\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    state: str\n    zip_code: Annotated[str, AfterValidator(validate_zip_code)]\n    phone: Annotated[str, AfterValidator(validate_phone_number)]\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 111,
          "line_range": [
            111,
            129
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python field-level-validation.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "007-validation",
      "section_title": "Validation"
    },
    {
      "id": "038-vision-inputs",
      "title": "Vision",
      "description": "",
      "order": 38,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Process and extract data from images with Instructor. Supports automatic detection of image paths and URLs for multimodal extraction.\n",
          "display_code": "",
          "annotation": "Process and extract data from images with Instructor. Supports automatic detection of image paths and URLs for multimodal extraction.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor provides simple, unified handling of vision inputs across different LLM providers through its `Image` class, which automatically handles the details of image formatting for each provider.\n",
          "display_code": "",
          "annotation": "Instructor provides simple, unified handling of vision inputs across different LLM providers through its `Image` class, which automatically handles the details of image formatting for each provider.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define a model for image analysis\n",
          "display_code": "",
          "annotation": "Define a model for image analysis",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            19
          ]
        },
        {
          "code": "class ImageContent(BaseModel):\n    description: str = Field(description=\"A detailed description of the image\")\n    objects: List[str] = Field(description=\"List of main objects in the image\")\n    colors: List[str] = Field(description=\"Dominant colors in the image\")\n\n",
          "display_code": "class ImageContent(BaseModel):\n    description: str = Field(description=\"A detailed description of the image\")\n    objects: List[str] = Field(description=\"List of main objects in the image\")\n    colors: List[str] = Field(description=\"Dominant colors in the image\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            19
          ]
        },
        {
          "code": "# Creating an Image object from a file path\n# Load images from local files for analysis\n",
          "display_code": "",
          "annotation": "Creating an Image object from a file path\nLoad images from local files for analysis",
          "is_comment": true,
          "start_line": 20,
          "line_range": [
            20,
            21
          ],
          "target_line_range": [
            22,
            38
          ]
        },
        {
          "code": "def analyze_image_from_file(file_path: str) -> ImageContent:\n    image = instructor.Image.from_path(file_path)\n\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=ImageContent,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Describe this image in detail:\",\n                    image  # The Image object is handled automatically\n                ]\n            }\n        ]\n    )\n\n",
          "display_code": "def analyze_image_from_file(file_path: str) -> ImageContent:\n    image = instructor.Image.from_path(file_path)\n\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=ImageContent,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Describe this image in detail:\",\n                    image  # The Image object is handled automatically\n                ]\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 22,
          "line_range": [
            22,
            38
          ]
        },
        {
          "code": "# Creating an Image object from a URL\n# Load images from URLs for analysis\n",
          "display_code": "",
          "annotation": "Creating an Image object from a URL\nLoad images from URLs for analysis",
          "is_comment": true,
          "start_line": 39,
          "line_range": [
            39,
            40
          ],
          "target_line_range": [
            41,
            57
          ]
        },
        {
          "code": "def analyze_image_from_url(image_url: str) -> ImageContent:\n    image = instructor.Image.from_url(image_url)\n\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=ImageContent,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Describe this image in detail:\",\n                    image\n                ]\n            }\n        ]\n    )\n\n",
          "display_code": "def analyze_image_from_url(image_url: str) -> ImageContent:\n    image = instructor.Image.from_url(image_url)\n\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=ImageContent,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Describe this image in detail:\",\n                    image\n                ]\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 41,
          "line_range": [
            41,
            57
          ]
        },
        {
          "code": "# Using autodetect_images for convenience\n",
          "display_code": "",
          "annotation": "Using autodetect_images for convenience",
          "is_comment": true,
          "start_line": 58,
          "line_range": [
            58,
            58
          ],
          "target_line_range": [
            59,
            74
          ]
        },
        {
          "code": "def analyze_with_autodetect(image_path_or_url: str) -> ImageContent:\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=ImageContent,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Describe this image in detail:\",\n                    image_path_or_url  # Will be automatically detected as an image\n                ]\n            }\n        ],\n        autodetect_images=True  # Automatically converts paths/URLs to Image objects\n    )\n\n",
          "display_code": "def analyze_with_autodetect(image_path_or_url: str) -> ImageContent:\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=ImageContent,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Describe this image in detail:\",\n                    image_path_or_url  # Will be automatically detected as an image\n                ]\n            }\n        ],\n        autodetect_images=True  # Automatically converts paths/URLs to Image objects\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 59,
          "line_range": [
            59,
            74
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 75,
          "line_range": [
            75,
            75
          ],
          "target_line_range": [
            76,
            80
          ]
        },
        {
          "code": "result = analyze_with_autodetect(\"https://example.com/image.jpg\")\nprint(f\"Description: {result.description}\")\nprint(f\"Objects: {', '.join(result.objects)}\")\nprint(f\"Colors: {', '.join(result.colors)}\")\n\n",
          "display_code": "result = analyze_with_autodetect(\"https://example.com/image.jpg\")\nprint(f\"Description: {result.description}\")\nprint(f\"Objects: {', '.join(result.objects)}\")\nprint(f\"Colors: {', '.join(result.colors)}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 76,
          "line_range": [
            76,
            80
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python vision-inputs.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "008-multimodal",
      "section_title": "Multimodal Inputs"
    },
    {
      "id": "039-image-to-structured-data",
      "title": "Image Extraction",
      "description": "",
      "order": 39,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Convert image content into structured data with Instructor. Enables integration with downstream processing pipelines for visual data.\n",
          "display_code": "",
          "annotation": "Convert image content into structured data with Instructor. Enables integration with downstream processing pipelines for visual data.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor excels at transforming images into structured data, combining vision capabilities with Pydantic models for reliable extraction.\n",
          "display_code": "",
          "annotation": "Instructor excels at transforming images into structured data, combining vision capabilities with Pydantic models for reliable extraction.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define a structured data model for product information\n",
          "display_code": "",
          "annotation": "Define a structured data model for product information",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            21
          ]
        },
        {
          "code": "class Product(BaseModel):\n    name: str = Field(description=\"Product name\")\n    price: float = Field(description=\"Product price in USD\")\n    description: str = Field(description=\"Brief product description\")\n    features: List[str] = Field(description=\"Key product features\")\n    brand: Optional[str] = Field(None, description=\"Brand name if visible\")\n\n",
          "display_code": "class Product(BaseModel):\n    name: str = Field(description=\"Product name\")\n    price: float = Field(description=\"Product price in USD\")\n    description: str = Field(description=\"Brief product description\")\n    features: List[str] = Field(description=\"Key product features\")\n    brand: Optional[str] = Field(None, description=\"Brand name if visible\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            21
          ]
        },
        {
          "code": "# Extract product information from an image\n",
          "display_code": "",
          "annotation": "Extract product information from an image",
          "is_comment": true,
          "start_line": 22,
          "line_range": [
            22,
            22
          ],
          "target_line_range": [
            23,
            38
          ]
        },
        {
          "code": "def extract_product_info(image_path_or_url: str) -> Product:\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=Product,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Extract detailed product information from this image:\",\n                    image_path_or_url\n                ]\n            }\n        ],\n        autodetect_images=True  # Automatically handle the image\n    )\n\n",
          "display_code": "def extract_product_info(image_path_or_url: str) -> Product:\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=Product,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Extract detailed product information from this image:\",\n                    image_path_or_url\n                ]\n            }\n        ],\n        autodetect_images=True  # Automatically handle the image\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 23,
          "line_range": [
            23,
            38
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 39,
          "line_range": [
            39,
            39
          ],
          "target_line_range": [
            40,
            46
          ]
        },
        {
          "code": "product = extract_product_info(\"path/to/product_image.jpg\")\nprint(f\"Product: {product.name} (${product.price:.2f})\")\nprint(f\"Description: {product.description}\")\nprint(f\"Features: {', '.join(product.features)}\")\nif product.brand:\n    print(f\"Brand: {product.brand}\")\n\n",
          "display_code": "product = extract_product_info(\"path/to/product_image.jpg\")\nprint(f\"Product: {product.name} (${product.price:.2f})\")\nprint(f\"Description: {product.description}\")\nprint(f\"Features: {', '.join(product.features)}\")\nif product.brand:\n    print(f\"Brand: {product.brand}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 40,
          "line_range": [
            40,
            46
          ]
        },
        {
          "code": "# You can extract more complex data structures from images:\n",
          "display_code": "",
          "annotation": "You can extract more complex data structures from images:",
          "is_comment": true,
          "start_line": 47,
          "line_range": [
            47,
            47
          ],
          "target_line_range": [
            48,
            52
          ]
        },
        {
          "code": "from typing import List, Optional\nfrom pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\n\n",
          "display_code": "from typing import List, Optional\nfrom pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 48,
          "line_range": [
            48,
            52
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 53,
          "line_range": [
            53,
            53
          ],
          "target_line_range": [
            54,
            55
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 54,
          "line_range": [
            54,
            55
          ]
        },
        {
          "code": "# Define a recipe structure\n",
          "display_code": "",
          "annotation": "Define a recipe structure",
          "is_comment": true,
          "start_line": 56,
          "line_range": [
            56,
            56
          ],
          "target_line_range": [
            57,
            74
          ]
        },
        {
          "code": "class Ingredient(BaseModel):\n    name: str = Field(description=\"Ingredient name\")\n    quantity: str = Field(description=\"Amount needed, including units\")\n    optional: bool = Field(description=\"Whether this ingredient is optional\")\n\nclass Step(BaseModel):\n    instruction: str = Field(description=\"Cooking instruction\")\n    time_minutes: Optional[int] = Field(None, description=\"Time required for this step in minutes\")\n\nclass Recipe(BaseModel):\n    title: str = Field(description=\"Recipe title\")\n    servings: int = Field(description=\"Number of servings\")\n    prep_time_minutes: int = Field(description=\"Preparation time in minutes\")\n    cook_time_minutes: int = Field(description=\"Cooking time in minutes\")\n    ingredients: List[Ingredient] = Field(description=\"List of ingredients\")\n    steps: List[Step] = Field(description=\"Cooking steps in order\")\n    difficulty: str = Field(description=\"Recipe difficulty (easy, medium, hard)\")\n\n",
          "display_code": "class Ingredient(BaseModel):\n    name: str = Field(description=\"Ingredient name\")\n    quantity: str = Field(description=\"Amount needed, including units\")\n    optional: bool = Field(description=\"Whether this ingredient is optional\")\n\nclass Step(BaseModel):\n    instruction: str = Field(description=\"Cooking instruction\")\n    time_minutes: Optional[int] = Field(None, description=\"Time required for this step in minutes\")\n\nclass Recipe(BaseModel):\n    title: str = Field(description=\"Recipe title\")\n    servings: int = Field(description=\"Number of servings\")\n    prep_time_minutes: int = Field(description=\"Preparation time in minutes\")\n    cook_time_minutes: int = Field(description=\"Cooking time in minutes\")\n    ingredients: List[Ingredient] = Field(description=\"List of ingredients\")\n    steps: List[Step] = Field(description=\"Cooking steps in order\")\n    difficulty: str = Field(description=\"Recipe difficulty (easy, medium, hard)\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 57,
          "line_range": [
            57,
            74
          ]
        },
        {
          "code": "# Extract recipe from an image\n",
          "display_code": "",
          "annotation": "Extract recipe from an image",
          "is_comment": true,
          "start_line": 75,
          "line_range": [
            75,
            75
          ],
          "target_line_range": [
            76,
            76
          ]
        },
        {
          "code": "def extract_recipe(image_path: str) -> Recipe:\n",
          "display_code": "def extract_recipe(image_path: str) -> Recipe:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 76,
          "line_range": [
            76,
            76
          ]
        },
        {
          "code": "    # Create an Image object\n",
          "display_code": "",
          "annotation": "Create an Image object",
          "is_comment": true,
          "start_line": 77,
          "line_range": [
            77,
            77
          ],
          "target_line_range": [
            78,
            97
          ]
        },
        {
          "code": "    image = instructor.Image.from_path(image_path)\n\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=Recipe,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract complete recipe information from the provided image.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Please extract the detailed recipe information from this image:\",\n                    image\n                ]\n            }\n        ]\n    )\n\n",
          "display_code": "    image = instructor.Image.from_path(image_path)\n\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=Recipe,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract complete recipe information from the provided image.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Please extract the detailed recipe information from this image:\",\n                    image\n                ]\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 78,
          "line_range": [
            78,
            97
          ]
        },
        {
          "code": "# The function would be used like this:\n# recipe = extract_recipe(\"path/to/recipe_card.jpg\")\n",
          "display_code": "",
          "annotation": "The function would be used like this:\nrecipe = extract_recipe(\"path/to/recipe_card.jpg\")",
          "is_comment": true,
          "start_line": 98,
          "line_range": [
            98,
            99
          ],
          "target_line_range": [
            100,
            100
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 100,
          "line_range": [
            100,
            100
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python image-to-structured-data.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "008-multimodal",
      "section_title": "Multimodal Inputs"
    },
    {
      "id": "040-table-extraction",
      "title": "Table Extraction",
      "description": "",
      "order": 40,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Extract structured tabular data from text using Instructor. Add descriptive metadata like captions to enhance table representation.\n",
          "display_code": "",
          "annotation": "Extract structured tabular data from text using Instructor. Add descriptive metadata like captions to enhance table representation.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor makes it easy to extract structured tables from images and convert them to pandas dataframes for analysis.\n",
          "display_code": "",
          "annotation": "Instructor makes it easy to extract structured tables from images and convert them to pandas dataframes for analysis.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            19
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nimport pandas as pd\nfrom typing import Annotated, Any\nfrom io import StringIO\nfrom pydantic import (\n    BaseModel,\n    BeforeValidator,\n    PlainSerializer,\n    InstanceOf,\n    WithJsonSchema,\n)\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nimport pandas as pd\nfrom typing import Annotated, Any\nfrom io import StringIO\nfrom pydantic import (\n    BaseModel,\n    BeforeValidator,\n    PlainSerializer,\n    InstanceOf,\n    WithJsonSchema,\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            19
          ]
        },
        {
          "code": "# Initialize the client with instructor (MD_JSON mode works well for tables)\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor (MD_JSON mode works well for tables)",
          "is_comment": true,
          "start_line": 20,
          "line_range": [
            20,
            20
          ],
          "target_line_range": [
            21,
            23
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI(), mode=instructor.Mode.MD_JSON)\n\n\n",
          "display_code": "client = instructor.from_openai(OpenAI(), mode=instructor.Mode.MD_JSON)\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 21,
          "line_range": [
            21,
            23
          ]
        },
        {
          "code": "# Define functions to convert between dataframe and markdown\n",
          "display_code": "",
          "annotation": "Define functions to convert between dataframe and markdown",
          "is_comment": true,
          "start_line": 24,
          "line_range": [
            24,
            24
          ],
          "target_line_range": [
            25,
            45
          ]
        },
        {
          "code": "def to_markdown(df: pd.DataFrame) -> str:\n    \"\"\"Convert a dataframe to markdown format.\"\"\"\n    return df.to_markdown()\n\n\ndef md_to_df(data: Any) -> Any:\n    \"\"\"Convert markdown table to a pandas dataframe.\"\"\"\n    if isinstance(data, str):\n        return (\n            pd.read_csv(\n                StringIO(data),\n                sep=\"|\",\n                index_col=1,\n            )\n            .dropna(axis=1, how=\"all\")\n            .iloc[1:]\n            .map(lambda x: x.strip())\n        )\n    return data\n\n\n",
          "display_code": "def to_markdown(df: pd.DataFrame) -> str:\n    \"\"\"Convert a dataframe to markdown format.\"\"\"\n    return df.to_markdown()\n\n\ndef md_to_df(data: Any) -> Any:\n    \"\"\"Convert markdown table to a pandas dataframe.\"\"\"\n    if isinstance(data, str):\n        return (\n            pd.read_csv(\n                StringIO(data),\n                sep=\"|\",\n                index_col=1,\n            )\n            .dropna(axis=1, how=\"all\")\n            .iloc[1:]\n            .map(lambda x: x.strip())\n        )\n    return data\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 25,
          "line_range": [
            25,
            45
          ]
        },
        {
          "code": "# Define a custom type for markdown dataframes\n",
          "display_code": "",
          "annotation": "Define a custom type for markdown dataframes",
          "is_comment": true,
          "start_line": 46,
          "line_range": [
            46,
            46
          ],
          "target_line_range": [
            47,
            59
          ]
        },
        {
          "code": "MarkdownDataFrame = Annotated[\n    InstanceOf[pd.DataFrame],\n    BeforeValidator(md_to_df),\n    PlainSerializer(to_markdown),\n    WithJsonSchema(\n        {\n            \"type\": \"string\",\n            \"description\": \"The markdown representation of the table\",\n        }\n    ),\n]\n\n\n",
          "display_code": "MarkdownDataFrame = Annotated[\n    InstanceOf[pd.DataFrame],\n    BeforeValidator(md_to_df),\n    PlainSerializer(to_markdown),\n    WithJsonSchema(\n        {\n            \"type\": \"string\",\n            \"description\": \"The markdown representation of the table\",\n        }\n    ),\n]\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 47,
          "line_range": [
            47,
            59
          ]
        },
        {
          "code": "# Define the table model\n",
          "display_code": "",
          "annotation": "Define the table model",
          "is_comment": true,
          "start_line": 60,
          "line_range": [
            60,
            60
          ],
          "target_line_range": [
            61,
            67
          ]
        },
        {
          "code": "class Table(BaseModel):\n    caption: str = Field(description=\"A descriptive caption for the table\")\n    dataframe: MarkdownDataFrame = Field(\n        description=\"The table data as a markdown table\"\n    )\n\n\n",
          "display_code": "class Table(BaseModel):\n    caption: str = Field(description=\"A descriptive caption for the table\")\n    dataframe: MarkdownDataFrame = Field(\n        description=\"The table data as a markdown table\"\n    )\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 61,
          "line_range": [
            61,
            67
          ]
        },
        {
          "code": "# Function to extract tables from images\n# Create an image object or use autodetect\n",
          "display_code": "",
          "annotation": "Function to extract tables from images\nCreate an image object or use autodetect",
          "is_comment": true,
          "start_line": 68,
          "line_range": [
            68,
            69
          ],
          "target_line_range": [
            70,
            95
          ]
        },
        {
          "code": "def extract_table_from_image(image_path_or_url: str) -> Table:\n    \"\"\"Extract a table from an image and return it as a structured object.\"\"\"\n    if image_path_or_url.startswith((\"http://\", \"https://\")):\n        image = instructor.Image.from_url(image_path_or_url)\n    else:\n        image = instructor.Image.from_path(image_path_or_url)\n\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=Table,\n        max_tokens=1800,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": \"Extract the table from this image with a descriptive caption.\",\n                    },\n                    image,\n                ],\n            }\n        ],\n    )\n\n\n",
          "display_code": "def extract_table_from_image(image_path_or_url: str) -> Table:\n    \"\"\"Extract a table from an image and return it as a structured object.\"\"\"\n    if image_path_or_url.startswith((\"http://\", \"https://\")):\n        image = instructor.Image.from_url(image_path_or_url)\n    else:\n        image = instructor.Image.from_path(image_path_or_url)\n\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=Table,\n        max_tokens=1800,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": \"Extract the table from this image with a descriptive caption.\",\n                    },\n                    image,\n                ],\n            }\n        ],\n    )\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 70,
          "line_range": [
            70,
            95
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 96,
          "line_range": [
            96,
            96
          ],
          "target_line_range": [
            97,
            104
          ]
        },
        {
          "code": "def analyze_table_data(image_path: str):\n    \"\"\"Extract and analyze a table from an image.\"\"\"\n    table = extract_table_from_image(image_path)\n\n    print(f\"Table Caption: {table.caption}\")\n    print(\"\\nExtracted Table:\")\n    print(table.dataframe)\n\n",
          "display_code": "def analyze_table_data(image_path: str):\n    \"\"\"Extract and analyze a table from an image.\"\"\"\n    table = extract_table_from_image(image_path)\n\n    print(f\"Table Caption: {table.caption}\")\n    print(\"\\nExtracted Table:\")\n    print(table.dataframe)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 97,
          "line_range": [
            97,
            104
          ]
        },
        {
          "code": "    # Perform data analysis if it's a pandas DataFrame\n",
          "display_code": "",
          "annotation": "Perform data analysis if it's a pandas DataFrame",
          "is_comment": true,
          "start_line": 105,
          "line_range": [
            105,
            105
          ],
          "target_line_range": [
            106,
            110
          ]
        },
        {
          "code": "    if isinstance(table.dataframe, pd.DataFrame):\n        print(\"\\nData Analysis:\")\n        print(f\"- Rows: {len(table.dataframe)}\")\n        print(f\"- Columns: {len(table.dataframe.columns)}\")\n\n",
          "display_code": "    if isinstance(table.dataframe, pd.DataFrame):\n        print(\"\\nData Analysis:\")\n        print(f\"- Rows: {len(table.dataframe)}\")\n        print(f\"- Columns: {len(table.dataframe.columns)}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 106,
          "line_range": [
            106,
            110
          ]
        },
        {
          "code": "        # Basic statistics if numeric columns exist\n",
          "display_code": "",
          "annotation": "Basic statistics if numeric columns exist",
          "is_comment": true,
          "start_line": 111,
          "line_range": [
            111,
            111
          ],
          "target_line_range": [
            112,
            125
          ]
        },
        {
          "code": "        numeric_cols = table.dataframe.select_dtypes(include=[\"number\"]).columns\n        if len(numeric_cols) > 0:\n            print(\"\\nNumeric Column Statistics:\")\n            for col in numeric_cols:\n                col_data = table.dataframe[col]\n                print(\n                    f\"- {col}: Min={col_data.min()}, Max={col_data.max()}, Mean={col_data.mean():.2f}\"\n                )\n\n        return table.dataframe\n\n    return None\n\n\n",
          "display_code": "        numeric_cols = table.dataframe.select_dtypes(include=[\"number\"]).columns\n        if len(numeric_cols) > 0:\n            print(\"\\nNumeric Column Statistics:\")\n            for col in numeric_cols:\n                col_data = table.dataframe[col]\n                print(\n                    f\"- {col}: Min={col_data.min()}, Max={col_data.max()}, Mean={col_data.mean():.2f}\"\n                )\n\n        return table.dataframe\n\n    return None\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 112,
          "line_range": [
            112,
            125
          ]
        },
        {
          "code": "# This would be called as:\n# df = analyze_table_data(\"path/to/table_image.jpg\")\n# After this, you can use pandas operations on the dataframe\n# For multiple tables in a single image, you can use the iterable response:\n",
          "display_code": "",
          "annotation": "This would be called as:\ndf = analyze_table_data(\"path/to/table_image.jpg\")\nAfter this, you can use pandas operations on the dataframe\nFor multiple tables in a single image, you can use the iterable response:",
          "is_comment": true,
          "start_line": 126,
          "line_range": [
            126,
            129
          ],
          "target_line_range": [
            130,
            157
          ]
        },
        {
          "code": "def extract_multiple_tables(image_path_or_url: str) -> list[Table]:\n    \"\"\"Extract all tables from an image.\"\"\"\n    if image_path_or_url.startswith((\"http://\", \"https://\")):\n        image = instructor.Image.from_url(image_path_or_url)\n    else:\n        image = instructor.Image.from_path(image_path_or_url)\n\n    tables = client.chat.completions.create_iterable(\n        model=\"gpt-4-vision-preview\",\n        response_model=Table,\n        max_tokens=1800,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": \"Extract all tables from this image. Each table should be separate and have its own caption.\",\n                    },\n                    image,\n                ],\n            }\n        ],\n    )\n\n    return list(tables)\n\n\n",
          "display_code": "def extract_multiple_tables(image_path_or_url: str) -> list[Table]:\n    \"\"\"Extract all tables from an image.\"\"\"\n    if image_path_or_url.startswith((\"http://\", \"https://\")):\n        image = instructor.Image.from_url(image_path_or_url)\n    else:\n        image = instructor.Image.from_path(image_path_or_url)\n\n    tables = client.chat.completions.create_iterable(\n        model=\"gpt-4-vision-preview\",\n        response_model=Table,\n        max_tokens=1800,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": \"Extract all tables from this image. Each table should be separate and have its own caption.\",\n                    },\n                    image,\n                ],\n            }\n        ],\n    )\n\n    return list(tables)\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 130,
          "line_range": [
            130,
            157
          ]
        },
        {
          "code": "# Process multiple tables from one image\n# Convert to dataframe and return list of dataframes\n",
          "display_code": "",
          "annotation": "Process multiple tables from one image\nConvert to dataframe and return list of dataframes",
          "is_comment": true,
          "start_line": 158,
          "line_range": [
            158,
            159
          ],
          "target_line_range": [
            160,
            171
          ]
        },
        {
          "code": "def analyze_multiple_tables(image_path: str):\n    \"\"\"Extract and analyze all tables from an image.\"\"\"\n    tables = extract_multiple_tables(image_path)\n\n    print(f\"Found {len(tables)} tables in the image.\")\n\n    for i, table in enumerate(tables):\n        print(f\"\\n--- Table {i+1}: {table.caption} ---\")\n        print(table.dataframe)\n\n        if isinstance(table.dataframe, pd.DataFrame):\n            yield table.dataframe\n",
          "display_code": "def analyze_multiple_tables(image_path: str):\n    \"\"\"Extract and analyze all tables from an image.\"\"\"\n    tables = extract_multiple_tables(image_path)\n\n    print(f\"Found {len(tables)} tables in the image.\")\n\n    for i, table in enumerate(tables):\n        print(f\"\\n--- Table {i+1}: {table.caption} ---\")\n        print(table.dataframe)\n\n        if isinstance(table.dataframe, pd.DataFrame):\n            yield table.dataframe\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 160,
          "line_range": [
            160,
            171
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python table-extraction.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "008-multimodal",
      "section_title": "Multimodal Inputs"
    },
    {
      "id": "041-audio-extraction",
      "title": "Audio Extraction",
      "description": "",
      "order": 41,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Extract structured information from audio content using Instructor. Supports handling multilingual audio and transcription data.\n",
          "display_code": "",
          "annotation": "Extract structured information from audio content using Instructor. Supports handling multilingual audio and transcription data.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor supports extracting structured data from audio files using the `Audio` class, making it easy to process speech and audio content.\n",
          "display_code": "",
          "annotation": "Instructor supports extracting structured data from audio files using the `Audio` class, making it easy to process speech and audio content.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom instructor.multimodal import Audio\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom instructor.multimodal import Audio\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define a model for audio transcription\n",
          "display_code": "",
          "annotation": "Define a model for audio transcription",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            20
          ]
        },
        {
          "code": "class AudioTranscription(BaseModel):\n    text: str = Field(description=\"Full transcription of the audio\")\n    speaker: str = Field(description=\"Identity of the speaker if known\")\n    language: str = Field(description=\"Language spoken in the audio\")\n    confidence: float = Field(description=\"Confidence score for the transcription\", ge=0.0, le=1.0)\n\n",
          "display_code": "class AudioTranscription(BaseModel):\n    text: str = Field(description=\"Full transcription of the audio\")\n    speaker: str = Field(description=\"Identity of the speaker if known\")\n    language: str = Field(description=\"Language spoken in the audio\")\n    confidence: float = Field(description=\"Confidence score for the transcription\", ge=0.0, le=1.0)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            20
          ]
        },
        {
          "code": "# Extract transcription from audio\n",
          "display_code": "",
          "annotation": "Extract transcription from audio",
          "is_comment": true,
          "start_line": 21,
          "line_range": [
            21,
            21
          ],
          "target_line_range": [
            22,
            23
          ]
        },
        {
          "code": "def transcribe_audio(audio_path: str) -> AudioTranscription:\n    \"\"\"Extract structured transcription from an audio file.\"\"\"\n",
          "display_code": "def transcribe_audio(audio_path: str) -> AudioTranscription:\n    \"\"\"Extract structured transcription from an audio file.\"\"\"\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 22,
          "line_range": [
            22,
            23
          ]
        },
        {
          "code": "    # Load the audio using Instructor's Audio class\n",
          "display_code": "",
          "annotation": "Load the audio using Instructor's Audio class",
          "is_comment": true,
          "start_line": 24,
          "line_range": [
            24,
            24
          ],
          "target_line_range": [
            25,
            40
          ]
        },
        {
          "code": "    audio = Audio.from_path(audio_path)\n\n    return client.chat.completions.create(\n        model=\"gpt-4o-audio-preview\",  # Audio-capable model\n        response_model=AudioTranscription,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Transcribe this audio file and identify the speaker and language:\",\n                    audio  # The Audio object is handled automatically\n                ]\n            }\n        ]\n    )\n\n",
          "display_code": "    audio = Audio.from_path(audio_path)\n\n    return client.chat.completions.create(\n        model=\"gpt-4o-audio-preview\",  # Audio-capable model\n        response_model=AudioTranscription,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Transcribe this audio file and identify the speaker and language:\",\n                    audio  # The Audio object is handled automatically\n                ]\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 25,
          "line_range": [
            25,
            40
          ]
        },
        {
          "code": "# Example usage\n# transcript = transcribe_audio(\"path/to/audio.wav\")\n# print(f\"Transcript: {transcript.text}\")\n# print(f\"Speaker: {transcript.speaker}\")\n# print(f\"Language: {transcript.language}\")\n# print(f\"Confidence: {transcript.confidence:.2f}\")\n",
          "display_code": "",
          "annotation": "Example usage\ntranscript = transcribe_audio(\"path/to/audio.wav\")\nprint(f\"Transcript: {transcript.text}\")\nprint(f\"Speaker: {transcript.speaker}\")\nprint(f\"Language: {transcript.language}\")\nprint(f\"Confidence: {transcript.confidence:.2f}\")",
          "is_comment": true,
          "start_line": 41,
          "line_range": [
            41,
            46
          ],
          "target_line_range": [
            47,
            47
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 47,
          "line_range": [
            47,
            47
          ]
        },
        {
          "code": "# For more specific information extraction from audio:\n",
          "display_code": "",
          "annotation": "For more specific information extraction from audio:",
          "is_comment": true,
          "start_line": 48,
          "line_range": [
            48,
            48
          ],
          "target_line_range": [
            49,
            54
          ]
        },
        {
          "code": "from typing import List, Optional\nfrom pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\nfrom instructor.multimodal import Audio\n\n",
          "display_code": "from typing import List, Optional\nfrom pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\nfrom instructor.multimodal import Audio\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 49,
          "line_range": [
            49,
            54
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 55,
          "line_range": [
            55,
            55
          ],
          "target_line_range": [
            56,
            57
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 56,
          "line_range": [
            56,
            57
          ]
        },
        {
          "code": "# Define a model for person information\n",
          "display_code": "",
          "annotation": "Define a model for person information",
          "is_comment": true,
          "start_line": 58,
          "line_range": [
            58,
            58
          ],
          "target_line_range": [
            59,
            63
          ]
        },
        {
          "code": "class Person(BaseModel):\n    name: str = Field(description=\"Person's full name\")\n    age: int = Field(description=\"Person's age in years\")\n    occupation: Optional[str] = Field(None, description=\"Person's job or profession if mentioned\")\n\n",
          "display_code": "class Person(BaseModel):\n    name: str = Field(description=\"Person's full name\")\n    age: int = Field(description=\"Person's age in years\")\n    occupation: Optional[str] = Field(None, description=\"Person's job or profession if mentioned\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 59,
          "line_range": [
            59,
            63
          ]
        },
        {
          "code": "# Define a model for meeting information\n",
          "display_code": "",
          "annotation": "Define a model for meeting information",
          "is_comment": true,
          "start_line": 64,
          "line_range": [
            64,
            64
          ],
          "target_line_range": [
            65,
            76
          ]
        },
        {
          "code": "class MeetingPoint(BaseModel):\n    topic: str = Field(description=\"Topic discussed\")\n    decision: Optional[str] = Field(None, description=\"Decision made on this topic\")\n    action_items: List[str] = Field(default_factory=list, description=\"Action items related to this topic\")\n\nclass Meeting(BaseModel):\n    title: str = Field(description=\"Meeting title or purpose\")\n    date: Optional[str] = Field(None, description=\"Meeting date if mentioned\")\n    participants: List[str] = Field(description=\"Names of meeting participants\")\n    key_points: List[MeetingPoint] = Field(description=\"Key discussion points and decisions\")\n    summary: str = Field(description=\"Brief summary of the meeting\")\n\n",
          "display_code": "class MeetingPoint(BaseModel):\n    topic: str = Field(description=\"Topic discussed\")\n    decision: Optional[str] = Field(None, description=\"Decision made on this topic\")\n    action_items: List[str] = Field(default_factory=list, description=\"Action items related to this topic\")\n\nclass Meeting(BaseModel):\n    title: str = Field(description=\"Meeting title or purpose\")\n    date: Optional[str] = Field(None, description=\"Meeting date if mentioned\")\n    participants: List[str] = Field(description=\"Names of meeting participants\")\n    key_points: List[MeetingPoint] = Field(description=\"Key discussion points and decisions\")\n    summary: str = Field(description=\"Brief summary of the meeting\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 65,
          "line_range": [
            65,
            76
          ]
        },
        {
          "code": "# Extract structured information from audio\n",
          "display_code": "",
          "annotation": "Extract structured information from audio",
          "is_comment": true,
          "start_line": 77,
          "line_range": [
            77,
            77
          ],
          "target_line_range": [
            78,
            99
          ]
        },
        {
          "code": "def extract_meeting_info(audio_path: str) -> Meeting:\n    \"\"\"Extract structured meeting information from audio recording.\"\"\"\n    audio = Audio.from_path(audio_path)\n\n    return client.chat.completions.create(\n        model=\"gpt-4o-audio-preview\",\n        response_model=Meeting,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract detailed meeting information from this audio recording.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Extract the complete meeting details from this recording:\",\n                    audio\n                ]\n            }\n        ]\n    )\n\n",
          "display_code": "def extract_meeting_info(audio_path: str) -> Meeting:\n    \"\"\"Extract structured meeting information from audio recording.\"\"\"\n    audio = Audio.from_path(audio_path)\n\n    return client.chat.completions.create(\n        model=\"gpt-4o-audio-preview\",\n        response_model=Meeting,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract detailed meeting information from this audio recording.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Extract the complete meeting details from this recording:\",\n                    audio\n                ]\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 78,
          "line_range": [
            78,
            99
          ]
        },
        {
          "code": "# Extract person information\n",
          "display_code": "",
          "annotation": "Extract person information",
          "is_comment": true,
          "start_line": 100,
          "line_range": [
            100,
            100
          ],
          "target_line_range": [
            101,
            118
          ]
        },
        {
          "code": "def extract_person_from_audio(audio_path: str) -> Person:\n    \"\"\"Extract structured person information from audio.\"\"\"\n    audio = Audio.from_path(audio_path)\n\n    return client.chat.completions.create(\n        model=\"gpt-4o-audio-preview\",\n        response_model=Person,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Extract the person's name, age, and occupation from this audio:\",\n                    audio\n                ]\n            }\n        ]\n    )\n\n",
          "display_code": "def extract_person_from_audio(audio_path: str) -> Person:\n    \"\"\"Extract structured person information from audio.\"\"\"\n    audio = Audio.from_path(audio_path)\n\n    return client.chat.completions.create(\n        model=\"gpt-4o-audio-preview\",\n        response_model=Person,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Extract the person's name, age, and occupation from this audio:\",\n                    audio\n                ]\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 101,
          "line_range": [
            101,
            118
          ]
        },
        {
          "code": "# Example usage\n# person = extract_person_from_audio(\"path/to/introduction.wav\")\n# print(f\"Name: {person.name}, Age: {person.age}\")\n# if person.occupation:\n#     print(f\"Occupation: {person.occupation}\")\n",
          "display_code": "",
          "annotation": "Example usage\nperson = extract_person_from_audio(\"path/to/introduction.wav\")\nprint(f\"Name: {person.name}, Age: {person.age}\")\nif person.occupation:\nprint(f\"Occupation: {person.occupation}\")",
          "is_comment": true,
          "start_line": 119,
          "line_range": [
            119,
            123
          ],
          "target_line_range": [
            124,
            124
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 124,
          "line_range": [
            124,
            124
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python audio-extraction.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "008-multimodal",
      "section_title": "Multimodal Inputs"
    },
    {
      "id": "042-pdf-extraction",
      "title": "PDF Extraction",
      "description": "",
      "order": 42,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Extract structured data from PDF documents with Instructor. Enables integration of PDF processing into data extraction pipelines.\n",
          "display_code": "",
          "annotation": "Extract structured data from PDF documents with Instructor. Enables integration of PDF processing into data extraction pipelines.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor provides support for working with PDF documents through a combination of vision capabilities and structured extraction.\n",
          "display_code": "",
          "annotation": "Instructor provides support for working with PDF documents through a combination of vision capabilities and structured extraction.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            12
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List\nimport tempfile\nfrom pdf2image import convert_from_path\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List\nimport tempfile\nfrom pdf2image import convert_from_path\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            12
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 13,
          "line_range": [
            13,
            13
          ],
          "target_line_range": [
            14,
            15
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 14,
          "line_range": [
            14,
            15
          ]
        },
        {
          "code": "# Define models for document extraction\n",
          "display_code": "",
          "annotation": "Define models for document extraction",
          "is_comment": true,
          "start_line": 16,
          "line_range": [
            16,
            16
          ],
          "target_line_range": [
            17,
            26
          ]
        },
        {
          "code": "class Section(BaseModel):\n    title: str = Field(description=\"Section title\")\n    content: str = Field(description=\"Section content\")\n\nclass Document(BaseModel):\n    title: str = Field(description=\"Document title\")\n    author: str = Field(description=\"Document author\")\n    sections: List[Section] = Field(description=\"Document sections\")\n    summary: str = Field(description=\"Brief document summary\")\n\n",
          "display_code": "class Section(BaseModel):\n    title: str = Field(description=\"Section title\")\n    content: str = Field(description=\"Section content\")\n\nclass Document(BaseModel):\n    title: str = Field(description=\"Document title\")\n    author: str = Field(description=\"Document author\")\n    sections: List[Section] = Field(description=\"Document sections\")\n    summary: str = Field(description=\"Brief document summary\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 17,
          "line_range": [
            17,
            26
          ]
        },
        {
          "code": "# Extract content from a PDF page as an image\n",
          "display_code": "",
          "annotation": "Extract content from a PDF page as an image",
          "is_comment": true,
          "start_line": 27,
          "line_range": [
            27,
            27
          ],
          "target_line_range": [
            28,
            29
          ]
        },
        {
          "code": "def extract_from_pdf_page(pdf_path: str, page_number: int = 0) -> Document:\n    \"\"\"Extract structured information from a PDF page.\"\"\"\n",
          "display_code": "def extract_from_pdf_page(pdf_path: str, page_number: int = 0) -> Document:\n    \"\"\"Extract structured information from a PDF page.\"\"\"\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 28,
          "line_range": [
            28,
            29
          ]
        },
        {
          "code": "    # Convert the PDF page to an image\n",
          "display_code": "",
          "annotation": "Convert the PDF page to an image",
          "is_comment": true,
          "start_line": 30,
          "line_range": [
            30,
            30
          ],
          "target_line_range": [
            31,
            32
          ]
        },
        {
          "code": "    images = convert_from_path(pdf_path, first_page=page_number+1, last_page=page_number+1)\n\n",
          "display_code": "    images = convert_from_path(pdf_path, first_page=page_number+1, last_page=page_number+1)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 31,
          "line_range": [
            31,
            32
          ]
        },
        {
          "code": "    # Save the image to a temporary file\n",
          "display_code": "",
          "annotation": "Save the image to a temporary file",
          "is_comment": true,
          "start_line": 33,
          "line_range": [
            33,
            33
          ],
          "target_line_range": [
            34,
            37
          ]
        },
        {
          "code": "    with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp:\n        temp_path = temp.name\n        images[0].save(temp_path, 'JPEG')\n\n",
          "display_code": "    with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp:\n        temp_path = temp.name\n        images[0].save(temp_path, 'JPEG')\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 34,
          "line_range": [
            34,
            37
          ]
        },
        {
          "code": "    # Create an Image object\n",
          "display_code": "",
          "annotation": "Create an Image object",
          "is_comment": true,
          "start_line": 38,
          "line_range": [
            38,
            38
          ],
          "target_line_range": [
            39,
            40
          ]
        },
        {
          "code": "    image = instructor.Image.from_path(temp_path)\n\n",
          "display_code": "    image = instructor.Image.from_path(temp_path)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 39,
          "line_range": [
            39,
            40
          ]
        },
        {
          "code": "    # Extract information using vision capabilities\n",
          "display_code": "",
          "annotation": "Extract information using vision capabilities",
          "is_comment": true,
          "start_line": 41,
          "line_range": [
            41,
            41
          ],
          "target_line_range": [
            42,
            59
          ]
        },
        {
          "code": "    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=Document,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract structured information from this document page.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Extract the complete document structure from this page:\",\n                    image\n                ]\n            }\n        ]\n    )\n\n",
          "display_code": "    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=Document,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract structured information from this document page.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Extract the complete document structure from this page:\",\n                    image\n                ]\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 42,
          "line_range": [
            42,
            59
          ]
        },
        {
          "code": "# Process multiple pages\n",
          "display_code": "",
          "annotation": "Process multiple pages",
          "is_comment": true,
          "start_line": 60,
          "line_range": [
            60,
            60
          ],
          "target_line_range": [
            61,
            64
          ]
        },
        {
          "code": "def process_pdf_document(pdf_path: str, max_pages: int = 5) -> List[Document]:\n    \"\"\"Process multiple pages from a PDF document.\"\"\"\n    results = []\n\n",
          "display_code": "def process_pdf_document(pdf_path: str, max_pages: int = 5) -> List[Document]:\n    \"\"\"Process multiple pages from a PDF document.\"\"\"\n    results = []\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 61,
          "line_range": [
            61,
            64
          ]
        },
        {
          "code": "    # Get the number of pages\n",
          "display_code": "",
          "annotation": "Get the number of pages",
          "is_comment": true,
          "start_line": 65,
          "line_range": [
            65,
            65
          ],
          "target_line_range": [
            66,
            70
          ]
        },
        {
          "code": "    from pypdf import PdfReader\n    reader = PdfReader(pdf_path)\n    num_pages = len(reader.pages)\n    actual_pages = min(num_pages, max_pages)\n\n",
          "display_code": "    from pypdf import PdfReader\n    reader = PdfReader(pdf_path)\n    num_pages = len(reader.pages)\n    actual_pages = min(num_pages, max_pages)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 66,
          "line_range": [
            66,
            70
          ]
        },
        {
          "code": "    # Process each page\n",
          "display_code": "",
          "annotation": "Process each page",
          "is_comment": true,
          "start_line": 71,
          "line_range": [
            71,
            71
          ],
          "target_line_range": [
            72,
            78
          ]
        },
        {
          "code": "    for i in range(actual_pages):\n        page_result = extract_from_pdf_page(pdf_path, i)\n        results.append(page_result)\n        print(f\"Processed page {i+1}/{actual_pages}\")\n\n    return results\n\n",
          "display_code": "    for i in range(actual_pages):\n        page_result = extract_from_pdf_page(pdf_path, i)\n        results.append(page_result)\n        print(f\"Processed page {i+1}/{actual_pages}\")\n\n    return results\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 72,
          "line_range": [
            72,
            78
          ]
        },
        {
          "code": "# Example usage\n# documents = process_pdf_document(\"path/to/document.pdf\", max_pages=3)\n# for i, doc in enumerate(documents):\n#     print(f\"Page {i+1}: {doc.title} by {doc.author}\")\n#     print(f\"Summary: {doc.summary}\")\n#     print(f\"Sections: {len(doc.sections)}\")\n",
          "display_code": "",
          "annotation": "Example usage\ndocuments = process_pdf_document(\"path/to/document.pdf\", max_pages=3)\nfor i, doc in enumerate(documents):\nprint(f\"Page {i+1}: {doc.title} by {doc.author}\")\nprint(f\"Summary: {doc.summary}\")\nprint(f\"Sections: {len(doc.sections)}\")",
          "is_comment": true,
          "start_line": 79,
          "line_range": [
            79,
            84
          ],
          "target_line_range": [
            85,
            85
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 85,
          "line_range": [
            85,
            85
          ]
        },
        {
          "code": "# For more specific document types, you can create specialized models:\n",
          "display_code": "",
          "annotation": "For more specific document types, you can create specialized models:",
          "is_comment": true,
          "start_line": 86,
          "line_range": [
            86,
            86
          ],
          "target_line_range": [
            87,
            93
          ]
        },
        {
          "code": "from typing import List, Optional\nfrom pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\nfrom pdf2image import convert_from_path\nimport tempfile\n\n",
          "display_code": "from typing import List, Optional\nfrom pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\nfrom pdf2image import convert_from_path\nimport tempfile\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 87,
          "line_range": [
            87,
            93
          ]
        },
        {
          "code": "# Initialize the client\n",
          "display_code": "",
          "annotation": "Initialize the client",
          "is_comment": true,
          "start_line": 94,
          "line_range": [
            94,
            94
          ],
          "target_line_range": [
            95,
            96
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 95,
          "line_range": [
            95,
            96
          ]
        },
        {
          "code": "# Define a model for invoice extraction\n",
          "display_code": "",
          "annotation": "Define a model for invoice extraction",
          "is_comment": true,
          "start_line": 97,
          "line_range": [
            97,
            97
          ],
          "target_line_range": [
            98,
            113
          ]
        },
        {
          "code": "class LineItem(BaseModel):\n    description: str = Field(description=\"Description of the item or service\")\n    quantity: float = Field(description=\"Quantity of the item\")\n    unit_price: float = Field(description=\"Price per unit\")\n    amount: float = Field(description=\"Total amount for this line\")\n\nclass Invoice(BaseModel):\n    invoice_number: str = Field(description=\"Invoice identifier\")\n    date: str = Field(description=\"Invoice date\")\n    vendor: str = Field(description=\"Name of the vendor/seller\")\n    customer: str = Field(description=\"Name of the customer/buyer\")\n    items: List[LineItem] = Field(description=\"Line items in the invoice\")\n    subtotal: float = Field(description=\"Sum of all items before tax\")\n    tax: Optional[float] = Field(None, description=\"Tax amount\")\n    total: float = Field(description=\"Total invoice amount\")\n\n",
          "display_code": "class LineItem(BaseModel):\n    description: str = Field(description=\"Description of the item or service\")\n    quantity: float = Field(description=\"Quantity of the item\")\n    unit_price: float = Field(description=\"Price per unit\")\n    amount: float = Field(description=\"Total amount for this line\")\n\nclass Invoice(BaseModel):\n    invoice_number: str = Field(description=\"Invoice identifier\")\n    date: str = Field(description=\"Invoice date\")\n    vendor: str = Field(description=\"Name of the vendor/seller\")\n    customer: str = Field(description=\"Name of the customer/buyer\")\n    items: List[LineItem] = Field(description=\"Line items in the invoice\")\n    subtotal: float = Field(description=\"Sum of all items before tax\")\n    tax: Optional[float] = Field(None, description=\"Tax amount\")\n    total: float = Field(description=\"Total invoice amount\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 98,
          "line_range": [
            98,
            113
          ]
        },
        {
          "code": "# Extract invoice from PDF\n",
          "display_code": "",
          "annotation": "Extract invoice from PDF",
          "is_comment": true,
          "start_line": 114,
          "line_range": [
            114,
            114
          ],
          "target_line_range": [
            115,
            116
          ]
        },
        {
          "code": "def extract_invoice(pdf_path: str) -> Invoice:\n    \"\"\"Extract structured invoice data from a PDF.\"\"\"\n",
          "display_code": "def extract_invoice(pdf_path: str) -> Invoice:\n    \"\"\"Extract structured invoice data from a PDF.\"\"\"\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 115,
          "line_range": [
            115,
            116
          ]
        },
        {
          "code": "    # Convert first page to image\n",
          "display_code": "",
          "annotation": "Convert first page to image",
          "is_comment": true,
          "start_line": 117,
          "line_range": [
            117,
            117
          ],
          "target_line_range": [
            118,
            119
          ]
        },
        {
          "code": "    images = convert_from_path(pdf_path, first_page=1, last_page=1)\n\n",
          "display_code": "    images = convert_from_path(pdf_path, first_page=1, last_page=1)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 118,
          "line_range": [
            118,
            119
          ]
        },
        {
          "code": "    # Save to temp file\n",
          "display_code": "",
          "annotation": "Save to temp file",
          "is_comment": true,
          "start_line": 120,
          "line_range": [
            120,
            120
          ],
          "target_line_range": [
            121,
            124
          ]
        },
        {
          "code": "    with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp:\n        temp_path = temp.name\n        images[0].save(temp_path, 'JPEG')\n\n",
          "display_code": "    with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp:\n        temp_path = temp.name\n        images[0].save(temp_path, 'JPEG')\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 121,
          "line_range": [
            121,
            124
          ]
        },
        {
          "code": "    # Create image object\n",
          "display_code": "",
          "annotation": "Create image object",
          "is_comment": true,
          "start_line": 125,
          "line_range": [
            125,
            125
          ],
          "target_line_range": [
            126,
            127
          ]
        },
        {
          "code": "    image = instructor.Image.from_path(temp_path)\n\n",
          "display_code": "    image = instructor.Image.from_path(temp_path)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 126,
          "line_range": [
            126,
            127
          ]
        },
        {
          "code": "    # Extract invoice data\n",
          "display_code": "",
          "annotation": "Extract invoice data",
          "is_comment": true,
          "start_line": 128,
          "line_range": [
            128,
            128
          ],
          "target_line_range": [
            129,
            146
          ]
        },
        {
          "code": "    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=Invoice,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You are an invoice processing assistant that extracts structured data from invoice images.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Extract complete invoice details from this document:\",\n                    image\n                ]\n            }\n        ]\n    )\n\n",
          "display_code": "    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=Invoice,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You are an invoice processing assistant that extracts structured data from invoice images.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Extract complete invoice details from this document:\",\n                    image\n                ]\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 129,
          "line_range": [
            129,
            146
          ]
        },
        {
          "code": "# Example usage\n# invoice = extract_invoice(\"path/to/invoice.pdf\")\n# print(f\"Invoice #{invoice.invoice_number} from {invoice.vendor}\")\n# print(f\"Date: {invoice.date}\")\n# print(f\"Total: ${invoice.total:.2f}\")\n# print(\"Line items:\")\n# for item in invoice.items:\n#     print(f\"- {item.description}: {item.quantity} x ${item.unit_price:.2f} = ${item.amount:.2f}\")\n",
          "display_code": "",
          "annotation": "Example usage\ninvoice = extract_invoice(\"path/to/invoice.pdf\")\nprint(f\"Invoice #{invoice.invoice_number} from {invoice.vendor}\")\nprint(f\"Date: {invoice.date}\")\nprint(f\"Total: ${invoice.total:.2f}\")\nprint(\"Line items:\")\nfor item in invoice.items:\nprint(f\"- {item.description}: {item.quantity} x ${item.unit_price:.2f} = ${item.amount:.2f}\")",
          "is_comment": true,
          "start_line": 147,
          "line_range": [
            147,
            154
          ],
          "target_line_range": [
            155,
            155
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 155,
          "line_range": [
            155,
            155
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python pdf-extraction.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "008-multimodal",
      "section_title": "Multimodal Inputs"
    },
    {
      "id": "043-caching-responses",
      "title": "Caching Responses",
      "description": "",
      "order": 43,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Implement caching strategies for LLM responses with Instructor. Supports Redis caching for distributed systems and performance optimization.\n",
          "display_code": "",
          "annotation": "Implement caching strategies for LLM responses with Instructor. Supports Redis caching for distributed systems and performance optimization.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Caching LLM responses can significantly improve performance and reduce costs. Instructor supports several caching strategies to suit different needs.\n",
          "display_code": "",
          "annotation": "Caching LLM responses can significantly improve performance and reduce costs. Instructor supports several caching strategies to suit different needs.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "import functools\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\n",
          "display_code": "import functools\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define a simple model\n",
          "display_code": "",
          "annotation": "Define a simple model",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            18
          ]
        },
        {
          "code": "class User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "class User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            18
          ]
        },
        {
          "code": "# Simple in-memory caching with functools.cache\n",
          "display_code": "",
          "annotation": "Simple in-memory caching with functools.cache",
          "is_comment": true,
          "start_line": 19,
          "line_range": [
            19,
            19
          ],
          "target_line_range": [
            20,
            33
          ]
        },
        {
          "code": "@functools.cache\ndef extract_user(text: str) -> User:\n    \"\"\"Extract user information with in-memory caching.\"\"\"\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Extract user information from: {text}\"\n            }\n        ]\n    )\n\n",
          "display_code": "@functools.cache\ndef extract_user(text: str) -> User:\n    \"\"\"Extract user information with in-memory caching.\"\"\"\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Extract user information from: {text}\"\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 20,
          "line_range": [
            20,
            33
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 34,
          "line_range": [
            34,
            34
          ],
          "target_line_range": [
            35,
            37
          ]
        },
        {
          "code": "user1 = extract_user(\"John is 30 years old\")\nprint(user1)\n\n",
          "display_code": "user1 = extract_user(\"John is 30 years old\")\nprint(user1)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 35,
          "line_range": [
            35,
            37
          ]
        },
        {
          "code": "# This call will use the cached result (no API call)\n",
          "display_code": "",
          "annotation": "This call will use the cached result (no API call)",
          "is_comment": true,
          "start_line": 38,
          "line_range": [
            38,
            38
          ],
          "target_line_range": [
            39,
            41
          ]
        },
        {
          "code": "user2 = extract_user(\"John is 30 years old\")\nprint(user2)\n\n",
          "display_code": "user2 = extract_user(\"John is 30 years old\")\nprint(user2)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 39,
          "line_range": [
            39,
            41
          ]
        },
        {
          "code": "# For persistent caching across sessions, you can use disk-based caching:\n",
          "display_code": "",
          "annotation": "For persistent caching across sessions, you can use disk-based caching:",
          "is_comment": true,
          "start_line": 42,
          "line_range": [
            42,
            42
          ],
          "target_line_range": [
            43,
            49
          ]
        },
        {
          "code": "import functools\nimport inspect\nimport instructor\nimport diskcache\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\n",
          "display_code": "import functools\nimport inspect\nimport instructor\nimport diskcache\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 43,
          "line_range": [
            43,
            49
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 50,
          "line_range": [
            50,
            50
          ],
          "target_line_range": [
            51,
            52
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 51,
          "line_range": [
            51,
            52
          ]
        },
        {
          "code": "# Initialize disk cache\n",
          "display_code": "",
          "annotation": "Initialize disk cache",
          "is_comment": true,
          "start_line": 53,
          "line_range": [
            53,
            53
          ],
          "target_line_range": [
            54,
            55
          ]
        },
        {
          "code": "cache = diskcache.Cache('./my_cache_directory')\n\n",
          "display_code": "cache = diskcache.Cache('./my_cache_directory')\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 54,
          "line_range": [
            54,
            55
          ]
        },
        {
          "code": "# Define a caching decorator for Pydantic models\n",
          "display_code": "",
          "annotation": "Define a caching decorator for Pydantic models",
          "is_comment": true,
          "start_line": 56,
          "line_range": [
            56,
            56
          ],
          "target_line_range": [
            57,
            64
          ]
        },
        {
          "code": "def instructor_cache(func):\n    \"\"\"Cache a function that returns a Pydantic model.\"\"\"\n    return_type = inspect.signature(func).return_annotation\n    if not issubclass(return_type, BaseModel):\n        raise ValueError(\"The return type must be a Pydantic model\")\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n",
          "display_code": "def instructor_cache(func):\n    \"\"\"Cache a function that returns a Pydantic model.\"\"\"\n    return_type = inspect.signature(func).return_annotation\n    if not issubclass(return_type, BaseModel):\n        raise ValueError(\"The return type must be a Pydantic model\")\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 57,
          "line_range": [
            57,
            64
          ]
        },
        {
          "code": "        # Create a cache key from the function name and arguments\n",
          "display_code": "",
          "annotation": "Create a cache key from the function name and arguments",
          "is_comment": true,
          "start_line": 65,
          "line_range": [
            65,
            65
          ],
          "target_line_range": [
            66,
            67
          ]
        },
        {
          "code": "        key = f\"{func.__name__}-{functools._make_key(args, kwargs, typed=False)}\"\n\n",
          "display_code": "        key = f\"{func.__name__}-{functools._make_key(args, kwargs, typed=False)}\"\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 66,
          "line_range": [
            66,
            67
          ]
        },
        {
          "code": "        # Check if result is already cached\n",
          "display_code": "",
          "annotation": "Check if result is already cached",
          "is_comment": true,
          "start_line": 68,
          "line_range": [
            68,
            68
          ],
          "target_line_range": [
            69,
            69
          ]
        },
        {
          "code": "        if (cached := cache.get(key)) is not None:\n",
          "display_code": "        if (cached := cache.get(key)) is not None:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 69,
          "line_range": [
            69,
            69
          ]
        },
        {
          "code": "            # Deserialize from JSON based on the return type\n",
          "display_code": "",
          "annotation": "Deserialize from JSON based on the return type",
          "is_comment": true,
          "start_line": 70,
          "line_range": [
            70,
            70
          ],
          "target_line_range": [
            71,
            72
          ]
        },
        {
          "code": "            return return_type.model_validate_json(cached)\n\n",
          "display_code": "            return return_type.model_validate_json(cached)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 71,
          "line_range": [
            71,
            72
          ]
        },
        {
          "code": "        # Call the function and cache its result\n",
          "display_code": "",
          "annotation": "Call the function and cache its result",
          "is_comment": true,
          "start_line": 73,
          "line_range": [
            73,
            73
          ],
          "target_line_range": [
            74,
            81
          ]
        },
        {
          "code": "        result = func(*args, **kwargs)\n        serialized_result = result.model_dump_json()\n        cache.set(key, serialized_result)\n\n        return result\n\n    return wrapper\n\n",
          "display_code": "        result = func(*args, **kwargs)\n        serialized_result = result.model_dump_json()\n        cache.set(key, serialized_result)\n\n        return result\n\n    return wrapper\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 74,
          "line_range": [
            74,
            81
          ]
        },
        {
          "code": "# Define a model\n",
          "display_code": "",
          "annotation": "Define a model",
          "is_comment": true,
          "start_line": 82,
          "line_range": [
            82,
            82
          ],
          "target_line_range": [
            83,
            87
          ]
        },
        {
          "code": "class Product(BaseModel):\n    name: str\n    price: float\n    category: str\n\n",
          "display_code": "class Product(BaseModel):\n    name: str\n    price: float\n    category: str\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 83,
          "line_range": [
            83,
            87
          ]
        },
        {
          "code": "# Use the caching decorator\n",
          "display_code": "",
          "annotation": "Use the caching decorator",
          "is_comment": true,
          "start_line": 88,
          "line_range": [
            88,
            88
          ],
          "target_line_range": [
            89,
            102
          ]
        },
        {
          "code": "@instructor_cache\ndef extract_product(text: str) -> Product:\n    \"\"\"Extract product information with disk caching.\"\"\"\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=Product,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Extract product information from: {text}\"\n            }\n        ]\n    )\n\n",
          "display_code": "@instructor_cache\ndef extract_product(text: str) -> Product:\n    \"\"\"Extract product information with disk caching.\"\"\"\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=Product,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Extract product information from: {text}\"\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 89,
          "line_range": [
            89,
            102
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 103,
          "line_range": [
            103,
            103
          ],
          "target_line_range": [
            104,
            106
          ]
        },
        {
          "code": "product = extract_product(\"iPhone 14 Pro costs $999 and is in the smartphones category\")\nprint(product)\n\n",
          "display_code": "product = extract_product(\"iPhone 14 Pro costs $999 and is in the smartphones category\")\nprint(product)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 104,
          "line_range": [
            104,
            106
          ]
        },
        {
          "code": "# For distributed systems, Redis caching is a great option:\n",
          "display_code": "",
          "annotation": "For distributed systems, Redis caching is a great option:",
          "is_comment": true,
          "start_line": 107,
          "line_range": [
            107,
            107
          ],
          "target_line_range": [
            108,
            114
          ]
        },
        {
          "code": "import redis\nimport functools\nimport inspect\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\n",
          "display_code": "import redis\nimport functools\nimport inspect\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 108,
          "line_range": [
            108,
            114
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 115,
          "line_range": [
            115,
            115
          ],
          "target_line_range": [
            116,
            117
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 116,
          "line_range": [
            116,
            117
          ]
        },
        {
          "code": "# Initialize Redis cache\n",
          "display_code": "",
          "annotation": "Initialize Redis cache",
          "is_comment": true,
          "start_line": 118,
          "line_range": [
            118,
            118
          ],
          "target_line_range": [
            119,
            120
          ]
        },
        {
          "code": "cache = redis.Redis(host=\"localhost\", port=6379, db=0)\n\n",
          "display_code": "cache = redis.Redis(host=\"localhost\", port=6379, db=0)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 119,
          "line_range": [
            119,
            120
          ]
        },
        {
          "code": "# Define a caching decorator for Redis\n",
          "display_code": "",
          "annotation": "Define a caching decorator for Redis",
          "is_comment": true,
          "start_line": 121,
          "line_range": [
            121,
            121
          ],
          "target_line_range": [
            122,
            129
          ]
        },
        {
          "code": "def redis_cache(func):\n    \"\"\"Cache a function that returns a Pydantic model using Redis.\"\"\"\n    return_type = inspect.signature(func).return_annotation\n    if not issubclass(return_type, BaseModel):\n        raise ValueError(\"The return type must be a Pydantic model\")\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n",
          "display_code": "def redis_cache(func):\n    \"\"\"Cache a function that returns a Pydantic model using Redis.\"\"\"\n    return_type = inspect.signature(func).return_annotation\n    if not issubclass(return_type, BaseModel):\n        raise ValueError(\"The return type must be a Pydantic model\")\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 122,
          "line_range": [
            122,
            129
          ]
        },
        {
          "code": "        # Create a cache key from the function name and arguments\n",
          "display_code": "",
          "annotation": "Create a cache key from the function name and arguments",
          "is_comment": true,
          "start_line": 130,
          "line_range": [
            130,
            130
          ],
          "target_line_range": [
            131,
            132
          ]
        },
        {
          "code": "        key = f\"{func.__name__}-{functools._make_key(args, kwargs, typed=False)}\"\n\n",
          "display_code": "        key = f\"{func.__name__}-{functools._make_key(args, kwargs, typed=False)}\"\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 131,
          "line_range": [
            131,
            132
          ]
        },
        {
          "code": "        # Check if result is already cached\n",
          "display_code": "",
          "annotation": "Check if result is already cached",
          "is_comment": true,
          "start_line": 133,
          "line_range": [
            133,
            133
          ],
          "target_line_range": [
            134,
            134
          ]
        },
        {
          "code": "        if (cached := cache.get(key)) is not None:\n",
          "display_code": "        if (cached := cache.get(key)) is not None:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 134,
          "line_range": [
            134,
            134
          ]
        },
        {
          "code": "            # Deserialize from JSON based on the return type\n",
          "display_code": "",
          "annotation": "Deserialize from JSON based on the return type",
          "is_comment": true,
          "start_line": 135,
          "line_range": [
            135,
            135
          ],
          "target_line_range": [
            136,
            137
          ]
        },
        {
          "code": "            return return_type.model_validate_json(cached)\n\n",
          "display_code": "            return return_type.model_validate_json(cached)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 136,
          "line_range": [
            136,
            137
          ]
        },
        {
          "code": "        # Call the function and cache its result\n",
          "display_code": "",
          "annotation": "Call the function and cache its result",
          "is_comment": true,
          "start_line": 138,
          "line_range": [
            138,
            138
          ],
          "target_line_range": [
            139,
            146
          ]
        },
        {
          "code": "        result = func(*args, **kwargs)\n        serialized_result = result.model_dump_json()\n        cache.set(key, serialized_result)\n\n        return result\n\n    return wrapper\n\n",
          "display_code": "        result = func(*args, **kwargs)\n        serialized_result = result.model_dump_json()\n        cache.set(key, serialized_result)\n\n        return result\n\n    return wrapper\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 139,
          "line_range": [
            139,
            146
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python caching-responses.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "009-performance",
      "section_title": "Performance and Optimization"
    },
    {
      "id": "044-parallel-extraction",
      "title": "Parallel Extraction",
      "description": "",
      "order": 44,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Process multiple extractions in parallel with Instructor. Enables more efficient use of context window for related extractions.\n",
          "display_code": "",
          "annotation": "Process multiple extractions in parallel with Instructor. Enables more efficient use of context window for related extractions.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor supports parallel function calling, allowing you to extract multiple pieces of information simultaneously. This can significantly reduce latency in your applications.\n",
          "display_code": "",
          "annotation": "Instructor supports parallel function calling, allowing you to extract multiple pieces of information simultaneously. This can significantly reduce latency in your applications.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom typing import Iterable, Literal, Union\nfrom pydantic import BaseModel\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom typing import Iterable, Literal, Union\nfrom pydantic import BaseModel\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor in parallel mode\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor in parallel mode",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI(), mode=instructor.Mode.PARALLEL_TOOLS)\n\n",
          "display_code": "client = instructor.from_openai(OpenAI(), mode=instructor.Mode.PARALLEL_TOOLS)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define multiple response models\n",
          "display_code": "",
          "annotation": "Define multiple response models",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            21
          ]
        },
        {
          "code": "class Weather(BaseModel):\n    location: str\n    units: Literal[\"imperial\", \"metric\"]\n\nclass SearchQuery(BaseModel):\n    query: str\n\n",
          "display_code": "class Weather(BaseModel):\n    location: str\n    units: Literal[\"imperial\", \"metric\"]\n\nclass SearchQuery(BaseModel):\n    query: str\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            21
          ]
        },
        {
          "code": "# Extract multiple pieces of information in parallel\n",
          "display_code": "",
          "annotation": "Extract multiple pieces of information in parallel",
          "is_comment": true,
          "start_line": 22,
          "line_range": [
            22,
            22
          ],
          "target_line_range": [
            23,
            37
          ]
        },
        {
          "code": "def extract_parallel_info(user_query: str) -> list[Union[Weather, SearchQuery]]:\n    function_calls = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"You must always use tools\"},\n            {\n                \"role\": \"user\",\n                \"content\": user_query\n            }\n        ],\n        response_model=Iterable[Weather | SearchQuery]\n    )\n\n    return list(function_calls)  # Convert the iterable to a list\n\n",
          "display_code": "def extract_parallel_info(user_query: str) -> list[Union[Weather, SearchQuery]]:\n    function_calls = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"You must always use tools\"},\n            {\n                \"role\": \"user\",\n                \"content\": user_query\n            }\n        ],\n        response_model=Iterable[Weather | SearchQuery]\n    )\n\n    return list(function_calls)  # Convert the iterable to a list\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 23,
          "line_range": [
            23,
            37
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 38,
          "line_range": [
            38,
            38
          ],
          "target_line_range": [
            39,
            48
          ]
        },
        {
          "code": "results = extract_parallel_info(\n    \"What's the weather in New York and Tokyo? Also, find information about renewable energy.\"\n)\n\nfor result in results:\n    if isinstance(result, Weather):\n        print(f\"Weather request for {result.location} in {result.units} units\")\n    elif isinstance(result, SearchQuery):\n        print(f\"Search query: {result.query}\")\n\n",
          "display_code": "results = extract_parallel_info(\n    \"What's the weather in New York and Tokyo? Also, find information about renewable energy.\"\n)\n\nfor result in results:\n    if isinstance(result, Weather):\n        print(f\"Weather request for {result.location} in {result.units} units\")\n    elif isinstance(result, SearchQuery):\n        print(f\"Search query: {result.query}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 39,
          "line_range": [
            39,
            48
          ]
        },
        {
          "code": "# You can also define more complex parallel extractions:\n",
          "display_code": "",
          "annotation": "You can also define more complex parallel extractions:",
          "is_comment": true,
          "start_line": 49,
          "line_range": [
            49,
            49
          ],
          "target_line_range": [
            50,
            54
          ]
        },
        {
          "code": "from typing import Iterable, Union\nfrom pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\n\n",
          "display_code": "from typing import Iterable, Union\nfrom pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 50,
          "line_range": [
            50,
            54
          ]
        },
        {
          "code": "# Initialize client with parallel mode\n",
          "display_code": "",
          "annotation": "Initialize client with parallel mode",
          "is_comment": true,
          "start_line": 55,
          "line_range": [
            55,
            55
          ],
          "target_line_range": [
            56,
            57
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI(), mode=instructor.Mode.PARALLEL_TOOLS)\n\n",
          "display_code": "client = instructor.from_openai(OpenAI(), mode=instructor.Mode.PARALLEL_TOOLS)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 56,
          "line_range": [
            56,
            57
          ]
        },
        {
          "code": "# Define extraction models\n",
          "display_code": "",
          "annotation": "Define extraction models",
          "is_comment": true,
          "start_line": 58,
          "line_range": [
            58,
            58
          ],
          "target_line_range": [
            59,
            73
          ]
        },
        {
          "code": "class Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\nclass Company(BaseModel):\n    name: str\n    industry: str\n    year_founded: int\n\nclass Location(BaseModel):\n    city: str\n    country: str\n    population: int = Field(description=\"Approximate population\")\n\n",
          "display_code": "class Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\nclass Company(BaseModel):\n    name: str\n    industry: str\n    year_founded: int\n\nclass Location(BaseModel):\n    city: str\n    country: str\n    population: int = Field(description=\"Approximate population\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 59,
          "line_range": [
            59,
            73
          ]
        },
        {
          "code": "# Extract multiple entity types from text\n",
          "display_code": "",
          "annotation": "Extract multiple entity types from text",
          "is_comment": true,
          "start_line": 74,
          "line_range": [
            74,
            74
          ],
          "target_line_range": [
            75,
            86
          ]
        },
        {
          "code": "def extract_entities(text: str) -> list[Union[Person, Company, Location]]:\n    results = client.chat.completions.create(\n        model=\"gpt-4-turbo\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"Extract all relevant entities from the text.\"},\n            {\"role\": \"user\", \"content\": text}\n        ],\n        response_model=Iterable[Person | Company | Location]\n    )\n\n    return list(results)\n\n",
          "display_code": "def extract_entities(text: str) -> list[Union[Person, Company, Location]]:\n    results = client.chat.completions.create(\n        model=\"gpt-4-turbo\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"Extract all relevant entities from the text.\"},\n            {\"role\": \"user\", \"content\": text}\n        ],\n        response_model=Iterable[Person | Company | Location]\n    )\n\n    return list(results)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 75,
          "line_range": [
            75,
            86
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 87,
          "line_range": [
            87,
            87
          ],
          "target_line_range": [
            88,
            97
          ]
        },
        {
          "code": "text = \"\"\"\nJohn Smith is a 35-year-old software engineer living in San Francisco, USA,\na city with about 815,000 people. He works at TechCorp, a software development\ncompany founded in 2005 that specializes in AI applications. His colleague\nMaria Rodriguez, 29, is a data scientist who recently moved from Madrid, Spain,\na city of approximately 3.2 million people.\n\"\"\"\n\nentities = extract_entities(text)\n\n",
          "display_code": "text = \"\"\"\nJohn Smith is a 35-year-old software engineer living in San Francisco, USA,\na city with about 815,000 people. He works at TechCorp, a software development\ncompany founded in 2005 that specializes in AI applications. His colleague\nMaria Rodriguez, 29, is a data scientist who recently moved from Madrid, Spain,\na city of approximately 3.2 million people.\n\"\"\"\n\nentities = extract_entities(text)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 88,
          "line_range": [
            88,
            97
          ]
        },
        {
          "code": "# Process different entity types\n",
          "display_code": "",
          "annotation": "Process different entity types",
          "is_comment": true,
          "start_line": 98,
          "line_range": [
            98,
            98
          ],
          "target_line_range": [
            99,
            104
          ]
        },
        {
          "code": "people = [e for e in entities if isinstance(e, Person)]\ncompanies = [e for e in entities if isinstance(e, Company)]\nlocations = [e for e in entities if isinstance(e, Location)]\n\nprint(f\"Found {len(people)} people, {len(companies)} companies, and {len(locations)} locations\")\n\n",
          "display_code": "people = [e for e in entities if isinstance(e, Person)]\ncompanies = [e for e in entities if isinstance(e, Company)]\nlocations = [e for e in entities if isinstance(e, Location)]\n\nprint(f\"Found {len(people)} people, {len(companies)} companies, and {len(locations)} locations\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 99,
          "line_range": [
            99,
            104
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python parallel-extraction.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "009-performance",
      "section_title": "Performance and Optimization"
    },
    {
      "id": "045-batch-processing",
      "title": "Batch Processing",
      "description": "",
      "order": 45,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Implement batch processing for efficient data extraction. Instructor provides structured output for easier data analysis of large datasets.\n",
          "display_code": "",
          "annotation": "Implement batch processing for efficient data extraction. Instructor provides structured output for easier data analysis of large datasets.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor supports batch processing for efficiently handling multiple requests, which is essential for large-scale data processing.\n",
          "display_code": "",
          "annotation": "Instructor supports batch processing for efficiently handling multiple requests, which is essential for large-scale data processing.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            11
          ]
        },
        {
          "code": "import asyncio\nimport instructor\nfrom openai import AsyncOpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List, Tuple\n\n",
          "display_code": "import asyncio\nimport instructor\nfrom openai import AsyncOpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List, Tuple\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            11
          ]
        },
        {
          "code": "# Initialize the async client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the async client with instructor",
          "is_comment": true,
          "start_line": 12,
          "line_range": [
            12,
            12
          ],
          "target_line_range": [
            13,
            14
          ]
        },
        {
          "code": "client = instructor.from_openai(AsyncOpenAI())\n\n",
          "display_code": "client = instructor.from_openai(AsyncOpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 13,
          "line_range": [
            13,
            14
          ]
        },
        {
          "code": "# Semaphore to limit concurrent requests (respect API rate limits)\n",
          "display_code": "",
          "annotation": "Semaphore to limit concurrent requests (respect API rate limits)",
          "is_comment": true,
          "start_line": 15,
          "line_range": [
            15,
            15
          ],
          "target_line_range": [
            16,
            17
          ]
        },
        {
          "code": "sem = asyncio.Semaphore(5)\n\n",
          "display_code": "sem = asyncio.Semaphore(5)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 16,
          "line_range": [
            16,
            17
          ]
        },
        {
          "code": "# Define a model for sentiment analysis\n",
          "display_code": "",
          "annotation": "Define a model for sentiment analysis",
          "is_comment": true,
          "start_line": 18,
          "line_range": [
            18,
            18
          ],
          "target_line_range": [
            19,
            23
          ]
        },
        {
          "code": "class SentimentAnalysis(BaseModel):\n    sentiment: str = Field(description=\"The sentiment of the text (positive, negative, or neutral)\")\n    confidence: float = Field(description=\"Confidence score from 0.0 to 1.0\")\n    reasoning: str = Field(description=\"Brief explanation for the sentiment classification\")\n\n",
          "display_code": "class SentimentAnalysis(BaseModel):\n    sentiment: str = Field(description=\"The sentiment of the text (positive, negative, or neutral)\")\n    confidence: float = Field(description=\"Confidence score from 0.0 to 1.0\")\n    reasoning: str = Field(description=\"Brief explanation for the sentiment classification\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 19,
          "line_range": [
            19,
            23
          ]
        },
        {
          "code": "# Function to analyze sentiment of a single text\n",
          "display_code": "",
          "annotation": "Function to analyze sentiment of a single text",
          "is_comment": true,
          "start_line": 24,
          "line_range": [
            24,
            24
          ],
          "target_line_range": [
            25,
            38
          ]
        },
        {
          "code": "async def analyze_sentiment(text: str) -> Tuple[str, SentimentAnalysis]:\n    async with sem:  # Rate limiting\n        result = await client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            response_model=SentimentAnalysis,\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Analyze the sentiment of this text: {text}\"\n                }\n            ]\n        )\n        return text, result\n\n",
          "display_code": "async def analyze_sentiment(text: str) -> Tuple[str, SentimentAnalysis]:\n    async with sem:  # Rate limiting\n        result = await client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            response_model=SentimentAnalysis,\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Analyze the sentiment of this text: {text}\"\n                }\n            ]\n        )\n        return text, result\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 25,
          "line_range": [
            25,
            38
          ]
        },
        {
          "code": "# Process a batch of texts efficiently with parallel processing\n",
          "display_code": "",
          "annotation": "Process a batch of texts efficiently with parallel processing",
          "is_comment": true,
          "start_line": 39,
          "line_range": [
            39,
            39
          ],
          "target_line_range": [
            40,
            42
          ]
        },
        {
          "code": "async def process_batch(texts: List[str]):\n    tasks = [analyze_sentiment(text) for text in texts]  # Create tasks for all texts\n\n",
          "display_code": "async def process_batch(texts: List[str]):\n    tasks = [analyze_sentiment(text) for text in texts]  # Create tasks for all texts\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 40,
          "line_range": [
            40,
            42
          ]
        },
        {
          "code": "    # Collect results as tasks complete (in any order)\n",
          "display_code": "",
          "annotation": "Collect results as tasks complete (in any order)",
          "is_comment": true,
          "start_line": 43,
          "line_range": [
            43,
            43
          ],
          "target_line_range": [
            44,
            55
          ]
        },
        {
          "code": "    results = []\n    for task in asyncio.as_completed(tasks):\n        original_text, sentiment = await task\n        results.append({\n            \"text\": original_text,\n            \"sentiment\": sentiment.sentiment,\n            \"confidence\": sentiment.confidence,\n            \"reasoning\": sentiment.reasoning\n        })\n\n    return results\n\n",
          "display_code": "    results = []\n    for task in asyncio.as_completed(tasks):\n        original_text, sentiment = await task\n        results.append({\n            \"text\": original_text,\n            \"sentiment\": sentiment.sentiment,\n            \"confidence\": sentiment.confidence,\n            \"reasoning\": sentiment.reasoning\n        })\n\n    return results\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 44,
          "line_range": [
            44,
            55
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 56,
          "line_range": [
            56,
            56
          ],
          "target_line_range": [
            57,
            73
          ]
        },
        {
          "code": "async def main():\n    texts = [\n        \"I absolutely love this product! It's amazing.\",\n        \"The service was terrible and the staff was rude.\",\n        \"The weather is cloudy today with a chance of rain.\",\n        \"I'm disappointed with the quality of this item.\",\n        \"The conference was informative and well-organized.\"\n    ]\n\n    results = await process_batch(texts)\n\n    for result in results:\n        print(f\"Text: {result['text']}\")\n        print(f\"Sentiment: {result['sentiment']} (Confidence: {result['confidence']:.2f})\")\n        print(f\"Reasoning: {result['reasoning']}\")\n        print(\"-\" * 50)\n\n",
          "display_code": "async def main():\n    texts = [\n        \"I absolutely love this product! It's amazing.\",\n        \"The service was terrible and the staff was rude.\",\n        \"The weather is cloudy today with a chance of rain.\",\n        \"I'm disappointed with the quality of this item.\",\n        \"The conference was informative and well-organized.\"\n    ]\n\n    results = await process_batch(texts)\n\n    for result in results:\n        print(f\"Text: {result['text']}\")\n        print(f\"Sentiment: {result['sentiment']} (Confidence: {result['confidence']:.2f})\")\n        print(f\"Reasoning: {result['reasoning']}\")\n        print(\"-\" * 50)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 57,
          "line_range": [
            57,
            73
          ]
        },
        {
          "code": "# Run the example\n",
          "display_code": "",
          "annotation": "Run the example",
          "is_comment": true,
          "start_line": 74,
          "line_range": [
            74,
            74
          ],
          "target_line_range": [
            75,
            77
          ]
        },
        {
          "code": "if __name__ == \"__main__\":\n    asyncio.run(main())\n\n",
          "display_code": "if __name__ == \"__main__\":\n    asyncio.run(main())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 75,
          "line_range": [
            75,
            77
          ]
        },
        {
          "code": "# For larger datasets, you can implement a more comprehensive batch processing solution:\n",
          "display_code": "",
          "annotation": "For larger datasets, you can implement a more comprehensive batch processing solution:",
          "is_comment": true,
          "start_line": 78,
          "line_range": [
            78,
            78
          ],
          "target_line_range": [
            79,
            86
          ]
        },
        {
          "code": "import json\nimport asyncio\nimport instructor\nfrom openai import AsyncOpenAI\nfrom pydantic import BaseModel, Field\nfrom enum import Enum\nfrom typing import List, Dict, Any, Optional\n\n",
          "display_code": "import json\nimport asyncio\nimport instructor\nfrom openai import AsyncOpenAI\nfrom pydantic import BaseModel, Field\nfrom enum import Enum\nfrom typing import List, Dict, Any, Optional\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 79,
          "line_range": [
            79,
            86
          ]
        },
        {
          "code": "# Initialize the client\n",
          "display_code": "",
          "annotation": "Initialize the client",
          "is_comment": true,
          "start_line": 87,
          "line_range": [
            87,
            87
          ],
          "target_line_range": [
            88,
            89
          ]
        },
        {
          "code": "client = instructor.from_openai(AsyncOpenAI())\n\n",
          "display_code": "client = instructor.from_openai(AsyncOpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 88,
          "line_range": [
            88,
            89
          ]
        },
        {
          "code": "# Define classification types\n",
          "display_code": "",
          "annotation": "Define classification types",
          "is_comment": true,
          "start_line": 90,
          "line_range": [
            90,
            90
          ],
          "target_line_range": [
            91,
            102
          ]
        },
        {
          "code": "class Category(str, Enum):\n    PRODUCT = \"PRODUCT\"\n    SERVICE = \"SERVICE\"\n    FEATURE = \"FEATURE\"\n    SUPPORT = \"SUPPORT\"\n    OTHER = \"OTHER\"\n\nclass FeedbackClassification(BaseModel):\n    categories: List[Category] = Field(description=\"Categories that apply to this feedback\")\n    priority: int = Field(description=\"Priority score from 1-5, where 5 is highest priority\", ge=1, le=5)\n    analysis: str = Field(description=\"Brief analysis of the feedback\")\n\n",
          "display_code": "class Category(str, Enum):\n    PRODUCT = \"PRODUCT\"\n    SERVICE = \"SERVICE\"\n    FEATURE = \"FEATURE\"\n    SUPPORT = \"SUPPORT\"\n    OTHER = \"OTHER\"\n\nclass FeedbackClassification(BaseModel):\n    categories: List[Category] = Field(description=\"Categories that apply to this feedback\")\n    priority: int = Field(description=\"Priority score from 1-5, where 5 is highest priority\", ge=1, le=5)\n    analysis: str = Field(description=\"Brief analysis of the feedback\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 91,
          "line_range": [
            91,
            102
          ]
        },
        {
          "code": "# Process function with error handling and retries\n",
          "display_code": "",
          "annotation": "Process function with error handling and retries",
          "is_comment": true,
          "start_line": 103,
          "line_range": [
            103,
            103
          ],
          "target_line_range": [
            104,
            138
          ]
        },
        {
          "code": "async def process_item(item: str, retry_count: int = 2) -> Dict[str, Any]:\n    attempts = 0\n    while attempts <= retry_count:\n        try:\n            result = await client.chat.completions.create(\n                model=\"gpt-3.5-turbo\",\n                response_model=FeedbackClassification,\n                messages=[\n                    {\n                        \"role\": \"system\",\n                        \"content\": \"You are a customer feedback analyzer. Categorize and prioritize the feedback.\"\n                    },\n                    {\n                        \"role\": \"user\",\n                        \"content\": f\"Analyze this feedback: {item}\"\n                    }\n                ]\n            )\n            return {\n                \"feedback\": item,\n                \"categories\": [c.value for c in result.categories],\n                \"priority\": result.priority,\n                \"analysis\": result.analysis,\n                \"status\": \"success\"\n            }\n        except Exception as e:\n            attempts += 1\n            if attempts > retry_count:\n                return {\n                    \"feedback\": item,\n                    \"error\": str(e),\n                    \"status\": \"failed\"\n                }\n            await asyncio.sleep(1)  # Backoff before retry\n\n",
          "display_code": "async def process_item(item: str, retry_count: int = 2) -> Dict[str, Any]:\n    attempts = 0\n    while attempts <= retry_count:\n        try:\n            result = await client.chat.completions.create(\n                model=\"gpt-3.5-turbo\",\n                response_model=FeedbackClassification,\n                messages=[\n                    {\n                        \"role\": \"system\",\n                        \"content\": \"You are a customer feedback analyzer. Categorize and prioritize the feedback.\"\n                    },\n                    {\n                        \"role\": \"user\",\n                        \"content\": f\"Analyze this feedback: {item}\"\n                    }\n                ]\n            )\n            return {\n                \"feedback\": item,\n                \"categories\": [c.value for c in result.categories],\n                \"priority\": result.priority,\n                \"analysis\": result.analysis,\n                \"status\": \"success\"\n            }\n        except Exception as e:\n            attempts += 1\n            if attempts > retry_count:\n                return {\n                    \"feedback\": item,\n                    \"error\": str(e),\n                    \"status\": \"failed\"\n                }\n            await asyncio.sleep(1)  # Backoff before retry\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 104,
          "line_range": [
            104,
            138
          ]
        },
        {
          "code": "# Batch processor with chunking and progress tracking\n",
          "display_code": "",
          "annotation": "Batch processor with chunking and progress tracking",
          "is_comment": true,
          "start_line": 139,
          "line_range": [
            139,
            139
          ],
          "target_line_range": [
            140,
            149
          ]
        },
        {
          "code": "async def batch_process(items: List[str],\n                        chunk_size: int = 10,\n                        concurrency_limit: int = 5,\n                        output_file: Optional[str] = None):\n\n    sem = asyncio.Semaphore(concurrency_limit)\n    results = []\n    processed = 0\n    total = len(items)\n\n",
          "display_code": "async def batch_process(items: List[str],\n                        chunk_size: int = 10,\n                        concurrency_limit: int = 5,\n                        output_file: Optional[str] = None):\n\n    sem = asyncio.Semaphore(concurrency_limit)\n    results = []\n    processed = 0\n    total = len(items)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 140,
          "line_range": [
            140,
            149
          ]
        },
        {
          "code": "# Efficiently process data in manageable chunks to prevent memory issues\n",
          "display_code": "",
          "annotation": "Efficiently process data in manageable chunks to prevent memory issues",
          "is_comment": true,
          "start_line": 150,
          "line_range": [
            150,
            150
          ],
          "target_line_range": [
            151,
            153
          ]
        },
        {
          "code": "    for i in range(0, total, chunk_size):\n        chunk = items[i:i+chunk_size]\n\n",
          "display_code": "    for i in range(0, total, chunk_size):\n        chunk = items[i:i+chunk_size]\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 151,
          "line_range": [
            151,
            153
          ]
        },
        {
          "code": "        # Create rate-limited processing function\n",
          "display_code": "",
          "annotation": "Create rate-limited processing function",
          "is_comment": true,
          "start_line": 154,
          "line_range": [
            154,
            154
          ],
          "target_line_range": [
            155,
            158
          ]
        },
        {
          "code": "        async def process_with_sem(item):\n            async with sem:\n                return await process_item(item)\n\n",
          "display_code": "        async def process_with_sem(item):\n            async with sem:\n                return await process_item(item)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 155,
          "line_range": [
            155,
            158
          ]
        },
        {
          "code": "        # Process current chunk of items\n",
          "display_code": "",
          "annotation": "Process current chunk of items",
          "is_comment": true,
          "start_line": 159,
          "line_range": [
            159,
            159
          ],
          "target_line_range": [
            160,
            163
          ]
        },
        {
          "code": "        tasks = [process_with_sem(item) for item in chunk]\n        chunk_results = await asyncio.gather(*tasks)\n        results.extend(chunk_results)\n\n",
          "display_code": "        tasks = [process_with_sem(item) for item in chunk]\n        chunk_results = await asyncio.gather(*tasks)\n        results.extend(chunk_results)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 160,
          "line_range": [
            160,
            163
          ]
        },
        {
          "code": "        # Track and display progress\n",
          "display_code": "",
          "annotation": "Track and display progress",
          "is_comment": true,
          "start_line": 164,
          "line_range": [
            164,
            164
          ],
          "target_line_range": [
            165,
            167
          ]
        },
        {
          "code": "        processed += len(chunk)\n        print(f\"Progress: {processed}/{total} ({processed/total*100:.1f}%)\")\n\n",
          "display_code": "        processed += len(chunk)\n        print(f\"Progress: {processed}/{total} ({processed/total*100:.1f}%)\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 165,
          "line_range": [
            165,
            167
          ]
        },
        {
          "code": "        # Save intermediate results to prevent data loss\n",
          "display_code": "",
          "annotation": "Save intermediate results to prevent data loss",
          "is_comment": true,
          "start_line": 168,
          "line_range": [
            168,
            168
          ],
          "target_line_range": [
            169,
            175
          ]
        },
        {
          "code": "        if output_file:\n            with open(output_file, \"a\") as f:\n                for result in chunk_results:\n                    f.write(json.dumps(result) + \"\\n\")\n\n    return results\n\n",
          "display_code": "        if output_file:\n            with open(output_file, \"a\") as f:\n                for result in chunk_results:\n                    f.write(json.dumps(result) + \"\\n\")\n\n    return results\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 169,
          "line_range": [
            169,
            175
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 176,
          "line_range": [
            176,
            176
          ],
          "target_line_range": [
            177,
            177
          ]
        },
        {
          "code": "async def main():\n",
          "display_code": "async def main():\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 177,
          "line_range": [
            177,
            177
          ]
        },
        {
          "code": "    # Test with sample feedback data\n",
          "display_code": "",
          "annotation": "Test with sample feedback data",
          "is_comment": true,
          "start_line": 178,
          "line_range": [
            178,
            178
          ],
          "target_line_range": [
            179,
            183
          ]
        },
        {
          "code": "    feedback_items = [\n        \"Your app crashes every time I try to upload a photo. Please fix this ASAP!\",\n        \"I love the new dark mode feature. It makes the app much easier on the eyes.\",\n        \"The checkout process is too complicated. I gave up trying to make a purchase.\",\n        \"Your customer service rep was very helpful in resolving my issue.\"\n",
          "display_code": "    feedback_items = [\n        \"Your app crashes every time I try to upload a photo. Please fix this ASAP!\",\n        \"I love the new dark mode feature. It makes the app much easier on the eyes.\",\n        \"The checkout process is too complicated. I gave up trying to make a purchase.\",\n        \"Your customer service rep was very helpful in resolving my issue.\"\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 179,
          "line_range": [
            179,
            183
          ]
        },
        {
          "code": "        # Examples of different types of feedback\n",
          "display_code": "",
          "annotation": "Examples of different types of feedback",
          "is_comment": true,
          "start_line": 184,
          "line_range": [
            184,
            184
          ],
          "target_line_range": [
            185,
            191
          ]
        },
        {
          "code": "    ]\n\n    results = await batch_process(\n        items=feedback_items,\n        output_file=\"feedback_results.jsonl\"\n    )\n\n",
          "display_code": "    ]\n\n    results = await batch_process(\n        items=feedback_items,\n        output_file=\"feedback_results.jsonl\"\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 185,
          "line_range": [
            185,
            191
          ]
        },
        {
          "code": "# Generate summary statistics from processing results\n",
          "display_code": "",
          "annotation": "Generate summary statistics from processing results",
          "is_comment": true,
          "start_line": 192,
          "line_range": [
            192,
            192
          ],
          "target_line_range": [
            193,
            195
          ]
        },
        {
          "code": "    success_count = sum(1 for r in results if r[\"status\"] == \"success\")\n    print(f\"Successfully processed: {success_count}/{len(results)}\")\n\n",
          "display_code": "    success_count = sum(1 for r in results if r[\"status\"] == \"success\")\n    print(f\"Successfully processed: {success_count}/{len(results)}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 193,
          "line_range": [
            193,
            195
          ]
        },
        {
          "code": "    # Analyze average priority of feedback items\n",
          "display_code": "",
          "annotation": "Analyze average priority of feedback items",
          "is_comment": true,
          "start_line": 196,
          "line_range": [
            196,
            196
          ],
          "target_line_range": [
            197,
            200
          ]
        },
        {
          "code": "    priorities = [r.get(\"priority\", 0) for r in results if r[\"status\"] == \"success\"]\n    if priorities:\n        print(f\"Average priority: {sum(priorities)/len(priorities):.1f}\")\n\n",
          "display_code": "    priorities = [r.get(\"priority\", 0) for r in results if r[\"status\"] == \"success\"]\n    if priorities:\n        print(f\"Average priority: {sum(priorities)/len(priorities):.1f}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 197,
          "line_range": [
            197,
            200
          ]
        },
        {
          "code": "    # Generate distribution of feedback categories\n",
          "display_code": "",
          "annotation": "Generate distribution of feedback categories",
          "is_comment": true,
          "start_line": 201,
          "line_range": [
            201,
            201
          ],
          "target_line_range": [
            202,
            214
          ]
        },
        {
          "code": "    categories = {}\n    for r in results:\n        if r[\"status\"] == \"success\":\n            for cat in r.get(\"categories\", []):\n                categories[cat] = categories.get(cat, 0) + 1\n\n    print(\"Category distribution:\")\n    for cat, count in categories.items():\n        print(f\"  {cat}: {count}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n\n",
          "display_code": "    categories = {}\n    for r in results:\n        if r[\"status\"] == \"success\":\n            for cat in r.get(\"categories\", []):\n                categories[cat] = categories.get(cat, 0) + 1\n\n    print(\"Category distribution:\")\n    for cat, count in categories.items():\n        print(f\"  {cat}: {count}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 202,
          "line_range": [
            202,
            214
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python batch-processing.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "009-performance",
      "section_title": "Performance and Optimization"
    },
    {
      "id": "046-hooks-and-callbacks",
      "title": "Hooks and Callbacks",
      "description": "",
      "order": 46,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Use hooks and callbacks to extend Instructor's functionality. Enables custom behavior for testing, mocking, logging, and error handling.\n",
          "display_code": "",
          "annotation": "Use hooks and callbacks to extend Instructor's functionality. Enables custom behavior for testing, mocking, logging, and error handling.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor provides a powerful hooks system that allows you to intercept and handle events during the completion and parsing process. Hooks can be used for logging, error handling, and custom behaviors.\n",
          "display_code": "",
          "annotation": "Instructor provides a powerful hooks system that allows you to intercept and handle events during the completion and parsing process. Hooks can be used for logging, error handling, and custom behaviors.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "import instructor\nimport openai\nimport pprint\nfrom pydantic import BaseModel\n\n",
          "display_code": "import instructor\nimport openai\nimport pprint\nfrom pydantic import BaseModel\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(openai.OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(openai.OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define a simple response model\n",
          "display_code": "",
          "annotation": "Define a simple response model",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            18
          ]
        },
        {
          "code": "class User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "class User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            18
          ]
        },
        {
          "code": "# Define hook handlers\n",
          "display_code": "",
          "annotation": "Define hook handlers",
          "is_comment": true,
          "start_line": 19,
          "line_range": [
            19,
            19
          ],
          "target_line_range": [
            20,
            35
          ]
        },
        {
          "code": "def log_completion_kwargs(*args, **kwargs):\n    \"\"\"Log all arguments passed to the completion function.\"\"\"\n    print(\"Arguments sent to completion:\")\n    pprint.pprint(kwargs)\n\ndef log_completion_response(response):\n    \"\"\"Log the raw response from the API.\"\"\"\n    print(\"API Response received:\")\n    print(f\"Model: {response.model}\")\n    print(f\"Usage: {response.usage.total_tokens} tokens\")\n\ndef handle_error(error):\n    \"\"\"Handle any errors that occur during completion.\"\"\"\n    print(f\"Error type: {type(error).__name__}\")\n    print(f\"Error message: {str(error)}\")\n\n",
          "display_code": "def log_completion_kwargs(*args, **kwargs):\n    \"\"\"Log all arguments passed to the completion function.\"\"\"\n    print(\"Arguments sent to completion:\")\n    pprint.pprint(kwargs)\n\ndef log_completion_response(response):\n    \"\"\"Log the raw response from the API.\"\"\"\n    print(\"API Response received:\")\n    print(f\"Model: {response.model}\")\n    print(f\"Usage: {response.usage.total_tokens} tokens\")\n\ndef handle_error(error):\n    \"\"\"Handle any errors that occur during completion.\"\"\"\n    print(f\"Error type: {type(error).__name__}\")\n    print(f\"Error message: {str(error)}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 20,
          "line_range": [
            20,
            35
          ]
        },
        {
          "code": "# Register the hooks\n",
          "display_code": "",
          "annotation": "Register the hooks",
          "is_comment": true,
          "start_line": 36,
          "line_range": [
            36,
            36
          ],
          "target_line_range": [
            37,
            41
          ]
        },
        {
          "code": "client.on(\"completion:kwargs\", log_completion_kwargs)\nclient.on(\"completion:response\", log_completion_response)\nclient.on(\"completion:error\", handle_error)\nclient.on(\"parse:error\", handle_error)\n\n",
          "display_code": "client.on(\"completion:kwargs\", log_completion_kwargs)\nclient.on(\"completion:response\", log_completion_response)\nclient.on(\"completion:error\", handle_error)\nclient.on(\"parse:error\", handle_error)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 37,
          "line_range": [
            37,
            41
          ]
        },
        {
          "code": "# Make a request with registered hooks\n",
          "display_code": "",
          "annotation": "Make a request with registered hooks",
          "is_comment": true,
          "start_line": 42,
          "line_range": [
            42,
            42
          ],
          "target_line_range": [
            43,
            52
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract the user info: John is 25 years old.\"}\n    ],\n    response_model=User\n)\n\nprint(\"Extracted user:\", user)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract the user info: John is 25 years old.\"}\n    ],\n    response_model=User\n)\n\nprint(\"Extracted user:\", user)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 43,
          "line_range": [
            43,
            52
          ]
        },
        {
          "code": "# Removing a specific hook\n",
          "display_code": "",
          "annotation": "Removing a specific hook",
          "is_comment": true,
          "start_line": 53,
          "line_range": [
            53,
            53
          ],
          "target_line_range": [
            54,
            55
          ]
        },
        {
          "code": "client.off(\"completion:kwargs\", log_completion_kwargs)\n\n",
          "display_code": "client.off(\"completion:kwargs\", log_completion_kwargs)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 54,
          "line_range": [
            54,
            55
          ]
        },
        {
          "code": "# Clearing all hooks for a specific event\n",
          "display_code": "",
          "annotation": "Clearing all hooks for a specific event",
          "is_comment": true,
          "start_line": 56,
          "line_range": [
            56,
            56
          ],
          "target_line_range": [
            57,
            58
          ]
        },
        {
          "code": "client.clear(\"completion:error\")\n\n",
          "display_code": "client.clear(\"completion:error\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 57,
          "line_range": [
            57,
            58
          ]
        },
        {
          "code": "# Clearing all hooks\n",
          "display_code": "",
          "annotation": "Clearing all hooks",
          "is_comment": true,
          "start_line": 59,
          "line_range": [
            59,
            59
          ],
          "target_line_range": [
            60,
            61
          ]
        },
        {
          "code": "client.clear()\n\n",
          "display_code": "client.clear()\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 60,
          "line_range": [
            60,
            61
          ]
        },
        {
          "code": "# You can also use hooks for more advanced use cases such as telemetry or performance monitoring:\n",
          "display_code": "",
          "annotation": "You can also use hooks for more advanced use cases such as telemetry or performance monitoring:",
          "is_comment": true,
          "start_line": 62,
          "line_range": [
            62,
            62
          ],
          "target_line_range": [
            63,
            67
          ]
        },
        {
          "code": "import time\nimport instructor\nimport openai\nfrom pydantic import BaseModel\n\n",
          "display_code": "import time\nimport instructor\nimport openai\nfrom pydantic import BaseModel\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 63,
          "line_range": [
            63,
            67
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 68,
          "line_range": [
            68,
            68
          ],
          "target_line_range": [
            69,
            70
          ]
        },
        {
          "code": "client = instructor.from_openai(openai.OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(openai.OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 69,
          "line_range": [
            69,
            70
          ]
        },
        {
          "code": "# Track performance metrics\n",
          "display_code": "",
          "annotation": "Track performance metrics",
          "is_comment": true,
          "start_line": 71,
          "line_range": [
            71,
            71
          ],
          "target_line_range": [
            72,
            108
          ]
        },
        {
          "code": "class Metrics:\n    def __init__(self):\n        self.request_times = []\n        self.token_counts = []\n        self.error_count = 0\n        self.request_start_time = None\n\n    def start_request(self, *args, **kwargs):\n        self.request_start_time = time.time()\n\n    def end_request(self, response):\n        if self.request_start_time is not None:\n            elapsed = time.time() - self.request_start_time\n            self.request_times.append(elapsed)\n            self.token_counts.append(response.usage.total_tokens)\n            print(f\"Request completed in {elapsed:.2f}s, {response.usage.total_tokens} tokens\")\n\n    def record_error(self, error):\n        self.error_count += 1\n        print(f\"Error recorded: {str(error)}\")\n\n    def report(self):\n        if not self.request_times:\n            return \"No requests recorded.\"\n\n        avg_time = sum(self.request_times) / len(self.request_times)\n        avg_tokens = sum(self.token_counts) / len(self.token_counts)\n        total_tokens = sum(self.token_counts)\n\n        return {\n            \"total_requests\": len(self.request_times),\n            \"avg_request_time\": f\"{avg_time:.2f}s\",\n            \"avg_tokens_per_request\": int(avg_tokens),\n            \"total_tokens\": total_tokens,\n            \"error_count\": self.error_count\n        }\n\n",
          "display_code": "class Metrics:\n    def __init__(self):\n        self.request_times = []\n        self.token_counts = []\n        self.error_count = 0\n        self.request_start_time = None\n\n    def start_request(self, *args, **kwargs):\n        self.request_start_time = time.time()\n\n    def end_request(self, response):\n        if self.request_start_time is not None:\n            elapsed = time.time() - self.request_start_time\n            self.request_times.append(elapsed)\n            self.token_counts.append(response.usage.total_tokens)\n            print(f\"Request completed in {elapsed:.2f}s, {response.usage.total_tokens} tokens\")\n\n    def record_error(self, error):\n        self.error_count += 1\n        print(f\"Error recorded: {str(error)}\")\n\n    def report(self):\n        if not self.request_times:\n            return \"No requests recorded.\"\n\n        avg_time = sum(self.request_times) / len(self.request_times)\n        avg_tokens = sum(self.token_counts) / len(self.token_counts)\n        total_tokens = sum(self.token_counts)\n\n        return {\n            \"total_requests\": len(self.request_times),\n            \"avg_request_time\": f\"{avg_time:.2f}s\",\n            \"avg_tokens_per_request\": int(avg_tokens),\n            \"total_tokens\": total_tokens,\n            \"error_count\": self.error_count\n        }\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 72,
          "line_range": [
            72,
            108
          ]
        },
        {
          "code": "# Create metrics tracker\n",
          "display_code": "",
          "annotation": "Create metrics tracker",
          "is_comment": true,
          "start_line": 109,
          "line_range": [
            109,
            109
          ],
          "target_line_range": [
            110,
            111
          ]
        },
        {
          "code": "metrics = Metrics()\n\n",
          "display_code": "metrics = Metrics()\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 110,
          "line_range": [
            110,
            111
          ]
        },
        {
          "code": "# Register hooks\n",
          "display_code": "",
          "annotation": "Register hooks",
          "is_comment": true,
          "start_line": 112,
          "line_range": [
            112,
            112
          ],
          "target_line_range": [
            113,
            117
          ]
        },
        {
          "code": "client.on(\"completion:kwargs\", metrics.start_request)\nclient.on(\"completion:response\", metrics.end_request)\nclient.on(\"completion:error\", metrics.record_error)\nclient.on(\"parse:error\", metrics.record_error)\n\n",
          "display_code": "client.on(\"completion:kwargs\", metrics.start_request)\nclient.on(\"completion:response\", metrics.end_request)\nclient.on(\"completion:error\", metrics.record_error)\nclient.on(\"parse:error\", metrics.record_error)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 113,
          "line_range": [
            113,
            117
          ]
        },
        {
          "code": "# Run a few example requests\n",
          "display_code": "",
          "annotation": "Run a few example requests",
          "is_comment": true,
          "start_line": 118,
          "line_range": [
            118,
            118
          ],
          "target_line_range": [
            119,
            140
          ]
        },
        {
          "code": "class Product(BaseModel):\n    name: str\n    price: float\n    category: str\n\nfor i, query in enumerate([\n    \"iPhone 13, $799, Smartphones\",\n    \"Air Fryer, $129.99, Kitchen Appliances\",\n    \"Nike Running Shoes, $89.95, Athletic Footwear\"\n]):\n    try:\n        product = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[\n                {\"role\": \"user\", \"content\": f\"Extract product info: {query}\"}\n            ],\n            response_model=Product\n        )\n        print(f\"Product {i+1}: {product.name}, ${product.price}, {product.category}\")\n    except Exception as e:\n        print(f\"Failed to extract product {i+1}: {e}\")\n\n",
          "display_code": "class Product(BaseModel):\n    name: str\n    price: float\n    category: str\n\nfor i, query in enumerate([\n    \"iPhone 13, $799, Smartphones\",\n    \"Air Fryer, $129.99, Kitchen Appliances\",\n    \"Nike Running Shoes, $89.95, Athletic Footwear\"\n]):\n    try:\n        product = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[\n                {\"role\": \"user\", \"content\": f\"Extract product info: {query}\"}\n            ],\n            response_model=Product\n        )\n        print(f\"Product {i+1}: {product.name}, ${product.price}, {product.category}\")\n    except Exception as e:\n        print(f\"Failed to extract product {i+1}: {e}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 119,
          "line_range": [
            119,
            140
          ]
        },
        {
          "code": "# Print performance report\n",
          "display_code": "",
          "annotation": "Print performance report",
          "is_comment": true,
          "start_line": 141,
          "line_range": [
            141,
            141
          ],
          "target_line_range": [
            142,
            146
          ]
        },
        {
          "code": "performance_report = metrics.report()\nprint(\"\\nPerformance Report:\")\nfor key, value in performance_report.items():\n    print(f\"  {key}: {value}\")\n\n",
          "display_code": "performance_report = metrics.report()\nprint(\"\\nPerformance Report:\")\nfor key, value in performance_report.items():\n    print(f\"  {key}: {value}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 142,
          "line_range": [
            142,
            146
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python hooks-and-callbacks.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "009-performance",
      "section_title": "Performance and Optimization"
    },
    {
      "id": "047-type-adapters",
      "title": "Type Adapters",
      "description": "",
      "order": 47,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Leverage Pydantic Type Adapters with Instructor for advanced validation. Provides better error messaging and custom type conversion.\n",
          "display_code": "",
          "annotation": "Leverage Pydantic Type Adapters with Instructor for advanced validation. Provides better error messaging and custom type conversion.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Pydantic's Type Adapter is a powerful feature that allows you to wrap arbitrary data parsing logic with Pydantic's validation. Instructor leverages this to provide flexible data conversion and validation.\n",
          "display_code": "",
          "annotation": "Pydantic's Type Adapter is a powerful feature that allows you to wrap arbitrary data parsing logic with Pydantic's validation. Instructor leverages this to provide flexible data conversion and validation.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "from typing import List, Dict, Any\nfrom pydantic import TypeAdapter, BaseModel\nimport instructor\nfrom openai import OpenAI\n\n",
          "display_code": "from typing import List, Dict, Any\nfrom pydantic import TypeAdapter, BaseModel\nimport instructor\nfrom openai import OpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define a model for validation\n",
          "display_code": "",
          "annotation": "Define a model for validation",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            19
          ]
        },
        {
          "code": "class User(BaseModel):\n    name: str\n    age: int\n    skills: List[str]\n\n",
          "display_code": "class User(BaseModel):\n    name: str\n    age: int\n    skills: List[str]\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            19
          ]
        },
        {
          "code": "# Create a type adapter for a list of users\n",
          "display_code": "",
          "annotation": "Create a type adapter for a list of users",
          "is_comment": true,
          "start_line": 20,
          "line_range": [
            20,
            20
          ],
          "target_line_range": [
            21,
            22
          ]
        },
        {
          "code": "UserListAdapter = TypeAdapter(List[User])\n\n",
          "display_code": "UserListAdapter = TypeAdapter(List[User])\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 21,
          "line_range": [
            21,
            22
          ]
        },
        {
          "code": "# Define an extraction function\n",
          "display_code": "",
          "annotation": "Define an extraction function",
          "is_comment": true,
          "start_line": 23,
          "line_range": [
            23,
            23
          ],
          "target_line_range": [
            24,
            24
          ]
        },
        {
          "code": "def extract_users_from_text(text: str) -> List[User]:\n",
          "display_code": "def extract_users_from_text(text: str) -> List[User]:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 24,
          "line_range": [
            24,
            24
          ]
        },
        {
          "code": "    # Get raw JSON data from LLM\n",
          "display_code": "",
          "annotation": "Get raw JSON data from LLM",
          "is_comment": true,
          "start_line": 25,
          "line_range": [
            25,
            25
          ],
          "target_line_range": [
            26,
            37
          ]
        },
        {
          "code": "    raw_data = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Extract all users from this text as a JSON array: {text}\"\n            }\n        ],\n        response_format={\"type\": \"json_object\"},\n        temperature=0\n    ).choices[0].message.content\n\n",
          "display_code": "    raw_data = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Extract all users from this text as a JSON array: {text}\"\n            }\n        ],\n        response_format={\"type\": \"json_object\"},\n        temperature=0\n    ).choices[0].message.content\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 26,
          "line_range": [
            26,
            37
          ]
        },
        {
          "code": "    # Parse JSON\n",
          "display_code": "",
          "annotation": "Parse JSON",
          "is_comment": true,
          "start_line": 38,
          "line_range": [
            38,
            38
          ],
          "target_line_range": [
            39,
            41
          ]
        },
        {
          "code": "    import json\n    try:\n        data = json.loads(raw_data)\n",
          "display_code": "    import json\n    try:\n        data = json.loads(raw_data)\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 39,
          "line_range": [
            39,
            41
          ]
        },
        {
          "code": "        # Use type adapter for validation\n",
          "display_code": "",
          "annotation": "Use type adapter for validation",
          "is_comment": true,
          "start_line": 42,
          "line_range": [
            42,
            42
          ],
          "target_line_range": [
            43,
            48
          ]
        },
        {
          "code": "        users = UserListAdapter.validate_python(data.get(\"users\", []))\n        return users\n    except Exception as e:\n        print(f\"Error parsing data: {e}\")\n        return []\n\n",
          "display_code": "        users = UserListAdapter.validate_python(data.get(\"users\", []))\n        return users\n    except Exception as e:\n        print(f\"Error parsing data: {e}\")\n        return []\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 43,
          "line_range": [
            43,
            48
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 49,
          "line_range": [
            49,
            49
          ],
          "target_line_range": [
            50,
            60
          ]
        },
        {
          "code": "text = \"\"\"\nTeam members:\n- John Smith, 32 years old, skills: Python, JavaScript, Docker\n- Maria Garcia, 28 years old, skills: UX Design, Figma, HTML/CSS\n- Alex Johnson, 35 years old, skills: Project Management, Agile, Scrum\n\"\"\"\n\nusers = extract_users_from_text(text)\nfor user in users:\n    print(f\"{user.name} ({user.age}): {', '.join(user.skills)}\")\n\n",
          "display_code": "text = \"\"\"\nTeam members:\n- John Smith, 32 years old, skills: Python, JavaScript, Docker\n- Maria Garcia, 28 years old, skills: UX Design, Figma, HTML/CSS\n- Alex Johnson, 35 years old, skills: Project Management, Agile, Scrum\n\"\"\"\n\nusers = extract_users_from_text(text)\nfor user in users:\n    print(f\"{user.name} ({user.age}): {', '.join(user.skills)}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 50,
          "line_range": [
            50,
            60
          ]
        },
        {
          "code": "# Type adapters can also be used with dictionaries and more complex structures:\n",
          "display_code": "",
          "annotation": "Type adapters can also be used with dictionaries and more complex structures:",
          "is_comment": true,
          "start_line": 61,
          "line_range": [
            61,
            61
          ],
          "target_line_range": [
            62,
            64
          ]
        },
        {
          "code": "from typing import Dict, List, Union, Any\nfrom pydantic import TypeAdapter, BaseModel, Field\n\n",
          "display_code": "from typing import Dict, List, Union, Any\nfrom pydantic import TypeAdapter, BaseModel, Field\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 62,
          "line_range": [
            62,
            64
          ]
        },
        {
          "code": "# Define some models\n",
          "display_code": "",
          "annotation": "Define some models",
          "is_comment": true,
          "start_line": 65,
          "line_range": [
            65,
            65
          ],
          "target_line_range": [
            66,
            77
          ]
        },
        {
          "code": "class Comment(BaseModel):\n    user: str\n    text: str\n    timestamp: str\n\nclass Post(BaseModel):\n    id: int\n    title: str\n    content: str\n    tags: List[str]\n    comments: List[Comment]\n\n",
          "display_code": "class Comment(BaseModel):\n    user: str\n    text: str\n    timestamp: str\n\nclass Post(BaseModel):\n    id: int\n    title: str\n    content: str\n    tags: List[str]\n    comments: List[Comment]\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 66,
          "line_range": [
            66,
            77
          ]
        },
        {
          "code": "# Create type adapters\n",
          "display_code": "",
          "annotation": "Create type adapters",
          "is_comment": true,
          "start_line": 78,
          "line_range": [
            78,
            78
          ],
          "target_line_range": [
            79,
            82
          ]
        },
        {
          "code": "CommentAdapter = TypeAdapter(Comment)\nPostAdapter = TypeAdapter(Post)\nPostDictAdapter = TypeAdapter(Dict[str, Post])\n\n",
          "display_code": "CommentAdapter = TypeAdapter(Comment)\nPostAdapter = TypeAdapter(Post)\nPostDictAdapter = TypeAdapter(Dict[str, Post])\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 79,
          "line_range": [
            79,
            82
          ]
        },
        {
          "code": "# Process raw data with type adapters\n",
          "display_code": "",
          "annotation": "Process raw data with type adapters",
          "is_comment": true,
          "start_line": 83,
          "line_range": [
            83,
            83
          ],
          "target_line_range": [
            84,
            92
          ]
        },
        {
          "code": "def process_comment(raw_comment: Dict[str, Any]) -> Comment:\n    return CommentAdapter.validate_python(raw_comment)\n\ndef process_post(raw_post: Dict[str, Any]) -> Post:\n    return PostAdapter.validate_python(raw_post)\n\ndef process_posts_dict(raw_posts: Dict[str, Any]) -> Dict[str, Post]:\n    return PostDictAdapter.validate_python(raw_posts)\n\n",
          "display_code": "def process_comment(raw_comment: Dict[str, Any]) -> Comment:\n    return CommentAdapter.validate_python(raw_comment)\n\ndef process_post(raw_post: Dict[str, Any]) -> Post:\n    return PostAdapter.validate_python(raw_post)\n\ndef process_posts_dict(raw_posts: Dict[str, Any]) -> Dict[str, Post]:\n    return PostDictAdapter.validate_python(raw_posts)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 84,
          "line_range": [
            84,
            92
          ]
        },
        {
          "code": "# Example data\n",
          "display_code": "",
          "annotation": "Example data",
          "is_comment": true,
          "start_line": 93,
          "line_range": [
            93,
            93
          ],
          "target_line_range": [
            94,
            110
          ]
        },
        {
          "code": "raw_comment = {\n    \"user\": \"alice\",\n    \"text\": \"Great post!\",\n    \"timestamp\": \"2023-06-15T14:30:00Z\"\n}\n\nraw_post = {\n    \"id\": 1,\n    \"title\": \"Introduction to Type Adapters\",\n    \"content\": \"Type adapters are a powerful feature...\",\n    \"tags\": [\"pydantic\", \"python\", \"validation\"],\n    \"comments\": [\n        raw_comment,\n        {\"user\": \"bob\", \"text\": \"Thanks for sharing!\", \"timestamp\": \"2023-06-15T15:45:00Z\"}\n    ]\n}\n\n",
          "display_code": "raw_comment = {\n    \"user\": \"alice\",\n    \"text\": \"Great post!\",\n    \"timestamp\": \"2023-06-15T14:30:00Z\"\n}\n\nraw_post = {\n    \"id\": 1,\n    \"title\": \"Introduction to Type Adapters\",\n    \"content\": \"Type adapters are a powerful feature...\",\n    \"tags\": [\"pydantic\", \"python\", \"validation\"],\n    \"comments\": [\n        raw_comment,\n        {\"user\": \"bob\", \"text\": \"Thanks for sharing!\", \"timestamp\": \"2023-06-15T15:45:00Z\"}\n    ]\n}\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 94,
          "line_range": [
            94,
            110
          ]
        },
        {
          "code": "# Validate and convert the data\n",
          "display_code": "",
          "annotation": "Validate and convert the data",
          "is_comment": true,
          "start_line": 111,
          "line_range": [
            111,
            111
          ],
          "target_line_range": [
            112,
            117
          ]
        },
        {
          "code": "comment = process_comment(raw_comment)\npost = process_post(raw_post)\n\nprint(f\"Comment by {comment.user}: {comment.text}\")\nprint(f\"Post: {post.title} with {len(post.comments)} comments and tags: {', '.join(post.tags)}\")\n\n",
          "display_code": "comment = process_comment(raw_comment)\npost = process_post(raw_post)\n\nprint(f\"Comment by {comment.user}: {comment.text}\")\nprint(f\"Post: {post.title} with {len(post.comments)} comments and tags: {', '.join(post.tags)}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 112,
          "line_range": [
            112,
            117
          ]
        },
        {
          "code": "# Type adapters can be particularly useful when working with external APIs or complex data structures:\n",
          "display_code": "",
          "annotation": "Type adapters can be particularly useful when working with external APIs or complex data structures:",
          "is_comment": true,
          "start_line": 118,
          "line_range": [
            118,
            118
          ],
          "target_line_range": [
            119,
            121
          ]
        },
        {
          "code": "from typing import List, Dict, Any, Optional\nfrom pydantic import TypeAdapter, BaseModel, Field\n\n",
          "display_code": "from typing import List, Dict, Any, Optional\nfrom pydantic import TypeAdapter, BaseModel, Field\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 119,
          "line_range": [
            119,
            121
          ]
        },
        {
          "code": "# Define complex nested structures\n",
          "display_code": "",
          "annotation": "Define complex nested structures",
          "is_comment": true,
          "start_line": 122,
          "line_range": [
            122,
            122
          ],
          "target_line_range": [
            123,
            140
          ]
        },
        {
          "code": "class Address(BaseModel):\n    street: str\n    city: str\n    postal_code: str\n    country: str\n\nclass ContactInfo(BaseModel):\n    email: str\n    phone: Optional[str] = None\n    address: Address\n\nclass Customer(BaseModel):\n    id: str\n    name: str\n    contact_info: ContactInfo\n    account_type: str\n    active: bool\n\n",
          "display_code": "class Address(BaseModel):\n    street: str\n    city: str\n    postal_code: str\n    country: str\n\nclass ContactInfo(BaseModel):\n    email: str\n    phone: Optional[str] = None\n    address: Address\n\nclass Customer(BaseModel):\n    id: str\n    name: str\n    contact_info: ContactInfo\n    account_type: str\n    active: bool\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 123,
          "line_range": [
            123,
            140
          ]
        },
        {
          "code": "# Create nested type adapters\n",
          "display_code": "",
          "annotation": "Create nested type adapters",
          "is_comment": true,
          "start_line": 141,
          "line_range": [
            141,
            141
          ],
          "target_line_range": [
            142,
            146
          ]
        },
        {
          "code": "AddressAdapter = TypeAdapter(Address)\nContactInfoAdapter = TypeAdapter(ContactInfo)\nCustomerAdapter = TypeAdapter(Customer)\nCustomerListAdapter = TypeAdapter(List[Customer])\n\n",
          "display_code": "AddressAdapter = TypeAdapter(Address)\nContactInfoAdapter = TypeAdapter(ContactInfo)\nCustomerAdapter = TypeAdapter(Customer)\nCustomerListAdapter = TypeAdapter(List[Customer])\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 142,
          "line_range": [
            142,
            146
          ]
        },
        {
          "code": "# Process data with validation\n",
          "display_code": "",
          "annotation": "Process data with validation",
          "is_comment": true,
          "start_line": 147,
          "line_range": [
            147,
            147
          ],
          "target_line_range": [
            148,
            149
          ]
        },
        {
          "code": "def process_customers(data: Dict[str, Any]) -> List[Customer]:\n    try:\n",
          "display_code": "def process_customers(data: Dict[str, Any]) -> List[Customer]:\n    try:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 148,
          "line_range": [
            148,
            149
          ]
        },
        {
          "code": "        # Extract customer data from a complex API response\n",
          "display_code": "",
          "annotation": "Extract customer data from a complex API response",
          "is_comment": true,
          "start_line": 150,
          "line_range": [
            150,
            150
          ],
          "target_line_range": [
            151,
            156
          ]
        },
        {
          "code": "        customers_data = data.get(\"results\", {}).get(\"customers\", [])\n        return CustomerListAdapter.validate_python(customers_data)\n    except Exception as e:\n        print(f\"Validation error: {e}\")\n        return []\n\n",
          "display_code": "        customers_data = data.get(\"results\", {}).get(\"customers\", [])\n        return CustomerListAdapter.validate_python(customers_data)\n    except Exception as e:\n        print(f\"Validation error: {e}\")\n        return []\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 151,
          "line_range": [
            151,
            156
          ]
        },
        {
          "code": "# Example API response data\n",
          "display_code": "",
          "annotation": "Example API response data",
          "is_comment": true,
          "start_line": 157,
          "line_range": [
            157,
            157
          ],
          "target_line_range": [
            158,
            196
          ]
        },
        {
          "code": "api_response = {\n    \"status\": \"success\",\n    \"results\": {\n        \"customers\": [\n            {\n                \"id\": \"cust-001\",\n                \"name\": \"Acme Corporation\",\n                \"contact_info\": {\n                    \"email\": \"contact@acme.com\",\n                    \"phone\": \"555-123-4567\",\n                    \"address\": {\n                        \"street\": \"123 Main St\",\n                        \"city\": \"San Francisco\",\n                        \"postal_code\": \"94105\",\n                        \"country\": \"USA\"\n                    }\n                },\n                \"account_type\": \"enterprise\",\n                \"active\": True\n            },\n            {\n                \"id\": \"cust-002\",\n                \"name\": \"Globex Inc\",\n                \"contact_info\": {\n                    \"email\": \"info@globex.com\",\n                    \"address\": {\n                        \"street\": \"456 Market St\",\n                        \"city\": \"New York\",\n                        \"postal_code\": \"10001\",\n                        \"country\": \"USA\"\n                    }\n                },\n                \"account_type\": \"small_business\",\n                \"active\": True\n            }\n        ]\n    }\n}\n\n",
          "display_code": "api_response = {\n    \"status\": \"success\",\n    \"results\": {\n        \"customers\": [\n            {\n                \"id\": \"cust-001\",\n                \"name\": \"Acme Corporation\",\n                \"contact_info\": {\n                    \"email\": \"contact@acme.com\",\n                    \"phone\": \"555-123-4567\",\n                    \"address\": {\n                        \"street\": \"123 Main St\",\n                        \"city\": \"San Francisco\",\n                        \"postal_code\": \"94105\",\n                        \"country\": \"USA\"\n                    }\n                },\n                \"account_type\": \"enterprise\",\n                \"active\": True\n            },\n            {\n                \"id\": \"cust-002\",\n                \"name\": \"Globex Inc\",\n                \"contact_info\": {\n                    \"email\": \"info@globex.com\",\n                    \"address\": {\n                        \"street\": \"456 Market St\",\n                        \"city\": \"New York\",\n                        \"postal_code\": \"10001\",\n                        \"country\": \"USA\"\n                    }\n                },\n                \"account_type\": \"small_business\",\n                \"active\": True\n            }\n        ]\n    }\n}\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 158,
          "line_range": [
            158,
            196
          ]
        },
        {
          "code": "# Process and validate the data\n",
          "display_code": "",
          "annotation": "Process and validate the data",
          "is_comment": true,
          "start_line": 197,
          "line_range": [
            197,
            197
          ],
          "target_line_range": [
            198,
            204
          ]
        },
        {
          "code": "customers = process_customers(api_response)\nprint(f\"Processed {len(customers)} valid customers\")\nfor customer in customers:\n    print(f\"- {customer.name} ({customer.id})\")\n    print(f\"  Email: {customer.contact_info.email}\")\n    print(f\"  Address: {customer.contact_info.address.city}, {customer.contact_info.address.country}\")\n\n",
          "display_code": "customers = process_customers(api_response)\nprint(f\"Processed {len(customers)} valid customers\")\nfor customer in customers:\n    print(f\"- {customer.name} ({customer.id})\")\n    print(f\"  Email: {customer.contact_info.email}\")\n    print(f\"  Address: {customer.contact_info.address.city}, {customer.contact_info.address.country}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 198,
          "line_range": [
            198,
            204
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python type-adapters.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "009-performance",
      "section_title": "Performance and Optimization"
    },
    {
      "id": "050-resources",
      "title": "Resources",
      "description": "",
      "order": 50,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Discover essential resources and tools for working with structured extraction. Instructor builds on Pydantic and integrates with various LLM providers.\n",
          "display_code": "",
          "annotation": "Discover essential resources and tools for working with structured extraction. Instructor builds on Pydantic and integrates with various LLM providers.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python resources.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/instructor-ai/instructor",
        "https://python.useinstructor.com/",
        "https://discord.gg/bD9YE9JArw",
        "https://twitter.com/jxnlco",
        "https://python.useinstructor.com/blog",
        "https://github.com/instructor-ai/instructor/tree/main/examples",
        "https://python.useinstructor.com/",
        "https://github.com/instructor-ai/instructor/issues",
        "https://discord.gg/bD9YE9JArw",
        "https://github.com/instructor-ai/instructor/issues/new",
        "https://github.com/instructor-ai/instructor",
        "https://discord.gg/bD9YE9JArw",
        "https://python.useinstructor.com/blog",
        "https://github.com/instructor-ai/instructor/blob/main/CONTRIBUTING.md",
        "https://github.com/instructor-ai/instructor/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22",
        "https://docs.pydantic.dev/"
      ],
      "section_id": "999-misc",
      "section_title": "Miscellaneous Examples"
    }
  ],
  "sections": [
    {
      "id": "001-getting-started",
      "title": "Getting Started",
      "description": "Introduction to structured outputs with Instructor and setting up your environment",
      "order": 1,
      "examples": [
        "001-getting-started",
        "002-installation",
        "003-first-extraction",
        "004-response-models",
        "005-client-setup"
      ]
    },
    {
      "id": "002-providers",
      "title": "LLM Providers",
      "description": "Using Instructor with different LLM providers",
      "order": 2,
      "examples": [
        "006-openai",
        "007-anthropic",
        "008-gemini",
        "009-cohere",
        "010-mistral",
        "011-other-providers"
      ]
    },
    {
      "id": "003-basic-extraction",
      "title": "Basic Extraction Patterns",
      "description": "Common patterns for extracting structured data",
      "order": 3,
      "examples": [
        "012-simple-object",
        "013-list-extraction",
        "014-nested-structures",
        "015-field-validation",
        "016-optional-fields",
        "017-working-with-enums"
      ]
    },
    {
      "id": "004-classification",
      "title": "Classification and Analysis",
      "description": "Using structured outputs for classification tasks",
      "order": 4,
      "examples": [
        "018-simple-classification",
        "019-multi-label-classification"
      ]
    },
    {
      "id": "005-streaming",
      "title": "Streaming",
      "description": "Working with streaming responses",
      "order": 5,
      "examples": [
        "023-streaming-basics",
        "025-streaming-lists"
      ]
    },
    {
      "id": "006-advanced-structures",
      "title": "Advanced Structures",
      "description": "Building complex structured outputs",
      "order": 6,
      "examples": [
        "028-recursive-structures",
        "029-knowledge-graphs",
        "030-dependency-trees",
        "031-task-planning",
        "032-document-structure"
      ]
    },
    {
      "id": "007-validation",
      "title": "Validation",
      "description": "Ensuring data quality with validation",
      "order": 7,
      "examples": [
        "033-validation-basics",
        "034-custom-validators",
        "035-retry-mechanisms",
        "036-fallback-strategies",
        "037-field-level-validation"
      ]
    },
    {
      "id": "008-multimodal",
      "title": "Multimodal Inputs",
      "description": "Working with images, audio, and documents",
      "order": 8,
      "examples": [
        "038-vision-inputs",
        "039-image-to-structured-data",
        "040-table-extraction",
        "041-audio-extraction",
        "042-pdf-extraction"
      ]
    },
    {
      "id": "009-performance",
      "title": "Performance and Optimization",
      "description": "Optimizing performance for production use",
      "order": 9,
      "examples": [
        "043-caching-responses",
        "044-parallel-extraction",
        "045-batch-processing",
        "046-hooks-and-callbacks",
        "047-type-adapters"
      ]
    },
    {
      "id": "999-misc",
      "title": "Miscellaneous Examples",
      "description": "Additional examples that don't fit into other categories",
      "order": 999
    }
  ]
}