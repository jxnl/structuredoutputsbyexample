{
  "examples": [
    {
      "id": "001-getting-started",
      "title": "Getting Started with Structured Outputs",
      "description": "",
      "order": 1,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Let's dive in!\n",
          "display_code": "",
          "annotation": "Let's dive in!",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Large language models (LLMs) are powerful tools for generating text, but extracting specific structured information from their outputs can be challenging. **Structured outputs** solve this problem by having LLMs return data in consistent, machine-readable formats rather than free-form text.\n# \n# \n# \n# When working with LLMs, there are several issues with unstructured responses:\n# Using a standard OpenAI client for unstructured output\n",
          "display_code": "",
          "annotation": "Large language models (LLMs) are powerful tools for generating text, but extracting specific structured information from their outputs can be challenging. **Structured outputs** solve this problem by having LLMs return data in consistent, machine-readable formats rather than free-form text.\n\n\n\nWhen working with LLMs, there are several issues with unstructured responses:\nUsing a standard OpenAI client for unstructured output",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            10
          ],
          "target_line_range": [
            11,
            13
          ]
        },
        {
          "code": "from openai import OpenAI\nclient = OpenAI()\n\n",
          "display_code": "from openai import OpenAI\nclient = OpenAI()\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 11,
          "line_range": [
            11,
            13
          ]
        },
        {
          "code": "# Ask for customer information in free text\n",
          "display_code": "",
          "annotation": "Ask for customer information in free text",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            22
          ]
        },
        {
          "code": "response = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract customer: John Doe, age 35, email: john@example.com\"}\n    ]\n)\n\nprint(response.choices[0].message.content)\n",
          "display_code": "response = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract customer: John Doe, age 35, email: john@example.com\"}\n    ]\n)\n\nprint(response.choices[0].message.content)\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            22
          ]
        },
        {
          "code": "# Output might be:\n# \"Customer information:\n# Name: John Doe\n# Age: 35\n# Email: john@example.com\"\n",
          "display_code": "",
          "annotation": "Output might be:\n\"Customer information:\nName: John Doe\nAge: 35\nEmail: john@example.com\"",
          "is_comment": true,
          "start_line": 23,
          "line_range": [
            23,
            27
          ],
          "target_line_range": [
            28,
            28
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 28,
          "line_range": [
            28,
            28
          ]
        },
        {
          "code": "# This approach has several problems:\n# \n# - **Inconsistent formats**: The LLM might return data in different formats each time\n# - **Parsing challenges**: You need custom code to extract specific fields\n# - **No validation**: There's no verification that the data is complete or correctly formatted\n# - **Error handling**: Missing or invalid data is difficult to detect and manage\n# \n# \n# \n# Instructor solves these problems by combining the power of LLMs with structured data validation through Pydantic:\n",
          "display_code": "",
          "annotation": "This approach has several problems:\n\n- **Inconsistent formats**: The LLM might return data in different formats each time\n- **Parsing challenges**: You need custom code to extract specific fields\n- **No validation**: There's no verification that the data is complete or correctly formatted\n- **Error handling**: Missing or invalid data is difficult to detect and manage\n\n\n\nInstructor solves these problems by combining the power of LLMs with structured data validation through Pydantic:",
          "is_comment": true,
          "start_line": 29,
          "line_range": [
            29,
            38
          ],
          "target_line_range": [
            39,
            42
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, EmailStr\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, EmailStr\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 39,
          "line_range": [
            39,
            42
          ]
        },
        {
          "code": "# Define a structured data model\n",
          "display_code": "",
          "annotation": "Define a structured data model",
          "is_comment": true,
          "start_line": 43,
          "line_range": [
            43,
            43
          ],
          "target_line_range": [
            44,
            48
          ]
        },
        {
          "code": "class Customer(BaseModel):\n    name: str = Field(description=\"Customer's full name\")\n    age: int = Field(description=\"Customer's age in years\", ge=0, le=120)\n    email: EmailStr = Field(description=\"Customer's email address\")\n\n",
          "display_code": "class Customer(BaseModel):\n    name: str = Field(description=\"Customer's full name\")\n    age: int = Field(description=\"Customer's age in years\", ge=0, le=120)\n    email: EmailStr = Field(description=\"Customer's email address\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 44,
          "line_range": [
            44,
            48
          ]
        },
        {
          "code": "# Patch the OpenAI client with Instructor\n",
          "display_code": "",
          "annotation": "Patch the OpenAI client with Instructor",
          "is_comment": true,
          "start_line": 49,
          "line_range": [
            49,
            49
          ],
          "target_line_range": [
            50,
            51
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 50,
          "line_range": [
            50,
            51
          ]
        },
        {
          "code": "# Extract structured customer data\n",
          "display_code": "",
          "annotation": "Extract structured customer data",
          "is_comment": true,
          "start_line": 52,
          "line_range": [
            52,
            52
          ],
          "target_line_range": [
            53,
            63
          ]
        },
        {
          "code": "customer = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract customer: John Doe, age 35, email: john@example.com\"}\n    ],\n    response_model=Customer  # This is the key part\n)\n\nprint(customer)  # Customer(name='John Doe', age=35, email='john@example.com')\nprint(f\"Name: {customer.name}, Age: {customer.age}, Email: {customer.email}\")\n\n",
          "display_code": "customer = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract customer: John Doe, age 35, email: john@example.com\"}\n    ],\n    response_model=Customer  # This is the key part\n)\n\nprint(customer)  # Customer(name='John Doe', age=35, email='john@example.com')\nprint(f\"Name: {customer.name}, Age: {customer.age}, Email: {customer.email}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 53,
          "line_range": [
            53,
            63
          ]
        },
        {
          "code": "# 1. **Type Safety**: Get properly typed Python objects instead of raw strings\n# 2. **Validation**: Automatic validation with detailed error messages\n# 3. **Self-documenting**: Models clearly define the expected data structure\n# 4. **Consistent Results**: Reliable, consistent data format across requests\n# 5. **Error Handling**: Automatic retry with informative feedback when validation fails\n# 6. **IDE Support**: Full autocomplete and type checking in your code editor\n# \n# \n# \n# Instructor works by:\n# \n# 1. Defining your expected data structure as a Pydantic model\n# 2. Instructing the LLM to return data in a specific format (JSON, function calls, etc.)\n# 3. Validating the response against your model\n# 4. Automatically retrying if validation fails, providing the error to the LLM\n# 5. Returning a properly typed Python object\n# \n# \n# \n# Structured outputs shine for complex data:\n",
          "display_code": "",
          "annotation": "1. **Type Safety**: Get properly typed Python objects instead of raw strings\n2. **Validation**: Automatic validation with detailed error messages\n3. **Self-documenting**: Models clearly define the expected data structure\n4. **Consistent Results**: Reliable, consistent data format across requests\n5. **Error Handling**: Automatic retry with informative feedback when validation fails\n6. **IDE Support**: Full autocomplete and type checking in your code editor\n\n\n\nInstructor works by:\n\n1. Defining your expected data structure as a Pydantic model\n2. Instructing the LLM to return data in a specific format (JSON, function calls, etc.)\n3. Validating the response against your model\n4. Automatically retrying if validation fails, providing the error to the LLM\n5. Returning a properly typed Python object\n\n\n\nStructured outputs shine for complex data:",
          "is_comment": true,
          "start_line": 64,
          "line_range": [
            64,
            83
          ],
          "target_line_range": [
            84,
            88
          ]
        },
        {
          "code": "from typing import List, Optional\nfrom pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\n\n",
          "display_code": "from typing import List, Optional\nfrom pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 84,
          "line_range": [
            84,
            88
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 89,
          "line_range": [
            89,
            89
          ],
          "target_line_range": [
            90,
            91
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 90,
          "line_range": [
            90,
            91
          ]
        },
        {
          "code": "# Define a complex, nested data structure\n",
          "display_code": "",
          "annotation": "Define a complex, nested data structure",
          "is_comment": true,
          "start_line": 92,
          "line_range": [
            92,
            92
          ],
          "target_line_range": [
            93,
            110
          ]
        },
        {
          "code": "class Address(BaseModel):\n    street: str\n    city: str\n    state: str\n    zip_code: str\n\nclass Contact(BaseModel):\n    email: Optional[str] = None\n    phone: Optional[str] = None\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n    address: Address\n    contact: Contact\n    skills: List[str] = Field(description=\"List of professional skills\")\n\n",
          "display_code": "class Address(BaseModel):\n    street: str\n    city: str\n    state: str\n    zip_code: str\n\nclass Contact(BaseModel):\n    email: Optional[str] = None\n    phone: Optional[str] = None\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n    address: Address\n    contact: Contact\n    skills: List[str] = Field(description=\"List of professional skills\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 93,
          "line_range": [
            93,
            110
          ]
        },
        {
          "code": "# Extract structured data\n",
          "display_code": "",
          "annotation": "Extract structured data",
          "is_comment": true,
          "start_line": 111,
          "line_range": [
            111,
            111
          ],
          "target_line_range": [
            112,
            124
          ]
        },
        {
          "code": "person = client.chat.completions.create(\n    model=\"gpt-4\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Extract detailed information for this person:\n        John Smith is a 42-year-old software engineer living at 123 Main St, San Francisco, CA 94105.\n        His email is john.smith@example.com and phone is 555-123-4567.\n        John is skilled in Python, JavaScript, and cloud architecture.\n        \"\"\"}\n    ],\n    response_model=Person\n)\n\n",
          "display_code": "person = client.chat.completions.create(\n    model=\"gpt-4\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Extract detailed information for this person:\n        John Smith is a 42-year-old software engineer living at 123 Main St, San Francisco, CA 94105.\n        His email is john.smith@example.com and phone is 555-123-4567.\n        John is skilled in Python, JavaScript, and cloud architecture.\n        \"\"\"}\n    ],\n    response_model=Person\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 112,
          "line_range": [
            112,
            124
          ]
        },
        {
          "code": "# Now you have a fully structured object\n",
          "display_code": "",
          "annotation": "Now you have a fully structured object",
          "is_comment": true,
          "start_line": 125,
          "line_range": [
            125,
            125
          ],
          "target_line_range": [
            126,
            129
          ]
        },
        {
          "code": "print(f\"Name: {person.name}\")\nprint(f\"Location: {person.address.city}, {person.address.state}\")\nprint(f\"Skills: {', '.join(person.skills)}\")\n\n",
          "display_code": "print(f\"Name: {person.name}\")\nprint(f\"Location: {person.address.city}, {person.address.state}\")\nprint(f\"Skills: {', '.join(person.skills)}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 126,
          "line_range": [
            126,
            129
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python getting-started.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "001-getting-started",
      "section_title": "Getting Started"
    },
    {
      "id": "002-installation",
      "title": "Installing Instructor",
      "description": "",
      "order": 2,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# You can also set keys in your code, but environment variables are recommended for security.\n",
          "display_code": "",
          "annotation": "You can also set keys in your code, but environment variables are recommended for security.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "## Basic Installation",
          "command": "# Install the base package",
          "output": "$ pip install instructor"
        },
        {
          "explanation": "Install with specific provider dependencies:",
          "command": "# For OpenAI (included by default)",
          "output": "$ pip install instructor\n$ \n$ # For Anthropic\n$ pip install \"instructor[anthropic]\"\n$ \n$ # For Google/Gemini\n$ pip install \"instructor[google-generativeai]\"\n$ \n$ # For Cohere\n$ pip install \"instructor[cohere]\"\n$ \n$ # For Mistral\n$ pip install \"instructor[mistralai]\"\n$ \n$ # For multiple providers via LiteLLM\n$ pip install \"instructor[litellm]\""
        },
        {
          "explanation": "Set your API keys as environment variables:",
          "command": "# OpenAI",
          "output": "$ export OPENAI_API_KEY=your_openai_key\n$ \n$ # Anthropic\n$ export ANTHROPIC_API_KEY=your_anthropic_key\n$ \n$ # Google/Gemini\n$ export GOOGLE_API_KEY=your_google_key"
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "001-getting-started",
      "section_title": "Getting Started"
    },
    {
      "id": "003-first-extraction",
      "title": "Your First Extraction",
      "description": "",
      "order": 3,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# 5. The response is automatically validated and converted to our model\n",
          "display_code": "",
          "annotation": "5. The response is automatically validated and converted to our model",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Extract structured data from text using Instructor and a Pydantic model.\n",
          "display_code": "",
          "annotation": "Extract structured data from text using Instructor and a Pydantic model.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            14
          ]
        },
        {
          "code": "from pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n\nimport instructor\nfrom openai import OpenAI\n\n",
          "display_code": "from pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n\nimport instructor\nfrom openai import OpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            14
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 15,
          "line_range": [
            15,
            15
          ],
          "target_line_range": [
            16,
            17
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 16,
          "line_range": [
            16,
            17
          ]
        },
        {
          "code": "# Extract structured data\n",
          "display_code": "",
          "annotation": "Extract structured data",
          "is_comment": true,
          "start_line": 18,
          "line_range": [
            18,
            18
          ],
          "target_line_range": [
            19,
            27
          ]
        },
        {
          "code": "person = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John Doe is 30 years old\"}\n    ]\n)\n\nprint(f\"Name: {person.name}, Age: {person.age}\")\n",
          "display_code": "person = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John Doe is 30 years old\"}\n    ]\n)\n\nprint(f\"Name: {person.name}, Age: {person.age}\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 19,
          "line_range": [
            19,
            27
          ]
        },
        {
          "code": "# Output: Name: John Doe, Age: 30\n",
          "display_code": "",
          "annotation": "Output: Name: John Doe, Age: 30",
          "is_comment": true,
          "start_line": 28,
          "line_range": [
            28,
            28
          ],
          "target_line_range": [
            29,
            29
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 29,
          "line_range": [
            29,
            29
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python first-extraction.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "001-getting-started",
      "section_title": "Getting Started"
    },
    {
      "id": "004-response-models",
      "title": "Understanding Response Models",
      "description": "",
      "order": 4,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# \n",
          "display_code": "",
          "annotation": "",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor uses Pydantic models to define the structure of your LLM outputs. Here's how to create effective models.\n",
          "display_code": "",
          "annotation": "Instructor uses Pydantic models to define the structure of your LLM outputs. Here's how to create effective models.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            25
          ]
        },
        {
          "code": "from pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\nfrom pydantic import BaseModel\nfrom typing import List, Optional\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    state: Optional[str] = None\n    country: str\n\nclass User(BaseModel):\n    name: str\n    age: int\n    addresses: List[Address]\n\n",
          "display_code": "from pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\nfrom pydantic import BaseModel\nfrom typing import List, Optional\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    state: Optional[str] = None\n    country: str\n\nclass User(BaseModel):\n    name: str\n    age: int\n    addresses: List[Address]\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            25
          ]
        },
        {
          "code": "# Add descriptions to help guide the LLM:\n",
          "display_code": "",
          "annotation": "Add descriptions to help guide the LLM:",
          "is_comment": true,
          "start_line": 26,
          "line_range": [
            26,
            26
          ],
          "target_line_range": [
            27,
            41
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\n\nclass WeatherForecast(BaseModel):\n    \"\"\"Weather forecast for a specific location\"\"\"\n\n    temperature: float = Field(\n        description=\"Current temperature in Celsius\"\n    )\n    condition: str = Field(\n        description=\"Weather condition (sunny, cloudy, rainy, etc.)\"\n    )\n    humidity: int = Field(\n        description=\"Humidity percentage from 0-100\"\n    )\n\n",
          "display_code": "from pydantic import BaseModel, Field\n\nclass WeatherForecast(BaseModel):\n    \"\"\"Weather forecast for a specific location\"\"\"\n\n    temperature: float = Field(\n        description=\"Current temperature in Celsius\"\n    )\n    condition: str = Field(\n        description=\"Weather condition (sunny, cloudy, rainy, etc.)\"\n    )\n    humidity: int = Field(\n        description=\"Humidity percentage from 0-100\"\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 27,
          "line_range": [
            27,
            41
          ]
        },
        {
          "code": "# Add validation constraints to ensure quality data:\n",
          "display_code": "",
          "annotation": "Add validation constraints to ensure quality data:",
          "is_comment": true,
          "start_line": 42,
          "line_range": [
            42,
            42
          ],
          "target_line_range": [
            43,
            65
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\n\nclass Product(BaseModel):\n    name: str = Field(min_length=3)\n    price: float = Field(gt=0)  # greater than 0\n    quantity: int = Field(ge=0)  # greater than or equal to 0\n    description: str = Field(max_length=500)\n\nimport instructor\nfrom openai import OpenAI\n\nclient = instructor.from_openai(OpenAI())\n\nforecast = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=WeatherForecast,\n    messages=[\n        {\"role\": \"user\", \"content\": \"What's the weather in New York today?\"}\n    ]\n)\n\nprint(forecast.model_dump_json(indent=2))\n\n",
          "display_code": "from pydantic import BaseModel, Field\n\nclass Product(BaseModel):\n    name: str = Field(min_length=3)\n    price: float = Field(gt=0)  # greater than 0\n    quantity: int = Field(ge=0)  # greater than or equal to 0\n    description: str = Field(max_length=500)\n\nimport instructor\nfrom openai import OpenAI\n\nclient = instructor.from_openai(OpenAI())\n\nforecast = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=WeatherForecast,\n    messages=[\n        {\"role\": \"user\", \"content\": \"What's the weather in New York today?\"}\n    ]\n)\n\nprint(forecast.model_dump_json(indent=2))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 43,
          "line_range": [
            43,
            65
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python response-models.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "001-getting-started",
      "section_title": "Getting Started"
    },
    {
      "id": "005-client-setup",
      "title": "Client Setup",
      "description": "",
      "order": 5,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Choose the appropriate mode based on your provider and needs.\n",
          "display_code": "",
          "annotation": "Choose the appropriate mode based on your provider and needs.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Set up Instructor with different LLM providers. Each provider requires slightly different setup.\n",
          "display_code": "",
          "annotation": "Set up Instructor with different LLM providers. Each provider requires slightly different setup.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            8
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            8
          ]
        },
        {
          "code": "# Default mode for OpenAI is TOOLS (function calling)\n",
          "display_code": "",
          "annotation": "Default mode for OpenAI is TOOLS (function calling)",
          "is_comment": true,
          "start_line": 9,
          "line_range": [
            9,
            9
          ],
          "target_line_range": [
            10,
            11
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 10,
          "line_range": [
            10,
            11
          ]
        },
        {
          "code": "# You can also specify a different mode\n",
          "display_code": "",
          "annotation": "You can also specify a different mode",
          "is_comment": true,
          "start_line": 12,
          "line_range": [
            12,
            12
          ],
          "target_line_range": [
            13,
            20
          ]
        },
        {
          "code": "client = instructor.from_openai(\n    OpenAI(),\n    mode=instructor.Mode.JSON  # Use JSON mode instead\n)\n\nimport instructor\nfrom anthropic import Anthropic\n\n",
          "display_code": "client = instructor.from_openai(\n    OpenAI(),\n    mode=instructor.Mode.JSON  # Use JSON mode instead\n)\n\nimport instructor\nfrom anthropic import Anthropic\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 13,
          "line_range": [
            13,
            20
          ]
        },
        {
          "code": "# Default mode is TOOLS for Claude 3\n",
          "display_code": "",
          "annotation": "Default mode is TOOLS for Claude 3",
          "is_comment": true,
          "start_line": 21,
          "line_range": [
            21,
            21
          ],
          "target_line_range": [
            22,
            23
          ]
        },
        {
          "code": "client = instructor.from_anthropic(Anthropic())\n\n",
          "display_code": "client = instructor.from_anthropic(Anthropic())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 22,
          "line_range": [
            22,
            23
          ]
        },
        {
          "code": "# Use JSON mode if needed\n",
          "display_code": "",
          "annotation": "Use JSON mode if needed",
          "is_comment": true,
          "start_line": 24,
          "line_range": [
            24,
            24
          ],
          "target_line_range": [
            25,
            32
          ]
        },
        {
          "code": "client = instructor.from_anthropic(\n    Anthropic(),\n    mode=instructor.Mode.JSON\n)\n\nimport instructor\nimport google.generativeai as genai\n\n",
          "display_code": "client = instructor.from_anthropic(\n    Anthropic(),\n    mode=instructor.Mode.JSON\n)\n\nimport instructor\nimport google.generativeai as genai\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 25,
          "line_range": [
            25,
            32
          ]
        },
        {
          "code": "# Configure Gemini\n",
          "display_code": "",
          "annotation": "Configure Gemini",
          "is_comment": true,
          "start_line": 33,
          "line_range": [
            33,
            33
          ],
          "target_line_range": [
            34,
            36
          ]
        },
        {
          "code": "genai.configure(api_key=\"YOUR_API_KEY\")\nmodel = genai.GenerativeModel(\"gemini-1.5-flash\")\n\n",
          "display_code": "genai.configure(api_key=\"YOUR_API_KEY\")\nmodel = genai.GenerativeModel(\"gemini-1.5-flash\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 34,
          "line_range": [
            34,
            36
          ]
        },
        {
          "code": "# Gemini needs a specific mode\n",
          "display_code": "",
          "annotation": "Gemini needs a specific mode",
          "is_comment": true,
          "start_line": 37,
          "line_range": [
            37,
            37
          ],
          "target_line_range": [
            38,
            45
          ]
        },
        {
          "code": "client = instructor.from_gemini(\n    model,\n    mode=instructor.Mode.GEMINI_TOOLS  # or GEMINI_JSON\n)\n\nimport instructor\nimport cohere\n\n",
          "display_code": "client = instructor.from_gemini(\n    model,\n    mode=instructor.Mode.GEMINI_TOOLS  # or GEMINI_JSON\n)\n\nimport instructor\nimport cohere\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 38,
          "line_range": [
            38,
            45
          ]
        },
        {
          "code": "# Create Cohere client\n",
          "display_code": "",
          "annotation": "Create Cohere client",
          "is_comment": true,
          "start_line": 46,
          "line_range": [
            46,
            46
          ],
          "target_line_range": [
            47,
            48
          ]
        },
        {
          "code": "cohere_client = cohere.Client(\"YOUR_API_KEY\")\n\n",
          "display_code": "cohere_client = cohere.Client(\"YOUR_API_KEY\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 47,
          "line_range": [
            47,
            48
          ]
        },
        {
          "code": "# Patch with instructor\n",
          "display_code": "",
          "annotation": "Patch with instructor",
          "is_comment": true,
          "start_line": 49,
          "line_range": [
            49,
            49
          ],
          "target_line_range": [
            50,
            56
          ]
        },
        {
          "code": "client = instructor.from_cohere(cohere_client)\n\nimport instructor\nfrom mistralai.client import MistralClient\n\nmistral_client = MistralClient(api_key=\"YOUR_API_KEY\")\n\n",
          "display_code": "client = instructor.from_cohere(cohere_client)\n\nimport instructor\nfrom mistralai.client import MistralClient\n\nmistral_client = MistralClient(api_key=\"YOUR_API_KEY\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 50,
          "line_range": [
            50,
            56
          ]
        },
        {
          "code": "# Patch with instructor\n",
          "display_code": "",
          "annotation": "Patch with instructor",
          "is_comment": true,
          "start_line": 57,
          "line_range": [
            57,
            57
          ],
          "target_line_range": [
            58,
            59
          ]
        },
        {
          "code": "client = instructor.from_mistral(mistral_client)\n\n",
          "display_code": "client = instructor.from_mistral(mistral_client)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 58,
          "line_range": [
            58,
            59
          ]
        },
        {
          "code": "# Instructor supports different modes for different providers:\n",
          "display_code": "",
          "annotation": "Instructor supports different modes for different providers:",
          "is_comment": true,
          "start_line": 60,
          "line_range": [
            60,
            60
          ],
          "target_line_range": [
            61,
            62
          ]
        },
        {
          "code": "from instructor import Mode\n\n",
          "display_code": "from instructor import Mode\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 61,
          "line_range": [
            61,
            62
          ]
        },
        {
          "code": "# Available modes\n",
          "display_code": "",
          "annotation": "Available modes",
          "is_comment": true,
          "start_line": 63,
          "line_range": [
            63,
            63
          ],
          "target_line_range": [
            64,
            70
          ]
        },
        {
          "code": "Mode.TOOLS         # OpenAI function calling format (default for OpenAI)\nMode.JSON          # Plain JSON generation\nMode.MD_JSON       # Markdown JSON (used by some providers)\nMode.ANTHROPIC_TOOLS # Claude tools mode (default for Anthropic)\nMode.GEMINI_TOOLS  # Gemini tools format\nMode.GEMINI_JSON   # Gemini JSON format\n\n",
          "display_code": "Mode.TOOLS         # OpenAI function calling format (default for OpenAI)\nMode.JSON          # Plain JSON generation\nMode.MD_JSON       # Markdown JSON (used by some providers)\nMode.ANTHROPIC_TOOLS # Claude tools mode (default for Anthropic)\nMode.GEMINI_TOOLS  # Gemini tools format\nMode.GEMINI_JSON   # Gemini JSON format\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 64,
          "line_range": [
            64,
            70
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python client-setup.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "001-getting-started",
      "section_title": "Getting Started"
    },
    {
      "id": "006-openai",
      "title": "OpenAI Integration",
      "description": "",
      "order": 6,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# \n",
          "display_code": "",
          "annotation": "",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor works seamlessly with OpenAI models. Here's how to use it with different OpenAI features.\n",
          "display_code": "",
          "annotation": "Instructor works seamlessly with OpenAI models. Here's how to use it with different OpenAI features.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            15
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\nclient = instructor.from_openai(OpenAI())\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\nclient = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            15
          ]
        },
        {
          "code": "# GPT-3.5 Turbo (cheaper, faster)\n",
          "display_code": "",
          "annotation": "GPT-3.5 Turbo (cheaper, faster)",
          "is_comment": true,
          "start_line": 16,
          "line_range": [
            16,
            16
          ],
          "target_line_range": [
            17,
            24
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is a 25-year-old engineer.\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is a 25-year-old engineer.\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 17,
          "line_range": [
            17,
            24
          ]
        },
        {
          "code": "# GPT-4 (more capable, better at complex tasks)\n",
          "display_code": "",
          "annotation": "GPT-4 (more capable, better at complex tasks)",
          "is_comment": true,
          "start_line": 25,
          "line_range": [
            25,
            25
          ],
          "target_line_range": [
            26,
            42
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"gpt-4\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is a 25-year-old engineer.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=User,\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are an expert at data extraction.\"},\n        {\"role\": \"user\", \"content\": \"Extract user details from: John is 25 years old.\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"gpt-4\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is a 25-year-old engineer.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=User,\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are an expert at data extraction.\"},\n        {\"role\": \"user\", \"content\": \"Extract user details from: John is 25 years old.\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 26,
          "line_range": [
            26,
            42
          ]
        },
        {
          "code": "# Lower temperature for more consistent results\n",
          "display_code": "",
          "annotation": "Lower temperature for more consistent results",
          "is_comment": true,
          "start_line": 43,
          "line_range": [
            43,
            43
          ],
          "target_line_range": [
            44,
            52
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    temperature=0.1,  # Very deterministic (0.0-1.0)\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is a 25-year-old engineer.\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    temperature=0.1,  # Very deterministic (0.0-1.0)\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is a 25-year-old engineer.\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 44,
          "line_range": [
            44,
            52
          ]
        },
        {
          "code": "# Instructor defaults to using OpenAI's function calling format, but you can use JSON mode too:\n",
          "display_code": "",
          "annotation": "Instructor defaults to using OpenAI's function calling format, but you can use JSON mode too:",
          "is_comment": true,
          "start_line": 53,
          "line_range": [
            53,
            53
          ],
          "target_line_range": [
            54,
            82
          ]
        },
        {
          "code": "client = instructor.from_openai(\n    OpenAI(),\n    mode=instructor.Mode.JSON\n)\n\nuser = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is a 25-year-old engineer.\"}\n    ]\n)\n\nimport asyncio\nfrom openai import AsyncOpenAI\n\nasync_client = instructor.from_openai(AsyncOpenAI())\n\nasync def extract_user():\n    return await async_client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Extract: John is a 25-year-old engineer.\"}\n        ]\n    )\n\nuser = asyncio.run(extract_user())\n\n",
          "display_code": "client = instructor.from_openai(\n    OpenAI(),\n    mode=instructor.Mode.JSON\n)\n\nuser = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is a 25-year-old engineer.\"}\n    ]\n)\n\nimport asyncio\nfrom openai import AsyncOpenAI\n\nasync_client = instructor.from_openai(AsyncOpenAI())\n\nasync def extract_user():\n    return await async_client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Extract: John is a 25-year-old engineer.\"}\n        ]\n    )\n\nuser = asyncio.run(extract_user())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 54,
          "line_range": [
            54,
            82
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python openai.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "002-providers",
      "section_title": "LLM Providers"
    },
    {
      "id": "007-anthropic",
      "title": "Anthropic Integration",
      "description": "",
      "order": 7,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Use Instructor with Anthropic's Claude models for structured data extraction.\n",
          "display_code": "",
          "annotation": "Use Instructor with Anthropic's Claude models for structured data extraction.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            13
          ]
        },
        {
          "code": "import instructor\nfrom anthropic import Anthropic\nfrom pydantic import BaseModel\n\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n\n",
          "display_code": "import instructor\nfrom anthropic import Anthropic\nfrom pydantic import BaseModel\n\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            13
          ]
        },
        {
          "code": "# Create patched client\n",
          "display_code": "",
          "annotation": "Create patched client",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            16
          ]
        },
        {
          "code": "client = instructor.from_anthropic(Anthropic())\n\n",
          "display_code": "client = instructor.from_anthropic(Anthropic())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            16
          ]
        },
        {
          "code": "# Claude 3 Haiku (faster, cheaper)\n",
          "display_code": "",
          "annotation": "Claude 3 Haiku (faster, cheaper)",
          "is_comment": true,
          "start_line": 17,
          "line_range": [
            17,
            17
          ],
          "target_line_range": [
            18,
            24
          ]
        },
        {
          "code": "user = client.messages.create(\n    model=\"claude-3-haiku-20240307\",\n    max_tokens=1000,\n    response_model=User,\n    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n)\n\n",
          "display_code": "user = client.messages.create(\n    model=\"claude-3-haiku-20240307\",\n    max_tokens=1000,\n    response_model=User,\n    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 18,
          "line_range": [
            18,
            24
          ]
        },
        {
          "code": "# Claude 3 Sonnet (balanced)\n",
          "display_code": "",
          "annotation": "Claude 3 Sonnet (balanced)",
          "is_comment": true,
          "start_line": 25,
          "line_range": [
            25,
            25
          ],
          "target_line_range": [
            26,
            32
          ]
        },
        {
          "code": "user = client.messages.create(\n    model=\"claude-3-sonnet-20240229\",\n    max_tokens=1000,\n    response_model=User,\n    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n)\n\n",
          "display_code": "user = client.messages.create(\n    model=\"claude-3-sonnet-20240229\",\n    max_tokens=1000,\n    response_model=User,\n    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 26,
          "line_range": [
            26,
            32
          ]
        },
        {
          "code": "# Claude 3 Opus (most capable)\n",
          "display_code": "",
          "annotation": "Claude 3 Opus (most capable)",
          "is_comment": true,
          "start_line": 33,
          "line_range": [
            33,
            33
          ],
          "target_line_range": [
            34,
            56
          ]
        },
        {
          "code": "user = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1000,\n    response_model=User,\n    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n)\n\nuser = client.messages.create(\n    model=\"claude-3-haiku-20240307\",\n    max_tokens=1000,\n    response_model=User,\n    system=\"You are an expert at data extraction. Always extract all details accurately.\",\n    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n)\n\nuser = client.messages.create(\n    model=\"claude-3-haiku-20240307\",\n    max_tokens=1000,\n    temperature=0.2,  # Lower temperature for more consistent results\n    response_model=User,\n    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n)\n\n",
          "display_code": "user = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1000,\n    response_model=User,\n    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n)\n\nuser = client.messages.create(\n    model=\"claude-3-haiku-20240307\",\n    max_tokens=1000,\n    response_model=User,\n    system=\"You are an expert at data extraction. Always extract all details accurately.\",\n    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n)\n\nuser = client.messages.create(\n    model=\"claude-3-haiku-20240307\",\n    max_tokens=1000,\n    temperature=0.2,  # Lower temperature for more consistent results\n    response_model=User,\n    messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 34,
          "line_range": [
            34,
            56
          ]
        },
        {
          "code": "# Default: ANTHROPIC_TOOLS mode\n",
          "display_code": "",
          "annotation": "Default: ANTHROPIC_TOOLS mode",
          "is_comment": true,
          "start_line": 57,
          "line_range": [
            57,
            57
          ],
          "target_line_range": [
            58,
            59
          ]
        },
        {
          "code": "client = instructor.from_anthropic(Anthropic())\n\n",
          "display_code": "client = instructor.from_anthropic(Anthropic())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 58,
          "line_range": [
            58,
            59
          ]
        },
        {
          "code": "# JSON mode\n",
          "display_code": "",
          "annotation": "JSON mode",
          "is_comment": true,
          "start_line": 60,
          "line_range": [
            60,
            60
          ],
          "target_line_range": [
            61,
            62
          ]
        },
        {
          "code": "json_client = instructor.from_anthropic(Anthropic(), mode=instructor.Mode.JSON)\n\n",
          "display_code": "json_client = instructor.from_anthropic(Anthropic(), mode=instructor.Mode.JSON)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 61,
          "line_range": [
            61,
            62
          ]
        },
        {
          "code": "# Markdown JSON mode\n",
          "display_code": "",
          "annotation": "Markdown JSON mode",
          "is_comment": true,
          "start_line": 63,
          "line_range": [
            63,
            63
          ],
          "target_line_range": [
            64,
            81
          ]
        },
        {
          "code": "md_client = instructor.from_anthropic(Anthropic(), mode=instructor.Mode.MD_JSON)\n\nimport asyncio\nfrom anthropic import AsyncAnthropic\n\nasync_client = instructor.from_anthropic(AsyncAnthropic())\n\n\nasync def extract_user():\n    return await async_client.messages.create(\n        model=\"claude-3-haiku-20240307\",\n        max_tokens=1000,\n        response_model=User,\n        messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n    )\n\n\nuser = asyncio.run(extract_user())\n",
          "display_code": "md_client = instructor.from_anthropic(Anthropic(), mode=instructor.Mode.MD_JSON)\n\nimport asyncio\nfrom anthropic import AsyncAnthropic\n\nasync_client = instructor.from_anthropic(AsyncAnthropic())\n\n\nasync def extract_user():\n    return await async_client.messages.create(\n        model=\"claude-3-haiku-20240307\",\n        max_tokens=1000,\n        response_model=User,\n        messages=[{\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}],\n    )\n\n\nuser = asyncio.run(extract_user())\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 64,
          "line_range": [
            64,
            81
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python anthropic.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "002-providers",
      "section_title": "LLM Providers"
    },
    {
      "id": "008-gemini",
      "title": "Gemini Integration",
      "description": "",
      "order": 8,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# \n",
          "display_code": "",
          "annotation": "",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Use Instructor with Google's Gemini models for structured data extraction.\n# \n# \n# \n# \n# \n# pip install instructor google-generativeai jsonref\n# \n",
          "display_code": "",
          "annotation": "Use Instructor with Google's Gemini models for structured data extraction.\n\n\n\n\n\npip install instructor google-generativeai jsonref\n",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            12
          ],
          "target_line_range": [
            13,
            16
          ]
        },
        {
          "code": "import instructor\nimport google.generativeai as genai\nfrom pydantic import BaseModel\n\n",
          "display_code": "import instructor\nimport google.generativeai as genai\nfrom pydantic import BaseModel\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 13,
          "line_range": [
            13,
            16
          ]
        },
        {
          "code": "# Configure API key\n",
          "display_code": "",
          "annotation": "Configure API key",
          "is_comment": true,
          "start_line": 17,
          "line_range": [
            17,
            17
          ],
          "target_line_range": [
            18,
            23
          ]
        },
        {
          "code": "genai.configure(api_key=\"YOUR_API_KEY\")\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "genai.configure(api_key=\"YOUR_API_KEY\")\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 18,
          "line_range": [
            18,
            23
          ]
        },
        {
          "code": "# Create Gemini model\n",
          "display_code": "",
          "annotation": "Create Gemini model",
          "is_comment": true,
          "start_line": 24,
          "line_range": [
            24,
            24
          ],
          "target_line_range": [
            25,
            26
          ]
        },
        {
          "code": "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n\n",
          "display_code": "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 25,
          "line_range": [
            25,
            26
          ]
        },
        {
          "code": "# Patch with instructor (require specific mode)\n",
          "display_code": "",
          "annotation": "Patch with instructor (require specific mode)",
          "is_comment": true,
          "start_line": 27,
          "line_range": [
            27,
            27
          ],
          "target_line_range": [
            28,
            32
          ]
        },
        {
          "code": "client = instructor.from_gemini(\n    model,\n    mode=instructor.Mode.GEMINI_TOOLS  # or GEMINI_JSON\n)\n\n",
          "display_code": "client = instructor.from_gemini(\n    model,\n    mode=instructor.Mode.GEMINI_TOOLS  # or GEMINI_JSON\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 28,
          "line_range": [
            28,
            32
          ]
        },
        {
          "code": "# Using generate_content method\n",
          "display_code": "",
          "annotation": "Using generate_content method",
          "is_comment": true,
          "start_line": 33,
          "line_range": [
            33,
            33
          ],
          "target_line_range": [
            34,
            39
          ]
        },
        {
          "code": "user = client.generate_content(\n    response_model=User,\n    contents=\"Extract: John is 25 years old.\"\n)\n\nprint(f\"Name: {user.name}, Age: {user.age}\")\n",
          "display_code": "user = client.generate_content(\n    response_model=User,\n    contents=\"Extract: John is 25 years old.\"\n)\n\nprint(f\"Name: {user.name}, Age: {user.age}\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 34,
          "line_range": [
            34,
            39
          ]
        },
        {
          "code": "# Output: Name: John, Age: 25\n",
          "display_code": "",
          "annotation": "Output: Name: John, Age: 25",
          "is_comment": true,
          "start_line": 40,
          "line_range": [
            40,
            40
          ],
          "target_line_range": [
            41,
            41
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 41,
          "line_range": [
            41,
            41
          ]
        },
        {
          "code": "# Gemini 1.5 Flash (faster)\n",
          "display_code": "",
          "annotation": "Gemini 1.5 Flash (faster)",
          "is_comment": true,
          "start_line": 42,
          "line_range": [
            42,
            42
          ],
          "target_line_range": [
            43,
            48
          ]
        },
        {
          "code": "flash_model = genai.GenerativeModel(\"gemini-1.5-flash\")\nflash_client = instructor.from_gemini(\n    flash_model,\n    mode=instructor.Mode.GEMINI_TOOLS\n)\n\n",
          "display_code": "flash_model = genai.GenerativeModel(\"gemini-1.5-flash\")\nflash_client = instructor.from_gemini(\n    flash_model,\n    mode=instructor.Mode.GEMINI_TOOLS\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 43,
          "line_range": [
            43,
            48
          ]
        },
        {
          "code": "# Gemini 1.5 Pro (more capable)\n",
          "display_code": "",
          "annotation": "Gemini 1.5 Pro (more capable)",
          "is_comment": true,
          "start_line": 49,
          "line_range": [
            49,
            49
          ],
          "target_line_range": [
            50,
            85
          ]
        },
        {
          "code": "pro_model = genai.GenerativeModel(\"gemini-1.5-pro\")\npro_client = instructor.from_gemini(\n    pro_model,\n    mode=instructor.Mode.GEMINI_TOOLS\n)\n\nuser = client.generate_content(\n    response_model=User,\n    contents=\"Extract: John is 25 years old.\",\n    generation_config={\n        \"system_instruction\": \"You are an expert at extracting structured data.\"\n    }\n)\n\nuser = client.generate_content(\n    response_model=User,\n    contents=[\n        {\"role\": \"user\", \"parts\": [\"Extract: John is 25 years old.\"]}\n    ]\n)\n\njson_client = instructor.from_gemini(\n    genai.GenerativeModel(\"gemini-1.5-flash\"),\n    mode=instructor.Mode.GEMINI_JSON\n)\n\nuser = json_client.generate_content(\n    response_model=User,\n    contents=\"Extract: John is 25 years old.\"\n)\n\nimport google.auth\nimport google.auth.transport.requests\nimport instructor\nfrom openai import OpenAI\n\n",
          "display_code": "pro_model = genai.GenerativeModel(\"gemini-1.5-pro\")\npro_client = instructor.from_gemini(\n    pro_model,\n    mode=instructor.Mode.GEMINI_TOOLS\n)\n\nuser = client.generate_content(\n    response_model=User,\n    contents=\"Extract: John is 25 years old.\",\n    generation_config={\n        \"system_instruction\": \"You are an expert at extracting structured data.\"\n    }\n)\n\nuser = client.generate_content(\n    response_model=User,\n    contents=[\n        {\"role\": \"user\", \"parts\": [\"Extract: John is 25 years old.\"]}\n    ]\n)\n\njson_client = instructor.from_gemini(\n    genai.GenerativeModel(\"gemini-1.5-flash\"),\n    mode=instructor.Mode.GEMINI_JSON\n)\n\nuser = json_client.generate_content(\n    response_model=User,\n    contents=\"Extract: John is 25 years old.\"\n)\n\nimport google.auth\nimport google.auth.transport.requests\nimport instructor\nfrom openai import OpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 50,
          "line_range": [
            50,
            85
          ]
        },
        {
          "code": "# Get Google auth credentials\n",
          "display_code": "",
          "annotation": "Get Google auth credentials",
          "is_comment": true,
          "start_line": 86,
          "line_range": [
            86,
            86
          ],
          "target_line_range": [
            87,
            90
          ]
        },
        {
          "code": "creds, project = google.auth.default()\nauth_req = google.auth.transport.requests.Request()\ncreds.refresh(auth_req)\n\n",
          "display_code": "creds, project = google.auth.default()\nauth_req = google.auth.transport.requests.Request()\ncreds.refresh(auth_req)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 87,
          "line_range": [
            87,
            90
          ]
        },
        {
          "code": "# Configure Vertex AI endpoint\n",
          "display_code": "",
          "annotation": "Configure Vertex AI endpoint",
          "is_comment": true,
          "start_line": 91,
          "line_range": [
            91,
            91
          ],
          "target_line_range": [
            92,
            95
          ]
        },
        {
          "code": "PROJECT = 'your-project-id'\nLOCATION = 'us-central1'  # or your preferred region\nendpoint = f'https://{LOCATION}-aiplatform.googleapis.com/v1beta1/projects/{PROJECT}/locations/{LOCATION}/endpoints/openapi'\n\n",
          "display_code": "PROJECT = 'your-project-id'\nLOCATION = 'us-central1'  # or your preferred region\nendpoint = f'https://{LOCATION}-aiplatform.googleapis.com/v1beta1/projects/{PROJECT}/locations/{LOCATION}/endpoints/openapi'\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 92,
          "line_range": [
            92,
            95
          ]
        },
        {
          "code": "# Create patched OpenAI client pointing to Vertex AI\n",
          "display_code": "",
          "annotation": "Create patched OpenAI client pointing to Vertex AI",
          "is_comment": true,
          "start_line": 96,
          "line_range": [
            96,
            96
          ],
          "target_line_range": [
            97,
            101
          ]
        },
        {
          "code": "client = instructor.from_openai(\n    OpenAI(base_url=endpoint, api_key=creds.token),\n    mode=instructor.Mode.JSON  # JSON mode required\n)\n\n",
          "display_code": "client = instructor.from_openai(\n    OpenAI(base_url=endpoint, api_key=creds.token),\n    mode=instructor.Mode.JSON  # JSON mode required\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 97,
          "line_range": [
            97,
            101
          ]
        },
        {
          "code": "# Use OpenAI-style interface\n",
          "display_code": "",
          "annotation": "Use OpenAI-style interface",
          "is_comment": true,
          "start_line": 102,
          "line_range": [
            102,
            102
          ],
          "target_line_range": [
            103,
            110
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"google/gemini-1.5-flash\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"google/gemini-1.5-flash\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 103,
          "line_range": [
            103,
            110
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "Use Instructor with Google's Gemini models for structured data extraction.",
          "command": "# Install required packages",
          "output": "$ pip install instructor google-generativeai jsonref"
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "002-providers",
      "section_title": "LLM Providers"
    },
    {
      "id": "009-cohere",
      "title": "Cohere Integration",
      "description": "",
      "order": 9,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# \n",
          "display_code": "",
          "annotation": "",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Use Instructor with Cohere's models for structured data extraction.\n# \n# \n# \n# \n# \n# pip install instructor cohere\n# \n",
          "display_code": "",
          "annotation": "Use Instructor with Cohere's models for structured data extraction.\n\n\n\n\n\npip install instructor cohere\n",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            12
          ],
          "target_line_range": [
            13,
            20
          ]
        },
        {
          "code": "import instructor\nimport cohere\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "import instructor\nimport cohere\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 13,
          "line_range": [
            13,
            20
          ]
        },
        {
          "code": "# Create Cohere client\n",
          "display_code": "",
          "annotation": "Create Cohere client",
          "is_comment": true,
          "start_line": 21,
          "line_range": [
            21,
            21
          ],
          "target_line_range": [
            22,
            23
          ]
        },
        {
          "code": "co = cohere.Client(\"YOUR_API_KEY\")  # or set CO_API_KEY env variable\n\n",
          "display_code": "co = cohere.Client(\"YOUR_API_KEY\")  # or set CO_API_KEY env variable\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 22,
          "line_range": [
            22,
            23
          ]
        },
        {
          "code": "# Patch with instructor\n",
          "display_code": "",
          "annotation": "Patch with instructor",
          "is_comment": true,
          "start_line": 24,
          "line_range": [
            24,
            24
          ],
          "target_line_range": [
            25,
            26
          ]
        },
        {
          "code": "client = instructor.from_cohere(co)\n\n",
          "display_code": "client = instructor.from_cohere(co)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 25,
          "line_range": [
            25,
            26
          ]
        },
        {
          "code": "# Using chat method\n",
          "display_code": "",
          "annotation": "Using chat method",
          "is_comment": true,
          "start_line": 27,
          "line_range": [
            27,
            27
          ],
          "target_line_range": [
            28,
            36
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"command-r-plus\",  # or other Cohere models\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nprint(f\"Name: {user.name}, Age: {user.age}\")\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"command-r-plus\",  # or other Cohere models\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nprint(f\"Name: {user.name}, Age: {user.age}\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 28,
          "line_range": [
            28,
            36
          ]
        },
        {
          "code": "# Output: Name: John, Age: 25\n",
          "display_code": "",
          "annotation": "Output: Name: John, Age: 25",
          "is_comment": true,
          "start_line": 37,
          "line_range": [
            37,
            37
          ],
          "target_line_range": [
            38,
            38
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 38,
          "line_range": [
            38,
            38
          ]
        },
        {
          "code": "# Command model\n",
          "display_code": "",
          "annotation": "Command model",
          "is_comment": true,
          "start_line": 39,
          "line_range": [
            39,
            39
          ],
          "target_line_range": [
            40,
            47
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"command\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"command\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 40,
          "line_range": [
            40,
            47
          ]
        },
        {
          "code": "# Command R model\n",
          "display_code": "",
          "annotation": "Command R model",
          "is_comment": true,
          "start_line": 48,
          "line_range": [
            48,
            48
          ],
          "target_line_range": [
            49,
            56
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"command-r\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"command-r\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 49,
          "line_range": [
            49,
            56
          ]
        },
        {
          "code": "# Command R+ model (most capable)\n",
          "display_code": "",
          "annotation": "Command R+ model (most capable)",
          "is_comment": true,
          "start_line": 57,
          "line_range": [
            57,
            57
          ],
          "target_line_range": [
            58,
            93
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"command-r-plus\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"command-r-plus\",\n    temperature=0.2,  # Lower for more consistent results\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"command-r-plus\",\n    response_model=User,\n    preamble=\"You are an expert at extracting structured information.\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"command-r-plus\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hi, I'd like to discuss John who is 25 years old.\"},\n        {\"role\": \"assistant\", \"content\": \"Hello! I'd be happy to discuss John with you.\"},\n        {\"role\": \"user\", \"content\": \"Can you extract his information in a structured format?\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"command-r-plus\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"command-r-plus\",\n    temperature=0.2,  # Lower for more consistent results\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"command-r-plus\",\n    response_model=User,\n    preamble=\"You are an expert at extracting structured information.\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"command-r-plus\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hi, I'd like to discuss John who is 25 years old.\"},\n        {\"role\": \"assistant\", \"content\": \"Hello! I'd be happy to discuss John with you.\"},\n        {\"role\": \"user\", \"content\": \"Can you extract his information in a structured format?\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 58,
          "line_range": [
            58,
            93
          ]
        },
        {
          "code": "# Default JSON mode\n",
          "display_code": "",
          "annotation": "Default JSON mode",
          "is_comment": true,
          "start_line": 94,
          "line_range": [
            94,
            94
          ],
          "target_line_range": [
            95,
            96
          ]
        },
        {
          "code": "client = instructor.from_cohere(co)\n\n",
          "display_code": "client = instructor.from_cohere(co)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 95,
          "line_range": [
            95,
            96
          ]
        },
        {
          "code": "# Explicit JSON mode\n",
          "display_code": "",
          "annotation": "Explicit JSON mode",
          "is_comment": true,
          "start_line": 97,
          "line_range": [
            97,
            97
          ],
          "target_line_range": [
            98,
            102
          ]
        },
        {
          "code": "client = instructor.from_cohere(\n    co,\n    mode=instructor.Mode.JSON\n)\n\n",
          "display_code": "client = instructor.from_cohere(\n    co,\n    mode=instructor.Mode.JSON\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 98,
          "line_range": [
            98,
            102
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "Use Instructor with Cohere's models for structured data extraction.",
          "command": "# Install required packages",
          "output": "$ pip install instructor cohere"
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "002-providers",
      "section_title": "LLM Providers"
    },
    {
      "id": "010-mistral",
      "title": "Mistral Integration",
      "description": "",
      "order": 10,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# \n",
          "display_code": "",
          "annotation": "",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Use Instructor with Mistral AI models for structured data extraction.\n# \n# \n# \n# \n# \n# pip install instructor mistralai\n# \n",
          "display_code": "",
          "annotation": "Use Instructor with Mistral AI models for structured data extraction.\n\n\n\n\n\npip install instructor mistralai\n",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            12
          ],
          "target_line_range": [
            13,
            20
          ]
        },
        {
          "code": "import instructor\nfrom mistralai.client import MistralClient\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "import instructor\nfrom mistralai.client import MistralClient\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 13,
          "line_range": [
            13,
            20
          ]
        },
        {
          "code": "# Create Mistral client\n",
          "display_code": "",
          "annotation": "Create Mistral client",
          "is_comment": true,
          "start_line": 21,
          "line_range": [
            21,
            21
          ],
          "target_line_range": [
            22,
            23
          ]
        },
        {
          "code": "mistral_client = MistralClient(api_key=\"YOUR_API_KEY\")\n\n",
          "display_code": "mistral_client = MistralClient(api_key=\"YOUR_API_KEY\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 22,
          "line_range": [
            22,
            23
          ]
        },
        {
          "code": "# Patch with instructor\n",
          "display_code": "",
          "annotation": "Patch with instructor",
          "is_comment": true,
          "start_line": 24,
          "line_range": [
            24,
            24
          ],
          "target_line_range": [
            25,
            26
          ]
        },
        {
          "code": "client = instructor.from_mistral(mistral_client)\n\n",
          "display_code": "client = instructor.from_mistral(mistral_client)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 25,
          "line_range": [
            25,
            26
          ]
        },
        {
          "code": "# Using chat method\n",
          "display_code": "",
          "annotation": "Using chat method",
          "is_comment": true,
          "start_line": 27,
          "line_range": [
            27,
            27
          ],
          "target_line_range": [
            28,
            36
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"mistral-large-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nprint(f\"Name: {user.name}, Age: {user.age}\")\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"mistral-large-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nprint(f\"Name: {user.name}, Age: {user.age}\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 28,
          "line_range": [
            28,
            36
          ]
        },
        {
          "code": "# Output: Name: John, Age: 25\n",
          "display_code": "",
          "annotation": "Output: Name: John, Age: 25",
          "is_comment": true,
          "start_line": 37,
          "line_range": [
            37,
            37
          ],
          "target_line_range": [
            38,
            38
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 38,
          "line_range": [
            38,
            38
          ]
        },
        {
          "code": "# Mistral Small\n",
          "display_code": "",
          "annotation": "Mistral Small",
          "is_comment": true,
          "start_line": 39,
          "line_range": [
            39,
            39
          ],
          "target_line_range": [
            40,
            47
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"mistral-small-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"mistral-small-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 40,
          "line_range": [
            40,
            47
          ]
        },
        {
          "code": "# Mistral Medium\n",
          "display_code": "",
          "annotation": "Mistral Medium",
          "is_comment": true,
          "start_line": 48,
          "line_range": [
            48,
            48
          ],
          "target_line_range": [
            49,
            56
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"mistral-medium-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"mistral-medium-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 49,
          "line_range": [
            49,
            56
          ]
        },
        {
          "code": "# Mistral Large (most capable)\n",
          "display_code": "",
          "annotation": "Mistral Large (most capable)",
          "is_comment": true,
          "start_line": 57,
          "line_range": [
            57,
            57
          ],
          "target_line_range": [
            58,
            93
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"mistral-large-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"mistral-large-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are an expert at data extraction.\"},\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"mistral-large-latest\",\n    temperature=0.2,  # Lower for more consistent results\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"mistral-large-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hi, I'd like to discuss John who is 25 years old.\"},\n        {\"role\": \"assistant\", \"content\": \"Hello! I'd be happy to discuss John with you.\"},\n        {\"role\": \"user\", \"content\": \"Can you extract his information in a structured format?\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"mistral-large-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"mistral-large-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are an expert at data extraction.\"},\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"mistral-large-latest\",\n    temperature=0.2,  # Lower for more consistent results\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n    ]\n)\n\nuser = client.chat.completions.create(\n    model=\"mistral-large-latest\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hi, I'd like to discuss John who is 25 years old.\"},\n        {\"role\": \"assistant\", \"content\": \"Hello! I'd be happy to discuss John with you.\"},\n        {\"role\": \"user\", \"content\": \"Can you extract his information in a structured format?\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 58,
          "line_range": [
            58,
            93
          ]
        },
        {
          "code": "# Default JSON mode\n",
          "display_code": "",
          "annotation": "Default JSON mode",
          "is_comment": true,
          "start_line": 94,
          "line_range": [
            94,
            94
          ],
          "target_line_range": [
            95,
            96
          ]
        },
        {
          "code": "client = instructor.from_mistral(mistral_client)\n\n",
          "display_code": "client = instructor.from_mistral(mistral_client)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 95,
          "line_range": [
            95,
            96
          ]
        },
        {
          "code": "# Explicit JSON mode\n",
          "display_code": "",
          "annotation": "Explicit JSON mode",
          "is_comment": true,
          "start_line": 97,
          "line_range": [
            97,
            97
          ],
          "target_line_range": [
            98,
            102
          ]
        },
        {
          "code": "client = instructor.from_mistral(\n    mistral_client,\n    mode=instructor.Mode.JSON\n)\n\n",
          "display_code": "client = instructor.from_mistral(\n    mistral_client,\n    mode=instructor.Mode.JSON\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 98,
          "line_range": [
            98,
            102
          ]
        },
        {
          "code": "# Using MD_JSON mode\n",
          "display_code": "",
          "annotation": "Using MD_JSON mode",
          "is_comment": true,
          "start_line": 103,
          "line_range": [
            103,
            103
          ],
          "target_line_range": [
            104,
            126
          ]
        },
        {
          "code": "client = instructor.from_mistral(\n    mistral_client,\n    mode=instructor.Mode.MD_JSON\n)\n\nimport asyncio\nfrom mistralai.async_client import MistralAsyncClient\n\nasync_client = instructor.from_mistral(\n    MistralAsyncClient(api_key=\"YOUR_API_KEY\")\n)\n\nasync def extract_user():\n    return await async_client.chat.completions.create(\n        model=\"mistral-large-latest\",\n        response_model=User,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n        ]\n    )\n\nuser = asyncio.run(extract_user())\n\n",
          "display_code": "client = instructor.from_mistral(\n    mistral_client,\n    mode=instructor.Mode.MD_JSON\n)\n\nimport asyncio\nfrom mistralai.async_client import MistralAsyncClient\n\nasync_client = instructor.from_mistral(\n    MistralAsyncClient(api_key=\"YOUR_API_KEY\")\n)\n\nasync def extract_user():\n    return await async_client.chat.completions.create(\n        model=\"mistral-large-latest\",\n        response_model=User,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Extract: John is 25 years old.\"}\n        ]\n    )\n\nuser = asyncio.run(extract_user())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 104,
          "line_range": [
            104,
            126
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "Use Instructor with Mistral AI models for structured data extraction.",
          "command": "# Install required packages",
          "output": "$ pip install instructor mistralai"
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "002-providers",
      "section_title": "LLM Providers"
    },
    {
      "id": "011-other-providers",
      "title": "Other Provider Integrations",
      "description": "",
      "order": 11,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# \n",
          "display_code": "",
          "annotation": "",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor supports many LLM providers beyond the major ones. Here's a quick overview of some additional providers.\n",
          "display_code": "",
          "annotation": "Instructor supports many LLM providers beyond the major ones. Here's a quick overview of some additional providers.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            13
          ]
        },
        {
          "code": "import instructor\nfrom litellm import completion\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "import instructor\nfrom litellm import completion\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            13
          ]
        },
        {
          "code": "# Patch LiteLLM completion function\n",
          "display_code": "",
          "annotation": "Patch LiteLLM completion function",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            16
          ]
        },
        {
          "code": "client = instructor.from_litellm(completion)\n\n",
          "display_code": "client = instructor.from_litellm(completion)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            16
          ]
        },
        {
          "code": "# Use with any provider supported by LiteLLM\n",
          "display_code": "",
          "annotation": "Use with any provider supported by LiteLLM",
          "is_comment": true,
          "start_line": 17,
          "line_range": [
            17,
            17
          ],
          "target_line_range": [
            18,
            33
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",  # or any other provider/model combination\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\nimport instructor\nfrom pydantic import BaseModel\nfrom vertexai.preview.generative_models import GenerativeModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",  # or any other provider/model combination\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\nimport instructor\nfrom pydantic import BaseModel\nfrom vertexai.preview.generative_models import GenerativeModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 18,
          "line_range": [
            18,
            33
          ]
        },
        {
          "code": "# Create a model\n",
          "display_code": "",
          "annotation": "Create a model",
          "is_comment": true,
          "start_line": 34,
          "line_range": [
            34,
            34
          ],
          "target_line_range": [
            35,
            36
          ]
        },
        {
          "code": "model = GenerativeModel(\"gemini-1.5-flash\")\n\n",
          "display_code": "model = GenerativeModel(\"gemini-1.5-flash\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 35,
          "line_range": [
            35,
            36
          ]
        },
        {
          "code": "# Patch with instructor\n",
          "display_code": "",
          "annotation": "Patch with instructor",
          "is_comment": true,
          "start_line": 37,
          "line_range": [
            37,
            37
          ],
          "target_line_range": [
            38,
            39
          ]
        },
        {
          "code": "client = instructor.from_vertexai(model)\n\n",
          "display_code": "client = instructor.from_vertexai(model)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 38,
          "line_range": [
            38,
            39
          ]
        },
        {
          "code": "# Extract data\n",
          "display_code": "",
          "annotation": "Extract data",
          "is_comment": true,
          "start_line": 40,
          "line_range": [
            40,
            40
          ],
          "target_line_range": [
            41,
            53
          ]
        },
        {
          "code": "user = client.generate_content(\n    response_model=User,\n    contents=\"Extract the user info: John is 25 years old.\"\n)\n\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "user = client.generate_content(\n    response_model=User,\n    contents=\"Extract the user info: John is 25 years old.\"\n)\n\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 41,
          "line_range": [
            41,
            53
          ]
        },
        {
          "code": "# Create OpenAI client with Perplexity base URL\n",
          "display_code": "",
          "annotation": "Create OpenAI client with Perplexity base URL",
          "is_comment": true,
          "start_line": 54,
          "line_range": [
            54,
            54
          ],
          "target_line_range": [
            55,
            58
          ]
        },
        {
          "code": "client = instructor.from_perplexity(\n    OpenAI(base_url=\"https://api.perplexity.ai\", api_key=\"YOUR_API_KEY\")\n)\n\n",
          "display_code": "client = instructor.from_perplexity(\n    OpenAI(base_url=\"https://api.perplexity.ai\", api_key=\"YOUR_API_KEY\")\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 55,
          "line_range": [
            55,
            58
          ]
        },
        {
          "code": "# Extract data\n",
          "display_code": "",
          "annotation": "Extract data",
          "is_comment": true,
          "start_line": 59,
          "line_range": [
            59,
            59
          ],
          "target_line_range": [
            60,
            75
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"sonar\",  # or other Perplexity models\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"sonar\",  # or other Perplexity models\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 60,
          "line_range": [
            60,
            75
          ]
        },
        {
          "code": "# Create OpenAI client with Fireworks base URL\n",
          "display_code": "",
          "annotation": "Create OpenAI client with Fireworks base URL",
          "is_comment": true,
          "start_line": 76,
          "line_range": [
            76,
            76
          ],
          "target_line_range": [
            77,
            80
          ]
        },
        {
          "code": "client = instructor.from_fireworks(\n    OpenAI(base_url=\"https://api.fireworks.ai/inference/v1\", api_key=\"YOUR_API_KEY\")\n)\n\n",
          "display_code": "client = instructor.from_fireworks(\n    OpenAI(base_url=\"https://api.fireworks.ai/inference/v1\", api_key=\"YOUR_API_KEY\")\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 77,
          "line_range": [
            77,
            80
          ]
        },
        {
          "code": "# Extract data\n",
          "display_code": "",
          "annotation": "Extract data",
          "is_comment": true,
          "start_line": 81,
          "line_range": [
            81,
            81
          ],
          "target_line_range": [
            82,
            97
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"accounts/fireworks/models/mixtral-8x7b-instruct\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"accounts/fireworks/models/mixtral-8x7b-instruct\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 82,
          "line_range": [
            82,
            97
          ]
        },
        {
          "code": "# Create OpenAI client with Anyscale base URL\n",
          "display_code": "",
          "annotation": "Create OpenAI client with Anyscale base URL",
          "is_comment": true,
          "start_line": 98,
          "line_range": [
            98,
            98
          ],
          "target_line_range": [
            99,
            102
          ]
        },
        {
          "code": "client = instructor.from_anyscale(\n    OpenAI(base_url=\"https://api.endpoints.anyscale.com/v1\", api_key=\"YOUR_API_KEY\")\n)\n\n",
          "display_code": "client = instructor.from_anyscale(\n    OpenAI(base_url=\"https://api.endpoints.anyscale.com/v1\", api_key=\"YOUR_API_KEY\")\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 99,
          "line_range": [
            99,
            102
          ]
        },
        {
          "code": "# Extract data\n",
          "display_code": "",
          "annotation": "Extract data",
          "is_comment": true,
          "start_line": 103,
          "line_range": [
            103,
            103
          ],
          "target_line_range": [
            104,
            119
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"meta-llama/Llama-3-8b-instruct\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"meta-llama/Llama-3-8b-instruct\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 104,
          "line_range": [
            104,
            119
          ]
        },
        {
          "code": "# Create OpenAI client with Together base URL\n",
          "display_code": "",
          "annotation": "Create OpenAI client with Together base URL",
          "is_comment": true,
          "start_line": 120,
          "line_range": [
            120,
            120
          ],
          "target_line_range": [
            121,
            124
          ]
        },
        {
          "code": "client = instructor.from_together(\n    OpenAI(base_url=\"https://api.together.xyz/v1\", api_key=\"YOUR_API_KEY\")\n)\n\n",
          "display_code": "client = instructor.from_together(\n    OpenAI(base_url=\"https://api.together.xyz/v1\", api_key=\"YOUR_API_KEY\")\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 121,
          "line_range": [
            121,
            124
          ]
        },
        {
          "code": "# Extract data\n",
          "display_code": "",
          "annotation": "Extract data",
          "is_comment": true,
          "start_line": 125,
          "line_range": [
            125,
            125
          ],
          "target_line_range": [
            126,
            141
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"togethercomputer/llama-3-8b-instructk\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"togethercomputer/llama-3-8b-instructk\",\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 126,
          "line_range": [
            126,
            141
          ]
        },
        {
          "code": "# Create OpenAI client with OpenRouter base URL\n",
          "display_code": "",
          "annotation": "Create OpenAI client with OpenRouter base URL",
          "is_comment": true,
          "start_line": 142,
          "line_range": [
            142,
            142
          ],
          "target_line_range": [
            143,
            146
          ]
        },
        {
          "code": "client = instructor.from_openrouter(\n    OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=\"YOUR_API_KEY\")\n)\n\n",
          "display_code": "client = instructor.from_openrouter(\n    OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=\"YOUR_API_KEY\")\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 143,
          "line_range": [
            143,
            146
          ]
        },
        {
          "code": "# Extract data - access to many models\n",
          "display_code": "",
          "annotation": "Extract data - access to many models",
          "is_comment": true,
          "start_line": 147,
          "line_range": [
            147,
            147
          ],
          "target_line_range": [
            148,
            155
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"google/gemma-7b-instruct\", # Or any other model on OpenRouter\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"google/gemma-7b-instruct\", # Or any other model on OpenRouter\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John is 25 years old.\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 148,
          "line_range": [
            148,
            155
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python other-providers.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "002-providers",
      "section_title": "LLM Providers"
    },
    {
      "id": "012-simple-object",
      "title": "Simple Object Extraction",
      "description": "",
      "order": 12,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# \n",
          "display_code": "",
          "annotation": "",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Extract basic objects from text with Instructor.\n",
          "display_code": "",
          "annotation": "Extract basic objects from text with Instructor.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            15
          ]
        },
        {
          "code": "from pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\nimport instructor\nfrom openai import OpenAI\n\n",
          "display_code": "from pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\nimport instructor\nfrom openai import OpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            15
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 16,
          "line_range": [
            16,
            16
          ],
          "target_line_range": [
            17,
            18
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 17,
          "line_range": [
            17,
            18
          ]
        },
        {
          "code": "# Extract the data\n",
          "display_code": "",
          "annotation": "Extract the data",
          "is_comment": true,
          "start_line": 19,
          "line_range": [
            19,
            19
          ],
          "target_line_range": [
            20,
            31
          ]
        },
        {
          "code": "person = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John Doe is a 30-year-old software engineer.\"}\n    ]\n)\n\nprint(f\"Name: {person.name}\")\nprint(f\"Age: {person.age}\")\nprint(f\"Occupation: {person.occupation}\")\n\n",
          "display_code": "person = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John Doe is a 30-year-old software engineer.\"}\n    ]\n)\n\nprint(f\"Name: {person.name}\")\nprint(f\"Age: {person.age}\")\nprint(f\"Occupation: {person.occupation}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 20,
          "line_range": [
            20,
            31
          ]
        },
        {
          "code": "# Output:\n# Name: John Doe\n# Age: 30\n# Occupation: software engineer\n",
          "display_code": "",
          "annotation": "Output:\nName: John Doe\nAge: 30\nOccupation: software engineer",
          "is_comment": true,
          "start_line": 32,
          "line_range": [
            32,
            35
          ],
          "target_line_range": [
            36,
            52
          ]
        },
        {
          "code": "\nextracted = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        In our company blog post, we want to highlight one of our newest team members.\n        John Smith joined us last month. He's 34 years old and works as a data scientist.\n        John previously worked at TechCorp for 5 years.\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {extracted.name}\")\nprint(f\"Age: {extracted.age}\")\nprint(f\"Occupation: {extracted.occupation}\")\n\n",
          "display_code": "\nextracted = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        In our company blog post, we want to highlight one of our newest team members.\n        John Smith joined us last month. He's 34 years old and works as a data scientist.\n        John previously worked at TechCorp for 5 years.\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {extracted.name}\")\nprint(f\"Age: {extracted.age}\")\nprint(f\"Occupation: {extracted.occupation}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 36,
          "line_range": [
            36,
            52
          ]
        },
        {
          "code": "# Output:\n# Name: John Smith\n# Age: 34\n# Occupation: data scientist\n",
          "display_code": "",
          "annotation": "Output:\nName: John Smith\nAge: 34\nOccupation: data scientist",
          "is_comment": true,
          "start_line": 53,
          "line_range": [
            53,
            56
          ],
          "target_line_range": [
            57,
            80
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field\n\nclass Person(BaseModel):\n    name: str = Field(description=\"The person's full name\")\n    age: int = Field(description=\"The person's age in years\")\n    occupation: str = Field(description=\"The person's current job title or role\")\n\nextracted = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Meet Sarah Johnson, one of our senior architects.\n        She's been with the firm since she was 28, and now at 42,\n        she leads our sustainable design initiatives.\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {extracted.name}\")\nprint(f\"Age: {extracted.age}\")\nprint(f\"Occupation: {extracted.occupation}\")\n\n",
          "display_code": "\nfrom pydantic import BaseModel, Field\n\nclass Person(BaseModel):\n    name: str = Field(description=\"The person's full name\")\n    age: int = Field(description=\"The person's age in years\")\n    occupation: str = Field(description=\"The person's current job title or role\")\n\nextracted = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Meet Sarah Johnson, one of our senior architects.\n        She's been with the firm since she was 28, and now at 42,\n        she leads our sustainable design initiatives.\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {extracted.name}\")\nprint(f\"Age: {extracted.age}\")\nprint(f\"Occupation: {extracted.occupation}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 57,
          "line_range": [
            57,
            80
          ]
        },
        {
          "code": "# Output:\n# Name: Sarah Johnson\n# Age: 42\n# Occupation: senior architect\n",
          "display_code": "",
          "annotation": "Output:\nName: Sarah Johnson\nAge: 42\nOccupation: senior architect",
          "is_comment": true,
          "start_line": 81,
          "line_range": [
            81,
            84
          ],
          "target_line_range": [
            85,
            108
          ]
        },
        {
          "code": "\nclass Employee(BaseModel):\n    \"\"\"Extract employee information from the provided text.\"\"\"\n\n    name: str\n    age: int\n    department: str\n    years_of_service: int\n\nextracted = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Employee,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Employee Profile: Michael Chen has been in our Marketing department for 7 years.\n        He's 36 years old and has led multiple successful campaigns.\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {extracted.name}\")\nprint(f\"Department: {extracted.department}\")\nprint(f\"Years of Service: {extracted.years_of_service}\")\n\n",
          "display_code": "\nclass Employee(BaseModel):\n    \"\"\"Extract employee information from the provided text.\"\"\"\n\n    name: str\n    age: int\n    department: str\n    years_of_service: int\n\nextracted = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Employee,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Employee Profile: Michael Chen has been in our Marketing department for 7 years.\n        He's 36 years old and has led multiple successful campaigns.\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {extracted.name}\")\nprint(f\"Department: {extracted.department}\")\nprint(f\"Years of Service: {extracted.years_of_service}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 85,
          "line_range": [
            85,
            108
          ]
        },
        {
          "code": "# Output:\n# Name: Michael Chen\n# Department: Marketing\n# Years of Service: 7\n",
          "display_code": "",
          "annotation": "Output:\nName: Michael Chen\nDepartment: Marketing\nYears of Service: 7",
          "is_comment": true,
          "start_line": 109,
          "line_range": [
            109,
            112
          ],
          "target_line_range": [
            113,
            113
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 113,
          "line_range": [
            113,
            113
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python simple-object.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "003-basic-extraction",
      "section_title": "Basic Extraction Patterns"
    },
    {
      "id": "013-list-extraction",
      "title": "List Extraction",
      "description": "",
      "order": 13,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# \n",
          "display_code": "",
          "annotation": "",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Extract multiple items in a list from text with Instructor.\n",
          "display_code": "",
          "annotation": "Extract multiple items in a list from text with Instructor.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            15
          ]
        },
        {
          "code": "from pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n\nimport instructor\nfrom openai import OpenAI\nfrom typing import List\n\n",
          "display_code": "from pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n\nimport instructor\nfrom openai import OpenAI\nfrom typing import List\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            15
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 16,
          "line_range": [
            16,
            16
          ],
          "target_line_range": [
            17,
            18
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 17,
          "line_range": [
            17,
            18
          ]
        },
        {
          "code": "# Extract a list of people\n",
          "display_code": "",
          "annotation": "Extract a list of people",
          "is_comment": true,
          "start_line": 19,
          "line_range": [
            19,
            19
          ],
          "target_line_range": [
            20,
            32
          ]
        },
        {
          "code": "people = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=List[Person],  # Note the List wrapper\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Extract all people mentioned in this text:\n        - John is 30 years old\n        - Mary is 25 years old\n        - Bob is 45 years old\n        \"\"\"}\n    ]\n)\n\n",
          "display_code": "people = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=List[Person],  # Note the List wrapper\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Extract all people mentioned in this text:\n        - John is 30 years old\n        - Mary is 25 years old\n        - Bob is 45 years old\n        \"\"\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 20,
          "line_range": [
            20,
            32
          ]
        },
        {
          "code": "# Print each person\n",
          "display_code": "",
          "annotation": "Print each person",
          "is_comment": true,
          "start_line": 33,
          "line_range": [
            33,
            33
          ],
          "target_line_range": [
            34,
            36
          ]
        },
        {
          "code": "for person in people:\n    print(f\"{person.name} is {person.age} years old\")\n\n",
          "display_code": "for person in people:\n    print(f\"{person.name} is {person.age} years old\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 34,
          "line_range": [
            34,
            36
          ]
        },
        {
          "code": "# Output:\n# John is 30 years old\n# Mary is 25 years old\n# Bob is 45 years old\n",
          "display_code": "",
          "annotation": "Output:\nJohn is 30 years old\nMary is 25 years old\nBob is 45 years old",
          "is_comment": true,
          "start_line": 37,
          "line_range": [
            37,
            40
          ],
          "target_line_range": [
            41,
            56
          ]
        },
        {
          "code": "\npeople = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=List[Person],\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Our team has grown significantly this year. John Smith, who is 32, joined our\n        engineering department. We also welcomed Sarah Johnson, 28, to our design team.\n        The most recent addition is Michael Chen, who is 35 and brings valuable experience.\n        \"\"\"}\n    ]\n)\n\nfor i, person in enumerate(people, 1):\n    print(f\"Person {i}: {person.name}, {person.age}\")\n\n",
          "display_code": "\npeople = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=List[Person],\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Our team has grown significantly this year. John Smith, who is 32, joined our\n        engineering department. We also welcomed Sarah Johnson, 28, to our design team.\n        The most recent addition is Michael Chen, who is 35 and brings valuable experience.\n        \"\"\"}\n    ]\n)\n\nfor i, person in enumerate(people, 1):\n    print(f\"Person {i}: {person.name}, {person.age}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 41,
          "line_range": [
            41,
            56
          ]
        },
        {
          "code": "# Output:\n# Person 1: John Smith, 32\n# Person 2: Sarah Johnson, 28\n# Person 3: Michael Chen, 35\n",
          "display_code": "",
          "annotation": "Output:\nPerson 1: John Smith, 32\nPerson 2: Sarah Johnson, 28\nPerson 3: Michael Chen, 35",
          "is_comment": true,
          "start_line": 57,
          "line_range": [
            57,
            60
          ],
          "target_line_range": [
            61,
            110
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    state: Optional[str] = None\n    country: str\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str = Field(description=\"The person's job or profession\")\n    addresses: List[Address] = Field(description=\"List of addresses associated with this person\")\n\npeople = client.chat.completions.create(\n    model=\"gpt-4\",  # More complex extraction works better with more capable models\n    response_model=List[Person],\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Our company employees include:\n\n        1. John Smith is a 34-year-old software developer who lives at 123 Main St, Boston, USA\n           and has a vacation home at 456 Beach Road, Miami, USA.\n\n        2. Maria Garcia is 29 and works as a marketing specialist. She lives at\n           78 Park Avenue, New York, USA.\n\n        3. Ahmed Hassan, 41, is our senior data scientist who recently moved from\n           555 River St, Cairo, Egypt to 890 Tech Blvd, San Francisco, USA.\n        \"\"\"}\n    ]\n)\n\nfor person in people:\n    print(f\"{person.name}, {person.age} - {person.occupation}\")\n    for i, addr in enumerate(person.addresses, 1):\n        print(f\"  Address {i}: {addr.street}, {addr.city}, {addr.country}\")\n    print()\n\nimport instructor\nfrom openai import OpenAI\nfrom typing import List\nfrom pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    state: Optional[str] = None\n    country: str\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str = Field(description=\"The person's job or profession\")\n    addresses: List[Address] = Field(description=\"List of addresses associated with this person\")\n\npeople = client.chat.completions.create(\n    model=\"gpt-4\",  # More complex extraction works better with more capable models\n    response_model=List[Person],\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Our company employees include:\n\n        1. John Smith is a 34-year-old software developer who lives at 123 Main St, Boston, USA\n           and has a vacation home at 456 Beach Road, Miami, USA.\n\n        2. Maria Garcia is 29 and works as a marketing specialist. She lives at\n           78 Park Avenue, New York, USA.\n\n        3. Ahmed Hassan, 41, is our senior data scientist who recently moved from\n           555 River St, Cairo, Egypt to 890 Tech Blvd, San Francisco, USA.\n        \"\"\"}\n    ]\n)\n\nfor person in people:\n    print(f\"{person.name}, {person.age} - {person.occupation}\")\n    for i, addr in enumerate(person.addresses, 1):\n        print(f\"  Address {i}: {addr.street}, {addr.city}, {addr.country}\")\n    print()\n\nimport instructor\nfrom openai import OpenAI\nfrom typing import List\nfrom pydantic import BaseModel\n\nclass Person(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 61,
          "line_range": [
            61,
            110
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 111,
          "line_range": [
            111,
            111
          ],
          "target_line_range": [
            112,
            113
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 112,
          "line_range": [
            112,
            113
          ]
        },
        {
          "code": "# Extract with streaming using create_iterable\n",
          "display_code": "",
          "annotation": "Extract with streaming using create_iterable",
          "is_comment": true,
          "start_line": 114,
          "line_range": [
            114,
            114
          ],
          "target_line_range": [
            115,
            127
          ]
        },
        {
          "code": "people_stream = client.chat.completions.create_iterable(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,  # Note: no List wrapper here\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Extract all people mentioned in this text:\n        - John is 30 years old\n        - Mary is 25 years old\n        - Bob is 45 years old\n        \"\"\"}\n    ]\n)\n\n",
          "display_code": "people_stream = client.chat.completions.create_iterable(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,  # Note: no List wrapper here\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Extract all people mentioned in this text:\n        - John is 30 years old\n        - Mary is 25 years old\n        - Bob is 45 years old\n        \"\"\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 115,
          "line_range": [
            115,
            127
          ]
        },
        {
          "code": "# Process each item as it's completed\n",
          "display_code": "",
          "annotation": "Process each item as it's completed",
          "is_comment": true,
          "start_line": 128,
          "line_range": [
            128,
            128
          ],
          "target_line_range": [
            129,
            131
          ]
        },
        {
          "code": "for person in people_stream:\n    print(f\"Received: {person.name} is {person.age} years old\")\n\n",
          "display_code": "for person in people_stream:\n    print(f\"Received: {person.name} is {person.age} years old\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 129,
          "line_range": [
            129,
            131
          ]
        },
        {
          "code": "# Output will appear one at a time as each is completed:\n# Received: John is 30 years old\n# Received: Mary is 25 years old\n# Received: Bob is 45 years old\n",
          "display_code": "",
          "annotation": "Output will appear one at a time as each is completed:\nReceived: John is 30 years old\nReceived: Mary is 25 years old\nReceived: Bob is 45 years old",
          "is_comment": true,
          "start_line": 132,
          "line_range": [
            132,
            135
          ],
          "target_line_range": [
            136,
            136
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 136,
          "line_range": [
            136,
            136
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python list-extraction.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "003-basic-extraction",
      "section_title": "Basic Extraction Patterns"
    },
    {
      "id": "014-nested-structures",
      "title": "Nested Structures",
      "description": "",
      "order": 14,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# \n",
          "display_code": "",
          "annotation": "",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Extract complex nested data structures from text using Instructor.\n",
          "display_code": "",
          "annotation": "Extract complex nested data structures from text using Instructor.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            29
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    state: Optional[str] = None\n    zip_code: Optional[str] = None\n    country: str\n\nclass PhoneNumber(BaseModel):\n    number: str\n    type: str  # e.g., \"home\", \"work\", \"mobile\"\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    addresses: List[Address]\n    phone_numbers: List[PhoneNumber]\n    email: Optional[str] = None\n\nimport instructor\nfrom openai import OpenAI\n\n",
          "display_code": "from pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    state: Optional[str] = None\n    zip_code: Optional[str] = None\n    country: str\n\nclass PhoneNumber(BaseModel):\n    number: str\n    type: str  # e.g., \"home\", \"work\", \"mobile\"\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    addresses: List[Address]\n    phone_numbers: List[PhoneNumber]\n    email: Optional[str] = None\n\nimport instructor\nfrom openai import OpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            29
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 30,
          "line_range": [
            30,
            30
          ],
          "target_line_range": [
            31,
            32
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 31,
          "line_range": [
            31,
            32
          ]
        },
        {
          "code": "# Extract nested data\n",
          "display_code": "",
          "annotation": "Extract nested data",
          "is_comment": true,
          "start_line": 33,
          "line_range": [
            33,
            33
          ],
          "target_line_range": [
            34,
            91
          ]
        },
        {
          "code": "person = client.chat.completions.create(\n    model=\"gpt-4\",  # Complex extraction works better with more capable models\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        John Smith is a 35-year-old professional. He has two addresses:\n        1. Home: 123 Main St, Austin, TX 78701, USA\n        2. Work: 456 Business Ave, Austin, TX 78702, USA\n\n        His phone numbers are:\n        - Mobile: (555) 123-4567\n        - Work: (555) 987-6543\n\n        You can reach him at john.smith@example.com\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {person.name}, Age: {person.age}\")\nprint(f\"Email: {person.email}\")\n\nprint(\"\\nAddresses:\")\nfor i, address in enumerate(person.addresses, 1):\n    print(f\"  {i}. {address.street}, {address.city}, {address.state} {address.zip_code}, {address.country}\")\n\nprint(\"\\nPhone Numbers:\")\nfor phone in person.phone_numbers:\n    print(f\"  {phone.type}: {phone.number}\")\n\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional, Dict\n\nclass Skill(BaseModel):\n    name: str\n    level: str  # e.g., \"beginner\", \"intermediate\", \"expert\"\n    years_of_experience: int\n\nclass Education(BaseModel):\n    degree: str\n    institution: str\n    year: int\n\nclass WorkExperience(BaseModel):\n    company: str\n    position: str\n    start_year: int\n    end_year: Optional[int] = None\n    is_current: bool\n    responsibilities: List[str]\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    skills: List[Skill]\n    education: List[Education]\n    work_experience: List[WorkExperience]\n    contact_info: Dict[str, str]  # e.g., \"email\", \"phone\", \"linkedin\"\n\n",
          "display_code": "person = client.chat.completions.create(\n    model=\"gpt-4\",  # Complex extraction works better with more capable models\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        John Smith is a 35-year-old professional. He has two addresses:\n        1. Home: 123 Main St, Austin, TX 78701, USA\n        2. Work: 456 Business Ave, Austin, TX 78702, USA\n\n        His phone numbers are:\n        - Mobile: (555) 123-4567\n        - Work: (555) 987-6543\n\n        You can reach him at john.smith@example.com\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {person.name}, Age: {person.age}\")\nprint(f\"Email: {person.email}\")\n\nprint(\"\\nAddresses:\")\nfor i, address in enumerate(person.addresses, 1):\n    print(f\"  {i}. {address.street}, {address.city}, {address.state} {address.zip_code}, {address.country}\")\n\nprint(\"\\nPhone Numbers:\")\nfor phone in person.phone_numbers:\n    print(f\"  {phone.type}: {phone.number}\")\n\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional, Dict\n\nclass Skill(BaseModel):\n    name: str\n    level: str  # e.g., \"beginner\", \"intermediate\", \"expert\"\n    years_of_experience: int\n\nclass Education(BaseModel):\n    degree: str\n    institution: str\n    year: int\n\nclass WorkExperience(BaseModel):\n    company: str\n    position: str\n    start_year: int\n    end_year: Optional[int] = None\n    is_current: bool\n    responsibilities: List[str]\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    skills: List[Skill]\n    education: List[Education]\n    work_experience: List[WorkExperience]\n    contact_info: Dict[str, str]  # e.g., \"email\", \"phone\", \"linkedin\"\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 34,
          "line_range": [
            34,
            91
          ]
        },
        {
          "code": "# Extract with a more capable model\n",
          "display_code": "",
          "annotation": "Extract with a more capable model",
          "is_comment": true,
          "start_line": 92,
          "line_range": [
            92,
            92
          ],
          "target_line_range": [
            93,
            165
          ]
        },
        {
          "code": "person = client.chat.completions.create(\n    model=\"gpt-4\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Resume: Sarah Johnson\n\n        Sarah is a 42-year-old software architect with 15 years in the industry.\n\n        Contact Information:\n        - Email: sarah.j@example.com\n        - Phone: (555) 234-5678\n        - LinkedIn: linkedin.com/in/sarahjohnson\n\n        Skills:\n        - Python (Expert, 12 years)\n        - JavaScript (Intermediate, 8 years)\n        - Cloud Architecture (Expert, 7 years)\n\n        Education:\n        - Master's in Computer Science, Stanford University, 2008\n        - Bachelor's in Software Engineering, MIT, 2006\n\n        Work Experience:\n        - TechCorp Inc.\n          Senior Software Architect\n          2018-Present\n          Responsibilities:\n          * Lead architecture design for cloud solutions\n          * Manage team of 12 developers\n          * Implement CI/CD pipelines\n\n        - DataSystems LLC\n          Software Developer\n          2012-2018\n          Responsibilities:\n          * Developed backend services in Python\n          * Optimized database performance\n          * Created RESTful APIs\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {person.name}, Age: {person.age}\")\n\nprint(\"\\nContact Info:\")\nfor key, value in person.contact_info.items():\n    print(f\"  {key}: {value}\")\n\nprint(\"\\nSkills:\")\nfor skill in person.skills:\n    print(f\"  {skill.name}: {skill.level} ({skill.years_of_experience} years)\")\n\nprint(\"\\nEducation:\")\nfor edu in person.education:\n    print(f\"  {edu.degree}, {edu.institution}, {edu.year}\")\n\nprint(\"\\nWork Experience:\")\nfor job in person.work_experience:\n    current = \"(Current)\" if job.is_current else f\"({job.start_year}-{job.end_year})\"\n    print(f\"  {job.position} at {job.company} {current}\")\n    print(\"  Responsibilities:\")\n    for resp in job.responsibilities:\n        print(f\"    - {resp}\")\n\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass Comment(BaseModel):\n    text: str\n    author: str\n    replies: List['Comment'] = []\n\n",
          "display_code": "person = client.chat.completions.create(\n    model=\"gpt-4\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Resume: Sarah Johnson\n\n        Sarah is a 42-year-old software architect with 15 years in the industry.\n\n        Contact Information:\n        - Email: sarah.j@example.com\n        - Phone: (555) 234-5678\n        - LinkedIn: linkedin.com/in/sarahjohnson\n\n        Skills:\n        - Python (Expert, 12 years)\n        - JavaScript (Intermediate, 8 years)\n        - Cloud Architecture (Expert, 7 years)\n\n        Education:\n        - Master's in Computer Science, Stanford University, 2008\n        - Bachelor's in Software Engineering, MIT, 2006\n\n        Work Experience:\n        - TechCorp Inc.\n          Senior Software Architect\n          2018-Present\n          Responsibilities:\n          * Lead architecture design for cloud solutions\n          * Manage team of 12 developers\n          * Implement CI/CD pipelines\n\n        - DataSystems LLC\n          Software Developer\n          2012-2018\n          Responsibilities:\n          * Developed backend services in Python\n          * Optimized database performance\n          * Created RESTful APIs\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {person.name}, Age: {person.age}\")\n\nprint(\"\\nContact Info:\")\nfor key, value in person.contact_info.items():\n    print(f\"  {key}: {value}\")\n\nprint(\"\\nSkills:\")\nfor skill in person.skills:\n    print(f\"  {skill.name}: {skill.level} ({skill.years_of_experience} years)\")\n\nprint(\"\\nEducation:\")\nfor edu in person.education:\n    print(f\"  {edu.degree}, {edu.institution}, {edu.year}\")\n\nprint(\"\\nWork Experience:\")\nfor job in person.work_experience:\n    current = \"(Current)\" if job.is_current else f\"({job.start_year}-{job.end_year})\"\n    print(f\"  {job.position} at {job.company} {current}\")\n    print(\"  Responsibilities:\")\n    for resp in job.responsibilities:\n        print(f\"    - {resp}\")\n\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass Comment(BaseModel):\n    text: str\n    author: str\n    replies: List['Comment'] = []\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 93,
          "line_range": [
            93,
            165
          ]
        },
        {
          "code": "# This is needed for recursive Pydantic models\n",
          "display_code": "",
          "annotation": "This is needed for recursive Pydantic models",
          "is_comment": true,
          "start_line": 166,
          "line_range": [
            166,
            166
          ],
          "target_line_range": [
            167,
            174
          ]
        },
        {
          "code": "Comment.model_rebuild()\n\nclass Post(BaseModel):\n    title: str\n    content: str\n    author: str\n    comments: List[Comment]\n\n",
          "display_code": "Comment.model_rebuild()\n\nclass Post(BaseModel):\n    title: str\n    content: str\n    author: str\n    comments: List[Comment]\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 167,
          "line_range": [
            167,
            174
          ]
        },
        {
          "code": "# Extract recursive structure\n",
          "display_code": "",
          "annotation": "Extract recursive structure",
          "is_comment": true,
          "start_line": 175,
          "line_range": [
            175,
            175
          ],
          "target_line_range": [
            176,
            210
          ]
        },
        {
          "code": "post = client.chat.completions.create(\n    model=\"gpt-4\",\n    response_model=Post,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Blog Post: \"Python Tips and Tricks\"\n        By: JohnDev\n\n        Python has many features that make it a versatile language. Here are some tips to improve your code...\n\n        Comments:\n        1. Comment by Alice: \"Great post! I especially liked the section on list comprehensions.\"\n          - Reply by JohnDev: \"Thanks Alice! Glad you found it useful.\"\n            - Reply by Bob: \"List comprehensions are my favorite too!\"\n               - Reply by Alice: \"They're so elegant compared to traditional loops.\"\n\n        2. Comment by Charlie: \"Could you do a follow-up on decorators?\"\n          - Reply by JohnDev: \"Great idea! I'll add it to my list of topics.\"\n        \"\"\"}\n    ]\n)\n\nprint(f\"Post: {post.title} by {post.author}\")\n\nfor i, comment in enumerate(post.comments, 1):\n    print(f\"\\nTop-level Comment {i}: {comment.author} said: '{comment.text}'\")\n\n    def print_replies(replies, indent=2):\n        for reply in replies:\n            print(f\"{'  ' * indent}{reply.author} replied: '{reply.text}'\")\n            if reply.replies:\n                print_replies(reply.replies, indent + 1)\n\n    print_replies(comment.replies)\n\n",
          "display_code": "post = client.chat.completions.create(\n    model=\"gpt-4\",\n    response_model=Post,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Blog Post: \"Python Tips and Tricks\"\n        By: JohnDev\n\n        Python has many features that make it a versatile language. Here are some tips to improve your code...\n\n        Comments:\n        1. Comment by Alice: \"Great post! I especially liked the section on list comprehensions.\"\n          - Reply by JohnDev: \"Thanks Alice! Glad you found it useful.\"\n            - Reply by Bob: \"List comprehensions are my favorite too!\"\n               - Reply by Alice: \"They're so elegant compared to traditional loops.\"\n\n        2. Comment by Charlie: \"Could you do a follow-up on decorators?\"\n          - Reply by JohnDev: \"Great idea! I'll add it to my list of topics.\"\n        \"\"\"}\n    ]\n)\n\nprint(f\"Post: {post.title} by {post.author}\")\n\nfor i, comment in enumerate(post.comments, 1):\n    print(f\"\\nTop-level Comment {i}: {comment.author} said: '{comment.text}'\")\n\n    def print_replies(replies, indent=2):\n        for reply in replies:\n            print(f\"{'  ' * indent}{reply.author} replied: '{reply.text}'\")\n            if reply.replies:\n                print_replies(reply.replies, indent + 1)\n\n    print_replies(comment.replies)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 176,
          "line_range": [
            176,
            210
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python nested-structures.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "003-basic-extraction",
      "section_title": "Basic Extraction Patterns"
    },
    {
      "id": "015-field-validation",
      "title": "Field Validation",
      "description": "",
      "order": 15,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# \n",
          "display_code": "",
          "annotation": "",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Apply validation rules to ensure high-quality data extraction with Instructor.\n",
          "display_code": "",
          "annotation": "Apply validation rules to ensure high-quality data extraction with Instructor.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            9
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\n\n",
          "display_code": "from pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            9
          ]
        },
        {
          "code": "# Define a model with validation rules\n",
          "display_code": "",
          "annotation": "Define a model with validation rules",
          "is_comment": true,
          "start_line": 10,
          "line_range": [
            10,
            10
          ],
          "target_line_range": [
            11,
            16
          ]
        },
        {
          "code": "class Product(BaseModel):\n    name: str = Field(min_length=3, max_length=50)\n    price: float = Field(gt=0)  # must be greater than 0\n    quantity: int = Field(ge=0)  # must be greater than or equal to 0\n    category: str\n\n",
          "display_code": "class Product(BaseModel):\n    name: str = Field(min_length=3, max_length=50)\n    price: float = Field(gt=0)  # must be greater than 0\n    quantity: int = Field(ge=0)  # must be greater than or equal to 0\n    category: str\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 11,
          "line_range": [
            11,
            16
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 17,
          "line_range": [
            17,
            17
          ],
          "target_line_range": [
            18,
            19
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 18,
          "line_range": [
            18,
            19
          ]
        },
        {
          "code": "# Extract with validation\n",
          "display_code": "",
          "annotation": "Extract with validation",
          "is_comment": true,
          "start_line": 20,
          "line_range": [
            20,
            20
          ],
          "target_line_range": [
            21,
            42
          ]
        },
        {
          "code": "product = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Product,\n    messages=[\n        {\"role\": \"user\", \"content\": \"We sell a premium coffee mug for $12.99 and have 25 in stock in our kitchen category.\"}\n    ]\n)\n\nprint(f\"Name: {product.name}\")\nprint(f\"Price: ${product.price}\")\nprint(f\"Quantity: {product.quantity}\")\nprint(f\"Category: {product.category}\")\n\nfrom pydantic import BaseModel, Field\n\nclass PersonStats(BaseModel):\n    name: str\n    age: int = Field(ge=0, lt=120)  # 0 \u2264 age < 120\n    height: float = Field(gt=0, le=300)  # 0 < height \u2264 300 (cm)\n    weight: float = Field(gt=0, le=500)  # 0 < weight \u2264 500 (kg)\n    body_temperature: float = Field(ge=35, le=42)  # normal human range in Celsius\n\n",
          "display_code": "product = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Product,\n    messages=[\n        {\"role\": \"user\", \"content\": \"We sell a premium coffee mug for $12.99 and have 25 in stock in our kitchen category.\"}\n    ]\n)\n\nprint(f\"Name: {product.name}\")\nprint(f\"Price: ${product.price}\")\nprint(f\"Quantity: {product.quantity}\")\nprint(f\"Category: {product.category}\")\n\nfrom pydantic import BaseModel, Field\n\nclass PersonStats(BaseModel):\n    name: str\n    age: int = Field(ge=0, lt=120)  # 0 \u2264 age < 120\n    height: float = Field(gt=0, le=300)  # 0 < height \u2264 300 (cm)\n    weight: float = Field(gt=0, le=500)  # 0 < weight \u2264 500 (kg)\n    body_temperature: float = Field(ge=35, le=42)  # normal human range in Celsius\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 21,
          "line_range": [
            21,
            42
          ]
        },
        {
          "code": "# Extract with validation\n",
          "display_code": "",
          "annotation": "Extract with validation",
          "is_comment": true,
          "start_line": 43,
          "line_range": [
            43,
            43
          ],
          "target_line_range": [
            44,
            72
          ]
        },
        {
          "code": "person = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=PersonStats,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Patient: John Smith\n        Age: 35 years old\n        Height: 180 cm\n        Weight: 75 kg\n        Temperature: 37.2\u00b0C\n        \"\"\"}\n    ]\n)\n\nprint(f\"Patient: {person.name}\")\nprint(f\"Age: {person.age}\")\nprint(f\"Height: {person.height} cm\")\nprint(f\"Weight: {person.weight} kg\")\nprint(f\"Body Temperature: {person.body_temperature}\u00b0C\")\n\nfrom pydantic import BaseModel, Field, field_validator\nimport re\n\nclass ContactInfo(BaseModel):\n    name: str\n    email: str = Field(pattern=r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$')\n    phone: str = Field(pattern=r'^\\+?[1-9]\\d{1,14}$')  # E.164 phone format\n    website: str = Field(pattern=r'^https?://(?:www\\.)?[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}(?:/[^\\s]*)?$')\n\n",
          "display_code": "person = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=PersonStats,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Patient: John Smith\n        Age: 35 years old\n        Height: 180 cm\n        Weight: 75 kg\n        Temperature: 37.2\u00b0C\n        \"\"\"}\n    ]\n)\n\nprint(f\"Patient: {person.name}\")\nprint(f\"Age: {person.age}\")\nprint(f\"Height: {person.height} cm\")\nprint(f\"Weight: {person.weight} kg\")\nprint(f\"Body Temperature: {person.body_temperature}\u00b0C\")\n\nfrom pydantic import BaseModel, Field, field_validator\nimport re\n\nclass ContactInfo(BaseModel):\n    name: str\n    email: str = Field(pattern=r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$')\n    phone: str = Field(pattern=r'^\\+?[1-9]\\d{1,14}$')  # E.164 phone format\n    website: str = Field(pattern=r'^https?://(?:www\\.)?[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}(?:/[^\\s]*)?$')\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 44,
          "line_range": [
            44,
            72
          ]
        },
        {
          "code": "# Additional custom validation\n",
          "display_code": "",
          "annotation": "Additional custom validation",
          "is_comment": true,
          "start_line": 73,
          "line_range": [
            73,
            73
          ],
          "target_line_range": [
            74,
            79
          ]
        },
        {
          "code": "    @field_validator('name')\n    def validate_name(cls, v):\n        if len(v.split()) < 2:\n            raise ValueError('Name must include at least first and last name')\n        return v\n\n",
          "display_code": "    @field_validator('name')\n    def validate_name(cls, v):\n        if len(v.split()) < 2:\n            raise ValueError('Name must include at least first and last name')\n        return v\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 74,
          "line_range": [
            74,
            79
          ]
        },
        {
          "code": "# Extract with validation\n",
          "display_code": "",
          "annotation": "Extract with validation",
          "is_comment": true,
          "start_line": 80,
          "line_range": [
            80,
            80
          ],
          "target_line_range": [
            81,
            99
          ]
        },
        {
          "code": "contact = client.chat.completions.create(\n    model=\"gpt-4\",  # More capable for handling pattern constraints\n    response_model=ContactInfo,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Contact details for our new client:\n        Name: John A. Smith\n        Email: john.smith@example.com\n        Phone: +1-555-123-4567\n        Website: https://www.johnsmith.com\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {contact.name}\")\nprint(f\"Email: {contact.email}\")\nprint(f\"Phone: {contact.phone}\")\nprint(f\"Website: {contact.website}\")\n\n",
          "display_code": "contact = client.chat.completions.create(\n    model=\"gpt-4\",  # More capable for handling pattern constraints\n    response_model=ContactInfo,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Contact details for our new client:\n        Name: John A. Smith\n        Email: john.smith@example.com\n        Phone: +1-555-123-4567\n        Website: https://www.johnsmith.com\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {contact.name}\")\nprint(f\"Email: {contact.email}\")\nprint(f\"Phone: {contact.phone}\")\nprint(f\"Website: {contact.website}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 81,
          "line_range": [
            81,
            99
          ]
        },
        {
          "code": "# Instructor automatically retries with validation errors:\n",
          "display_code": "",
          "annotation": "Instructor automatically retries with validation errors:",
          "is_comment": true,
          "start_line": 100,
          "line_range": [
            100,
            100
          ],
          "target_line_range": [
            101,
            107
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\n\nclass User(BaseModel):\n    name: str\n    age: int = Field(ge=18, le=100)  # Must be between 18 and 100\n    email: str = Field(pattern=r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$')\n\n",
          "display_code": "from pydantic import BaseModel, Field\n\nclass User(BaseModel):\n    name: str\n    age: int = Field(ge=18, le=100)  # Must be between 18 and 100\n    email: str = Field(pattern=r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$')\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 101,
          "line_range": [
            101,
            107
          ]
        },
        {
          "code": "# This example has invalid data\n",
          "display_code": "",
          "annotation": "This example has invalid data",
          "is_comment": true,
          "start_line": 108,
          "line_range": [
            108,
            108
          ],
          "target_line_range": [
            109,
            117
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=User,\n    max_retries=2,  # Limit retries (default is 3)\n    messages=[\n        {\"role\": \"user\", \"content\": \"Sam is 16 years old and his email is sam@example\"}\n    ]\n)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=User,\n    max_retries=2,  # Limit retries (default is 3)\n    messages=[\n        {\"role\": \"user\", \"content\": \"Sam is 16 years old and his email is sam@example\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 109,
          "line_range": [
            109,
            117
          ]
        },
        {
          "code": "# Instructor will automatically retry with validation errors to get a fixed response\n",
          "display_code": "",
          "annotation": "Instructor will automatically retry with validation errors to get a fixed response",
          "is_comment": true,
          "start_line": 118,
          "line_range": [
            118,
            118
          ],
          "target_line_range": [
            119,
            149
          ]
        },
        {
          "code": "print(f\"Name: {user.name}\")\nprint(f\"Age: {user.age}\")  # Should be adjusted to valid range\nprint(f\"Email: {user.email}\")  # Should include a valid domain\n\nfrom pydantic import BaseModel, Field, field_validator\nfrom datetime import date\nfrom typing import Optional\n\nclass Reservation(BaseModel):\n    guest_name: str\n    check_in_date: date\n    check_out_date: date\n    room_type: str\n    num_guests: int = Field(gt=0)\n    special_requests: Optional[str] = None\n\n    @field_validator('check_out_date')\n    def validate_dates(cls, v, values):\n        if 'check_in_date' in values.data and v <= values.data['check_in_date']:\n            raise ValueError('check_out_date must be after check_in_date')\n        return v\n\n    @field_validator('num_guests')\n    def validate_guests(cls, v, values):\n        if 'room_type' in values.data:\n            if values.data['room_type'].lower() == 'single' and v > 1:\n                raise ValueError('Single rooms can only accommodate 1 guest')\n            elif values.data['room_type'].lower() == 'double' and v > 2:\n                raise ValueError('Double rooms can only accommodate 2 guests')\n        return v\n\n",
          "display_code": "print(f\"Name: {user.name}\")\nprint(f\"Age: {user.age}\")  # Should be adjusted to valid range\nprint(f\"Email: {user.email}\")  # Should include a valid domain\n\nfrom pydantic import BaseModel, Field, field_validator\nfrom datetime import date\nfrom typing import Optional\n\nclass Reservation(BaseModel):\n    guest_name: str\n    check_in_date: date\n    check_out_date: date\n    room_type: str\n    num_guests: int = Field(gt=0)\n    special_requests: Optional[str] = None\n\n    @field_validator('check_out_date')\n    def validate_dates(cls, v, values):\n        if 'check_in_date' in values.data and v <= values.data['check_in_date']:\n            raise ValueError('check_out_date must be after check_in_date')\n        return v\n\n    @field_validator('num_guests')\n    def validate_guests(cls, v, values):\n        if 'room_type' in values.data:\n            if values.data['room_type'].lower() == 'single' and v > 1:\n                raise ValueError('Single rooms can only accommodate 1 guest')\n            elif values.data['room_type'].lower() == 'double' and v > 2:\n                raise ValueError('Double rooms can only accommodate 2 guests')\n        return v\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 119,
          "line_range": [
            119,
            149
          ]
        },
        {
          "code": "# Extract with validation\n",
          "display_code": "",
          "annotation": "Extract with validation",
          "is_comment": true,
          "start_line": 150,
          "line_range": [
            150,
            150
          ],
          "target_line_range": [
            151,
            172
          ]
        },
        {
          "code": "reservation = client.chat.completions.create(\n    model=\"gpt-4\",\n    response_model=Reservation,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Hotel reservation details:\n        Guest: Maria Garcia\n        Check-in: 2023-11-15\n        Check-out: 2023-11-20\n        Room: Double\n        Guests: 2\n        Special requests: Early check-in if possible\n        \"\"\"}\n    ]\n)\n\nprint(f\"Guest: {reservation.guest_name}\")\nprint(f\"Stay: {reservation.check_in_date} to {reservation.check_out_date}\")\nprint(f\"Room: {reservation.room_type} for {reservation.num_guests} guests\")\nif reservation.special_requests:\n    print(f\"Special requests: {reservation.special_requests}\")\n\n",
          "display_code": "reservation = client.chat.completions.create(\n    model=\"gpt-4\",\n    response_model=Reservation,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Hotel reservation details:\n        Guest: Maria Garcia\n        Check-in: 2023-11-15\n        Check-out: 2023-11-20\n        Room: Double\n        Guests: 2\n        Special requests: Early check-in if possible\n        \"\"\"}\n    ]\n)\n\nprint(f\"Guest: {reservation.guest_name}\")\nprint(f\"Stay: {reservation.check_in_date} to {reservation.check_out_date}\")\nprint(f\"Room: {reservation.room_type} for {reservation.num_guests} guests\")\nif reservation.special_requests:\n    print(f\"Special requests: {reservation.special_requests}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 151,
          "line_range": [
            151,
            172
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python field-validation.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "003-basic-extraction",
      "section_title": "Basic Extraction Patterns"
    },
    {
      "id": "016-optional-fields",
      "title": "Optional Fields",
      "description": "",
      "order": 16,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# \n",
          "display_code": "",
          "annotation": "",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Handle missing or optional data in your structured extractions with Instructor.\n",
          "display_code": "",
          "annotation": "Handle missing or optional data in your structured extractions with Instructor.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            13
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\nfrom typing import Optional\nimport instructor\nfrom openai import OpenAI\n\nclass Person(BaseModel):\n    name: str\n    age: int\n",
          "display_code": "from pydantic import BaseModel, Field\nfrom typing import Optional\nimport instructor\nfrom openai import OpenAI\n\nclass Person(BaseModel):\n    name: str\n    age: int\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            13
          ]
        },
        {
          "code": "    # Optional fields with default value of None\n",
          "display_code": "",
          "annotation": "Optional fields with default value of None",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            18
          ]
        },
        {
          "code": "    email: Optional[str] = None\n    phone: Optional[str] = None\n    occupation: Optional[str] = None\n\n",
          "display_code": "    email: Optional[str] = None\n    phone: Optional[str] = None\n    occupation: Optional[str] = None\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            18
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 19,
          "line_range": [
            19,
            19
          ],
          "target_line_range": [
            20,
            21
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 20,
          "line_range": [
            20,
            21
          ]
        },
        {
          "code": "# Extract with optional fields\n",
          "display_code": "",
          "annotation": "Extract with optional fields",
          "is_comment": true,
          "start_line": 22,
          "line_range": [
            22,
            22
          ],
          "target_line_range": [
            23,
            42
          ]
        },
        {
          "code": "person = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John Smith is 35 years old and works as a software engineer.\"}\n    ]\n)\n\nprint(f\"Name: {person.name}\")\nprint(f\"Age: {person.age}\")\nprint(f\"Email: {person.email}\")  # None\nprint(f\"Phone: {person.phone}\")  # None\nprint(f\"Occupation: {person.occupation}\")  # \"software engineer\"\n\nfrom pydantic import BaseModel, Field\nfrom typing import Optional\n\nclass Product(BaseModel):\n    name: str\n    price: float\n",
          "display_code": "person = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John Smith is 35 years old and works as a software engineer.\"}\n    ]\n)\n\nprint(f\"Name: {person.name}\")\nprint(f\"Age: {person.age}\")\nprint(f\"Email: {person.email}\")  # None\nprint(f\"Phone: {person.phone}\")  # None\nprint(f\"Occupation: {person.occupation}\")  # \"software engineer\"\n\nfrom pydantic import BaseModel, Field\nfrom typing import Optional\n\nclass Product(BaseModel):\n    name: str\n    price: float\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 23,
          "line_range": [
            23,
            42
          ]
        },
        {
          "code": "    # Optional with custom defaults\n",
          "display_code": "",
          "annotation": "Optional with custom defaults",
          "is_comment": true,
          "start_line": 43,
          "line_range": [
            43,
            43
          ],
          "target_line_range": [
            44,
            69
          ]
        },
        {
          "code": "    currency: str = \"USD\"\n    in_stock: bool = True\n    category: Optional[str] = None\n    tags: list[str] = Field(default_factory=list)  # Empty list by default\n\nproduct = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Product,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Our new coffee mug costs 12.99 and is categorized under 'Kitchen'.\"}\n    ]\n)\n\nprint(f\"Product: {product.name}\")\nprint(f\"Price: {product.price} {product.currency}\")  # USD is the default\nprint(f\"In Stock: {product.in_stock}\")  # True is the default\nprint(f\"Category: {product.category}\")  # \"Kitchen\"\nprint(f\"Tags: {product.tags}\")  # Empty list by default\n\nfrom pydantic import BaseModel, Field\nfrom typing import Optional\n\nclass JobApplication(BaseModel):\n    name: str = Field(description=\"Applicant's full name\")\n    email: str = Field(description=\"Contact email address\")\n\n",
          "display_code": "    currency: str = \"USD\"\n    in_stock: bool = True\n    category: Optional[str] = None\n    tags: list[str] = Field(default_factory=list)  # Empty list by default\n\nproduct = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Product,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Our new coffee mug costs 12.99 and is categorized under 'Kitchen'.\"}\n    ]\n)\n\nprint(f\"Product: {product.name}\")\nprint(f\"Price: {product.price} {product.currency}\")  # USD is the default\nprint(f\"In Stock: {product.in_stock}\")  # True is the default\nprint(f\"Category: {product.category}\")  # \"Kitchen\"\nprint(f\"Tags: {product.tags}\")  # Empty list by default\n\nfrom pydantic import BaseModel, Field\nfrom typing import Optional\n\nclass JobApplication(BaseModel):\n    name: str = Field(description=\"Applicant's full name\")\n    email: str = Field(description=\"Contact email address\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 44,
          "line_range": [
            44,
            69
          ]
        },
        {
          "code": "    # Optional fields with descriptions\n",
          "display_code": "",
          "annotation": "Optional fields with descriptions",
          "is_comment": true,
          "start_line": 70,
          "line_range": [
            70,
            70
          ],
          "target_line_range": [
            71,
            103
          ]
        },
        {
          "code": "    phone: Optional[str] = Field(\n        None, description=\"Phone number in international format (optional)\"\n    )\n    years_experience: Optional[int] = Field(\n        None, description=\"Years of relevant work experience (optional)\"\n    )\n    portfolio_url: Optional[str] = Field(\n        None, description=\"Link to portfolio or personal website (optional)\"\n    )\n    cover_letter: Optional[str] = Field(\n        None, description=\"Brief cover letter or introduction (optional)\"\n    )\n\napplication = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=JobApplication,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Job application from Sarah Johnson:\n        I'm applying for the software developer position. My email is sarah.j@example.com\n        and I have 5 years of experience in frontend development. You can see my work\n        at https://sarahjohnson.dev\n        \"\"\"}\n    ]\n)\n\nprint(f\"Applicant: {application.name}\")\nprint(f\"Email: {application.email}\")\nprint(f\"Phone: {application.phone or 'Not provided'}\")  # None -> 'Not provided'\nprint(f\"Experience: {application.years_experience or 'Not specified'} years\")\nprint(f\"Portfolio: {application.portfolio_url or 'None provided'}\")\nprint(f\"Cover Letter: {application.cover_letter or 'Not included'}\")\n\n",
          "display_code": "    phone: Optional[str] = Field(\n        None, description=\"Phone number in international format (optional)\"\n    )\n    years_experience: Optional[int] = Field(\n        None, description=\"Years of relevant work experience (optional)\"\n    )\n    portfolio_url: Optional[str] = Field(\n        None, description=\"Link to portfolio or personal website (optional)\"\n    )\n    cover_letter: Optional[str] = Field(\n        None, description=\"Brief cover letter or introduction (optional)\"\n    )\n\napplication = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=JobApplication,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Job application from Sarah Johnson:\n        I'm applying for the software developer position. My email is sarah.j@example.com\n        and I have 5 years of experience in frontend development. You can see my work\n        at https://sarahjohnson.dev\n        \"\"\"}\n    ]\n)\n\nprint(f\"Applicant: {application.name}\")\nprint(f\"Email: {application.email}\")\nprint(f\"Phone: {application.phone or 'Not provided'}\")  # None -> 'Not provided'\nprint(f\"Experience: {application.years_experience or 'Not specified'} years\")\nprint(f\"Portfolio: {application.portfolio_url or 'None provided'}\")\nprint(f\"Cover Letter: {application.cover_letter or 'Not included'}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 71,
          "line_range": [
            71,
            103
          ]
        },
        {
          "code": "# Instructor provides a `Maybe` type that explicitly tracks whether fields were present in the source text:\n",
          "display_code": "",
          "annotation": "Instructor provides a `Maybe` type that explicitly tracks whether fields were present in the source text:",
          "is_comment": true,
          "start_line": 104,
          "line_range": [
            104,
            104
          ],
          "target_line_range": [
            105,
            112
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\nfrom instructor.dsl.maybe import Maybe\nimport instructor\nfrom openai import OpenAI\n\nclass Person(BaseModel):\n    name: str\n    age: int\n",
          "display_code": "from pydantic import BaseModel, Field\nfrom instructor.dsl.maybe import Maybe\nimport instructor\nfrom openai import OpenAI\n\nclass Person(BaseModel):\n    name: str\n    age: int\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 105,
          "line_range": [
            105,
            112
          ]
        },
        {
          "code": "    # Maybe fields track if the information was in the text\n",
          "display_code": "",
          "annotation": "Maybe fields track if the information was in the text",
          "is_comment": true,
          "start_line": 113,
          "line_range": [
            113,
            113
          ],
          "target_line_range": [
            114,
            117
          ]
        },
        {
          "code": "    occupation: Maybe[str] = Field(default=None)\n    email: Maybe[str] = Field(default=None)\n    location: Maybe[str] = Field(default=None)\n\n",
          "display_code": "    occupation: Maybe[str] = Field(default=None)\n    email: Maybe[str] = Field(default=None)\n    location: Maybe[str] = Field(default=None)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 114,
          "line_range": [
            114,
            117
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 118,
          "line_range": [
            118,
            118
          ],
          "target_line_range": [
            119,
            120
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 119,
          "line_range": [
            119,
            120
          ]
        },
        {
          "code": "# Extract with Maybe fields\n",
          "display_code": "",
          "annotation": "Extract with Maybe fields",
          "is_comment": true,
          "start_line": 121,
          "line_range": [
            121,
            121
          ],
          "target_line_range": [
            122,
            132
          ]
        },
        {
          "code": "person = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John Smith is 35 years old and works as a software engineer.\"}\n    ]\n)\n\nprint(f\"Name: {person.name}\")\nprint(f\"Age: {person.age}\")\n\n",
          "display_code": "person = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"John Smith is 35 years old and works as a software engineer.\"}\n    ]\n)\n\nprint(f\"Name: {person.name}\")\nprint(f\"Age: {person.age}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 122,
          "line_range": [
            122,
            132
          ]
        },
        {
          "code": "# Check if occupation was present\n",
          "display_code": "",
          "annotation": "Check if occupation was present",
          "is_comment": true,
          "start_line": 133,
          "line_range": [
            133,
            133
          ],
          "target_line_range": [
            134,
            138
          ]
        },
        {
          "code": "if person.occupation.exists:\n    print(f\"Occupation: {person.occupation.value}\")\nelse:\n    print(\"Occupation: Not mentioned\")\n\n",
          "display_code": "if person.occupation.exists:\n    print(f\"Occupation: {person.occupation.value}\")\nelse:\n    print(\"Occupation: Not mentioned\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 134,
          "line_range": [
            134,
            138
          ]
        },
        {
          "code": "# Check if email was present\n",
          "display_code": "",
          "annotation": "Check if email was present",
          "is_comment": true,
          "start_line": 139,
          "line_range": [
            139,
            139
          ],
          "target_line_range": [
            140,
            144
          ]
        },
        {
          "code": "if person.email.exists:\n    print(f\"Email: {person.email.value}\")\nelse:\n    print(\"Email: Not mentioned\")\n\n",
          "display_code": "if person.email.exists:\n    print(f\"Email: {person.email.value}\")\nelse:\n    print(\"Email: Not mentioned\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 140,
          "line_range": [
            140,
            144
          ]
        },
        {
          "code": "# Check if location was present\n",
          "display_code": "",
          "annotation": "Check if location was present",
          "is_comment": true,
          "start_line": 145,
          "line_range": [
            145,
            145
          ],
          "target_line_range": [
            146,
            163
          ]
        },
        {
          "code": "if person.location.exists:\n    print(f\"Location: {person.location.value}\")\nelse:\n    print(\"Location: Not mentioned\")\n\nfrom pydantic import BaseModel, Field\nfrom typing import Optional, List\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    country: str\n    zip_code: Optional[str] = None\n\nclass ContactInfo(BaseModel):\n    email: Optional[str] = None\n    phone: Optional[str] = None\n\n",
          "display_code": "if person.location.exists:\n    print(f\"Location: {person.location.value}\")\nelse:\n    print(\"Location: Not mentioned\")\n\nfrom pydantic import BaseModel, Field\nfrom typing import Optional, List\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    country: str\n    zip_code: Optional[str] = None\n\nclass ContactInfo(BaseModel):\n    email: Optional[str] = None\n    phone: Optional[str] = None\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 146,
          "line_range": [
            146,
            163
          ]
        },
        {
          "code": "    # An optional nested object\n",
          "display_code": "",
          "annotation": "An optional nested object",
          "is_comment": true,
          "start_line": 164,
          "line_range": [
            164,
            164
          ],
          "target_line_range": [
            165,
            197
          ]
        },
        {
          "code": "    address: Optional[Address] = None\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    contact: Optional[ContactInfo] = None\n    hobbies: List[str] = Field(default_factory=list)\n\nperson = client.chat.completions.create(\n    model=\"gpt-4\",  # Better for complex structures\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Profile: Jane Smith, 42 years old.\n        She enjoys hiking, photography, and playing piano.\n        Contact her at jane.smith@example.com or at her home in\n        123 Maple Street, Toronto, Canada.\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {person.name}, Age: {person.age}\")\nprint(f\"Hobbies: {', '.join(person.hobbies)}\")\n\nif person.contact:\n    if person.contact.email:\n        print(f\"Email: {person.contact.email}\")\n    if person.contact.phone:\n        print(f\"Phone: {person.contact.phone}\")\n    if person.contact.address:\n        addr = person.contact.address\n        print(f\"Address: {addr.street}, {addr.city}, {addr.country}\")\n\n",
          "display_code": "    address: Optional[Address] = None\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    contact: Optional[ContactInfo] = None\n    hobbies: List[str] = Field(default_factory=list)\n\nperson = client.chat.completions.create(\n    model=\"gpt-4\",  # Better for complex structures\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Profile: Jane Smith, 42 years old.\n        She enjoys hiking, photography, and playing piano.\n        Contact her at jane.smith@example.com or at her home in\n        123 Maple Street, Toronto, Canada.\n        \"\"\"}\n    ]\n)\n\nprint(f\"Name: {person.name}, Age: {person.age}\")\nprint(f\"Hobbies: {', '.join(person.hobbies)}\")\n\nif person.contact:\n    if person.contact.email:\n        print(f\"Email: {person.contact.email}\")\n    if person.contact.phone:\n        print(f\"Phone: {person.contact.phone}\")\n    if person.contact.address:\n        addr = person.contact.address\n        print(f\"Address: {addr.street}, {addr.city}, {addr.country}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 165,
          "line_range": [
            165,
            197
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python optional-fields.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "003-basic-extraction",
      "section_title": "Basic Extraction Patterns"
    },
    {
      "id": "017-working-with-enums",
      "title": "Working with Enums",
      "description": "",
      "order": 17,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# \n",
          "display_code": "",
          "annotation": "",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Use enumerated types in your data extraction for more consistent and validated results.\n",
          "display_code": "",
          "annotation": "Use enumerated types in your data extraction for more consistent and validated results.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "from enum import Enum\nfrom pydantic import BaseModel\nimport instructor\nfrom openai import OpenAI\n\n",
          "display_code": "from enum import Enum\nfrom pydantic import BaseModel\nimport instructor\nfrom openai import OpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Define an enum for product categories\n",
          "display_code": "",
          "annotation": "Define an enum for product categories",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            23
          ]
        },
        {
          "code": "class ProductCategory(str, Enum):\n    ELECTRONICS = \"electronics\"\n    CLOTHING = \"clothing\"\n    HOME = \"home\"\n    BOOKS = \"books\"\n    TOYS = \"toys\"\n\nclass Product(BaseModel):\n    name: str\n    price: float\n    category: ProductCategory\n\n",
          "display_code": "class ProductCategory(str, Enum):\n    ELECTRONICS = \"electronics\"\n    CLOTHING = \"clothing\"\n    HOME = \"home\"\n    BOOKS = \"books\"\n    TOYS = \"toys\"\n\nclass Product(BaseModel):\n    name: str\n    price: float\n    category: ProductCategory\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            23
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 24,
          "line_range": [
            24,
            24
          ],
          "target_line_range": [
            25,
            26
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 25,
          "line_range": [
            25,
            26
          ]
        },
        {
          "code": "# Extract with enum validation\n",
          "display_code": "",
          "annotation": "Extract with enum validation",
          "is_comment": true,
          "start_line": 27,
          "line_range": [
            27,
            27
          ],
          "target_line_range": [
            28,
            38
          ]
        },
        {
          "code": "product = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Product,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Our new wireless headphones cost $79.99 and belong in our electronics department.\"}\n    ]\n)\n\nprint(f\"Product: {product.name}\")\nprint(f\"Price: ${product.price}\")\nprint(f\"Category: {product.category}\")\n",
          "display_code": "product = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Product,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Our new wireless headphones cost $79.99 and belong in our electronics department.\"}\n    ]\n)\n\nprint(f\"Product: {product.name}\")\nprint(f\"Price: ${product.price}\")\nprint(f\"Category: {product.category}\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 28,
          "line_range": [
            28,
            38
          ]
        },
        {
          "code": "# Will be ProductCategory.ELECTRONICS, not just a string\n",
          "display_code": "",
          "annotation": "Will be ProductCategory.ELECTRONICS, not just a string",
          "is_comment": true,
          "start_line": 39,
          "line_range": [
            39,
            39
          ],
          "target_line_range": [
            40,
            40
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 40,
          "line_range": [
            40,
            40
          ]
        },
        {
          "code": "# You can use the enum for comparisons\n",
          "display_code": "",
          "annotation": "You can use the enum for comparisons",
          "is_comment": true,
          "start_line": 41,
          "line_range": [
            41,
            41
          ],
          "target_line_range": [
            42,
            48
          ]
        },
        {
          "code": "if product.category == ProductCategory.ELECTRONICS:\n    print(\"This is an electronic product.\")\n\nfrom enum import Enum, auto\nfrom pydantic import BaseModel\nfrom typing import List\n\n",
          "display_code": "if product.category == ProductCategory.ELECTRONICS:\n    print(\"This is an electronic product.\")\n\nfrom enum import Enum, auto\nfrom pydantic import BaseModel\nfrom typing import List\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 42,
          "line_range": [
            42,
            48
          ]
        },
        {
          "code": "# Define priority enum\n",
          "display_code": "",
          "annotation": "Define priority enum",
          "is_comment": true,
          "start_line": 49,
          "line_range": [
            49,
            49
          ],
          "target_line_range": [
            50,
            55
          ]
        },
        {
          "code": "class Priority(str, Enum):\n    LOW = \"low\"\n    MEDIUM = \"medium\"\n    HIGH = \"high\"\n    CRITICAL = \"critical\"\n\n",
          "display_code": "class Priority(str, Enum):\n    LOW = \"low\"\n    MEDIUM = \"medium\"\n    HIGH = \"high\"\n    CRITICAL = \"critical\"\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 50,
          "line_range": [
            50,
            55
          ]
        },
        {
          "code": "# Define status enum\n",
          "display_code": "",
          "annotation": "Define status enum",
          "is_comment": true,
          "start_line": 56,
          "line_range": [
            56,
            56
          ],
          "target_line_range": [
            57,
            90
          ]
        },
        {
          "code": "class Status(str, Enum):\n    TODO = \"todo\"\n    IN_PROGRESS = \"in_progress\"\n    REVIEW = \"review\"\n    DONE = \"done\"\n\nclass Task(BaseModel):\n    title: str\n    description: str\n    priority: Priority\n    status: Status\n    tags: List[str] = []\n\ntask = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Task,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Task Details:\n        Title: Fix login page bug\n        Description: Users report seeing errors when trying to log in with special characters\n        Priority: High\n        Status: In Progress\n        Tags: bug, authentication, frontend\n        \"\"\"}\n    ]\n)\n\nprint(f\"Task: {task.title}\")\nprint(f\"Description: {task.description}\")\nprint(f\"Priority: {task.priority}\")  # Priority.HIGH\nprint(f\"Status: {task.status}\")  # Status.IN_PROGRESS\nprint(f\"Tags: {', '.join(task.tags)}\")\n\n",
          "display_code": "class Status(str, Enum):\n    TODO = \"todo\"\n    IN_PROGRESS = \"in_progress\"\n    REVIEW = \"review\"\n    DONE = \"done\"\n\nclass Task(BaseModel):\n    title: str\n    description: str\n    priority: Priority\n    status: Status\n    tags: List[str] = []\n\ntask = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Task,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Task Details:\n        Title: Fix login page bug\n        Description: Users report seeing errors when trying to log in with special characters\n        Priority: High\n        Status: In Progress\n        Tags: bug, authentication, frontend\n        \"\"\"}\n    ]\n)\n\nprint(f\"Task: {task.title}\")\nprint(f\"Description: {task.description}\")\nprint(f\"Priority: {task.priority}\")  # Priority.HIGH\nprint(f\"Status: {task.status}\")  # Status.IN_PROGRESS\nprint(f\"Tags: {', '.join(task.tags)}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 57,
          "line_range": [
            57,
            90
          ]
        },
        {
          "code": "# Use enums for conditional logic\n",
          "display_code": "",
          "annotation": "Use enums for conditional logic",
          "is_comment": true,
          "start_line": 91,
          "line_range": [
            91,
            91
          ],
          "target_line_range": [
            92,
            100
          ]
        },
        {
          "code": "if task.priority in [Priority.HIGH, Priority.CRITICAL]:\n    print(\"This task requires immediate attention!\")\n\nif task.status == Status.IN_PROGRESS:\n    print(\"This task is being worked on.\")\n\nfrom enum import IntEnum\nfrom pydantic import BaseModel\n\n",
          "display_code": "if task.priority in [Priority.HIGH, Priority.CRITICAL]:\n    print(\"This task requires immediate attention!\")\n\nif task.status == Status.IN_PROGRESS:\n    print(\"This task is being worked on.\")\n\nfrom enum import IntEnum\nfrom pydantic import BaseModel\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 92,
          "line_range": [
            92,
            100
          ]
        },
        {
          "code": "# Define an integer-based enum\n",
          "display_code": "",
          "annotation": "Define an integer-based enum",
          "is_comment": true,
          "start_line": 101,
          "line_range": [
            101,
            101
          ],
          "target_line_range": [
            102,
            133
          ]
        },
        {
          "code": "class SeverityLevel(IntEnum):\n    LOW = 1\n    MODERATE = 2\n    HIGH = 3\n    SEVERE = 4\n    CRITICAL = 5\n\nclass SecurityIssue(BaseModel):\n    title: str\n    description: str\n    severity: SeverityLevel\n    affected_users: int\n\nissue = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=SecurityIssue,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Security Alert:\n        Issue: Database Exposure\n        Details: Customer database was partially exposed due to misconfigured firewall\n        Severity: 4 (Severe)\n        Affected Users: 5,230\n        \"\"\"}\n    ]\n)\n\nprint(f\"Issue: {issue.title}\")\nprint(f\"Description: {issue.description}\")\nprint(f\"Severity: {issue.severity.name} (Level {issue.severity.value})\")  # \"SEVERE (Level 4)\"\nprint(f\"Affected Users: {issue.affected_users}\")\n\n",
          "display_code": "class SeverityLevel(IntEnum):\n    LOW = 1\n    MODERATE = 2\n    HIGH = 3\n    SEVERE = 4\n    CRITICAL = 5\n\nclass SecurityIssue(BaseModel):\n    title: str\n    description: str\n    severity: SeverityLevel\n    affected_users: int\n\nissue = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=SecurityIssue,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        Security Alert:\n        Issue: Database Exposure\n        Details: Customer database was partially exposed due to misconfigured firewall\n        Severity: 4 (Severe)\n        Affected Users: 5,230\n        \"\"\"}\n    ]\n)\n\nprint(f\"Issue: {issue.title}\")\nprint(f\"Description: {issue.description}\")\nprint(f\"Severity: {issue.severity.name} (Level {issue.severity.value})\")  # \"SEVERE (Level 4)\"\nprint(f\"Affected Users: {issue.affected_users}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 102,
          "line_range": [
            102,
            133
          ]
        },
        {
          "code": "# Use integer enum for thresholds\n",
          "display_code": "",
          "annotation": "Use integer enum for thresholds",
          "is_comment": true,
          "start_line": 134,
          "line_range": [
            134,
            134
          ],
          "target_line_range": [
            135,
            151
          ]
        },
        {
          "code": "if issue.severity >= SeverityLevel.HIGH and issue.affected_users > 1000:\n    print(\"This requires executive notification!\")\n\nfrom enum import Enum\nfrom pydantic import BaseModel, Field\n\nclass TicketType(str, Enum):\n    BUG = \"bug\"\n    FEATURE = \"feature\"\n    IMPROVEMENT = \"improvement\"\n    DOCUMENTATION = \"documentation\"\n    QUESTION = \"question\"\n\nclass Ticket(BaseModel):\n    title: str\n    description: str\n\n",
          "display_code": "if issue.severity >= SeverityLevel.HIGH and issue.affected_users > 1000:\n    print(\"This requires executive notification!\")\n\nfrom enum import Enum\nfrom pydantic import BaseModel, Field\n\nclass TicketType(str, Enum):\n    BUG = \"bug\"\n    FEATURE = \"feature\"\n    IMPROVEMENT = \"improvement\"\n    DOCUMENTATION = \"documentation\"\n    QUESTION = \"question\"\n\nclass Ticket(BaseModel):\n    title: str\n    description: str\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 135,
          "line_range": [
            135,
            151
          ]
        },
        {
          "code": "    # Add descriptions to help the LLM understand the enum\n",
          "display_code": "",
          "annotation": "Add descriptions to help the LLM understand the enum",
          "is_comment": true,
          "start_line": 152,
          "line_range": [
            152,
            152
          ],
          "target_line_range": [
            153,
            180
          ]
        },
        {
          "code": "    ticket_type: TicketType = Field(\n        description=\"\"\"Type of ticket with these options:\n        - bug: Something is not working correctly\n        - feature: A new capability is requested\n        - improvement: Enhancement to an existing feature\n        - documentation: Updates to documentation\n        - question: Question about functionality\"\"\"\n    )\n\nticket = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Ticket,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        New Ticket:\n        Title: Add dark mode to application\n        Description: Users would like a dark theme option to reduce eye strain when using the app at night\n        \"\"\"}\n    ]\n)\n\nprint(f\"Ticket: {ticket.title}\")\nprint(f\"Description: {ticket.description}\")\nprint(f\"Type: {ticket.ticket_type}\")  # Should be TicketType.IMPROVEMENT or TicketType.FEATURE\n\nfrom enum import Flag, auto\nfrom pydantic import BaseModel, Field\n\n",
          "display_code": "    ticket_type: TicketType = Field(\n        description=\"\"\"Type of ticket with these options:\n        - bug: Something is not working correctly\n        - feature: A new capability is requested\n        - improvement: Enhancement to an existing feature\n        - documentation: Updates to documentation\n        - question: Question about functionality\"\"\"\n    )\n\nticket = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=Ticket,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        New Ticket:\n        Title: Add dark mode to application\n        Description: Users would like a dark theme option to reduce eye strain when using the app at night\n        \"\"\"}\n    ]\n)\n\nprint(f\"Ticket: {ticket.title}\")\nprint(f\"Description: {ticket.description}\")\nprint(f\"Type: {ticket.ticket_type}\")  # Should be TicketType.IMPROVEMENT or TicketType.FEATURE\n\nfrom enum import Flag, auto\nfrom pydantic import BaseModel, Field\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 153,
          "line_range": [
            153,
            180
          ]
        },
        {
          "code": "# Define a Flag enum for permissions\n",
          "display_code": "",
          "annotation": "Define a Flag enum for permissions",
          "is_comment": true,
          "start_line": 181,
          "line_range": [
            181,
            181
          ],
          "target_line_range": [
            182,
            188
          ]
        },
        {
          "code": "class Permissions(Flag):\n    NONE = 0\n    READ = auto()       # 1\n    WRITE = auto()      # 2\n    DELETE = auto()     # 4\n    ADMIN = auto()      # 8\n\n",
          "display_code": "class Permissions(Flag):\n    NONE = 0\n    READ = auto()       # 1\n    WRITE = auto()      # 2\n    DELETE = auto()     # 4\n    ADMIN = auto()      # 8\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 182,
          "line_range": [
            182,
            188
          ]
        },
        {
          "code": "    # Combinations\n",
          "display_code": "",
          "annotation": "Combinations",
          "is_comment": true,
          "start_line": 189,
          "line_range": [
            189,
            189
          ],
          "target_line_range": [
            190,
            222
          ]
        },
        {
          "code": "    READ_WRITE = READ | WRITE                # 3\n    STANDARD = READ | WRITE | DELETE         # 7\n    ALL = READ | WRITE | DELETE | ADMIN      # 15\n\nclass User(BaseModel):\n    name: str\n    role: str\n    permissions: Permissions = Field(\n        description=\"\"\"User permissions, can be a combination of:\n        - READ: Can view content\n        - WRITE: Can create and edit content\n        - DELETE: Can remove content\n        - ADMIN: Has administrative privileges\n        - Or predefined combinations like READ_WRITE, STANDARD, or ALL\"\"\"\n    )\n\nuser = client.chat.completions.create(\n    model=\"gpt-4\",  # Better for complex models\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        User Profile:\n        Name: Sarah Johnson\n        Role: Content Manager\n        Permissions: Can read, write, and delete content\n        \"\"\"}\n    ]\n)\n\nprint(f\"User: {user.name}\")\nprint(f\"Role: {user.role}\")\nprint(f\"Permissions: {user.permissions.name}\")  # Should be \"STANDARD\"\n\n",
          "display_code": "    READ_WRITE = READ | WRITE                # 3\n    STANDARD = READ | WRITE | DELETE         # 7\n    ALL = READ | WRITE | DELETE | ADMIN      # 15\n\nclass User(BaseModel):\n    name: str\n    role: str\n    permissions: Permissions = Field(\n        description=\"\"\"User permissions, can be a combination of:\n        - READ: Can view content\n        - WRITE: Can create and edit content\n        - DELETE: Can remove content\n        - ADMIN: Has administrative privileges\n        - Or predefined combinations like READ_WRITE, STANDARD, or ALL\"\"\"\n    )\n\nuser = client.chat.completions.create(\n    model=\"gpt-4\",  # Better for complex models\n    response_model=User,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n        User Profile:\n        Name: Sarah Johnson\n        Role: Content Manager\n        Permissions: Can read, write, and delete content\n        \"\"\"}\n    ]\n)\n\nprint(f\"User: {user.name}\")\nprint(f\"Role: {user.role}\")\nprint(f\"Permissions: {user.permissions.name}\")  # Should be \"STANDARD\"\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 190,
          "line_range": [
            190,
            222
          ]
        },
        {
          "code": "# Check individual permissions\n",
          "display_code": "",
          "annotation": "Check individual permissions",
          "is_comment": true,
          "start_line": 223,
          "line_range": [
            223,
            223
          ],
          "target_line_range": [
            224,
            234
          ]
        },
        {
          "code": "if Permissions.READ in user.permissions:\n    print(\"User can read content\")\n\nif Permissions.WRITE in user.permissions:\n    print(\"User can write content\")\n\nif Permissions.ADMIN in user.permissions:\n    print(\"User has admin privileges\")\nelse:\n    print(\"User does not have admin privileges\")\n\n",
          "display_code": "if Permissions.READ in user.permissions:\n    print(\"User can read content\")\n\nif Permissions.WRITE in user.permissions:\n    print(\"User can write content\")\n\nif Permissions.ADMIN in user.permissions:\n    print(\"User has admin privileges\")\nelse:\n    print(\"User does not have admin privileges\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 224,
          "line_range": [
            224,
            234
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python working-with-enums.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "003-basic-extraction",
      "section_title": "Basic Extraction Patterns"
    },
    {
      "id": "018-simple-classification",
      "title": "Simple Classification",
      "description": "",
      "order": 18,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# \n",
          "display_code": "",
          "annotation": "",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Perform single-label classification with Instructor and structured outputs.\n",
          "display_code": "",
          "annotation": "Perform single-label classification with Instructor and structured outputs.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            17
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\nfrom typing import Literal\nimport instructor\nfrom openai import OpenAI\n\nclass Classification(BaseModel):\n    \"\"\"A single-label classification for text as SPAM or NOT_SPAM\"\"\"\n\n    label: Literal[\"SPAM\", \"NOT_SPAM\"] = Field(\n        description=\"The classification label, either SPAM or NOT_SPAM\"\n    )\n\n",
          "display_code": "from pydantic import BaseModel, Field\nfrom typing import Literal\nimport instructor\nfrom openai import OpenAI\n\nclass Classification(BaseModel):\n    \"\"\"A single-label classification for text as SPAM or NOT_SPAM\"\"\"\n\n    label: Literal[\"SPAM\", \"NOT_SPAM\"] = Field(\n        description=\"The classification label, either SPAM or NOT_SPAM\"\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            17
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 18,
          "line_range": [
            18,
            18
          ],
          "target_line_range": [
            19,
            45
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\ndef classify_text(text: str) -> Classification:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=Classification,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"\"\"\n                You are an email spam classifier. Classify the provided text as either SPAM or NOT_SPAM.\n\n                Examples of SPAM:\n                - \"Claim your free prize now!\"\n                - \"Make $1000 a day working from home\"\n                - \"Limited time offer - 90% discount\"\n\n                Examples of NOT_SPAM:\n                - \"Can we schedule a meeting tomorrow?\"\n                - \"Here's the report you requested\"\n                - \"Please review the attached document\"\n                \"\"\"\n            },\n            {\"role\": \"user\", \"content\": f\"Classify this text: {text}\"}\n        ]\n    )\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\ndef classify_text(text: str) -> Classification:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=Classification,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"\"\"\n                You are an email spam classifier. Classify the provided text as either SPAM or NOT_SPAM.\n\n                Examples of SPAM:\n                - \"Claim your free prize now!\"\n                - \"Make $1000 a day working from home\"\n                - \"Limited time offer - 90% discount\"\n\n                Examples of NOT_SPAM:\n                - \"Can we schedule a meeting tomorrow?\"\n                - \"Here's the report you requested\"\n                - \"Please review the attached document\"\n                \"\"\"\n            },\n            {\"role\": \"user\", \"content\": f\"Classify this text: {text}\"}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 19,
          "line_range": [
            19,
            45
          ]
        },
        {
          "code": "# Test with examples\n",
          "display_code": "",
          "annotation": "Test with examples",
          "is_comment": true,
          "start_line": 46,
          "line_range": [
            46,
            46
          ],
          "target_line_range": [
            47,
            54
          ]
        },
        {
          "code": "spam_text = \"URGENT: Your account has been compromised. Click here to verify details!\"\nlegit_text = \"Please review the meeting notes and provide your feedback by Friday.\"\n\nspam_result = classify_text(spam_text)\nlegit_result = classify_text(legit_text)\n\nprint(f\"Text: '{spam_text}'\")\nprint(f\"Classification: {spam_result.label}\")\n",
          "display_code": "spam_text = \"URGENT: Your account has been compromised. Click here to verify details!\"\nlegit_text = \"Please review the meeting notes and provide your feedback by Friday.\"\n\nspam_result = classify_text(spam_text)\nlegit_result = classify_text(legit_text)\n\nprint(f\"Text: '{spam_text}'\")\nprint(f\"Classification: {spam_result.label}\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 47,
          "line_range": [
            47,
            54
          ]
        },
        {
          "code": "# Output: Classification: SPAM\n",
          "display_code": "",
          "annotation": "Output: Classification: SPAM",
          "is_comment": true,
          "start_line": 55,
          "line_range": [
            55,
            55
          ],
          "target_line_range": [
            56,
            58
          ]
        },
        {
          "code": "\nprint(f\"\\nText: '{legit_text}'\")\nprint(f\"Classification: {legit_result.label}\")\n",
          "display_code": "\nprint(f\"\\nText: '{legit_text}'\")\nprint(f\"Classification: {legit_result.label}\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 56,
          "line_range": [
            56,
            58
          ]
        },
        {
          "code": "# Output: Classification: NOT_SPAM\n",
          "display_code": "",
          "annotation": "Output: Classification: NOT_SPAM",
          "is_comment": true,
          "start_line": 59,
          "line_range": [
            59,
            59
          ],
          "target_line_range": [
            60,
            89
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field\nfrom typing import Literal\n\nclass ClassificationWithConfidence(BaseModel):\n    label: Literal[\"SPAM\", \"NOT_SPAM\"]\n    confidence: float = Field(\n        gt=0, le=1,  # Greater than 0, less than or equal to 1\n        description=\"Confidence score between 0 and 1 (higher = more confident)\"\n    )\n\ndef classify_with_confidence(text: str) -> ClassificationWithConfidence:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=ClassificationWithConfidence,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Classify the text as SPAM or NOT_SPAM with a confidence score.\"\n            },\n            {\"role\": \"user\", \"content\": f\"Classify this text: {text}\"}\n        ]\n    )\n\nborderline_text = \"Get your free account upgrade today. Limited availability.\"\nresult = classify_with_confidence(borderline_text)\n\nprint(f\"Text: '{borderline_text}'\")\nprint(f\"Classification: {result.label}\")\nprint(f\"Confidence: {result.confidence:.2f}\")\n",
          "display_code": "\nfrom pydantic import BaseModel, Field\nfrom typing import Literal\n\nclass ClassificationWithConfidence(BaseModel):\n    label: Literal[\"SPAM\", \"NOT_SPAM\"]\n    confidence: float = Field(\n        gt=0, le=1,  # Greater than 0, less than or equal to 1\n        description=\"Confidence score between 0 and 1 (higher = more confident)\"\n    )\n\ndef classify_with_confidence(text: str) -> ClassificationWithConfidence:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=ClassificationWithConfidence,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Classify the text as SPAM or NOT_SPAM with a confidence score.\"\n            },\n            {\"role\": \"user\", \"content\": f\"Classify this text: {text}\"}\n        ]\n    )\n\nborderline_text = \"Get your free account upgrade today. Limited availability.\"\nresult = classify_with_confidence(borderline_text)\n\nprint(f\"Text: '{borderline_text}'\")\nprint(f\"Classification: {result.label}\")\nprint(f\"Confidence: {result.confidence:.2f}\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 60,
          "line_range": [
            60,
            89
          ]
        },
        {
          "code": "# Example Output:\n# Classification: SPAM\n# Confidence: 0.75\n",
          "display_code": "",
          "annotation": "Example Output:\nClassification: SPAM\nConfidence: 0.75",
          "is_comment": true,
          "start_line": 90,
          "line_range": [
            90,
            92
          ],
          "target_line_range": [
            93,
            129
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field\nfrom typing import Literal\n\nclass DetailedClassification(BaseModel):\n    label: Literal[\"SPAM\", \"NOT_SPAM\"]\n    explanation: str = Field(\n        description=\"Detailed reasoning for this classification\"\n    )\n    spam_indicators: list[str] = Field(\n        default_factory=list,\n        description=\"List of specific elements that indicate spam, if any\"\n    )\n\ndef classify_with_details(text: str) -> DetailedClassification:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=DetailedClassification,\n        messages=[\n            {\"role\": \"system\", \"content\": \"Classify the text and provide a detailed explanation.\"},\n            {\"role\": \"user\", \"content\": f\"Classify this text: {text}\"}\n        ]\n    )\n\ntext = \"CONGRATULATIONS! You've been selected to receive a free iPhone! Click now to claim: bit.ly/claim-prize\"\nresult = classify_with_details(text)\n\nprint(f\"Text: '{text}'\")\nprint(f\"Classification: {result.label}\")\nprint(f\"Explanation: {result.explanation}\")\nprint(\"Spam indicators:\")\nfor indicator in result.spam_indicators:\n    print(f\"- {indicator}\")\n\nfrom typing import List\n\ndef classify_batch(texts: List[str]) -> List[Classification]:\n",
          "display_code": "\nfrom pydantic import BaseModel, Field\nfrom typing import Literal\n\nclass DetailedClassification(BaseModel):\n    label: Literal[\"SPAM\", \"NOT_SPAM\"]\n    explanation: str = Field(\n        description=\"Detailed reasoning for this classification\"\n    )\n    spam_indicators: list[str] = Field(\n        default_factory=list,\n        description=\"List of specific elements that indicate spam, if any\"\n    )\n\ndef classify_with_details(text: str) -> DetailedClassification:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=DetailedClassification,\n        messages=[\n            {\"role\": \"system\", \"content\": \"Classify the text and provide a detailed explanation.\"},\n            {\"role\": \"user\", \"content\": f\"Classify this text: {text}\"}\n        ]\n    )\n\ntext = \"CONGRATULATIONS! You've been selected to receive a free iPhone! Click now to claim: bit.ly/claim-prize\"\nresult = classify_with_details(text)\n\nprint(f\"Text: '{text}'\")\nprint(f\"Classification: {result.label}\")\nprint(f\"Explanation: {result.explanation}\")\nprint(\"Spam indicators:\")\nfor indicator in result.spam_indicators:\n    print(f\"- {indicator}\")\n\nfrom typing import List\n\ndef classify_batch(texts: List[str]) -> List[Classification]:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 93,
          "line_range": [
            93,
            129
          ]
        },
        {
          "code": "    # Use a batch prompt to classify multiple texts at once\n",
          "display_code": "",
          "annotation": "Use a batch prompt to classify multiple texts at once",
          "is_comment": true,
          "start_line": 130,
          "line_range": [
            130,
            130
          ],
          "target_line_range": [
            131,
            141
          ]
        },
        {
          "code": "    formatted_texts = \"\\n\\n\".join([f\"Text {i+1}: {text}\" for i, text in enumerate(texts)])\n\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=List[Classification],\n        messages=[\n            {\"role\": \"system\", \"content\": \"Classify each text as SPAM or NOT_SPAM.\"},\n            {\"role\": \"user\", \"content\": f\"Classify these texts:\\n\\n{formatted_texts}\"}\n        ]\n    )\n\n",
          "display_code": "    formatted_texts = \"\\n\\n\".join([f\"Text {i+1}: {text}\" for i, text in enumerate(texts)])\n\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=List[Classification],\n        messages=[\n            {\"role\": \"system\", \"content\": \"Classify each text as SPAM or NOT_SPAM.\"},\n            {\"role\": \"user\", \"content\": f\"Classify these texts:\\n\\n{formatted_texts}\"}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 131,
          "line_range": [
            131,
            141
          ]
        },
        {
          "code": "# Test with a batch of texts\n",
          "display_code": "",
          "annotation": "Test with a batch of texts",
          "is_comment": true,
          "start_line": 142,
          "line_range": [
            142,
            142
          ],
          "target_line_range": [
            143,
            154
          ]
        },
        {
          "code": "texts = [\n    \"Your application has been approved. Sign the documents at your earliest convenience.\",\n    \"WINNER! You've been selected to receive $1000! Send your bank details now!\",\n    \"Meeting rescheduled to 3PM tomorrow. Same Zoom link.\"\n]\n\nresults = classify_batch(texts)\n\nfor i, (text, result) in enumerate(zip(texts, results)):\n    print(f\"Text {i+1}: '{text}'\")\n    print(f\"Classification: {result.label}\\n\")\n\n",
          "display_code": "texts = [\n    \"Your application has been approved. Sign the documents at your earliest convenience.\",\n    \"WINNER! You've been selected to receive $1000! Send your bank details now!\",\n    \"Meeting rescheduled to 3PM tomorrow. Same Zoom link.\"\n]\n\nresults = classify_batch(texts)\n\nfor i, (text, result) in enumerate(zip(texts, results)):\n    print(f\"Text {i+1}: '{text}'\")\n    print(f\"Classification: {result.label}\\n\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 143,
          "line_range": [
            143,
            154
          ]
        },
        {
          "code": "# Output:\n# Text 1: 'Your application has been approved. Sign the documents at your earliest convenience.'\n# Classification: NOT_SPAM\n#\n# Text 2: 'WINNER! You've been selected to receive $1000! Send your bank details now!'\n# Classification: SPAM\n#\n# Text 3: 'Meeting rescheduled to 3PM tomorrow. Same Zoom link.'\n# Classification: NOT_SPAM\n",
          "display_code": "",
          "annotation": "Output:\nText 1: 'Your application has been approved. Sign the documents at your earliest convenience.'\nClassification: NOT_SPAM\n\nText 2: 'WINNER! You've been selected to receive $1000! Send your bank details now!'\nClassification: SPAM\n\nText 3: 'Meeting rescheduled to 3PM tomorrow. Same Zoom link.'\nClassification: NOT_SPAM",
          "is_comment": true,
          "start_line": 155,
          "line_range": [
            155,
            163
          ],
          "target_line_range": [
            164,
            164
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 164,
          "line_range": [
            164,
            164
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python simple-classification.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "004-classification",
      "section_title": "Classification and Analysis"
    },
    {
      "id": "019-multi-label-classification",
      "title": "Multi-label Classification",
      "description": "",
      "order": 19,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# \n",
          "display_code": "",
          "annotation": "",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Extract multiple labels from text using Instructor.\n",
          "display_code": "",
          "annotation": "Extract multiple labels from text using Instructor.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            17
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\nfrom typing import List\nimport instructor\nfrom openai import OpenAI\n\nclass MultiLabelClassification(BaseModel):\n    \"\"\"Multi-label classification of text content\"\"\"\n\n    labels: List[str] = Field(\n        description=\"List of applicable category labels for the text\"\n    )\n\n",
          "display_code": "from pydantic import BaseModel, Field\nfrom typing import List\nimport instructor\nfrom openai import OpenAI\n\nclass MultiLabelClassification(BaseModel):\n    \"\"\"Multi-label classification of text content\"\"\"\n\n    labels: List[str] = Field(\n        description=\"List of applicable category labels for the text\"\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            17
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 18,
          "line_range": [
            18,
            18
          ],
          "target_line_range": [
            19,
            45
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\ndef classify_text(text: str) -> MultiLabelClassification:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=MultiLabelClassification,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"\"\"\n                Classify the text into one or more of these categories:\n                - Technology\n                - Finance\n                - Health\n                - Sports\n                - Entertainment\n                - Politics\n                - Science\n                - Education\n\n                Return all categories that apply to the text.\n                \"\"\"\n            },\n            {\"role\": \"user\", \"content\": f\"Text for classification: {text}\"}\n        ]\n    )\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\ndef classify_text(text: str) -> MultiLabelClassification:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=MultiLabelClassification,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"\"\"\n                Classify the text into one or more of these categories:\n                - Technology\n                - Finance\n                - Health\n                - Sports\n                - Entertainment\n                - Politics\n                - Science\n                - Education\n\n                Return all categories that apply to the text.\n                \"\"\"\n            },\n            {\"role\": \"user\", \"content\": f\"Text for classification: {text}\"}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 19,
          "line_range": [
            19,
            45
          ]
        },
        {
          "code": "# Test with an example\n",
          "display_code": "",
          "annotation": "Test with an example",
          "is_comment": true,
          "start_line": 46,
          "line_range": [
            46,
            46
          ],
          "target_line_range": [
            47,
            56
          ]
        },
        {
          "code": "article = \"\"\"\n    Bitcoin prices surged to a new all-time high today as several tech companies announced\n    plans to add the cryptocurrency to their balance sheets. Health officials warned that\n    the excitement might cause stress for some investors.\n\"\"\"\n\nresult = classify_text(article)\n\nprint(f\"Text: '{article}'\")\nprint(f\"Labels: {', '.join(result.labels)}\")\n",
          "display_code": "article = \"\"\"\n    Bitcoin prices surged to a new all-time high today as several tech companies announced\n    plans to add the cryptocurrency to their balance sheets. Health officials warned that\n    the excitement might cause stress for some investors.\n\"\"\"\n\nresult = classify_text(article)\n\nprint(f\"Text: '{article}'\")\nprint(f\"Labels: {', '.join(result.labels)}\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 47,
          "line_range": [
            47,
            56
          ]
        },
        {
          "code": "# Example Output: Labels: Technology, Finance, Health\n",
          "display_code": "",
          "annotation": "Example Output: Labels: Technology, Finance, Health",
          "is_comment": true,
          "start_line": 57,
          "line_range": [
            57,
            57
          ],
          "target_line_range": [
            58,
            62
          ]
        },
        {
          "code": "\nfrom enum import Enum\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\n",
          "display_code": "\nfrom enum import Enum\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 58,
          "line_range": [
            58,
            62
          ]
        },
        {
          "code": "# Define fixed categories as an enum\n",
          "display_code": "",
          "annotation": "Define fixed categories as an enum",
          "is_comment": true,
          "start_line": 63,
          "line_range": [
            63,
            63
          ],
          "target_line_range": [
            64,
            99
          ]
        },
        {
          "code": "class Category(str, Enum):\n    BUSINESS = \"business\"\n    TECHNOLOGY = \"technology\"\n    POLITICS = \"politics\"\n    HEALTH = \"health\"\n    ENTERTAINMENT = \"entertainment\"\n    SPORTS = \"sports\"\n    SCIENCE = \"science\"\n    EDUCATION = \"education\"\n\nclass EnumMultiLabelClassification(BaseModel):\n    \"\"\"Multi-label classification using predefined categories\"\"\"\n\n    categories: List[Category] = Field(\n        description=\"List of applicable categories from the predefined set\"\n    )\n\ndef classify_with_enums(text: str) -> EnumMultiLabelClassification:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=EnumMultiLabelClassification,\n        messages=[\n            {\"role\": \"system\", \"content\": \"Classify the text into one or more predefined categories.\"},\n            {\"role\": \"user\", \"content\": f\"Text for classification: {text}\"}\n        ]\n    )\n\narticle = \"\"\"\n    New educational technology is transforming classrooms across the country.\n    Students are using AI-powered tools to enhance their learning experiences.\n\"\"\"\n\nresult = classify_with_enums(article)\n\nprint(f\"Text: '{article}'\")\nprint(f\"Categories: {', '.join([c.value for c in result.categories])}\")\n",
          "display_code": "class Category(str, Enum):\n    BUSINESS = \"business\"\n    TECHNOLOGY = \"technology\"\n    POLITICS = \"politics\"\n    HEALTH = \"health\"\n    ENTERTAINMENT = \"entertainment\"\n    SPORTS = \"sports\"\n    SCIENCE = \"science\"\n    EDUCATION = \"education\"\n\nclass EnumMultiLabelClassification(BaseModel):\n    \"\"\"Multi-label classification using predefined categories\"\"\"\n\n    categories: List[Category] = Field(\n        description=\"List of applicable categories from the predefined set\"\n    )\n\ndef classify_with_enums(text: str) -> EnumMultiLabelClassification:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=EnumMultiLabelClassification,\n        messages=[\n            {\"role\": \"system\", \"content\": \"Classify the text into one or more predefined categories.\"},\n            {\"role\": \"user\", \"content\": f\"Text for classification: {text}\"}\n        ]\n    )\n\narticle = \"\"\"\n    New educational technology is transforming classrooms across the country.\n    Students are using AI-powered tools to enhance their learning experiences.\n\"\"\"\n\nresult = classify_with_enums(article)\n\nprint(f\"Text: '{article}'\")\nprint(f\"Categories: {', '.join([c.value for c in result.categories])}\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 64,
          "line_range": [
            64,
            99
          ]
        },
        {
          "code": "# Example Output: Categories: technology, education\n",
          "display_code": "",
          "annotation": "Example Output: Categories: technology, education",
          "is_comment": true,
          "start_line": 100,
          "line_range": [
            100,
            100
          ],
          "target_line_range": [
            101,
            146
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Dict\n\nclass LabelWithConfidence(BaseModel):\n    label: str\n    confidence: float = Field(gt=0, le=1)  # Between 0 and 1\n\nclass ConfidenceClassification(BaseModel):\n    labels: List[LabelWithConfidence] = Field(\n        description=\"List of applicable labels with confidence scores\"\n    )\n\ndef classify_with_confidence(text: str) -> ConfidenceClassification:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=ConfidenceClassification,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"\"\"\n                Classify the text into these categories and provide confidence scores (0-1):\n                - Technology\n                - Finance\n                - Health\n                - Sports\n                - Entertainment\n                Only include categories that apply with a confidence score over 0.4.\n                \"\"\"\n            },\n            {\"role\": \"user\", \"content\": f\"Text for classification: {text}\"}\n        ]\n    )\n\narticle = \"\"\"\n    The new smartphone features a built-in heart rate monitor that can alert users\n    about potential cardiac issues while they exercise.\n\"\"\"\n\nresult = classify_with_confidence(article)\n\nprint(f\"Text: '{article}'\")\nprint(\"Labels with confidence:\")\nfor label in result.labels:\n    print(f\"- {label.label}: {label.confidence:.2f}\")\n\n",
          "display_code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Dict\n\nclass LabelWithConfidence(BaseModel):\n    label: str\n    confidence: float = Field(gt=0, le=1)  # Between 0 and 1\n\nclass ConfidenceClassification(BaseModel):\n    labels: List[LabelWithConfidence] = Field(\n        description=\"List of applicable labels with confidence scores\"\n    )\n\ndef classify_with_confidence(text: str) -> ConfidenceClassification:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=ConfidenceClassification,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"\"\"\n                Classify the text into these categories and provide confidence scores (0-1):\n                - Technology\n                - Finance\n                - Health\n                - Sports\n                - Entertainment\n                Only include categories that apply with a confidence score over 0.4.\n                \"\"\"\n            },\n            {\"role\": \"user\", \"content\": f\"Text for classification: {text}\"}\n        ]\n    )\n\narticle = \"\"\"\n    The new smartphone features a built-in heart rate monitor that can alert users\n    about potential cardiac issues while they exercise.\n\"\"\"\n\nresult = classify_with_confidence(article)\n\nprint(f\"Text: '{article}'\")\nprint(\"Labels with confidence:\")\nfor label in result.labels:\n    print(f\"- {label.label}: {label.confidence:.2f}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 101,
          "line_range": [
            101,
            146
          ]
        },
        {
          "code": "# Example Output:\n# Labels with confidence:\n# - Technology: 0.95\n# - Health: 0.85\n# - Sports: 0.62\n",
          "display_code": "",
          "annotation": "Example Output:\nLabels with confidence:\n- Technology: 0.95\n- Health: 0.85\n- Sports: 0.62",
          "is_comment": true,
          "start_line": 147,
          "line_range": [
            147,
            151
          ],
          "target_line_range": [
            152,
            206
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass SubCategory(BaseModel):\n    name: str\n    confidence: float = Field(gt=0, le=1)\n\nclass MainCategory(BaseModel):\n    name: str\n    confidence: float = Field(gt=0, le=1)\n    subcategories: List[SubCategory] = []\n\nclass HierarchicalClassification(BaseModel):\n    categories: List[MainCategory] = Field(\n        description=\"Hierarchical categories with confidence scores\"\n    )\n\ndef classify_hierarchical(text: str) -> HierarchicalClassification:\n    return client.chat.completions.create(\n        model=\"gpt-4\",  # More complex tasks work better with GPT-4\n        response_model=HierarchicalClassification,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"\"\"\n                Classify the text into main categories and subcategories:\n\n                Main categories:\n                - Technology (subcategories: Hardware, Software, AI, Internet)\n                - Science (subcategories: Physics, Biology, Chemistry, Astronomy)\n                - Health (subcategories: Fitness, Nutrition, Medical, Mental Health)\n\n                Return only relevant categories with confidence scores.\n                \"\"\"\n            },\n            {\"role\": \"user\", \"content\": f\"Text for classification: {text}\"}\n        ]\n    )\n\narticle = \"\"\"\n    Researchers have developed a new AI algorithm that can detect early signs of\n    Alzheimer's disease from brain scans with 94% accuracy. The deep learning software\n    could help doctors diagnose patients years earlier than current methods.\n\"\"\"\n\nresult = classify_hierarchical(article)\n\nprint(f\"Text: '{article}'\")\nprint(\"Classification:\")\nfor category in result.categories:\n    print(f\"- {category.name} ({category.confidence:.2f})\")\n    for subcategory in category.subcategories:\n        print(f\"  - {subcategory.name} ({subcategory.confidence:.2f})\")\n\n",
          "display_code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass SubCategory(BaseModel):\n    name: str\n    confidence: float = Field(gt=0, le=1)\n\nclass MainCategory(BaseModel):\n    name: str\n    confidence: float = Field(gt=0, le=1)\n    subcategories: List[SubCategory] = []\n\nclass HierarchicalClassification(BaseModel):\n    categories: List[MainCategory] = Field(\n        description=\"Hierarchical categories with confidence scores\"\n    )\n\ndef classify_hierarchical(text: str) -> HierarchicalClassification:\n    return client.chat.completions.create(\n        model=\"gpt-4\",  # More complex tasks work better with GPT-4\n        response_model=HierarchicalClassification,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"\"\"\n                Classify the text into main categories and subcategories:\n\n                Main categories:\n                - Technology (subcategories: Hardware, Software, AI, Internet)\n                - Science (subcategories: Physics, Biology, Chemistry, Astronomy)\n                - Health (subcategories: Fitness, Nutrition, Medical, Mental Health)\n\n                Return only relevant categories with confidence scores.\n                \"\"\"\n            },\n            {\"role\": \"user\", \"content\": f\"Text for classification: {text}\"}\n        ]\n    )\n\narticle = \"\"\"\n    Researchers have developed a new AI algorithm that can detect early signs of\n    Alzheimer's disease from brain scans with 94% accuracy. The deep learning software\n    could help doctors diagnose patients years earlier than current methods.\n\"\"\"\n\nresult = classify_hierarchical(article)\n\nprint(f\"Text: '{article}'\")\nprint(\"Classification:\")\nfor category in result.categories:\n    print(f\"- {category.name} ({category.confidence:.2f})\")\n    for subcategory in category.subcategories:\n        print(f\"  - {subcategory.name} ({subcategory.confidence:.2f})\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 152,
          "line_range": [
            152,
            206
          ]
        },
        {
          "code": "# Example Output:\n# Classification:\n# - Technology (0.90)\n#   - AI (0.95)\n#   - Software (0.80)\n# - Health (0.85)\n#   - Medical (0.90)\n# - Science (0.75)\n#   - Biology (0.70)\n",
          "display_code": "",
          "annotation": "Example Output:\nClassification:\n- Technology (0.90)\n- AI (0.95)\n- Software (0.80)\n- Health (0.85)\n- Medical (0.90)\n- Science (0.75)\n- Biology (0.70)",
          "is_comment": true,
          "start_line": 207,
          "line_range": [
            207,
            215
          ],
          "target_line_range": [
            216,
            216
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 216,
          "line_range": [
            216,
            216
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python multi-label-classification.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "004-classification",
      "section_title": "Classification and Analysis"
    },
    {
      "id": "020-sentiment-analysis",
      "title": "Sentiment Analysis",
      "description": "",
      "order": 20,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# \n",
          "display_code": "",
          "annotation": "",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Perform sentiment analysis on text with structured outputs using Instructor.\n",
          "display_code": "",
          "annotation": "Perform sentiment analysis on text with structured outputs using Instructor.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            17
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\nfrom typing import Literal\nimport instructor\nfrom openai import OpenAI\n\nclass Sentiment(BaseModel):\n    \"\"\"Sentiment analysis result\"\"\"\n\n    sentiment: Literal[\"positive\", \"neutral\", \"negative\"] = Field(\n        description=\"The overall sentiment of the text\"\n    )\n\n",
          "display_code": "from pydantic import BaseModel, Field\nfrom typing import Literal\nimport instructor\nfrom openai import OpenAI\n\nclass Sentiment(BaseModel):\n    \"\"\"Sentiment analysis result\"\"\"\n\n    sentiment: Literal[\"positive\", \"neutral\", \"negative\"] = Field(\n        description=\"The overall sentiment of the text\"\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            17
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 18,
          "line_range": [
            18,
            18
          ],
          "target_line_range": [
            19,
            30
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\ndef analyze_sentiment(text: str) -> Sentiment:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=Sentiment,\n        messages=[\n            {\"role\": \"system\", \"content\": \"Analyze the sentiment of the provided text.\"},\n            {\"role\": \"user\", \"content\": f\"Text: {text}\"}\n        ]\n    )\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\ndef analyze_sentiment(text: str) -> Sentiment:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=Sentiment,\n        messages=[\n            {\"role\": \"system\", \"content\": \"Analyze the sentiment of the provided text.\"},\n            {\"role\": \"user\", \"content\": f\"Text: {text}\"}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 19,
          "line_range": [
            19,
            30
          ]
        },
        {
          "code": "# Test with examples\n",
          "display_code": "",
          "annotation": "Test with examples",
          "is_comment": true,
          "start_line": 31,
          "line_range": [
            31,
            31
          ],
          "target_line_range": [
            32,
            42
          ]
        },
        {
          "code": "examples = [\n    \"I absolutely love this product! It exceeded all my expectations.\",\n    \"The service was okay. Nothing special but got the job done.\",\n    \"This is the worst experience I've ever had. Complete waste of money.\"\n]\n\nfor text in examples:\n    result = analyze_sentiment(text)\n    print(f\"Text: '{text}'\")\n    print(f\"Sentiment: {result.sentiment}\\n\")\n\n",
          "display_code": "examples = [\n    \"I absolutely love this product! It exceeded all my expectations.\",\n    \"The service was okay. Nothing special but got the job done.\",\n    \"This is the worst experience I've ever had. Complete waste of money.\"\n]\n\nfor text in examples:\n    result = analyze_sentiment(text)\n    print(f\"Text: '{text}'\")\n    print(f\"Sentiment: {result.sentiment}\\n\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 32,
          "line_range": [
            32,
            42
          ]
        },
        {
          "code": "# Example Output:\n# Text: 'I absolutely love this product! It exceeded all my expectations.'\n# Sentiment: positive\n#\n# Text: 'The service was okay. Nothing special but got the job done.'\n# Sentiment: neutral\n#\n# Text: 'This is the worst experience I've ever had. Complete waste of money.'\n# Sentiment: negative\n",
          "display_code": "",
          "annotation": "Example Output:\nText: 'I absolutely love this product! It exceeded all my expectations.'\nSentiment: positive\n\nText: 'The service was okay. Nothing special but got the job done.'\nSentiment: neutral\n\nText: 'This is the worst experience I've ever had. Complete waste of money.'\nSentiment: negative",
          "is_comment": true,
          "start_line": 43,
          "line_range": [
            43,
            51
          ],
          "target_line_range": [
            52,
            84
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field\n\nclass SentimentWithScore(BaseModel):\n    \"\"\"Sentiment analysis with numeric score\"\"\"\n\n    score: float = Field(\n        ge=-1.0, le=1.0,  # Between -1.0 and 1.0\n        description=\"Sentiment score from -1.0 (very negative) to 1.0 (very positive)\"\n    )\n\n    @property\n    def sentiment(self) -> str:\n        if self.score > 0.3:\n            return \"positive\"\n        elif self.score < -0.3:\n            return \"negative\"\n        else:\n            return \"neutral\"\n\ndef analyze_sentiment_with_score(text: str) -> SentimentWithScore:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=SentimentWithScore,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Analyze the sentiment of the text and provide a score from -1.0 (very negative) to 1.0 (very positive).\"\n            },\n            {\"role\": \"user\", \"content\": f\"Text: {text}\"}\n        ]\n    )\n\n",
          "display_code": "\nfrom pydantic import BaseModel, Field\n\nclass SentimentWithScore(BaseModel):\n    \"\"\"Sentiment analysis with numeric score\"\"\"\n\n    score: float = Field(\n        ge=-1.0, le=1.0,  # Between -1.0 and 1.0\n        description=\"Sentiment score from -1.0 (very negative) to 1.0 (very positive)\"\n    )\n\n    @property\n    def sentiment(self) -> str:\n        if self.score > 0.3:\n            return \"positive\"\n        elif self.score < -0.3:\n            return \"negative\"\n        else:\n            return \"neutral\"\n\ndef analyze_sentiment_with_score(text: str) -> SentimentWithScore:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=SentimentWithScore,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Analyze the sentiment of the text and provide a score from -1.0 (very negative) to 1.0 (very positive).\"\n            },\n            {\"role\": \"user\", \"content\": f\"Text: {text}\"}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 52,
          "line_range": [
            52,
            84
          ]
        },
        {
          "code": "# Test with examples\n",
          "display_code": "",
          "annotation": "Test with examples",
          "is_comment": true,
          "start_line": 85,
          "line_range": [
            85,
            85
          ],
          "target_line_range": [
            86,
            97
          ]
        },
        {
          "code": "examples = [\n    \"The movie was absolutely phenomenal. Best I've seen in years!\",\n    \"The new update is slightly better than the previous version.\",\n    \"I'm really disappointed with the customer service response time.\"\n]\n\nfor text in examples:\n    result = analyze_sentiment_with_score(text)\n    print(f\"Text: '{text}'\")\n    print(f\"Score: {result.score:.2f}\")\n    print(f\"Sentiment: {result.sentiment}\\n\")\n\n",
          "display_code": "examples = [\n    \"The movie was absolutely phenomenal. Best I've seen in years!\",\n    \"The new update is slightly better than the previous version.\",\n    \"I'm really disappointed with the customer service response time.\"\n]\n\nfor text in examples:\n    result = analyze_sentiment_with_score(text)\n    print(f\"Text: '{text}'\")\n    print(f\"Score: {result.score:.2f}\")\n    print(f\"Sentiment: {result.sentiment}\\n\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 86,
          "line_range": [
            86,
            97
          ]
        },
        {
          "code": "# Example Output:\n# Text: 'The movie was absolutely phenomenal. Best I've seen in years!'\n# Score: 0.95\n# Sentiment: positive\n#\n# Text: 'The new update is slightly better than the previous version.'\n# Score: 0.20\n# Sentiment: neutral\n#\n# Text: 'I'm really disappointed with the customer service response time.'\n# Score: -0.75\n# Sentiment: negative\n",
          "display_code": "",
          "annotation": "Example Output:\nText: 'The movie was absolutely phenomenal. Best I've seen in years!'\nScore: 0.95\nSentiment: positive\n\nText: 'The new update is slightly better than the previous version.'\nScore: 0.20\nSentiment: neutral\n\nText: 'I'm really disappointed with the customer service response time.'\nScore: -0.75\nSentiment: negative",
          "is_comment": true,
          "start_line": 98,
          "line_range": [
            98,
            109
          ],
          "target_line_range": [
            110,
            142
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Literal, Optional\n\nclass AspectSentiment(BaseModel):\n    aspect: str = Field(description=\"The specific aspect being evaluated\")\n    sentiment: Literal[\"positive\", \"neutral\", \"negative\"]\n    explanation: str = Field(description=\"Brief explanation of the sentiment\")\n\nclass DetailedSentiment(BaseModel):\n    overall_sentiment: Literal[\"positive\", \"neutral\", \"negative\"] = Field(\n        description=\"The overall sentiment of the entire text\"\n    )\n    aspects: List[AspectSentiment] = Field(\n        description=\"Sentiment breakdown by specific aspects mentioned in the text\"\n    )\n    summary: str = Field(\n        description=\"A brief summary of the sentiment analysis\"\n    )\n\ndef analyze_detailed_sentiment(text: str) -> DetailedSentiment:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=DetailedSentiment,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Perform a detailed sentiment analysis, breaking down sentiment by aspects.\"\n            },\n            {\"role\": \"user\", \"content\": f\"Text: {text}\"}\n        ]\n    )\n\n",
          "display_code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Literal, Optional\n\nclass AspectSentiment(BaseModel):\n    aspect: str = Field(description=\"The specific aspect being evaluated\")\n    sentiment: Literal[\"positive\", \"neutral\", \"negative\"]\n    explanation: str = Field(description=\"Brief explanation of the sentiment\")\n\nclass DetailedSentiment(BaseModel):\n    overall_sentiment: Literal[\"positive\", \"neutral\", \"negative\"] = Field(\n        description=\"The overall sentiment of the entire text\"\n    )\n    aspects: List[AspectSentiment] = Field(\n        description=\"Sentiment breakdown by specific aspects mentioned in the text\"\n    )\n    summary: str = Field(\n        description=\"A brief summary of the sentiment analysis\"\n    )\n\ndef analyze_detailed_sentiment(text: str) -> DetailedSentiment:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=DetailedSentiment,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Perform a detailed sentiment analysis, breaking down sentiment by aspects.\"\n            },\n            {\"role\": \"user\", \"content\": f\"Text: {text}\"}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 110,
          "line_range": [
            110,
            142
          ]
        },
        {
          "code": "# Test with a product review\n",
          "display_code": "",
          "annotation": "Test with a product review",
          "is_comment": true,
          "start_line": 143,
          "line_range": [
            143,
            143
          ],
          "target_line_range": [
            144,
            161
          ]
        },
        {
          "code": "review = \"\"\"\n    I recently purchased the XYZ Bluetooth headphones. The sound quality is amazing and\n    battery life exceeds expectations - nearly 30 hours on a single charge! However,\n    they're a bit too tight on my head after a few hours, which gets uncomfortable.\n    The price was reasonable for the quality. Customer service was unhelpful when I asked\n    about adjustment options.\n\"\"\"\n\nresult = analyze_detailed_sentiment(review)\n\nprint(f\"Overall Sentiment: {result.overall_sentiment}\")\nprint(\"\\nAspect Breakdown:\")\nfor aspect in result.aspects:\n    print(f\"- {aspect.aspect}: {aspect.sentiment}\")\n    print(f\"  {aspect.explanation}\")\n\nprint(f\"\\nSummary: {result.summary}\")\n\n",
          "display_code": "review = \"\"\"\n    I recently purchased the XYZ Bluetooth headphones. The sound quality is amazing and\n    battery life exceeds expectations - nearly 30 hours on a single charge! However,\n    they're a bit too tight on my head after a few hours, which gets uncomfortable.\n    The price was reasonable for the quality. Customer service was unhelpful when I asked\n    about adjustment options.\n\"\"\"\n\nresult = analyze_detailed_sentiment(review)\n\nprint(f\"Overall Sentiment: {result.overall_sentiment}\")\nprint(\"\\nAspect Breakdown:\")\nfor aspect in result.aspects:\n    print(f\"- {aspect.aspect}: {aspect.sentiment}\")\n    print(f\"  {aspect.explanation}\")\n\nprint(f\"\\nSummary: {result.summary}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 144,
          "line_range": [
            144,
            161
          ]
        },
        {
          "code": "# Example Output:\n# Overall Sentiment: positive\n#\n# Aspect Breakdown:\n# - Sound Quality: positive\n#   The reviewer describes the sound quality as \"amazing\"\n# - Battery Life: positive\n#   The battery life \"exceeds expectations\" with nearly 30 hours on a single charge\n# - Comfort: negative\n#   The headphones are described as \"too tight\" and \"uncomfortable\" after extended use\n# - Price: positive\n#   The reviewer found the price \"reasonable for the quality\"\n# - Customer Service: negative\n#   Customer service was described as \"unhelpful\"\n#\n# Summary: The review is overall positive, particularly praising sound quality, battery life, and price,\n# but notes issues with comfort and customer service.\n",
          "display_code": "",
          "annotation": "Example Output:\nOverall Sentiment: positive\n\nAspect Breakdown:\n- Sound Quality: positive\nThe reviewer describes the sound quality as \"amazing\"\n- Battery Life: positive\nThe battery life \"exceeds expectations\" with nearly 30 hours on a single charge\n- Comfort: negative\nThe headphones are described as \"too tight\" and \"uncomfortable\" after extended use\n- Price: positive\nThe reviewer found the price \"reasonable for the quality\"\n- Customer Service: negative\nCustomer service was described as \"unhelpful\"\n\nSummary: The review is overall positive, particularly praising sound quality, battery life, and price,\nbut notes issues with comfort and customer service.",
          "is_comment": true,
          "start_line": 162,
          "line_range": [
            162,
            178
          ],
          "target_line_range": [
            179,
            214
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Literal, Optional\nfrom datetime import datetime\n\nclass Emotion(BaseModel):\n    name: str\n    intensity: float = Field(ge=0, le=1)  # 0-1 scale\n\nclass SocialMediaSentiment(BaseModel):\n    primary_sentiment: Literal[\"positive\", \"neutral\", \"negative\"]\n    emotions: List[Emotion] = Field(description=\"Emotions detected in the text with intensity\")\n    is_sarcastic: bool = Field(description=\"Whether the text appears to contain sarcasm\")\n    topics: List[str] = Field(description=\"Key topics mentioned in the text\")\n    action_items: Optional[List[str]] = Field(\n        default=None,\n        description=\"Suggested actions if this is a customer complaint or request\"\n    )\n    urgency: int = Field(\n        ge=1, le=5,\n        description=\"Urgency level from 1 (not urgent) to 5 (extremely urgent)\"\n    )\n\ndef analyze_social_post(text: str) -> SocialMediaSentiment:\n    return client.chat.completions.create(\n        model=\"gpt-4\",  # Using GPT-4 for more nuanced analysis\n        response_model=SocialMediaSentiment,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Analyze this social media post for sentiment, emotions, sarcasm, and topics.\"\n            },\n            {\"role\": \"user\", \"content\": f\"Social Media Post: {text}\"}\n        ]\n    )\n\n",
          "display_code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Literal, Optional\nfrom datetime import datetime\n\nclass Emotion(BaseModel):\n    name: str\n    intensity: float = Field(ge=0, le=1)  # 0-1 scale\n\nclass SocialMediaSentiment(BaseModel):\n    primary_sentiment: Literal[\"positive\", \"neutral\", \"negative\"]\n    emotions: List[Emotion] = Field(description=\"Emotions detected in the text with intensity\")\n    is_sarcastic: bool = Field(description=\"Whether the text appears to contain sarcasm\")\n    topics: List[str] = Field(description=\"Key topics mentioned in the text\")\n    action_items: Optional[List[str]] = Field(\n        default=None,\n        description=\"Suggested actions if this is a customer complaint or request\"\n    )\n    urgency: int = Field(\n        ge=1, le=5,\n        description=\"Urgency level from 1 (not urgent) to 5 (extremely urgent)\"\n    )\n\ndef analyze_social_post(text: str) -> SocialMediaSentiment:\n    return client.chat.completions.create(\n        model=\"gpt-4\",  # Using GPT-4 for more nuanced analysis\n        response_model=SocialMediaSentiment,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Analyze this social media post for sentiment, emotions, sarcasm, and topics.\"\n            },\n            {\"role\": \"user\", \"content\": f\"Social Media Post: {text}\"}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 179,
          "line_range": [
            179,
            214
          ]
        },
        {
          "code": "# Example social media posts\n",
          "display_code": "",
          "annotation": "Example social media posts",
          "is_comment": true,
          "start_line": 215,
          "line_range": [
            215,
            215
          ],
          "target_line_range": [
            216,
            238
          ]
        },
        {
          "code": "posts = [\n    \"@AirlineX Your customer service is just AMAZING! 3 hours on hold and then hung up on. Can't wait to fly with you again... #sarcasm #badservice\",\n    \"Just tried the new coffee shop downtown and WOW! Best latte I've ever had, friendly staff, and great atmosphere. Definitely my new regular spot! #coffee #happy\"\n]\n\nfor post in posts:\n    result = analyze_social_post(post)\n    print(f\"\\nPost: '{post}'\")\n    print(f\"Primary Sentiment: {result.primary_sentiment}\")\n    print(f\"Sarcastic: {result.is_sarcastic}\")\n\n    print(\"\\nEmotions:\")\n    for emotion in result.emotions:\n        print(f\"- {emotion.name}: {emotion.intensity:.2f}\")\n\n    print(f\"\\nTopics: {', '.join(result.topics)}\")\n    print(f\"Urgency: {result.urgency}/5\")\n\n    if result.action_items:\n        print(\"\\nSuggested Actions:\")\n        for item in result.action_items:\n            print(f\"- {item}\")\n\n",
          "display_code": "posts = [\n    \"@AirlineX Your customer service is just AMAZING! 3 hours on hold and then hung up on. Can't wait to fly with you again... #sarcasm #badservice\",\n    \"Just tried the new coffee shop downtown and WOW! Best latte I've ever had, friendly staff, and great atmosphere. Definitely my new regular spot! #coffee #happy\"\n]\n\nfor post in posts:\n    result = analyze_social_post(post)\n    print(f\"\\nPost: '{post}'\")\n    print(f\"Primary Sentiment: {result.primary_sentiment}\")\n    print(f\"Sarcastic: {result.is_sarcastic}\")\n\n    print(\"\\nEmotions:\")\n    for emotion in result.emotions:\n        print(f\"- {emotion.name}: {emotion.intensity:.2f}\")\n\n    print(f\"\\nTopics: {', '.join(result.topics)}\")\n    print(f\"Urgency: {result.urgency}/5\")\n\n    if result.action_items:\n        print(\"\\nSuggested Actions:\")\n        for item in result.action_items:\n            print(f\"- {item}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 216,
          "line_range": [
            216,
            238
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python sentiment-analysis.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "004-classification",
      "section_title": "Classification and Analysis"
    },
    {
      "id": "021-entity-classification",
      "title": "Entity Classification",
      "description": "",
      "order": 21,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# \n",
          "display_code": "",
          "annotation": "",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Categorize entities from text using Instructor.\n",
          "display_code": "",
          "annotation": "Categorize entities from text using Instructor.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            21
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\nfrom typing import List, Literal\nimport instructor\nfrom openai import OpenAI\n\nclass Entity(BaseModel):\n    text: str = Field(description=\"The entity text as it appears in the document\")\n    type: Literal[\"PERSON\", \"ORGANIZATION\", \"LOCATION\", \"DATE\", \"PRODUCT\"] = Field(\n        description=\"The category/type of the entity\"\n    )\n    start_index: int = Field(description=\"The starting character position in text\")\n    end_index: int = Field(description=\"The ending character position in text\")\n\nclass EntitiesExtraction(BaseModel):\n    entities: List[Entity] = Field(description=\"List of entities extracted from the text\")\n\n",
          "display_code": "from pydantic import BaseModel, Field\nfrom typing import List, Literal\nimport instructor\nfrom openai import OpenAI\n\nclass Entity(BaseModel):\n    text: str = Field(description=\"The entity text as it appears in the document\")\n    type: Literal[\"PERSON\", \"ORGANIZATION\", \"LOCATION\", \"DATE\", \"PRODUCT\"] = Field(\n        description=\"The category/type of the entity\"\n    )\n    start_index: int = Field(description=\"The starting character position in text\")\n    end_index: int = Field(description=\"The ending character position in text\")\n\nclass EntitiesExtraction(BaseModel):\n    entities: List[Entity] = Field(description=\"List of entities extracted from the text\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            21
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 22,
          "line_range": [
            22,
            22
          ],
          "target_line_range": [
            23,
            37
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\ndef extract_entities(text: str) -> EntitiesExtraction:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=EntitiesExtraction,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract named entities from the text with their types and positions.\"\n            },\n            {\"role\": \"user\", \"content\": text}\n        ]\n    )\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\ndef extract_entities(text: str) -> EntitiesExtraction:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=EntitiesExtraction,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract named entities from the text with their types and positions.\"\n            },\n            {\"role\": \"user\", \"content\": text}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 23,
          "line_range": [
            23,
            37
          ]
        },
        {
          "code": "# Test with an example\n",
          "display_code": "",
          "annotation": "Test with an example",
          "is_comment": true,
          "start_line": 38,
          "line_range": [
            38,
            38
          ],
          "target_line_range": [
            39,
            48
          ]
        },
        {
          "code": "sample_text = \"\"\"Apple Inc. is planning to open a new store in Berlin, Germany in July 2024.\n               CEO Tim Cook announced the expansion during a press conference yesterday.\"\"\"\n\nresult = extract_entities(sample_text)\n\nprint(f\"Text: '{sample_text}'\")\nprint(\"\\nExtracted Entities:\")\nfor entity in result.entities:\n    print(f\"- {entity.text} ({entity.type}) at positions {entity.start_index}-{entity.end_index}\")\n\n",
          "display_code": "sample_text = \"\"\"Apple Inc. is planning to open a new store in Berlin, Germany in July 2024.\n               CEO Tim Cook announced the expansion during a press conference yesterday.\"\"\"\n\nresult = extract_entities(sample_text)\n\nprint(f\"Text: '{sample_text}'\")\nprint(\"\\nExtracted Entities:\")\nfor entity in result.entities:\n    print(f\"- {entity.text} ({entity.type}) at positions {entity.start_index}-{entity.end_index}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 39,
          "line_range": [
            39,
            48
          ]
        },
        {
          "code": "# Example Output:\n# Extracted Entities:\n# - Apple Inc. (ORGANIZATION) at positions 0-10\n# - Berlin (LOCATION) at positions 42-48\n# - Germany (LOCATION) at positions 50-57\n# - July 2024 (DATE) at positions 61-70\n# - Tim Cook (PERSON) at positions 76-84\n# - yesterday (DATE) at positions 128-137\n",
          "display_code": "",
          "annotation": "Example Output:\nExtracted Entities:\n- Apple Inc. (ORGANIZATION) at positions 0-10\n- Berlin (LOCATION) at positions 42-48\n- Germany (LOCATION) at positions 50-57\n- July 2024 (DATE) at positions 61-70\n- Tim Cook (PERSON) at positions 76-84\n- yesterday (DATE) at positions 128-137",
          "is_comment": true,
          "start_line": 49,
          "line_range": [
            49,
            56
          ],
          "target_line_range": [
            57,
            60
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Literal\n\n",
          "display_code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Literal\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 57,
          "line_range": [
            57,
            60
          ]
        },
        {
          "code": "# Define custom entity types\n",
          "display_code": "",
          "annotation": "Define custom entity types",
          "is_comment": true,
          "start_line": 61,
          "line_range": [
            61,
            61
          ],
          "target_line_range": [
            62,
            89
          ]
        },
        {
          "code": "EntityType = Literal[\n    \"COMPANY\", \"PERSON\", \"CITY\", \"COUNTRY\", \"PRODUCT\", \"TECHNOLOGY\",\n    \"JOB_TITLE\", \"EVENT\", \"CURRENCY\", \"DATE_TIME\"\n]\n\nclass CustomEntity(BaseModel):\n    text: str\n    type: EntityType\n    context: str = Field(description=\"Brief contextual information about this entity\")\n\nclass CustomEntitiesExtraction(BaseModel):\n    entities: List[CustomEntity]\n\ndef extract_custom_entities(text: str) -> CustomEntitiesExtraction:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=CustomEntitiesExtraction,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"\"\"Extract named entities from the text using only these types:\n                COMPANY, PERSON, CITY, COUNTRY, PRODUCT, TECHNOLOGY, JOB_TITLE, EVENT, CURRENCY, DATE_TIME.\n                Include brief contextual information about each entity.\"\"\"\n            },\n            {\"role\": \"user\", \"content\": text}\n        ]\n    )\n\n",
          "display_code": "EntityType = Literal[\n    \"COMPANY\", \"PERSON\", \"CITY\", \"COUNTRY\", \"PRODUCT\", \"TECHNOLOGY\",\n    \"JOB_TITLE\", \"EVENT\", \"CURRENCY\", \"DATE_TIME\"\n]\n\nclass CustomEntity(BaseModel):\n    text: str\n    type: EntityType\n    context: str = Field(description=\"Brief contextual information about this entity\")\n\nclass CustomEntitiesExtraction(BaseModel):\n    entities: List[CustomEntity]\n\ndef extract_custom_entities(text: str) -> CustomEntitiesExtraction:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=CustomEntitiesExtraction,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"\"\"Extract named entities from the text using only these types:\n                COMPANY, PERSON, CITY, COUNTRY, PRODUCT, TECHNOLOGY, JOB_TITLE, EVENT, CURRENCY, DATE_TIME.\n                Include brief contextual information about each entity.\"\"\"\n            },\n            {\"role\": \"user\", \"content\": text}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 62,
          "line_range": [
            62,
            89
          ]
        },
        {
          "code": "# Test with a tech news example\n",
          "display_code": "",
          "annotation": "Test with a tech news example",
          "is_comment": true,
          "start_line": 90,
          "line_range": [
            90,
            90
          ],
          "target_line_range": [
            91,
            102
          ]
        },
        {
          "code": "tech_news = \"\"\"Microsoft's CEO Satya Nadella revealed the new Surface Pro 10 at the Build 2024 conference in\n               Seattle last week. The device features Qualcomm's Snapdragon X processor and will sell for $1,299\n               in the United States starting June 15th.\"\"\"\n\nresult = extract_custom_entities(tech_news)\n\nprint(f\"Text: '{tech_news}'\")\nprint(\"\\nExtracted Entities:\")\nfor entity in result.entities:\n    print(f\"- {entity.text} ({entity.type})\")\n    print(f\"  Context: {entity.context}\")\n\n",
          "display_code": "tech_news = \"\"\"Microsoft's CEO Satya Nadella revealed the new Surface Pro 10 at the Build 2024 conference in\n               Seattle last week. The device features Qualcomm's Snapdragon X processor and will sell for $1,299\n               in the United States starting June 15th.\"\"\"\n\nresult = extract_custom_entities(tech_news)\n\nprint(f\"Text: '{tech_news}'\")\nprint(\"\\nExtracted Entities:\")\nfor entity in result.entities:\n    print(f\"- {entity.text} ({entity.type})\")\n    print(f\"  Context: {entity.context}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 91,
          "line_range": [
            91,
            102
          ]
        },
        {
          "code": "# Example Output:\n# Extracted Entities:\n# - Microsoft (COMPANY)\n#   Context: The company that makes Surface products\n# - Satya Nadella (PERSON)\n#   Context: The CEO of Microsoft\n# - Surface Pro 10 (PRODUCT)\n#   Context: A new device revealed by Microsoft\n# - Build 2024 (EVENT)\n#   Context: Conference where the Surface Pro 10 was revealed\n# - Seattle (CITY)\n#   Context: Location of the Build 2024 conference\n# - Qualcomm's Snapdragon X (TECHNOLOGY)\n#   Context: Processor used in the Surface Pro 10\n# - $1,299 (CURRENCY)\n#   Context: The price of the Surface Pro 10\n# - United States (COUNTRY)\n#   Context: Where the Surface Pro 10 will be sold\n# - June 15th (DATE_TIME)\n#   Context: When the Surface Pro 10 will start selling\n",
          "display_code": "",
          "annotation": "Example Output:\nExtracted Entities:\n- Microsoft (COMPANY)\nContext: The company that makes Surface products\n- Satya Nadella (PERSON)\nContext: The CEO of Microsoft\n- Surface Pro 10 (PRODUCT)\nContext: A new device revealed by Microsoft\n- Build 2024 (EVENT)\nContext: Conference where the Surface Pro 10 was revealed\n- Seattle (CITY)\nContext: Location of the Build 2024 conference\n- Qualcomm's Snapdragon X (TECHNOLOGY)\nContext: Processor used in the Surface Pro 10\n- $1,299 (CURRENCY)\nContext: The price of the Surface Pro 10\n- United States (COUNTRY)\nContext: Where the Surface Pro 10 will be sold\n- June 15th (DATE_TIME)\nContext: When the Surface Pro 10 will start selling",
          "is_comment": true,
          "start_line": 103,
          "line_range": [
            103,
            122
          ],
          "target_line_range": [
            123,
            173
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional, Dict, Union, Literal\n\nclass PersonEntity(BaseModel):\n    name: str\n    type: Literal[\"PERSON\"] = \"PERSON\"\n    title: Optional[str] = None\n    organization: Optional[str] = None\n\nclass OrganizationEntity(BaseModel):\n    name: str\n    type: Literal[\"ORGANIZATION\"] = \"ORGANIZATION\"\n    industry: Optional[str] = None\n    location: Optional[str] = None\n\nclass ProductEntity(BaseModel):\n    name: str\n    type: Literal[\"PRODUCT\"] = \"PRODUCT\"\n    category: Optional[str] = None\n    manufacturer: Optional[str] = None\n    price: Optional[str] = None\n\nclass LocationEntity(BaseModel):\n    name: str\n    type: Literal[\"LOCATION\"] = \"LOCATION\"\n    location_type: Optional[str] = None  # city, country, address, etc.\n    region: Optional[str] = None\n\nclass DateEntity(BaseModel):\n    text: str\n    type: Literal[\"DATE\"] = \"DATE\"\n    is_range: bool = False\n    precision: Optional[str] = None  # day, month, year, etc.\n\nclass EntitiesWithAttributes(BaseModel):\n    entities: List[Union[PersonEntity, OrganizationEntity, ProductEntity, LocationEntity, DateEntity]]\n\ndef extract_entities_with_attributes(text: str) -> EntitiesWithAttributes:\n    return client.chat.completions.create(\n        model=\"gpt-4\",  # More complex task, better with GPT-4\n        response_model=EntitiesWithAttributes,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract entities with their attributes. Each entity type has specific attributes.\"\n            },\n            {\"role\": \"user\", \"content\": text}\n        ]\n    )\n\n",
          "display_code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional, Dict, Union, Literal\n\nclass PersonEntity(BaseModel):\n    name: str\n    type: Literal[\"PERSON\"] = \"PERSON\"\n    title: Optional[str] = None\n    organization: Optional[str] = None\n\nclass OrganizationEntity(BaseModel):\n    name: str\n    type: Literal[\"ORGANIZATION\"] = \"ORGANIZATION\"\n    industry: Optional[str] = None\n    location: Optional[str] = None\n\nclass ProductEntity(BaseModel):\n    name: str\n    type: Literal[\"PRODUCT\"] = \"PRODUCT\"\n    category: Optional[str] = None\n    manufacturer: Optional[str] = None\n    price: Optional[str] = None\n\nclass LocationEntity(BaseModel):\n    name: str\n    type: Literal[\"LOCATION\"] = \"LOCATION\"\n    location_type: Optional[str] = None  # city, country, address, etc.\n    region: Optional[str] = None\n\nclass DateEntity(BaseModel):\n    text: str\n    type: Literal[\"DATE\"] = \"DATE\"\n    is_range: bool = False\n    precision: Optional[str] = None  # day, month, year, etc.\n\nclass EntitiesWithAttributes(BaseModel):\n    entities: List[Union[PersonEntity, OrganizationEntity, ProductEntity, LocationEntity, DateEntity]]\n\ndef extract_entities_with_attributes(text: str) -> EntitiesWithAttributes:\n    return client.chat.completions.create(\n        model=\"gpt-4\",  # More complex task, better with GPT-4\n        response_model=EntitiesWithAttributes,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract entities with their attributes. Each entity type has specific attributes.\"\n            },\n            {\"role\": \"user\", \"content\": text}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 123,
          "line_range": [
            123,
            173
          ]
        },
        {
          "code": "# Test with a complex example\n",
          "display_code": "",
          "annotation": "Test with a complex example",
          "is_comment": true,
          "start_line": 174,
          "line_range": [
            174,
            174
          ],
          "target_line_range": [
            175,
            184
          ]
        },
        {
          "code": "complex_text = \"\"\"Tesla CEO Elon Musk announced the new Cybertruck will be available in Austin, Texas\n                 from December 2023. The electric vehicle starts at $39,900 and will be manufactured\n                 at Tesla's Gigafactory.\"\"\"\n\nresult = extract_entities_with_attributes(complex_text)\n\nprint(f\"Text: '{complex_text}'\")\nprint(\"\\nExtracted Entities with Attributes:\")\nfor entity in result.entities:\n    print(f\"\\n- {entity.name if hasattr(entity, 'name') else entity.text} ({entity.type})\")\n",
          "display_code": "complex_text = \"\"\"Tesla CEO Elon Musk announced the new Cybertruck will be available in Austin, Texas\n                 from December 2023. The electric vehicle starts at $39,900 and will be manufactured\n                 at Tesla's Gigafactory.\"\"\"\n\nresult = extract_entities_with_attributes(complex_text)\n\nprint(f\"Text: '{complex_text}'\")\nprint(\"\\nExtracted Entities with Attributes:\")\nfor entity in result.entities:\n    print(f\"\\n- {entity.name if hasattr(entity, 'name') else entity.text} ({entity.type})\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 175,
          "line_range": [
            175,
            184
          ]
        },
        {
          "code": "    # Print all attributes except name and type\n",
          "display_code": "",
          "annotation": "Print all attributes except name and type",
          "is_comment": true,
          "start_line": 185,
          "line_range": [
            185,
            185
          ],
          "target_line_range": [
            186,
            224
          ]
        },
        {
          "code": "    for key, value in entity.model_dump().items():\n        if key not in ['name', 'text', 'type'] and value is not None:\n            print(f\"  {key}: {value}\")\n\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional, Dict, Any\n\nclass EntityWithId(BaseModel):\n    id: str = Field(description=\"Unique identifier for the entity\")\n    text: str = Field(description=\"The entity text as found in the document\")\n    type: str = Field(description=\"The entity type/category\")\n    attributes: Dict[str, Any] = Field(default_factory=dict, description=\"Additional entity attributes\")\n\nclass Relationship(BaseModel):\n    source_id: str = Field(description=\"ID of the source entity\")\n    target_id: str = Field(description=\"ID of the target entity\")\n    relation_type: str = Field(description=\"Type of relationship between entities\")\n    description: Optional[str] = None\n\nclass EntityRelationExtraction(BaseModel):\n    entities: List[EntityWithId] = Field(description=\"List of entities with unique IDs\")\n    relationships: List[Relationship] = Field(description=\"Relationships between entities\")\n\ndef extract_entity_relationships(text: str) -> EntityRelationExtraction:\n    return client.chat.completions.create(\n        model=\"gpt-4\",  # Complex relationships need GPT-4\n        response_model=EntityRelationExtraction,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"\"\"Extract entities and their relationships from the text.\n                Assign each entity a unique ID and identify relationships between entities.\n\n                Example relationship types: WORKS_FOR, LOCATED_IN, MANUFACTURES, OWNS, PART_OF, etc.\"\"\"\n            },\n            {\"role\": \"user\", \"content\": text}\n        ]\n    )\n\n",
          "display_code": "    for key, value in entity.model_dump().items():\n        if key not in ['name', 'text', 'type'] and value is not None:\n            print(f\"  {key}: {value}\")\n\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional, Dict, Any\n\nclass EntityWithId(BaseModel):\n    id: str = Field(description=\"Unique identifier for the entity\")\n    text: str = Field(description=\"The entity text as found in the document\")\n    type: str = Field(description=\"The entity type/category\")\n    attributes: Dict[str, Any] = Field(default_factory=dict, description=\"Additional entity attributes\")\n\nclass Relationship(BaseModel):\n    source_id: str = Field(description=\"ID of the source entity\")\n    target_id: str = Field(description=\"ID of the target entity\")\n    relation_type: str = Field(description=\"Type of relationship between entities\")\n    description: Optional[str] = None\n\nclass EntityRelationExtraction(BaseModel):\n    entities: List[EntityWithId] = Field(description=\"List of entities with unique IDs\")\n    relationships: List[Relationship] = Field(description=\"Relationships between entities\")\n\ndef extract_entity_relationships(text: str) -> EntityRelationExtraction:\n    return client.chat.completions.create(\n        model=\"gpt-4\",  # Complex relationships need GPT-4\n        response_model=EntityRelationExtraction,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"\"\"Extract entities and their relationships from the text.\n                Assign each entity a unique ID and identify relationships between entities.\n\n                Example relationship types: WORKS_FOR, LOCATED_IN, MANUFACTURES, OWNS, PART_OF, etc.\"\"\"\n            },\n            {\"role\": \"user\", \"content\": text}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 186,
          "line_range": [
            186,
            224
          ]
        },
        {
          "code": "# Test with a corporate news example\n",
          "display_code": "",
          "annotation": "Test with a corporate news example",
          "is_comment": true,
          "start_line": 225,
          "line_range": [
            225,
            225
          ],
          "target_line_range": [
            226,
            247
          ]
        },
        {
          "code": "corporate_news = \"\"\"\n    Amazon CEO Andy Jassy announced that the e-commerce giant is acquiring Anthropic,\n    an AI startup based in San Francisco. The deal, worth $4 billion, will help Amazon\n    compete with Microsoft, which has invested heavily in OpenAI. Anthropic's founder\n    Dario Amodei will continue to lead the company after the acquisition.\n\"\"\"\n\nresult = extract_entity_relationships(corporate_news)\n\nprint(\"Entities:\")\nfor entity in result.entities:\n    attrs = \", \".join([f\"{k}: {v}\" for k, v in entity.attributes.items()]) if entity.attributes else \"\"\n    print(f\"- [{entity.id}] {entity.text} ({entity.type}) {attrs}\")\n\nprint(\"\\nRelationships:\")\nfor rel in result.relationships:\n    source = next((e.text for e in result.entities if e.id == rel.source_id), \"Unknown\")\n    target = next((e.text for e in result.entities if e.id == rel.target_id), \"Unknown\")\n    print(f\"- {source} {rel.relation_type} {target}\")\n    if rel.description:\n        print(f\"  Description: {rel.description}\")\n\n",
          "display_code": "corporate_news = \"\"\"\n    Amazon CEO Andy Jassy announced that the e-commerce giant is acquiring Anthropic,\n    an AI startup based in San Francisco. The deal, worth $4 billion, will help Amazon\n    compete with Microsoft, which has invested heavily in OpenAI. Anthropic's founder\n    Dario Amodei will continue to lead the company after the acquisition.\n\"\"\"\n\nresult = extract_entity_relationships(corporate_news)\n\nprint(\"Entities:\")\nfor entity in result.entities:\n    attrs = \", \".join([f\"{k}: {v}\" for k, v in entity.attributes.items()]) if entity.attributes else \"\"\n    print(f\"- [{entity.id}] {entity.text} ({entity.type}) {attrs}\")\n\nprint(\"\\nRelationships:\")\nfor rel in result.relationships:\n    source = next((e.text for e in result.entities if e.id == rel.source_id), \"Unknown\")\n    target = next((e.text for e in result.entities if e.id == rel.target_id), \"Unknown\")\n    print(f\"- {source} {rel.relation_type} {target}\")\n    if rel.description:\n        print(f\"  Description: {rel.description}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 226,
          "line_range": [
            226,
            247
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python entity-classification.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "004-classification",
      "section_title": "Classification and Analysis"
    },
    {
      "id": "022-confidence-scores",
      "title": "Working with Confidence Scores",
      "description": "",
      "order": 22,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# \n",
          "display_code": "",
          "annotation": "",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Add confidence metrics to your structured extractions with Instructor.\n",
          "display_code": "",
          "annotation": "Add confidence metrics to your structured extractions with Instructor.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            16
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\n\nclass PredictionWithConfidence(BaseModel):\n    prediction: str = Field(description=\"The predicted answer or category\")\n    confidence: float = Field(\n        gt=0, le=1,  # Greater than 0, less than or equal to 1\n        description=\"Confidence score between 0 and 1 (higher = more confident)\"\n    )\n\n",
          "display_code": "from pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\n\nclass PredictionWithConfidence(BaseModel):\n    prediction: str = Field(description=\"The predicted answer or category\")\n    confidence: float = Field(\n        gt=0, le=1,  # Greater than 0, less than or equal to 1\n        description=\"Confidence score between 0 and 1 (higher = more confident)\"\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            16
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 17,
          "line_range": [
            17,
            17
          ],
          "target_line_range": [
            18,
            35
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\ndef predict_with_confidence(question: str, context: str) -> PredictionWithConfidence:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=PredictionWithConfidence,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Answer the question based on the provided context. Include a confidence score.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": f\"Context: {context}\\n\\nQuestion: {question}\"\n            }\n        ]\n    )\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\ndef predict_with_confidence(question: str, context: str) -> PredictionWithConfidence:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=PredictionWithConfidence,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Answer the question based on the provided context. Include a confidence score.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": f\"Context: {context}\\n\\nQuestion: {question}\"\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 18,
          "line_range": [
            18,
            35
          ]
        },
        {
          "code": "# Test with varying levels of confidence\n",
          "display_code": "",
          "annotation": "Test with varying levels of confidence",
          "is_comment": true,
          "start_line": 36,
          "line_range": [
            36,
            36
          ],
          "target_line_range": [
            37,
            37
          ]
        },
        {
          "code": "contexts = [\n",
          "display_code": "contexts = [\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 37,
          "line_range": [
            37,
            37
          ]
        },
        {
          "code": "    # High confidence - direct answer in context\n",
          "display_code": "",
          "annotation": "High confidence - direct answer in context",
          "is_comment": true,
          "start_line": 38,
          "line_range": [
            38,
            38
          ],
          "target_line_range": [
            39,
            40
          ]
        },
        {
          "code": "    \"The Golden Gate Bridge was completed in 1937. It is located in San Francisco, California.\",\n\n",
          "display_code": "    \"The Golden Gate Bridge was completed in 1937. It is located in San Francisco, California.\",\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 39,
          "line_range": [
            39,
            40
          ]
        },
        {
          "code": "    # Medium confidence - partial information\n",
          "display_code": "",
          "annotation": "Medium confidence - partial information",
          "is_comment": true,
          "start_line": 41,
          "line_range": [
            41,
            41
          ],
          "target_line_range": [
            42,
            43
          ]
        },
        {
          "code": "    \"The Golden Gate Bridge is a famous landmark in California. Many tourists visit it each year.\",\n\n",
          "display_code": "    \"The Golden Gate Bridge is a famous landmark in California. Many tourists visit it each year.\",\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 42,
          "line_range": [
            42,
            43
          ]
        },
        {
          "code": "    # Low confidence - minimal relevant information\n",
          "display_code": "",
          "annotation": "Low confidence - minimal relevant information",
          "is_comment": true,
          "start_line": 44,
          "line_range": [
            44,
            44
          ],
          "target_line_range": [
            45,
            57
          ]
        },
        {
          "code": "    \"California has many famous landmarks and tourist attractions that draw visitors from around the world.\"\n]\n\nquestion = \"When was the Golden Gate Bridge completed?\"\n\nfor i, context in enumerate(contexts):\n    result = predict_with_confidence(question, context)\n    print(f\"Example {i+1}:\")\n    print(f\"Context: '{context}'\")\n    print(f\"Question: '{question}'\")\n    print(f\"Prediction: {result.prediction}\")\n    print(f\"Confidence: {result.confidence:.2f}\\n\")\n\n",
          "display_code": "    \"California has many famous landmarks and tourist attractions that draw visitors from around the world.\"\n]\n\nquestion = \"When was the Golden Gate Bridge completed?\"\n\nfor i, context in enumerate(contexts):\n    result = predict_with_confidence(question, context)\n    print(f\"Example {i+1}:\")\n    print(f\"Context: '{context}'\")\n    print(f\"Question: '{question}'\")\n    print(f\"Prediction: {result.prediction}\")\n    print(f\"Confidence: {result.confidence:.2f}\\n\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 45,
          "line_range": [
            45,
            57
          ]
        },
        {
          "code": "# Example Output:\n# Example 1:\n# Prediction: 1937\n# Confidence: 0.98\n#\n# Example 2:\n# Prediction: The completion date is not specified in the context.\n# Confidence: 0.45\n#\n# Example 3:\n# Prediction: The context does not provide information about the Golden Gate Bridge's completion date.\n# Confidence: 0.95\n",
          "display_code": "",
          "annotation": "Example Output:\nExample 1:\nPrediction: 1937\nConfidence: 0.98\n\nExample 2:\nPrediction: The completion date is not specified in the context.\nConfidence: 0.45\n\nExample 3:\nPrediction: The context does not provide information about the Golden Gate Bridge's completion date.\nConfidence: 0.95",
          "is_comment": true,
          "start_line": 58,
          "line_range": [
            58,
            69
          ],
          "target_line_range": [
            70,
            97
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field\nfrom typing import Literal\n\nclass ClassificationWithConfidence(BaseModel):\n    category: Literal[\"sports\", \"politics\", \"technology\", \"entertainment\", \"business\"]\n    confidence: float = Field(\n        gt=0, le=1,\n        description=\"Confidence score between 0 and 1\"\n    )\n\n    @property\n    def is_reliable(self) -> bool:\n        return self.confidence >= 0.7  # Threshold for reliability\n\ndef classify_with_confidence(text: str) -> ClassificationWithConfidence:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=ClassificationWithConfidence,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Classify the text into one of these categories: sports, politics, technology, entertainment, business.\"\n            },\n            {\"role\": \"user\", \"content\": text}\n        ]\n    )\n\n",
          "display_code": "\nfrom pydantic import BaseModel, Field\nfrom typing import Literal\n\nclass ClassificationWithConfidence(BaseModel):\n    category: Literal[\"sports\", \"politics\", \"technology\", \"entertainment\", \"business\"]\n    confidence: float = Field(\n        gt=0, le=1,\n        description=\"Confidence score between 0 and 1\"\n    )\n\n    @property\n    def is_reliable(self) -> bool:\n        return self.confidence >= 0.7  # Threshold for reliability\n\ndef classify_with_confidence(text: str) -> ClassificationWithConfidence:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=ClassificationWithConfidence,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Classify the text into one of these categories: sports, politics, technology, entertainment, business.\"\n            },\n            {\"role\": \"user\", \"content\": text}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 70,
          "line_range": [
            70,
            97
          ]
        },
        {
          "code": "# Test with examples\n",
          "display_code": "",
          "annotation": "Test with examples",
          "is_comment": true,
          "start_line": 98,
          "line_range": [
            98,
            98
          ],
          "target_line_range": [
            99,
            111
          ]
        },
        {
          "code": "examples = [\n    \"Apple announced its new M3 chip with significantly improved performance.\",  # Clear tech\n    \"The game went into overtime after a last-minute equalizer.\",  # Clear sports\n    \"The gathering included discussion of market trends and artistic influences.\"  # Ambiguous\n]\n\nfor text in examples:\n    result = classify_with_confidence(text)\n    print(f\"Text: '{text}'\")\n    print(f\"Category: {result.category}\")\n    print(f\"Confidence: {result.confidence:.2f}\")\n    print(f\"Reliable: {result.is_reliable}\\n\")\n\n",
          "display_code": "examples = [\n    \"Apple announced its new M3 chip with significantly improved performance.\",  # Clear tech\n    \"The game went into overtime after a last-minute equalizer.\",  # Clear sports\n    \"The gathering included discussion of market trends and artistic influences.\"  # Ambiguous\n]\n\nfor text in examples:\n    result = classify_with_confidence(text)\n    print(f\"Text: '{text}'\")\n    print(f\"Category: {result.category}\")\n    print(f\"Confidence: {result.confidence:.2f}\")\n    print(f\"Reliable: {result.is_reliable}\\n\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 99,
          "line_range": [
            99,
            111
          ]
        },
        {
          "code": "# Example Output:\n# Text: 'Apple announced its new M3 chip with significantly improved performance.'\n# Category: technology\n# Confidence: 0.95\n# Reliable: True\n#\n# Text: 'The game went into overtime after a last-minute equalizer.'\n# Category: sports\n# Confidence: 0.91\n# Reliable: True\n#\n# Text: 'The gathering included discussion of market trends and artistic influences.'\n# Category: business\n# Confidence: 0.51\n# Reliable: False\n",
          "display_code": "",
          "annotation": "Example Output:\nText: 'Apple announced its new M3 chip with significantly improved performance.'\nCategory: technology\nConfidence: 0.95\nReliable: True\n\nText: 'The game went into overtime after a last-minute equalizer.'\nCategory: sports\nConfidence: 0.91\nReliable: True\n\nText: 'The gathering included discussion of market trends and artistic influences.'\nCategory: business\nConfidence: 0.51\nReliable: False",
          "is_comment": true,
          "start_line": 112,
          "line_range": [
            112,
            126
          ],
          "target_line_range": [
            127,
            157
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nclass PredictionOption(BaseModel):\n    value: str\n    confidence: float = Field(gt=0, le=1)\n\nclass MultipleOptions(BaseModel):\n    options: List[PredictionOption] = Field(\n        description=\"List of possible answers with confidence scores\",\n        min_items=1\n    )\n\n    @property\n    def best_option(self) -> PredictionOption:\n        return max(self.options, key=lambda x: x.confidence)\n\ndef generate_options(question: str) -> MultipleOptions:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=MultipleOptions,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Generate 2-4 possible answers to the question with confidence scores.\"\n            },\n            {\"role\": \"user\", \"content\": question}\n        ]\n    )\n\n",
          "display_code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\nclass PredictionOption(BaseModel):\n    value: str\n    confidence: float = Field(gt=0, le=1)\n\nclass MultipleOptions(BaseModel):\n    options: List[PredictionOption] = Field(\n        description=\"List of possible answers with confidence scores\",\n        min_items=1\n    )\n\n    @property\n    def best_option(self) -> PredictionOption:\n        return max(self.options, key=lambda x: x.confidence)\n\ndef generate_options(question: str) -> MultipleOptions:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=MultipleOptions,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Generate 2-4 possible answers to the question with confidence scores.\"\n            },\n            {\"role\": \"user\", \"content\": question}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 127,
          "line_range": [
            127,
            157
          ]
        },
        {
          "code": "# Test with an ambiguous question\n",
          "display_code": "",
          "annotation": "Test with an ambiguous question",
          "is_comment": true,
          "start_line": 158,
          "line_range": [
            158,
            158
          ],
          "target_line_range": [
            159,
            199
          ]
        },
        {
          "code": "question = \"What year is considered the beginning of the modern internet?\"\n\nresult = generate_options(question)\n\nprint(f\"Question: '{question}'\")\nprint(\"Possible answers:\")\nfor option in sorted(result.options, key=lambda x: x.confidence, reverse=True):\n    print(f\"- {option.value} (confidence: {option.confidence:.2f})\")\n\nprint(f\"\\nBest option: {result.best_option.value} (confidence: {result.best_option.confidence:.2f})\")\n\nfrom pydantic import BaseModel, Field\nfrom typing import Dict, List\n\nclass ConfidenceMatrix(BaseModel):\n    category_scores: Dict[str, float] = Field(\n        description=\"Confidence scores for each possible category\"\n    )\n    most_likely_category: str = Field(\n        description=\"The category with the highest confidence score\"\n    )\n    reliability: Literal[\"high\", \"medium\", \"low\"] = Field(\n        description=\"Reliability assessment of the classification\"\n    )\n\ndef multi_category_confidence(text: str, categories: List[str]) -> ConfidenceMatrix:\n    categories_str = \", \".join(categories)\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=ConfidenceMatrix,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": f\"\"\"Analyze the text and provide confidence scores for each possible category: {categories_str}.\n                Confidence scores should be between 0 and 1, sum to 1.0, and represent the probability of the text belonging to each category.\n                Also assess if the classification reliability is high (clear winner >0.7), medium (top score 0.4-0.7), or low (ambiguous, top score <0.4).\"\"\"\n            },\n            {\"role\": \"user\", \"content\": text}\n        ]\n    )\n\n",
          "display_code": "question = \"What year is considered the beginning of the modern internet?\"\n\nresult = generate_options(question)\n\nprint(f\"Question: '{question}'\")\nprint(\"Possible answers:\")\nfor option in sorted(result.options, key=lambda x: x.confidence, reverse=True):\n    print(f\"- {option.value} (confidence: {option.confidence:.2f})\")\n\nprint(f\"\\nBest option: {result.best_option.value} (confidence: {result.best_option.confidence:.2f})\")\n\nfrom pydantic import BaseModel, Field\nfrom typing import Dict, List\n\nclass ConfidenceMatrix(BaseModel):\n    category_scores: Dict[str, float] = Field(\n        description=\"Confidence scores for each possible category\"\n    )\n    most_likely_category: str = Field(\n        description=\"The category with the highest confidence score\"\n    )\n    reliability: Literal[\"high\", \"medium\", \"low\"] = Field(\n        description=\"Reliability assessment of the classification\"\n    )\n\ndef multi_category_confidence(text: str, categories: List[str]) -> ConfidenceMatrix:\n    categories_str = \", \".join(categories)\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=ConfidenceMatrix,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": f\"\"\"Analyze the text and provide confidence scores for each possible category: {categories_str}.\n                Confidence scores should be between 0 and 1, sum to 1.0, and represent the probability of the text belonging to each category.\n                Also assess if the classification reliability is high (clear winner >0.7), medium (top score 0.4-0.7), or low (ambiguous, top score <0.4).\"\"\"\n            },\n            {\"role\": \"user\", \"content\": text}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 159,
          "line_range": [
            159,
            199
          ]
        },
        {
          "code": "# Test with examples\n",
          "display_code": "",
          "annotation": "Test with examples",
          "is_comment": true,
          "start_line": 200,
          "line_range": [
            200,
            200
          ],
          "target_line_range": [
            201,
            251
          ]
        },
        {
          "code": "categories = [\"health\", \"finance\", \"technology\", \"travel\", \"education\"]\ntext = \"The new smartwatch can track your heart rate, sleep patterns, and activity levels throughout the day.\"\n\nresult = multi_category_confidence(text, categories)\n\nprint(f\"Text: '{text}'\")\nprint(\"\\nConfidence Scores:\")\nfor category, score in sorted(result.category_scores.items(), key=lambda x: x[1], reverse=True):\n    print(f\"- {category}: {score:.2f}\")\n\nprint(f\"\\nMost Likely Category: {result.most_likely_category}\")\nprint(f\"Reliability: {result.reliability}\")\n\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional, Union, Literal\nfrom enum import Enum\n\nclass ConfidenceLevel(str, Enum):\n    HIGH = \"high\"\n    MEDIUM = \"medium\"\n    LOW = \"low\"\n\nclass Extraction(BaseModel):\n    value: str\n    confidence: float = Field(gt=0, le=1)\n    confidence_level: ConfidenceLevel\n    requires_human_review: bool\n\nclass ExtractionResult(BaseModel):\n    extracted_info: Extraction\n    alternative_values: Optional[List[str]] = None\n    extraction_notes: Optional[str] = None\n    suggested_action: Literal[\"accept\", \"review\", \"reject\"] = Field(\n        description=\"Recommended action based on confidence: accept (high confidence), review (medium), reject (low)\"\n    )\n\ndef extract_with_decision(text: str, field_to_extract: str) -> ExtractionResult:\n    return client.chat.completions.create(\n        model=\"gpt-4\",  # Better judgement with GPT-4\n        response_model=ExtractionResult,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": f\"\"\"Extract the {field_to_extract} from the text with a confidence score.\n                Assess confidence level (high: >0.8, medium: 0.5-0.8, low: <0.5) and determine if human review is needed.\n                Recommend an action (accept/review/reject) based on confidence.\"\"\"\n            },\n            {\"role\": \"user\", \"content\": text}\n        ]\n    )\n\n",
          "display_code": "categories = [\"health\", \"finance\", \"technology\", \"travel\", \"education\"]\ntext = \"The new smartwatch can track your heart rate, sleep patterns, and activity levels throughout the day.\"\n\nresult = multi_category_confidence(text, categories)\n\nprint(f\"Text: '{text}'\")\nprint(\"\\nConfidence Scores:\")\nfor category, score in sorted(result.category_scores.items(), key=lambda x: x[1], reverse=True):\n    print(f\"- {category}: {score:.2f}\")\n\nprint(f\"\\nMost Likely Category: {result.most_likely_category}\")\nprint(f\"Reliability: {result.reliability}\")\n\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional, Union, Literal\nfrom enum import Enum\n\nclass ConfidenceLevel(str, Enum):\n    HIGH = \"high\"\n    MEDIUM = \"medium\"\n    LOW = \"low\"\n\nclass Extraction(BaseModel):\n    value: str\n    confidence: float = Field(gt=0, le=1)\n    confidence_level: ConfidenceLevel\n    requires_human_review: bool\n\nclass ExtractionResult(BaseModel):\n    extracted_info: Extraction\n    alternative_values: Optional[List[str]] = None\n    extraction_notes: Optional[str] = None\n    suggested_action: Literal[\"accept\", \"review\", \"reject\"] = Field(\n        description=\"Recommended action based on confidence: accept (high confidence), review (medium), reject (low)\"\n    )\n\ndef extract_with_decision(text: str, field_to_extract: str) -> ExtractionResult:\n    return client.chat.completions.create(\n        model=\"gpt-4\",  # Better judgement with GPT-4\n        response_model=ExtractionResult,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": f\"\"\"Extract the {field_to_extract} from the text with a confidence score.\n                Assess confidence level (high: >0.8, medium: 0.5-0.8, low: <0.5) and determine if human review is needed.\n                Recommend an action (accept/review/reject) based on confidence.\"\"\"\n            },\n            {\"role\": \"user\", \"content\": text}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 201,
          "line_range": [
            201,
            251
          ]
        },
        {
          "code": "# Test with varying examples\n",
          "display_code": "",
          "annotation": "Test with varying examples",
          "is_comment": true,
          "start_line": 252,
          "line_range": [
            252,
            252
          ],
          "target_line_range": [
            253,
            272
          ]
        },
        {
          "code": "examples = [\n    \"Patient's DOB: 04/15/1985. Patient presented with symptoms of...\",  # Clear\n    \"The pt. was born in the mid-1980s (possibly '85) and first presented...\",  # Uncertain\n    \"Patient demographic information will be provided in a follow-up report.\"  # Missing\n]\n\nfor text in examples:\n    result = extract_with_decision(text, \"date of birth\")\n    print(f\"Text: '{text}'\")\n    print(f\"Extracted Value: {result.extracted_info.value}\")\n    print(f\"Confidence: {result.extracted_info.confidence:.2f} ({result.extracted_info.confidence_level})\")\n    print(f\"Requires Human Review: {result.extracted_info.requires_human_review}\")\n    print(f\"Suggested Action: {result.suggested_action}\")\n\n    if result.alternative_values:\n        print(f\"Alternative Values: {', '.join(result.alternative_values)}\")\n    if result.extraction_notes:\n        print(f\"Notes: {result.extraction_notes}\")\n    print()\n\n",
          "display_code": "examples = [\n    \"Patient's DOB: 04/15/1985. Patient presented with symptoms of...\",  # Clear\n    \"The pt. was born in the mid-1980s (possibly '85) and first presented...\",  # Uncertain\n    \"Patient demographic information will be provided in a follow-up report.\"  # Missing\n]\n\nfor text in examples:\n    result = extract_with_decision(text, \"date of birth\")\n    print(f\"Text: '{text}'\")\n    print(f\"Extracted Value: {result.extracted_info.value}\")\n    print(f\"Confidence: {result.extracted_info.confidence:.2f} ({result.extracted_info.confidence_level})\")\n    print(f\"Requires Human Review: {result.extracted_info.requires_human_review}\")\n    print(f\"Suggested Action: {result.suggested_action}\")\n\n    if result.alternative_values:\n        print(f\"Alternative Values: {', '.join(result.alternative_values)}\")\n    if result.extraction_notes:\n        print(f\"Notes: {result.extraction_notes}\")\n    print()\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 253,
          "line_range": [
            253,
            272
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python confidence-scores.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "004-classification",
      "section_title": "Classification and Analysis"
    },
    {
      "id": "023-streaming-basics",
      "title": "Streaming Basics",
      "description": "",
      "order": 23,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Get started with streaming responses in Instructor for real-time processing.\n# \n# Streaming allows you to receive partial responses from LLMs as they're being generated, \n# rather than waiting for the complete response.\n#\n# Instructor offers two main ways to stream structured data:\n# \n# 1. Partial: Stream a single object as it's being populated field by field\n# 2. Iterable: Stream multiple complete objects one at a time\n",
          "display_code": "",
          "annotation": "Get started with streaming responses in Instructor for real-time processing.\n\nStreaming allows you to receive partial responses from LLMs as they're being generated,\nrather than waiting for the complete response.\n\nInstructor offers two main ways to stream structured data:\n\n1. Partial: Stream a single object as it's being populated field by field\n2. Iterable: Stream multiple complete objects one at a time",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            11
          ],
          "target_line_range": [
            12,
            20
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n    bio: str\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\nclass User(BaseModel):\n    name: str\n    age: int\n    bio: str\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            20
          ]
        },
        {
          "code": "# Patch the OpenAI client\n",
          "display_code": "",
          "annotation": "Patch the OpenAI client",
          "is_comment": true,
          "start_line": 21,
          "line_range": [
            21,
            21
          ],
          "target_line_range": [
            22,
            24
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\ndef stream_user_info():\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\ndef stream_user_info():\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 22,
          "line_range": [
            22,
            24
          ]
        },
        {
          "code": "    # Create a streaming response\n",
          "display_code": "",
          "annotation": "Create a streaming response",
          "is_comment": true,
          "start_line": 25,
          "line_range": [
            25,
            25
          ],
          "target_line_range": [
            26,
            34
          ]
        },
        {
          "code": "    stream = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        stream=True,  # Enable streaming\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate a profile for a fictional user named Alice who is 28 years old.\"}\n        ]\n    )\n\n",
          "display_code": "    stream = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        stream=True,  # Enable streaming\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate a profile for a fictional user named Alice who is 28 years old.\"}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 26,
          "line_range": [
            26,
            34
          ]
        },
        {
          "code": "    # Process the stream\n",
          "display_code": "",
          "annotation": "Process the stream",
          "is_comment": true,
          "start_line": 35,
          "line_range": [
            35,
            35
          ],
          "target_line_range": [
            36,
            36
          ]
        },
        {
          "code": "    for chunk in stream:\n",
          "display_code": "    for chunk in stream:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 36,
          "line_range": [
            36,
            36
          ]
        },
        {
          "code": "        # The chunk contains a partial response so far\n",
          "display_code": "",
          "annotation": "The chunk contains a partial response so far",
          "is_comment": true,
          "start_line": 37,
          "line_range": [
            37,
            37
          ],
          "target_line_range": [
            38,
            39
          ]
        },
        {
          "code": "        print(f\"Received chunk: {chunk}\")\n\n",
          "display_code": "        print(f\"Received chunk: {chunk}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 38,
          "line_range": [
            38,
            39
          ]
        },
        {
          "code": "    # The last chunk is the complete response\n",
          "display_code": "",
          "annotation": "The last chunk is the complete response",
          "is_comment": true,
          "start_line": 40,
          "line_range": [
            40,
            40
          ],
          "target_line_range": [
            41,
            48
          ]
        },
        {
          "code": "    return chunk\n\nuser = stream_user_info()\nprint(f\"\\nFinal result: {user}\")\n\nfrom instructor import Partial\n\ndef stream_user_with_partial():\n",
          "display_code": "    return chunk\n\nuser = stream_user_info()\nprint(f\"\\nFinal result: {user}\")\n\nfrom instructor import Partial\n\ndef stream_user_with_partial():\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 41,
          "line_range": [
            41,
            48
          ]
        },
        {
          "code": "    # Create a streaming response using create_partial\n",
          "display_code": "",
          "annotation": "Create a streaming response using create_partial",
          "is_comment": true,
          "start_line": 49,
          "line_range": [
            49,
            49
          ],
          "target_line_range": [
            50,
            57
          ]
        },
        {
          "code": "    user_stream = client.chat.completions.create_partial(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate a profile for a fictional user named Bob who is 35 years old and works as a software developer.\"}\n        ]\n    )\n\n",
          "display_code": "    user_stream = client.chat.completions.create_partial(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate a profile for a fictional user named Bob who is 35 years old and works as a software developer.\"}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 50,
          "line_range": [
            50,
            57
          ]
        },
        {
          "code": "    # Process the stream of Partial[User] objects\n",
          "display_code": "",
          "annotation": "Process the stream of Partial[User] objects",
          "is_comment": true,
          "start_line": 58,
          "line_range": [
            58,
            58
          ],
          "target_line_range": [
            59,
            61
          ]
        },
        {
          "code": "    print(\"Streaming user data:\")\n\n    for partial_user in user_stream:\n",
          "display_code": "    print(\"Streaming user data:\")\n\n    for partial_user in user_stream:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 59,
          "line_range": [
            59,
            61
          ]
        },
        {
          "code": "        # As new fields are populated, they show up in the partial_user\n",
          "display_code": "",
          "annotation": "As new fields are populated, they show up in the partial_user",
          "is_comment": true,
          "start_line": 62,
          "line_range": [
            62,
            62
          ],
          "target_line_range": [
            63,
            64
          ]
        },
        {
          "code": "        print(f\"Current state: name={partial_user.name}, age={partial_user.age}, bio={partial_user.bio!r}\")\n\n",
          "display_code": "        print(f\"Current state: name={partial_user.name}, age={partial_user.age}, bio={partial_user.bio!r}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 63,
          "line_range": [
            63,
            64
          ]
        },
        {
          "code": "# Example output:\n# Current state: name=None, age=None, bio=None\n# Current state: name='Bob', age=None, bio=None\n# Current state: name='Bob', age=35, bio=None\n# Current state: name='Bob', age=35, bio='Software developer with 10 years of experience...'\n",
          "display_code": "",
          "annotation": "Example output:\nCurrent state: name=None, age=None, bio=None\nCurrent state: name='Bob', age=None, bio=None\nCurrent state: name='Bob', age=35, bio=None\nCurrent state: name='Bob', age=35, bio='Software developer with 10 years of experience...'",
          "is_comment": true,
          "start_line": 65,
          "line_range": [
            65,
            69
          ],
          "target_line_range": [
            70,
            77
          ]
        },
        {
          "code": "\nfrom typing import Dict, Any\n\nclass ProgressTracker:\n    def __init__(self):\n        self.progress = {}\n\n    def update(self, partial_user: Partial[User]):\n",
          "display_code": "\nfrom typing import Dict, Any\n\nclass ProgressTracker:\n    def __init__(self):\n        self.progress = {}\n\n    def update(self, partial_user: Partial[User]):\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 70,
          "line_range": [
            70,
            77
          ]
        },
        {
          "code": "        # Calculate percentage of fields that are populated\n",
          "display_code": "",
          "annotation": "Calculate percentage of fields that are populated",
          "is_comment": true,
          "start_line": 78,
          "line_range": [
            78,
            78
          ],
          "target_line_range": [
            79,
            82
          ]
        },
        {
          "code": "        total_fields = len(User.model_fields)\n        populated = sum(1 for v in [partial_user.name, partial_user.age, partial_user.bio] if v is not None)\n        completion = int(populated / total_fields * 100)\n\n",
          "display_code": "        total_fields = len(User.model_fields)\n        populated = sum(1 for v in [partial_user.name, partial_user.age, partial_user.bio] if v is not None)\n        completion = int(populated / total_fields * 100)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 79,
          "line_range": [
            79,
            82
          ]
        },
        {
          "code": "        # Track changes\n",
          "display_code": "",
          "annotation": "Track changes",
          "is_comment": true,
          "start_line": 83,
          "line_range": [
            83,
            83
          ],
          "target_line_range": [
            84,
            113
          ]
        },
        {
          "code": "        data = {}\n        if partial_user.name is not None:\n            data[\"name\"] = partial_user.name\n        if partial_user.age is not None:\n            data[\"age\"] = partial_user.age\n        if partial_user.bio is not None:\n            data[\"bio\"] = partial_user.bio\n\n        self.progress = {\n            \"completion\": f\"{completion}%\",\n            \"data\": data\n        }\n\n        return self.progress\n\ndef stream_with_progress():\n    tracker = ProgressTracker()\n\n    user_stream = client.chat.completions.create_partial(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate a profile for a fictional user named Carol who is 42 years old.\"}\n        ]\n    )\n\n    for partial_user in user_stream:\n        progress = tracker.update(partial_user)\n        print(f\"Progress: {progress['completion']} - Current data: {progress['data']}\")\n\n",
          "display_code": "        data = {}\n        if partial_user.name is not None:\n            data[\"name\"] = partial_user.name\n        if partial_user.age is not None:\n            data[\"age\"] = partial_user.age\n        if partial_user.bio is not None:\n            data[\"bio\"] = partial_user.bio\n\n        self.progress = {\n            \"completion\": f\"{completion}%\",\n            \"data\": data\n        }\n\n        return self.progress\n\ndef stream_with_progress():\n    tracker = ProgressTracker()\n\n    user_stream = client.chat.completions.create_partial(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate a profile for a fictional user named Carol who is 42 years old.\"}\n        ]\n    )\n\n    for partial_user in user_stream:\n        progress = tracker.update(partial_user)\n        print(f\"Progress: {progress['completion']} - Current data: {progress['data']}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 84,
          "line_range": [
            84,
            113
          ]
        },
        {
          "code": "# Example output:\n# Progress: 33% - Current data: {'name': 'Carol'}\n# Progress: 66% - Current data: {'name': 'Carol', 'age': 42}\n# Progress: 100% - Current data: {'name': 'Carol', 'age': 42, 'bio': 'Carol is a passionate...'}\n",
          "display_code": "",
          "annotation": "Example output:\nProgress: 33% - Current data: {'name': 'Carol'}\nProgress: 66% - Current data: {'name': 'Carol', 'age': 42}\nProgress: 100% - Current data: {'name': 'Carol', 'age': 42, 'bio': 'Carol is a passionate...'}",
          "is_comment": true,
          "start_line": 114,
          "line_range": [
            114,
            117
          ],
          "target_line_range": [
            118,
            122
          ]
        },
        {
          "code": "\nimport asyncio\nfrom openai import AsyncOpenAI\n\nasync def stream_async():\n",
          "display_code": "\nimport asyncio\nfrom openai import AsyncOpenAI\n\nasync def stream_async():\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 118,
          "line_range": [
            118,
            122
          ]
        },
        {
          "code": "    # Create async client\n",
          "display_code": "",
          "annotation": "Create async client",
          "is_comment": true,
          "start_line": 123,
          "line_range": [
            123,
            123
          ],
          "target_line_range": [
            124,
            125
          ]
        },
        {
          "code": "    async_client = instructor.from_openai(AsyncOpenAI())\n\n",
          "display_code": "    async_client = instructor.from_openai(AsyncOpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 124,
          "line_range": [
            124,
            125
          ]
        },
        {
          "code": "    # Create an async streaming response\n",
          "display_code": "",
          "annotation": "Create an async streaming response",
          "is_comment": true,
          "start_line": 126,
          "line_range": [
            126,
            126
          ],
          "target_line_range": [
            127,
            134
          ]
        },
        {
          "code": "    user_stream = await async_client.chat.completions.create_partial(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate a profile for a fictional user named Dave who is 31 years old.\"}\n        ]\n    )\n\n",
          "display_code": "    user_stream = await async_client.chat.completions.create_partial(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate a profile for a fictional user named Dave who is 31 years old.\"}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 127,
          "line_range": [
            127,
            134
          ]
        },
        {
          "code": "    # Process the stream\n",
          "display_code": "",
          "annotation": "Process the stream",
          "is_comment": true,
          "start_line": 135,
          "line_range": [
            135,
            135
          ],
          "target_line_range": [
            136,
            138
          ]
        },
        {
          "code": "    async for partial_user in user_stream:\n        print(f\"Async stream update: {partial_user}\")\n\n",
          "display_code": "    async for partial_user in user_stream:\n        print(f\"Async stream update: {partial_user}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 136,
          "line_range": [
            136,
            138
          ]
        },
        {
          "code": "# Run the async function\n",
          "display_code": "",
          "annotation": "Run the async function",
          "is_comment": true,
          "start_line": 139,
          "line_range": [
            139,
            139
          ],
          "target_line_range": [
            140,
            141
          ]
        },
        {
          "code": "asyncio.run(stream_async())\n\n",
          "display_code": "asyncio.run(stream_async())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 140,
          "line_range": [
            140,
            141
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python streaming-basics.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "005-streaming",
      "section_title": "Streaming"
    },
    {
      "id": "024-partial-objects",
      "title": "Streaming Partial Objects",
      "description": "",
      "order": 24,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# \n",
          "display_code": "",
          "annotation": "",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Stream progressively populated structured objects with Instructor.\n",
          "display_code": "",
          "annotation": "Stream progressively populated structured objects with Instructor.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            17
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\nfrom typing import Optional, List\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n    skills: List[str] = Field(description=\"List of professional skills\")\n    bio: Optional[str] = None\n\n",
          "display_code": "from pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\nfrom typing import Optional, List\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n    skills: List[str] = Field(description=\"List of professional skills\")\n    bio: Optional[str] = None\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            17
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 18,
          "line_range": [
            18,
            18
          ],
          "target_line_range": [
            19,
            20
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 19,
          "line_range": [
            19,
            20
          ]
        },
        {
          "code": "# Create a partial stream\n",
          "display_code": "",
          "annotation": "Create a partial stream",
          "is_comment": true,
          "start_line": 21,
          "line_range": [
            21,
            21
          ],
          "target_line_range": [
            22,
            29
          ]
        },
        {
          "code": "person_stream = client.chat.completions.create_partial(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Generate profile: John Smith is a 35-year-old software engineer who knows Python, JavaScript, and SQL.\"}\n    ]\n)\n\n",
          "display_code": "person_stream = client.chat.completions.create_partial(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Generate profile: John Smith is a 35-year-old software engineer who knows Python, JavaScript, and SQL.\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 22,
          "line_range": [
            22,
            29
          ]
        },
        {
          "code": "# Print updates as they arrive\n",
          "display_code": "",
          "annotation": "Print updates as they arrive",
          "is_comment": true,
          "start_line": 30,
          "line_range": [
            30,
            30
          ],
          "target_line_range": [
            31,
            32
          ]
        },
        {
          "code": "print(\"Receiving partial updates:\")\nfor person in person_stream:\n",
          "display_code": "print(\"Receiving partial updates:\")\nfor person in person_stream:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 31,
          "line_range": [
            31,
            32
          ]
        },
        {
          "code": "    # Get a snapshot of current state\n",
          "display_code": "",
          "annotation": "Get a snapshot of current state",
          "is_comment": true,
          "start_line": 33,
          "line_range": [
            33,
            33
          ],
          "target_line_range": [
            34,
            39
          ]
        },
        {
          "code": "    name = person.name if person.name is not None else \"[pending]\"\n    age = person.age if person.age is not None else \"[pending]\"\n    occupation = person.occupation if person.occupation is not None else \"[pending]\"\n    skills = \", \".join(person.skills) if person.skills else \"[pending]\"\n    bio = person.bio if person.bio is not None else \"[pending]\"\n\n",
          "display_code": "    name = person.name if person.name is not None else \"[pending]\"\n    age = person.age if person.age is not None else \"[pending]\"\n    occupation = person.occupation if person.occupation is not None else \"[pending]\"\n    skills = \", \".join(person.skills) if person.skills else \"[pending]\"\n    bio = person.bio if person.bio is not None else \"[pending]\"\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 34,
          "line_range": [
            34,
            39
          ]
        },
        {
          "code": "    # Print current state\n",
          "display_code": "",
          "annotation": "Print current state",
          "is_comment": true,
          "start_line": 40,
          "line_range": [
            40,
            40
          ],
          "target_line_range": [
            41,
            47
          ]
        },
        {
          "code": "    print(f\"\\nCurrent state:\")\n    print(f\"Name: {name}\")\n    print(f\"Age: {age}\")\n    print(f\"Occupation: {occupation}\")\n    print(f\"Skills: {skills}\")\n    print(f\"Bio: {bio}\")\n\n",
          "display_code": "    print(f\"\\nCurrent state:\")\n    print(f\"Name: {name}\")\n    print(f\"Age: {age}\")\n    print(f\"Occupation: {occupation}\")\n    print(f\"Skills: {skills}\")\n    print(f\"Bio: {bio}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 41,
          "line_range": [
            41,
            47
          ]
        },
        {
          "code": "# Example partial outputs:\n# Current state:\n# Name: [pending]\n# Age: [pending]\n# Occupation: [pending]\n# Skills: [pending]\n# Bio: [pending]\n#\n# Current state:\n# Name: John Smith\n# Age: [pending]\n# Occupation: [pending]\n# Skills: [pending]\n# Bio: [pending]\n#\n# ...\n#\n# Current state:\n# Name: John Smith\n# Age: 35\n# Occupation: software engineer\n# Skills: Python, JavaScript, SQL\n# Bio: John Smith is an experienced software engineer with a passion for building scalable applications...\n",
          "display_code": "",
          "annotation": "Example partial outputs:\nCurrent state:\nName: [pending]\nAge: [pending]\nOccupation: [pending]\nSkills: [pending]\nBio: [pending]\n\nCurrent state:\nName: John Smith\nAge: [pending]\nOccupation: [pending]\nSkills: [pending]\nBio: [pending]\n\n...\n\nCurrent state:\nName: John Smith\nAge: 35\nOccupation: software engineer\nSkills: Python, JavaScript, SQL\nBio: John Smith is an experienced software engineer with a passion for building scalable applications...",
          "is_comment": true,
          "start_line": 48,
          "line_range": [
            48,
            70
          ],
          "target_line_range": [
            71,
            77
          ]
        },
        {
          "code": "\nclass FieldTracker:\n    def __init__(self, model_class):\n        self.field_names = list(model_class.model_fields.keys())\n        self.completed_fields = set()\n\n    def update(self, partial_obj):\n",
          "display_code": "\nclass FieldTracker:\n    def __init__(self, model_class):\n        self.field_names = list(model_class.model_fields.keys())\n        self.completed_fields = set()\n\n    def update(self, partial_obj):\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 71,
          "line_range": [
            71,
            77
          ]
        },
        {
          "code": "        # Check which fields are now populated\n",
          "display_code": "",
          "annotation": "Check which fields are now populated",
          "is_comment": true,
          "start_line": 78,
          "line_range": [
            78,
            78
          ],
          "target_line_range": [
            79,
            88
          ]
        },
        {
          "code": "        newly_completed = []\n\n        for field in self.field_names:\n            value = getattr(partial_obj, field)\n            if value is not None and field not in self.completed_fields:\n                self.completed_fields.add(field)\n                newly_completed.append(field)\n\n        return newly_completed\n\n",
          "display_code": "        newly_completed = []\n\n        for field in self.field_names:\n            value = getattr(partial_obj, field)\n            if value is not None and field not in self.completed_fields:\n                self.completed_fields.add(field)\n                newly_completed.append(field)\n\n        return newly_completed\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 79,
          "line_range": [
            79,
            88
          ]
        },
        {
          "code": "# Create a partial stream\n",
          "display_code": "",
          "annotation": "Create a partial stream",
          "is_comment": true,
          "start_line": 89,
          "line_range": [
            89,
            89
          ],
          "target_line_range": [
            90,
            97
          ]
        },
        {
          "code": "person_stream = client.chat.completions.create_partial(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Generate profile: Sarah Johnson is a 42-year-old marketing director skilled in SEO, content strategy, and social media.\"}\n    ]\n)\n\n",
          "display_code": "person_stream = client.chat.completions.create_partial(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Generate profile: Sarah Johnson is a 42-year-old marketing director skilled in SEO, content strategy, and social media.\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 90,
          "line_range": [
            90,
            97
          ]
        },
        {
          "code": "# Track field completion\n",
          "display_code": "",
          "annotation": "Track field completion",
          "is_comment": true,
          "start_line": 98,
          "line_range": [
            98,
            98
          ],
          "target_line_range": [
            99,
            106
          ]
        },
        {
          "code": "tracker = FieldTracker(Person)\n\nfor person in person_stream:\n    new_fields = tracker.update(person)\n\n    if new_fields:\n        print(f\"Newly completed fields: {', '.join(new_fields)}\")\n\n",
          "display_code": "tracker = FieldTracker(Person)\n\nfor person in person_stream:\n    new_fields = tracker.update(person)\n\n    if new_fields:\n        print(f\"Newly completed fields: {', '.join(new_fields)}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 99,
          "line_range": [
            99,
            106
          ]
        },
        {
          "code": "        # Show newly available data\n",
          "display_code": "",
          "annotation": "Show newly available data",
          "is_comment": true,
          "start_line": 107,
          "line_range": [
            107,
            107
          ],
          "target_line_range": [
            108,
            111
          ]
        },
        {
          "code": "        for field in new_fields:\n            value = getattr(person, field)\n            print(f\"  {field}: {value}\")\n\n",
          "display_code": "        for field in new_fields:\n            value = getattr(person, field)\n            print(f\"  {field}: {value}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 108,
          "line_range": [
            108,
            111
          ]
        },
        {
          "code": "# Example output:\n# Newly completed fields: name\n#   name: Sarah Johnson\n# Newly completed fields: age\n#   age: 42\n# Newly completed fields: occupation\n#   occupation: marketing director\n# Newly completed fields: skills\n#   skills: ['SEO', 'content strategy', 'social media']\n# Newly completed fields: bio\n#   bio: Sarah Johnson is an accomplished marketing director with over 15 years of experience...\n",
          "display_code": "",
          "annotation": "Example output:\nNewly completed fields: name\nname: Sarah Johnson\nNewly completed fields: age\nage: 42\nNewly completed fields: occupation\noccupation: marketing director\nNewly completed fields: skills\nskills: ['SEO', 'content strategy', 'social media']\nNewly completed fields: bio\nbio: Sarah Johnson is an accomplished marketing director with over 15 years of experience...",
          "is_comment": true,
          "start_line": 112,
          "line_range": [
            112,
            122
          ],
          "target_line_range": [
            123,
            133
          ]
        },
        {
          "code": "\nimport time\n\nclass CompletionBar:\n    def __init__(self, model_class, width=40):\n        self.fields = list(model_class.model_fields.keys())\n        self.total_fields = len(self.fields)\n        self.width = width\n        self.last_progress = 0\n\n    def update(self, partial_obj):\n",
          "display_code": "\nimport time\n\nclass CompletionBar:\n    def __init__(self, model_class, width=40):\n        self.fields = list(model_class.model_fields.keys())\n        self.total_fields = len(self.fields)\n        self.width = width\n        self.last_progress = 0\n\n    def update(self, partial_obj):\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 123,
          "line_range": [
            123,
            133
          ]
        },
        {
          "code": "        # Count populated fields\n",
          "display_code": "",
          "annotation": "Count populated fields",
          "is_comment": true,
          "start_line": 134,
          "line_range": [
            134,
            134
          ],
          "target_line_range": [
            135,
            137
          ]
        },
        {
          "code": "        populated = sum(1 for field in self.fields if getattr(partial_obj, field) is not None)\n        progress = populated / self.total_fields\n\n",
          "display_code": "        populated = sum(1 for field in self.fields if getattr(partial_obj, field) is not None)\n        progress = populated / self.total_fields\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 135,
          "line_range": [
            135,
            137
          ]
        },
        {
          "code": "        # Only update if progress changed\n",
          "display_code": "",
          "annotation": "Only update if progress changed",
          "is_comment": true,
          "start_line": 138,
          "line_range": [
            138,
            138
          ],
          "target_line_range": [
            139,
            141
          ]
        },
        {
          "code": "        if progress > self.last_progress:\n            self.last_progress = progress\n\n",
          "display_code": "        if progress > self.last_progress:\n            self.last_progress = progress\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 139,
          "line_range": [
            139,
            141
          ]
        },
        {
          "code": "            # Create progress bar\n",
          "display_code": "",
          "annotation": "Create progress bar",
          "is_comment": true,
          "start_line": 142,
          "line_range": [
            142,
            142
          ],
          "target_line_range": [
            143,
            147
          ]
        },
        {
          "code": "            filled_width = int(self.width * progress)\n            empty_width = self.width - filled_width\n            bar = \"\u2588\" * filled_width + \"\u2591\" * empty_width\n            percent = int(progress * 100)\n\n",
          "display_code": "            filled_width = int(self.width * progress)\n            empty_width = self.width - filled_width\n            bar = \"\u2588\" * filled_width + \"\u2591\" * empty_width\n            percent = int(progress * 100)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 143,
          "line_range": [
            143,
            147
          ]
        },
        {
          "code": "            # Print progress\n",
          "display_code": "",
          "annotation": "Print progress",
          "is_comment": true,
          "start_line": 148,
          "line_range": [
            148,
            148
          ],
          "target_line_range": [
            149,
            154
          ]
        },
        {
          "code": "            print(f\"\\rProgress: [{bar}] {percent}% ({populated}/{self.total_fields} fields)\", end=\"\")\n            return True\n\n        return False\n\ndef stream_with_progress_bar():\n",
          "display_code": "            print(f\"\\rProgress: [{bar}] {percent}% ({populated}/{self.total_fields} fields)\", end=\"\")\n            return True\n\n        return False\n\ndef stream_with_progress_bar():\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 149,
          "line_range": [
            149,
            154
          ]
        },
        {
          "code": "    # Create progress bar\n",
          "display_code": "",
          "annotation": "Create progress bar",
          "is_comment": true,
          "start_line": 155,
          "line_range": [
            155,
            155
          ],
          "target_line_range": [
            156,
            157
          ]
        },
        {
          "code": "    bar = CompletionBar(Person)\n\n",
          "display_code": "    bar = CompletionBar(Person)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 156,
          "line_range": [
            156,
            157
          ]
        },
        {
          "code": "    # Create partial stream\n",
          "display_code": "",
          "annotation": "Create partial stream",
          "is_comment": true,
          "start_line": 158,
          "line_range": [
            158,
            158
          ],
          "target_line_range": [
            159,
            166
          ]
        },
        {
          "code": "    person_stream = client.chat.completions.create_partial(\n        model=\"gpt-3.5-turbo\",\n        response_model=Person,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate profile: Michael Chen is a 39-year-old data scientist who knows Python, R, and machine learning techniques.\"}\n        ]\n    )\n\n",
          "display_code": "    person_stream = client.chat.completions.create_partial(\n        model=\"gpt-3.5-turbo\",\n        response_model=Person,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate profile: Michael Chen is a 39-year-old data scientist who knows Python, R, and machine learning techniques.\"}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 159,
          "line_range": [
            159,
            166
          ]
        },
        {
          "code": "    # Track progress\n",
          "display_code": "",
          "annotation": "Track progress",
          "is_comment": true,
          "start_line": 167,
          "line_range": [
            167,
            167
          ],
          "target_line_range": [
            168,
            171
          ]
        },
        {
          "code": "    for person in person_stream:\n        bar.update(person)\n        time.sleep(0.1)  # Slow down updates for visibility\n\n",
          "display_code": "    for person in person_stream:\n        bar.update(person)\n        time.sleep(0.1)  # Slow down updates for visibility\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 168,
          "line_range": [
            168,
            171
          ]
        },
        {
          "code": "    # Complete the progress display\n",
          "display_code": "",
          "annotation": "Complete the progress display",
          "is_comment": true,
          "start_line": 172,
          "line_range": [
            172,
            172
          ],
          "target_line_range": [
            173,
            180
          ]
        },
        {
          "code": "    print(\"\\n\\nFinal result:\")\n    print(f\"Name: {person.name}\")\n    print(f\"Age: {person.age}\")\n    print(f\"Occupation: {person.occupation}\")\n    print(f\"Skills: {', '.join(person.skills)}\")\n    if person.bio:\n        print(f\"Bio: {person.bio}\")\n\n",
          "display_code": "    print(\"\\n\\nFinal result:\")\n    print(f\"Name: {person.name}\")\n    print(f\"Age: {person.age}\")\n    print(f\"Occupation: {person.occupation}\")\n    print(f\"Skills: {', '.join(person.skills)}\")\n    if person.bio:\n        print(f\"Bio: {person.bio}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 173,
          "line_range": [
            173,
            180
          ]
        },
        {
          "code": "# Example output:\n# Progress: [\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588] 100% (5/5 fields)\n#\n# Final result:\n# Name: Michael Chen\n# Age: 39\n# Occupation: data scientist\n# Skills: Python, R, machine learning\n# Bio: Michael Chen is an experienced data scientist with a strong background in statistical analysis...\n",
          "display_code": "",
          "annotation": "Example output:\nProgress: [\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588] 100% (5/5 fields)\n\nFinal result:\nName: Michael Chen\nAge: 39\nOccupation: data scientist\nSkills: Python, R, machine learning\nBio: Michael Chen is an experienced data scientist with a strong background in statistical analysis...",
          "is_comment": true,
          "start_line": 181,
          "line_range": [
            181,
            189
          ],
          "target_line_range": [
            190,
            211
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    country: str\n    postal_code: Optional[str] = None\n\nclass Experience(BaseModel):\n    title: str\n    company: str\n    years: int\n    description: Optional[str] = None\n\nclass ProfileWithNested(BaseModel):\n    name: str\n    age: int\n    addresses: List[Address] = Field(default_factory=list)\n    experience: List[Experience] = Field(default_factory=list)\n\n",
          "display_code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    country: str\n    postal_code: Optional[str] = None\n\nclass Experience(BaseModel):\n    title: str\n    company: str\n    years: int\n    description: Optional[str] = None\n\nclass ProfileWithNested(BaseModel):\n    name: str\n    age: int\n    addresses: List[Address] = Field(default_factory=list)\n    experience: List[Experience] = Field(default_factory=list)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 190,
          "line_range": [
            190,
            211
          ]
        },
        {
          "code": "# Stream with nested data\n",
          "display_code": "",
          "annotation": "Stream with nested data",
          "is_comment": true,
          "start_line": 212,
          "line_range": [
            212,
            212
          ],
          "target_line_range": [
            213,
            228
          ]
        },
        {
          "code": "profile_stream = client.chat.completions.create_partial(\n    model=\"gpt-4\",  # More complex model handles nested data better\n    response_model=ProfileWithNested,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n            Generate a profile for Emma Wilson, a 45-year-old executive who has homes in:\n            - 123 Main St, New York, USA, 10001\n            - 45 Beach Road, Sydney, Australia, 2000\n\n            Work experience:\n            - CEO at TechCorp for 5 years\n            - VP of Operations at GlobalSystems for 8 years\n        \"\"\"}\n    ]\n)\n\n",
          "display_code": "profile_stream = client.chat.completions.create_partial(\n    model=\"gpt-4\",  # More complex model handles nested data better\n    response_model=ProfileWithNested,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n            Generate a profile for Emma Wilson, a 45-year-old executive who has homes in:\n            - 123 Main St, New York, USA, 10001\n            - 45 Beach Road, Sydney, Australia, 2000\n\n            Work experience:\n            - CEO at TechCorp for 5 years\n            - VP of Operations at GlobalSystems for 8 years\n        \"\"\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 213,
          "line_range": [
            213,
            228
          ]
        },
        {
          "code": "# Track the evolving nested data\n",
          "display_code": "",
          "annotation": "Track the evolving nested data",
          "is_comment": true,
          "start_line": 229,
          "line_range": [
            229,
            229
          ],
          "target_line_range": [
            230,
            234
          ]
        },
        {
          "code": "for profile in profile_stream:\n    print(\"\\nCurrent profile state:\")\n    print(f\"Name: {profile.name if profile.name else '[pending]'}\")\n    print(f\"Age: {profile.age if profile.age is not None else '[pending]'}\")\n\n",
          "display_code": "for profile in profile_stream:\n    print(\"\\nCurrent profile state:\")\n    print(f\"Name: {profile.name if profile.name else '[pending]'}\")\n    print(f\"Age: {profile.age if profile.age is not None else '[pending]'}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 230,
          "line_range": [
            230,
            234
          ]
        },
        {
          "code": "    # Show addresses as they come in\n",
          "display_code": "",
          "annotation": "Show addresses as they come in",
          "is_comment": true,
          "start_line": 235,
          "line_range": [
            235,
            235
          ],
          "target_line_range": [
            236,
            246
          ]
        },
        {
          "code": "    print(\"Addresses:\")\n    if not profile.addresses:\n        print(\"  [pending]\")\n    else:\n        for i, addr in enumerate(profile.addresses):\n            print(f\"  Address {i+1}:\")\n            print(f\"    Street: {addr.street if addr.street else '[pending]'}\")\n            print(f\"    City: {addr.city if addr.city else '[pending]'}\")\n            print(f\"    Country: {addr.country if addr.country else '[pending]'}\")\n            print(f\"    Postal Code: {addr.postal_code if addr.postal_code else '[pending]'}\")\n\n",
          "display_code": "    print(\"Addresses:\")\n    if not profile.addresses:\n        print(\"  [pending]\")\n    else:\n        for i, addr in enumerate(profile.addresses):\n            print(f\"  Address {i+1}:\")\n            print(f\"    Street: {addr.street if addr.street else '[pending]'}\")\n            print(f\"    City: {addr.city if addr.city else '[pending]'}\")\n            print(f\"    Country: {addr.country if addr.country else '[pending]'}\")\n            print(f\"    Postal Code: {addr.postal_code if addr.postal_code else '[pending]'}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 236,
          "line_range": [
            236,
            246
          ]
        },
        {
          "code": "    # Show experience as it comes in\n",
          "display_code": "",
          "annotation": "Show experience as it comes in",
          "is_comment": true,
          "start_line": 247,
          "line_range": [
            247,
            247
          ],
          "target_line_range": [
            248,
            258
          ]
        },
        {
          "code": "    print(\"Experience:\")\n    if not profile.experience:\n        print(\"  [pending]\")\n    else:\n        for i, exp in enumerate(profile.experience):\n            print(f\"  Job {i+1}:\")\n            print(f\"    Title: {exp.title if exp.title else '[pending]'}\")\n            print(f\"    Company: {exp.company if exp.company else '[pending]'}\")\n            print(f\"    Years: {exp.years if exp.years is not None else '[pending]'}\")\n            print(f\"    Description: {exp.description if exp.description else '[pending]'}\")\n\n",
          "display_code": "    print(\"Experience:\")\n    if not profile.experience:\n        print(\"  [pending]\")\n    else:\n        for i, exp in enumerate(profile.experience):\n            print(f\"  Job {i+1}:\")\n            print(f\"    Title: {exp.title if exp.title else '[pending]'}\")\n            print(f\"    Company: {exp.company if exp.company else '[pending]'}\")\n            print(f\"    Years: {exp.years if exp.years is not None else '[pending]'}\")\n            print(f\"    Description: {exp.description if exp.description else '[pending]'}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 248,
          "line_range": [
            248,
            258
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python partial-objects.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "005-streaming",
      "section_title": "Streaming"
    },
    {
      "id": "025-streaming-lists",
      "title": "Streaming Lists",
      "description": "",
      "order": 25,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# \n",
          "display_code": "",
          "annotation": "",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Stream collections of objects one at a time with Instructor.\n",
          "display_code": "",
          "annotation": "Stream collections of objects one at a time with Instructor.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            15
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\nfrom typing import List\nimport instructor\nfrom openai import OpenAI\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\n",
          "display_code": "from pydantic import BaseModel, Field\nfrom typing import List\nimport instructor\nfrom openai import OpenAI\n\nclass Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            15
          ]
        },
        {
          "code": "# Patch the client\n",
          "display_code": "",
          "annotation": "Patch the client",
          "is_comment": true,
          "start_line": 16,
          "line_range": [
            16,
            16
          ],
          "target_line_range": [
            17,
            18
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 17,
          "line_range": [
            17,
            18
          ]
        },
        {
          "code": "# Create a streaming iterable\n",
          "display_code": "",
          "annotation": "Create a streaming iterable",
          "is_comment": true,
          "start_line": 19,
          "line_range": [
            19,
            19
          ],
          "target_line_range": [
            20,
            32
          ]
        },
        {
          "code": "people_stream = client.chat.completions.create_iterable(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,  # Note: no List[] wrapper needed here\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n            Generate profiles for three different people:\n            1. A software engineer in their 30s\n            2. A teacher in their 40s\n            3. A doctor in their 50s\n        \"\"\"}\n    ]\n)\n\n",
          "display_code": "people_stream = client.chat.completions.create_iterable(\n    model=\"gpt-3.5-turbo\",\n    response_model=Person,  # Note: no List[] wrapper needed here\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n            Generate profiles for three different people:\n            1. A software engineer in their 30s\n            2. A teacher in their 40s\n            3. A doctor in their 50s\n        \"\"\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 20,
          "line_range": [
            20,
            32
          ]
        },
        {
          "code": "# Process each person as they are completed\n",
          "display_code": "",
          "annotation": "Process each person as they are completed",
          "is_comment": true,
          "start_line": 33,
          "line_range": [
            33,
            33
          ],
          "target_line_range": [
            34,
            39
          ]
        },
        {
          "code": "print(\"Receiving people one at a time:\")\nfor i, person in enumerate(people_stream, 1):\n    print(f\"\\nPerson {i}:\")\n    print(f\"Name: {person.name}\")\n    print(f\"Age: {person.age}\")\n    print(f\"Occupation: {person.occupation}\")\n",
          "display_code": "print(\"Receiving people one at a time:\")\nfor i, person in enumerate(people_stream, 1):\n    print(f\"\\nPerson {i}:\")\n    print(f\"Name: {person.name}\")\n    print(f\"Age: {person.age}\")\n    print(f\"Occupation: {person.occupation}\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 34,
          "line_range": [
            34,
            39
          ]
        },
        {
          "code": "    # Note: Each person is fully complete when received\n",
          "display_code": "",
          "annotation": "Note: Each person is fully complete when received",
          "is_comment": true,
          "start_line": 40,
          "line_range": [
            40,
            40
          ],
          "target_line_range": [
            41,
            41
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 41,
          "line_range": [
            41,
            41
          ]
        },
        {
          "code": "# Example output:\n# Receiving people one at a time:\n#\n# Person 1:\n# Name: Michael Chen\n# Age: 34\n# Occupation: software engineer\n#\n# Person 2:\n# Name: Sarah Johnson\n# Age: 42\n# Occupation: teacher\n#\n# Person 3:\n# Name: Robert Garcia\n# Age: 56\n# Occupation: doctor\n",
          "display_code": "",
          "annotation": "Example output:\nReceiving people one at a time:\n\nPerson 1:\nName: Michael Chen\nAge: 34\nOccupation: software engineer\n\nPerson 2:\nName: Sarah Johnson\nAge: 42\nOccupation: teacher\n\nPerson 3:\nName: Robert Garcia\nAge: 56\nOccupation: doctor",
          "is_comment": true,
          "start_line": 42,
          "line_range": [
            42,
            58
          ],
          "target_line_range": [
            59,
            70
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass Book(BaseModel):\n    title: str\n    author: str\n    year: int\n    genre: str\n    summary: str = Field(description=\"Brief summary of the book's plot\")\n    rating: Optional[float] = Field(None, ge=0, le=5, description=\"Rating from 0-5 stars\")\n\n",
          "display_code": "\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass Book(BaseModel):\n    title: str\n    author: str\n    year: int\n    genre: str\n    summary: str = Field(description=\"Brief summary of the book's plot\")\n    rating: Optional[float] = Field(None, ge=0, le=5, description=\"Rating from 0-5 stars\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 59,
          "line_range": [
            59,
            70
          ]
        },
        {
          "code": "# Create a streaming iterable for complex objects\n",
          "display_code": "",
          "annotation": "Create a streaming iterable for complex objects",
          "is_comment": true,
          "start_line": 71,
          "line_range": [
            71,
            71
          ],
          "target_line_range": [
            72,
            83
          ]
        },
        {
          "code": "books_stream = client.chat.completions.create_iterable(\n    model=\"gpt-3.5-turbo\",\n    response_model=Book,\n    messages=[\n        {\"role\": \"system\", \"content\": \"Generate detailed book entries with accurate information.\"},\n        {\"role\": \"user\", \"content\": \"\"\"\n            Generate entries for three classic science fiction books.\n            Include their titles, authors, publication years, and summaries.\n        \"\"\"}\n    ]\n)\n\n",
          "display_code": "books_stream = client.chat.completions.create_iterable(\n    model=\"gpt-3.5-turbo\",\n    response_model=Book,\n    messages=[\n        {\"role\": \"system\", \"content\": \"Generate detailed book entries with accurate information.\"},\n        {\"role\": \"user\", \"content\": \"\"\"\n            Generate entries for three classic science fiction books.\n            Include their titles, authors, publication years, and summaries.\n        \"\"\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 72,
          "line_range": [
            72,
            83
          ]
        },
        {
          "code": "# Process each book as it's generated\n",
          "display_code": "",
          "annotation": "Process each book as it's generated",
          "is_comment": true,
          "start_line": 84,
          "line_range": [
            84,
            84
          ],
          "target_line_range": [
            85,
            101
          ]
        },
        {
          "code": "print(\"Streaming book data:\")\nfor i, book in enumerate(books_stream, 1):\n    print(f\"\\nBook {i}: {book.title} ({book.year})\")\n    print(f\"Author: {book.author}\")\n    print(f\"Genre: {book.genre}\")\n    print(f\"Rating: {book.rating if book.rating is not None else 'Not rated'}\")\n    print(f\"Summary: {book.summary}\")\n\nfrom typing import List, Dict, Any\nimport time\n\nclass Task(BaseModel):\n    title: str\n    priority: str\n    estimated_hours: float\n    assigned_to: Optional[str] = None\n\n",
          "display_code": "print(\"Streaming book data:\")\nfor i, book in enumerate(books_stream, 1):\n    print(f\"\\nBook {i}: {book.title} ({book.year})\")\n    print(f\"Author: {book.author}\")\n    print(f\"Genre: {book.genre}\")\n    print(f\"Rating: {book.rating if book.rating is not None else 'Not rated'}\")\n    print(f\"Summary: {book.summary}\")\n\nfrom typing import List, Dict, Any\nimport time\n\nclass Task(BaseModel):\n    title: str\n    priority: str\n    estimated_hours: float\n    assigned_to: Optional[str] = None\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 85,
          "line_range": [
            85,
            101
          ]
        },
        {
          "code": "# Setup for real-time processing\n",
          "display_code": "",
          "annotation": "Setup for real-time processing",
          "is_comment": true,
          "start_line": 102,
          "line_range": [
            102,
            102
          ],
          "target_line_range": [
            103,
            107
          ]
        },
        {
          "code": "all_tasks = []\ntotal_hours = 0\nby_priority = {\"high\": 0, \"medium\": 0, \"low\": 0}\nby_assignee = {}\n\n",
          "display_code": "all_tasks = []\ntotal_hours = 0\nby_priority = {\"high\": 0, \"medium\": 0, \"low\": 0}\nby_assignee = {}\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 103,
          "line_range": [
            103,
            107
          ]
        },
        {
          "code": "# Create a streaming iterable\n",
          "display_code": "",
          "annotation": "Create a streaming iterable",
          "is_comment": true,
          "start_line": 108,
          "line_range": [
            108,
            108
          ],
          "target_line_range": [
            109,
            120
          ]
        },
        {
          "code": "tasks_stream = client.chat.completions.create_iterable(\n    model=\"gpt-3.5-turbo\",\n    response_model=Task,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n            Generate 5 tasks for a software development sprint.\n            Include high, medium, and low priority tasks.\n            Assign team members: Alex, Jamie, Taylor, and Morgan.\n        \"\"\"}\n    ]\n)\n\n",
          "display_code": "tasks_stream = client.chat.completions.create_iterable(\n    model=\"gpt-3.5-turbo\",\n    response_model=Task,\n    messages=[\n        {\"role\": \"user\", \"content\": \"\"\"\n            Generate 5 tasks for a software development sprint.\n            Include high, medium, and low priority tasks.\n            Assign team members: Alex, Jamie, Taylor, and Morgan.\n        \"\"\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 109,
          "line_range": [
            109,
            120
          ]
        },
        {
          "code": "# Process tasks in real-time\n",
          "display_code": "",
          "annotation": "Process tasks in real-time",
          "is_comment": true,
          "start_line": 121,
          "line_range": [
            121,
            121
          ],
          "target_line_range": [
            122,
            125
          ]
        },
        {
          "code": "print(\"Project task planning:\")\nprint(\"---------------------\")\n\nfor task in tasks_stream:\n",
          "display_code": "print(\"Project task planning:\")\nprint(\"---------------------\")\n\nfor task in tasks_stream:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 122,
          "line_range": [
            122,
            125
          ]
        },
        {
          "code": "    # Update statistics\n",
          "display_code": "",
          "annotation": "Update statistics",
          "is_comment": true,
          "start_line": 126,
          "line_range": [
            126,
            126
          ],
          "target_line_range": [
            127,
            133
          ]
        },
        {
          "code": "    all_tasks.append(task)\n    total_hours += task.estimated_hours\n    by_priority[task.priority.lower()] += 1\n\n    if task.assigned_to:\n        by_assignee[task.assigned_to] = by_assignee.get(task.assigned_to, 0) + 1\n\n",
          "display_code": "    all_tasks.append(task)\n    total_hours += task.estimated_hours\n    by_priority[task.priority.lower()] += 1\n\n    if task.assigned_to:\n        by_assignee[task.assigned_to] = by_assignee.get(task.assigned_to, 0) + 1\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 127,
          "line_range": [
            127,
            133
          ]
        },
        {
          "code": "    # Print the task\n",
          "display_code": "",
          "annotation": "Print the task",
          "is_comment": true,
          "start_line": 134,
          "line_range": [
            134,
            134
          ],
          "target_line_range": [
            135,
            139
          ]
        },
        {
          "code": "    print(f\"\\nNew Task: {task.title}\")\n    print(f\"Priority: {task.priority}\")\n    print(f\"Estimate: {task.estimated_hours} hours\")\n    print(f\"Assigned to: {task.assigned_to or 'Unassigned'}\")\n\n",
          "display_code": "    print(f\"\\nNew Task: {task.title}\")\n    print(f\"Priority: {task.priority}\")\n    print(f\"Estimate: {task.estimated_hours} hours\")\n    print(f\"Assigned to: {task.assigned_to or 'Unassigned'}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 135,
          "line_range": [
            135,
            139
          ]
        },
        {
          "code": "    # Print current statistics\n",
          "display_code": "",
          "annotation": "Print current statistics",
          "is_comment": true,
          "start_line": 140,
          "line_range": [
            140,
            140
          ],
          "target_line_range": [
            141,
            146
          ]
        },
        {
          "code": "    print(\"\\nCurrent Sprint Stats:\")\n    print(f\"Tasks planned: {len(all_tasks)}\")\n    print(f\"Total hours: {total_hours:.1f}\")\n    print(f\"By priority: {by_priority}\")\n    print(f\"By assignee: {by_assignee}\")\n\n",
          "display_code": "    print(\"\\nCurrent Sprint Stats:\")\n    print(f\"Tasks planned: {len(all_tasks)}\")\n    print(f\"Total hours: {total_hours:.1f}\")\n    print(f\"By priority: {by_priority}\")\n    print(f\"By assignee: {by_assignee}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 141,
          "line_range": [
            141,
            146
          ]
        },
        {
          "code": "    # Simulate a pause for real-time updates\n",
          "display_code": "",
          "annotation": "Simulate a pause for real-time updates",
          "is_comment": true,
          "start_line": 147,
          "line_range": [
            147,
            147
          ],
          "target_line_range": [
            148,
            169
          ]
        },
        {
          "code": "    time.sleep(0.5)\n\nprint(\"\\nSprint planning complete!\")\n\nfrom typing import Dict, List, Any, Generator, TypeVar, Generic\n\nT = TypeVar('T')\n\ndef combine_streams(streams: Dict[str, Generator[T, None, None]]) -> Generator[Dict[str, T], None, None]:\n    \"\"\"Combine multiple iterables with identification.\"\"\"\n    active_streams = streams.copy()\n    results = {key: None for key in streams}\n\n    while active_streams:\n        for key, stream in list(active_streams.items()):\n            try:\n                value = next(stream)\n                results[key] = value\n                yield results.copy()\n            except StopIteration:\n                del active_streams[key]\n\n",
          "display_code": "    time.sleep(0.5)\n\nprint(\"\\nSprint planning complete!\")\n\nfrom typing import Dict, List, Any, Generator, TypeVar, Generic\n\nT = TypeVar('T')\n\ndef combine_streams(streams: Dict[str, Generator[T, None, None]]) -> Generator[Dict[str, T], None, None]:\n    \"\"\"Combine multiple iterables with identification.\"\"\"\n    active_streams = streams.copy()\n    results = {key: None for key in streams}\n\n    while active_streams:\n        for key, stream in list(active_streams.items()):\n            try:\n                value = next(stream)\n                results[key] = value\n                yield results.copy()\n            except StopIteration:\n                del active_streams[key]\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 148,
          "line_range": [
            148,
            169
          ]
        },
        {
          "code": "# Create multiple document iterables\n",
          "display_code": "",
          "annotation": "Create multiple document iterables",
          "is_comment": true,
          "start_line": 170,
          "line_range": [
            170,
            170
          ],
          "target_line_range": [
            171,
            176
          ]
        },
        {
          "code": "class DocumentSummary(BaseModel):\n    title: str\n    content_type: str\n    key_points: List[str]\n    word_count: int\n\n",
          "display_code": "class DocumentSummary(BaseModel):\n    title: str\n    content_type: str\n    key_points: List[str]\n    word_count: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 171,
          "line_range": [
            171,
            176
          ]
        },
        {
          "code": "# Generate different types of documents\n",
          "display_code": "",
          "annotation": "Generate different types of documents",
          "is_comment": true,
          "start_line": 177,
          "line_range": [
            177,
            177
          ],
          "target_line_range": [
            178,
            183
          ]
        },
        {
          "code": "prompts = {\n    \"emails\": \"Generate summaries for 3 important emails about project deadlines\",\n    \"reports\": \"Generate summaries for 2 financial reports about quarterly earnings\",\n    \"articles\": \"Generate summaries for 2 news articles about technology trends\"\n}\n\n",
          "display_code": "prompts = {\n    \"emails\": \"Generate summaries for 3 important emails about project deadlines\",\n    \"reports\": \"Generate summaries for 2 financial reports about quarterly earnings\",\n    \"articles\": \"Generate summaries for 2 news articles about technology trends\"\n}\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 178,
          "line_range": [
            178,
            183
          ]
        },
        {
          "code": "# Create multiple streams\n",
          "display_code": "",
          "annotation": "Create multiple streams",
          "is_comment": true,
          "start_line": 184,
          "line_range": [
            184,
            184
          ],
          "target_line_range": [
            185,
            192
          ]
        },
        {
          "code": "streams = {}\nfor category, prompt in prompts.items():\n    streams[category] = client.chat.completions.create_iterable(\n        model=\"gpt-3.5-turbo\",\n        response_model=DocumentSummary,\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n\n",
          "display_code": "streams = {}\nfor category, prompt in prompts.items():\n    streams[category] = client.chat.completions.create_iterable(\n        model=\"gpt-3.5-turbo\",\n        response_model=DocumentSummary,\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 185,
          "line_range": [
            185,
            192
          ]
        },
        {
          "code": "# Process combined streams as they arrive\n",
          "display_code": "",
          "annotation": "Process combined streams as they arrive",
          "is_comment": true,
          "start_line": 193,
          "line_range": [
            193,
            193
          ],
          "target_line_range": [
            194,
            211
          ]
        },
        {
          "code": "for i, result in enumerate(combine_streams(streams), 1):\n    print(f\"\\nUpdate {i}:\")\n    for category, doc in result.items():\n        if doc:\n            print(f\"  {category.upper()}: {doc.title}\")\n        else:\n            print(f\"  {category.upper()}: No documents yet\")\n\nfrom typing import List, Optional, Iterator\nimport itertools\n\nclass NewsHeadline(BaseModel):\n    title: str\n    source: str\n    category: str\n    publish_date: str\n    summary: str\n\n",
          "display_code": "for i, result in enumerate(combine_streams(streams), 1):\n    print(f\"\\nUpdate {i}:\")\n    for category, doc in result.items():\n        if doc:\n            print(f\"  {category.upper()}: {doc.title}\")\n        else:\n            print(f\"  {category.upper()}: No documents yet\")\n\nfrom typing import List, Optional, Iterator\nimport itertools\n\nclass NewsHeadline(BaseModel):\n    title: str\n    source: str\n    category: str\n    publish_date: str\n    summary: str\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 194,
          "line_range": [
            194,
            211
          ]
        },
        {
          "code": "# Generate a potentially large stream of headlines\n",
          "display_code": "",
          "annotation": "Generate a potentially large stream of headlines",
          "is_comment": true,
          "start_line": 212,
          "line_range": [
            212,
            212
          ],
          "target_line_range": [
            213,
            220
          ]
        },
        {
          "code": "headlines_stream = client.chat.completions.create_iterable(\n    model=\"gpt-3.5-turbo\",\n    response_model=NewsHeadline,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Generate 10 fictional technology news headlines from the past week.\"}\n    ]\n)\n\n",
          "display_code": "headlines_stream = client.chat.completions.create_iterable(\n    model=\"gpt-3.5-turbo\",\n    response_model=NewsHeadline,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Generate 10 fictional technology news headlines from the past week.\"}\n    ]\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 213,
          "line_range": [
            213,
            220
          ]
        },
        {
          "code": "# Get only the first 3 headlines\n",
          "display_code": "",
          "annotation": "Get only the first 3 headlines",
          "is_comment": true,
          "start_line": 221,
          "line_range": [
            221,
            221
          ],
          "target_line_range": [
            222,
            229
          ]
        },
        {
          "code": "print(\"Top Headlines:\")\nfor i, headline in enumerate(itertools.islice(headlines_stream, 3)):\n    print(f\"\\nHeadline {i+1}: {headline.title}\")\n    print(f\"Source: {headline.source}\")\n    print(f\"Category: {headline.category}\")\n    print(f\"Date: {headline.publish_date}\")\n    print(f\"Summary: {headline.summary}\")\n\n",
          "display_code": "print(\"Top Headlines:\")\nfor i, headline in enumerate(itertools.islice(headlines_stream, 3)):\n    print(f\"\\nHeadline {i+1}: {headline.title}\")\n    print(f\"Source: {headline.source}\")\n    print(f\"Category: {headline.category}\")\n    print(f\"Date: {headline.publish_date}\")\n    print(f\"Summary: {headline.summary}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 222,
          "line_range": [
            222,
            229
          ]
        },
        {
          "code": "# Note: The rest of the stream is not processed, which saves tokens\n",
          "display_code": "",
          "annotation": "Note: The rest of the stream is not processed, which saves tokens",
          "is_comment": true,
          "start_line": 230,
          "line_range": [
            230,
            230
          ],
          "target_line_range": [
            231,
            232
          ]
        },
        {
          "code": "print(\"\\nShowing only the first 3 headlines.\")\n\n",
          "display_code": "print(\"\\nShowing only the first 3 headlines.\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 231,
          "line_range": [
            231,
            232
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python streaming-lists.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "005-streaming",
      "section_title": "Streaming"
    },
    {
      "id": "026-progressive-updates",
      "title": "Progressive Updates",
      "description": "",
      "order": 26,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Instructor's partial streaming capability allows you to render UI updates as structured data becomes available.\n# This example shows how to progressively update a user interface as data streams in.\n",
          "display_code": "",
          "annotation": "Instructor's partial streaming capability allows you to render UI updates as structured data becomes available.\nThis example shows how to progressively update a user interface as data streams in.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            4
          ],
          "target_line_range": [
            5,
            5
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 5,
          "line_range": [
            5,
            5
          ]
        },
        {
          "code": "# Import necessary libraries\n",
          "display_code": "",
          "annotation": "Import necessary libraries",
          "is_comment": true,
          "start_line": 6,
          "line_range": [
            6,
            6
          ],
          "target_line_range": [
            7,
            20
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\nfrom typing import List, Dict, Optional\nimport instructor\nfrom openai import OpenAI\nimport time\nfrom enum import Enum\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.progress import Progress, BarColumn, TextColumn, TaskProgressColumn\nfrom rich.table import Table\nfrom rich.layout import Layout\nfrom rich.live import Live\nfrom rich.text import Text\n\n",
          "display_code": "from pydantic import BaseModel, Field\nfrom typing import List, Dict, Optional\nimport instructor\nfrom openai import OpenAI\nimport time\nfrom enum import Enum\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.progress import Progress, BarColumn, TextColumn, TaskProgressColumn\nfrom rich.table import Table\nfrom rich.layout import Layout\nfrom rich.live import Live\nfrom rich.text import Text\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 7,
          "line_range": [
            7,
            20
          ]
        },
        {
          "code": "# Initialize Rich console\n",
          "display_code": "",
          "annotation": "Initialize Rich console",
          "is_comment": true,
          "start_line": 21,
          "line_range": [
            21,
            21
          ],
          "target_line_range": [
            22,
            24
          ]
        },
        {
          "code": "console = Console()\n\n\n",
          "display_code": "console = Console()\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 22,
          "line_range": [
            22,
            24
          ]
        },
        {
          "code": "# Define our weather forecast data model\n",
          "display_code": "",
          "annotation": "Define our weather forecast data model",
          "is_comment": true,
          "start_line": 25,
          "line_range": [
            25,
            25
          ],
          "target_line_range": [
            26,
            34
          ]
        },
        {
          "code": "class WeatherForecast(BaseModel):\n    location: str\n    current_temp: float = Field(description=\"Current temperature in Celsius\")\n    conditions: str = Field(description=\"Current weather conditions\")\n    forecast: List[str] = Field(description=\"Weather forecast for the next few days\")\n    humidity: Optional[float] = Field(None, description=\"Current humidity percentage\")\n    wind_speed: Optional[float] = Field(None, description=\"Wind speed in km/h\")\n\n\n",
          "display_code": "class WeatherForecast(BaseModel):\n    location: str\n    current_temp: float = Field(description=\"Current temperature in Celsius\")\n    conditions: str = Field(description=\"Current weather conditions\")\n    forecast: List[str] = Field(description=\"Weather forecast for the next few days\")\n    humidity: Optional[float] = Field(None, description=\"Current humidity percentage\")\n    wind_speed: Optional[float] = Field(None, description=\"Wind speed in km/h\")\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 26,
          "line_range": [
            26,
            34
          ]
        },
        {
          "code": "# Patch the OpenAI client with Instructor\n",
          "display_code": "",
          "annotation": "Patch the OpenAI client with Instructor",
          "is_comment": true,
          "start_line": 35,
          "line_range": [
            35,
            35
          ],
          "target_line_range": [
            36,
            38
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 36,
          "line_range": [
            36,
            38
          ]
        },
        {
          "code": "# Define a simulated UI update function to display partial forecast data\n",
          "display_code": "",
          "annotation": "Define a simulated UI update function to display partial forecast data",
          "is_comment": true,
          "start_line": 39,
          "line_range": [
            39,
            39
          ],
          "target_line_range": [
            40,
            40
          ]
        },
        {
          "code": "def update_ui(partial_forecast):\n",
          "display_code": "def update_ui(partial_forecast):\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 40,
          "line_range": [
            40,
            40
          ]
        },
        {
          "code": "    # Create a panel for weather information\n",
          "display_code": "",
          "annotation": "Create a panel for weather information",
          "is_comment": true,
          "start_line": 41,
          "line_range": [
            41,
            41
          ],
          "target_line_range": [
            42,
            45
          ]
        },
        {
          "code": "    weather_table = Table(show_header=False, expand=True)\n    weather_table.add_column(\"Label\")\n    weather_table.add_column(\"Value\")\n\n",
          "display_code": "    weather_table = Table(show_header=False, expand=True)\n    weather_table.add_column(\"Label\")\n    weather_table.add_column(\"Value\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 42,
          "line_range": [
            42,
            45
          ]
        },
        {
          "code": "    # Location - show placeholder if not available yet\n",
          "display_code": "",
          "annotation": "Location - show placeholder if not available yet",
          "is_comment": true,
          "start_line": 46,
          "line_range": [
            46,
            46
          ],
          "target_line_range": [
            47,
            53
          ]
        },
        {
          "code": "    location = (\n        partial_forecast.location\n        if partial_forecast.location\n        else \"Loading location...\"\n    )\n    weather_table.add_row(\"\ud83d\udccd Location\", location)\n\n",
          "display_code": "    location = (\n        partial_forecast.location\n        if partial_forecast.location\n        else \"Loading location...\"\n    )\n    weather_table.add_row(\"\ud83d\udccd Location\", location)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 47,
          "line_range": [
            47,
            53
          ]
        },
        {
          "code": "    # Temperature and conditions section\n",
          "display_code": "",
          "annotation": "Temperature and conditions section",
          "is_comment": true,
          "start_line": 54,
          "line_range": [
            54,
            54
          ],
          "target_line_range": [
            55,
            67
          ]
        },
        {
          "code": "    temp = (\n        f\"{partial_forecast.current_temp}\u00b0C\"\n        if partial_forecast.current_temp is not None\n        else \"--\u00b0C\"\n    )\n    conditions = (\n        partial_forecast.conditions\n        if partial_forecast.conditions\n        else \"Loading conditions...\"\n    )\n    weather_table.add_row(\"\ud83c\udf21\ufe0f Temperature\", temp)\n    weather_table.add_row(\"\u2601\ufe0f Conditions\", conditions)\n\n",
          "display_code": "    temp = (\n        f\"{partial_forecast.current_temp}\u00b0C\"\n        if partial_forecast.current_temp is not None\n        else \"--\u00b0C\"\n    )\n    conditions = (\n        partial_forecast.conditions\n        if partial_forecast.conditions\n        else \"Loading conditions...\"\n    )\n    weather_table.add_row(\"\ud83c\udf21\ufe0f Temperature\", temp)\n    weather_table.add_row(\"\u2601\ufe0f Conditions\", conditions)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 55,
          "line_range": [
            55,
            67
          ]
        },
        {
          "code": "    # Additional data\n",
          "display_code": "",
          "annotation": "Additional data",
          "is_comment": true,
          "start_line": 68,
          "line_range": [
            68,
            68
          ],
          "target_line_range": [
            69,
            81
          ]
        },
        {
          "code": "    humidity = (\n        f\"{partial_forecast.humidity}%\"\n        if partial_forecast.humidity is not None\n        else \"--%\"\n    )\n    wind = (\n        f\"{partial_forecast.wind_speed} km/h\"\n        if partial_forecast.wind_speed is not None\n        else \"-- km/h\"\n    )\n    weather_table.add_row(\"\ud83d\udca7 Humidity\", humidity)\n    weather_table.add_row(\"\ud83d\udca8 Wind\", wind)\n\n",
          "display_code": "    humidity = (\n        f\"{partial_forecast.humidity}%\"\n        if partial_forecast.humidity is not None\n        else \"--%\"\n    )\n    wind = (\n        f\"{partial_forecast.wind_speed} km/h\"\n        if partial_forecast.wind_speed is not None\n        else \"-- km/h\"\n    )\n    weather_table.add_row(\"\ud83d\udca7 Humidity\", humidity)\n    weather_table.add_row(\"\ud83d\udca8 Wind\", wind)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 69,
          "line_range": [
            69,
            81
          ]
        },
        {
          "code": "    # Forecast section\n",
          "display_code": "",
          "annotation": "Forecast section",
          "is_comment": true,
          "start_line": 82,
          "line_range": [
            82,
            82
          ],
          "target_line_range": [
            83,
            91
          ]
        },
        {
          "code": "    forecast_text = Text()\n    if not partial_forecast.forecast:\n        forecast_text.append(\"Loading forecast data...\")\n    else:\n        for i, day in enumerate(partial_forecast.forecast):\n            forecast_text.append(\n                f\"\u2022 {day}\\n\" if i < len(partial_forecast.forecast) - 1 else f\"\u2022 {day}\"\n            )\n\n",
          "display_code": "    forecast_text = Text()\n    if not partial_forecast.forecast:\n        forecast_text.append(\"Loading forecast data...\")\n    else:\n        for i, day in enumerate(partial_forecast.forecast):\n            forecast_text.append(\n                f\"\u2022 {day}\\n\" if i < len(partial_forecast.forecast) - 1 else f\"\u2022 {day}\"\n            )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 83,
          "line_range": [
            83,
            91
          ]
        },
        {
          "code": "    # Calculate progress\n",
          "display_code": "",
          "annotation": "Calculate progress",
          "is_comment": true,
          "start_line": 92,
          "line_range": [
            92,
            92
          ],
          "target_line_range": [
            93,
            116
          ]
        },
        {
          "code": "    fields = [\n        \"location\",\n        \"current_temp\",\n        \"conditions\",\n        \"forecast\",\n        \"humidity\",\n        \"wind_speed\",\n    ]\n    populated = sum(\n        1\n        for f in fields\n        if getattr(partial_forecast, f) is not None\n        and getattr(partial_forecast, f) != []\n    )\n    progress_value = populated / len(fields)\n\n    progress = Progress(\n        TextColumn(\"[bold blue]Loading:\"),\n        BarColumn(),\n        TaskProgressColumn(),\n        expand=True,\n    )\n    task = progress.add_task(\"\", total=1.0, completed=progress_value)\n\n",
          "display_code": "    fields = [\n        \"location\",\n        \"current_temp\",\n        \"conditions\",\n        \"forecast\",\n        \"humidity\",\n        \"wind_speed\",\n    ]\n    populated = sum(\n        1\n        for f in fields\n        if getattr(partial_forecast, f) is not None\n        and getattr(partial_forecast, f) != []\n    )\n    progress_value = populated / len(fields)\n\n    progress = Progress(\n        TextColumn(\"[bold blue]Loading:\"),\n        BarColumn(),\n        TaskProgressColumn(),\n        expand=True,\n    )\n    task = progress.add_task(\"\", total=1.0, completed=progress_value)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 93,
          "line_range": [
            93,
            116
          ]
        },
        {
          "code": "    # Combine everything in a panel\n",
          "display_code": "",
          "annotation": "Combine everything in a panel",
          "is_comment": true,
          "start_line": 117,
          "line_range": [
            117,
            117
          ],
          "target_line_range": [
            118,
            128
          ]
        },
        {
          "code": "    layout = Layout()\n    layout.split(\n        Layout(Panel(weather_table, title=\"Weather Forecast\"), name=\"weather\"),\n        Layout(Panel(forecast_text, title=\"Forecast\"), name=\"forecast\"),\n        Layout(Panel(progress, title=\"Progress\"), name=\"progress\"),\n    )\n\n    console.clear()\n    console.print(layout)\n\n\n",
          "display_code": "    layout = Layout()\n    layout.split(\n        Layout(Panel(weather_table, title=\"Weather Forecast\"), name=\"weather\"),\n        Layout(Panel(forecast_text, title=\"Forecast\"), name=\"forecast\"),\n        Layout(Panel(progress, title=\"Progress\"), name=\"progress\"),\n    )\n\n    console.clear()\n    console.print(layout)\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 118,
          "line_range": [
            118,
            128
          ]
        },
        {
          "code": "# Create a partial stream using Instructor's create_partial method\n",
          "display_code": "",
          "annotation": "Create a partial stream using Instructor's create_partial method",
          "is_comment": true,
          "start_line": 129,
          "line_range": [
            129,
            129
          ],
          "target_line_range": [
            130,
            140
          ]
        },
        {
          "code": "forecast_stream = client.chat.completions.create_partial(\n    model=\"gpt-3.5-turbo\",\n    response_model=WeatherForecast,\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Generate a fictional weather forecast for Tokyo, Japan.\",\n        }\n    ],\n)\n\n",
          "display_code": "forecast_stream = client.chat.completions.create_partial(\n    model=\"gpt-3.5-turbo\",\n    response_model=WeatherForecast,\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Generate a fictional weather forecast for Tokyo, Japan.\",\n        }\n    ],\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 130,
          "line_range": [
            130,
            140
          ]
        },
        {
          "code": "# Update UI with each new partial object received from the stream\n",
          "display_code": "",
          "annotation": "Update UI with each new partial object received from the stream",
          "is_comment": true,
          "start_line": 141,
          "line_range": [
            141,
            141
          ],
          "target_line_range": [
            142,
            147
          ]
        },
        {
          "code": "for partial_forecast in forecast_stream:\n    update_ui(partial_forecast)\n    time.sleep(0.3)  # Slow down for demonstration\n\nconsole.print(\"[bold green]\u2705 Forecast fully loaded!\")\n\n",
          "display_code": "for partial_forecast in forecast_stream:\n    update_ui(partial_forecast)\n    time.sleep(0.3)  # Slow down for demonstration\n\nconsole.print(\"[bold green]\u2705 Forecast fully loaded!\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 142,
          "line_range": [
            142,
            147
          ]
        },
        {
          "code": "# EXAMPLE 2: Sales Dashboard\n# This example demonstrates using partial streaming for a business dashboard\n",
          "display_code": "",
          "annotation": "EXAMPLE 2: Sales Dashboard\nThis example demonstrates using partial streaming for a business dashboard",
          "is_comment": true,
          "start_line": 148,
          "line_range": [
            148,
            149
          ],
          "target_line_range": [
            150,
            151
          ]
        },
        {
          "code": "\n\n",
          "display_code": "\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 150,
          "line_range": [
            150,
            151
          ]
        },
        {
          "code": "# Define a data model for sales information\n",
          "display_code": "",
          "annotation": "Define a data model for sales information",
          "is_comment": true,
          "start_line": 152,
          "line_range": [
            152,
            152
          ],
          "target_line_range": [
            153,
            164
          ]
        },
        {
          "code": "class SalesData(BaseModel):\n    total_revenue: float = Field(description=\"Total revenue in USD\")\n    products_sold: int = Field(description=\"Total number of products sold\")\n    by_category: Dict[str, float] = Field(\n        description=\"Revenue breakdown by product category\"\n    )\n    top_products: List[str] = Field(description=\"List of top-selling products\")\n    growth_rate: Optional[float] = Field(\n        None, description=\"Year-over-year growth rate percentage\"\n    )\n\n\n",
          "display_code": "class SalesData(BaseModel):\n    total_revenue: float = Field(description=\"Total revenue in USD\")\n    products_sold: int = Field(description=\"Total number of products sold\")\n    by_category: Dict[str, float] = Field(\n        description=\"Revenue breakdown by product category\"\n    )\n    top_products: List[str] = Field(description=\"List of top-selling products\")\n    growth_rate: Optional[float] = Field(\n        None, description=\"Year-over-year growth rate percentage\"\n    )\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 153,
          "line_range": [
            153,
            164
          ]
        },
        {
          "code": "# Simulated chart rendering function\n",
          "display_code": "",
          "annotation": "Simulated chart rendering function",
          "is_comment": true,
          "start_line": 165,
          "line_range": [
            165,
            165
          ],
          "target_line_range": [
            166,
            168
          ]
        },
        {
          "code": "def render_charts(data):\n    layout = Layout()\n\n",
          "display_code": "def render_charts(data):\n    layout = Layout()\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 166,
          "line_range": [
            166,
            168
          ]
        },
        {
          "code": "    # Header\n",
          "display_code": "",
          "annotation": "Header",
          "is_comment": true,
          "start_line": 169,
          "line_range": [
            169,
            169
          ],
          "target_line_range": [
            170,
            171
          ]
        },
        {
          "code": "    header = Panel(\"Sales Dashboard\", style=\"bold white on blue\")\n\n",
          "display_code": "    header = Panel(\"Sales Dashboard\", style=\"bold white on blue\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 170,
          "line_range": [
            170,
            171
          ]
        },
        {
          "code": "    # Revenue and products display\n",
          "display_code": "",
          "annotation": "Revenue and products display",
          "is_comment": true,
          "start_line": 172,
          "line_range": [
            172,
            172
          ],
          "target_line_range": [
            173,
            188
          ]
        },
        {
          "code": "    stats_table = Table(expand=True)\n    stats_table.add_column(\"Metric\", style=\"cyan\")\n    stats_table.add_column(\"Value\", style=\"green\")\n\n    revenue = (\n        f\"${data.total_revenue:,.2f}\"\n        if data.total_revenue is not None\n        else \"Loading...\"\n    )\n    products = (\n        f\"{data.products_sold:,}\" if data.products_sold is not None else \"Loading...\"\n    )\n\n    stats_table.add_row(\"Revenue\", revenue)\n    stats_table.add_row(\"Products Sold\", products)\n\n",
          "display_code": "    stats_table = Table(expand=True)\n    stats_table.add_column(\"Metric\", style=\"cyan\")\n    stats_table.add_column(\"Value\", style=\"green\")\n\n    revenue = (\n        f\"${data.total_revenue:,.2f}\"\n        if data.total_revenue is not None\n        else \"Loading...\"\n    )\n    products = (\n        f\"{data.products_sold:,}\" if data.products_sold is not None else \"Loading...\"\n    )\n\n    stats_table.add_row(\"Revenue\", revenue)\n    stats_table.add_row(\"Products Sold\", products)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 173,
          "line_range": [
            173,
            188
          ]
        },
        {
          "code": "    # Growth rate\n",
          "display_code": "",
          "annotation": "Growth rate",
          "is_comment": true,
          "start_line": 189,
          "line_range": [
            189,
            189
          ],
          "target_line_range": [
            190,
            196
          ]
        },
        {
          "code": "    growth_text = \"Loading...\"\n    if data.growth_rate is not None:\n        growth = f\"{data.growth_rate:+.1f}%\"\n        color = \"green\" if data.growth_rate > 0 else \"red\"\n        growth_text = Text(growth, style=color)\n    stats_table.add_row(\"Growth Rate\", growth_text)\n\n",
          "display_code": "    growth_text = \"Loading...\"\n    if data.growth_rate is not None:\n        growth = f\"{data.growth_rate:+.1f}%\"\n        color = \"green\" if data.growth_rate > 0 else \"red\"\n        growth_text = Text(growth, style=color)\n    stats_table.add_row(\"Growth Rate\", growth_text)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 190,
          "line_range": [
            190,
            196
          ]
        },
        {
          "code": "    # Category breakdown\n",
          "display_code": "",
          "annotation": "Category breakdown",
          "is_comment": true,
          "start_line": 197,
          "line_range": [
            197,
            197
          ],
          "target_line_range": [
            198,
            211
          ]
        },
        {
          "code": "    category_table = Table(title=\"Revenue by Category\", expand=True)\n    category_table.add_column(\"Category\")\n    category_table.add_column(\"Amount\")\n    category_table.add_column(\"Chart\")\n\n    if not data.by_category:\n        category_table.add_row(\"Loading category data...\", \"\", \"\")\n    else:\n        max_value = max(data.by_category.values()) if data.by_category else 0\n        for category, amount in data.by_category.items():\n            bar_length = int(20 * (amount / max_value)) if max_value > 0 else 0\n            bar = \"\u2588\" * bar_length\n            category_table.add_row(category, f\"${amount:,.2f}\", bar)\n\n",
          "display_code": "    category_table = Table(title=\"Revenue by Category\", expand=True)\n    category_table.add_column(\"Category\")\n    category_table.add_column(\"Amount\")\n    category_table.add_column(\"Chart\")\n\n    if not data.by_category:\n        category_table.add_row(\"Loading category data...\", \"\", \"\")\n    else:\n        max_value = max(data.by_category.values()) if data.by_category else 0\n        for category, amount in data.by_category.items():\n            bar_length = int(20 * (amount / max_value)) if max_value > 0 else 0\n            bar = \"\u2588\" * bar_length\n            category_table.add_row(category, f\"${amount:,.2f}\", bar)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 198,
          "line_range": [
            198,
            211
          ]
        },
        {
          "code": "    # Top products\n",
          "display_code": "",
          "annotation": "Top products",
          "is_comment": true,
          "start_line": 212,
          "line_range": [
            212,
            212
          ],
          "target_line_range": [
            213,
            222
          ]
        },
        {
          "code": "    products_table = Table(title=\"Top Products\", expand=True)\n    products_table.add_column(\"Rank\")\n    products_table.add_column(\"Product\")\n\n    if not data.top_products:\n        products_table.add_row(\"\", \"Loading top products...\")\n    else:\n        for i, product in enumerate(data.top_products, 1):\n            products_table.add_row(f\"{i}\", product)\n\n",
          "display_code": "    products_table = Table(title=\"Top Products\", expand=True)\n    products_table.add_column(\"Rank\")\n    products_table.add_column(\"Product\")\n\n    if not data.top_products:\n        products_table.add_row(\"\", \"Loading top products...\")\n    else:\n        for i, product in enumerate(data.top_products, 1):\n            products_table.add_row(f\"{i}\", product)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 213,
          "line_range": [
            213,
            222
          ]
        },
        {
          "code": "    # Create layout\n",
          "display_code": "",
          "annotation": "Create layout",
          "is_comment": true,
          "start_line": 223,
          "line_range": [
            223,
            223
          ],
          "target_line_range": [
            224,
            234
          ]
        },
        {
          "code": "    layout.split(\n        Layout(header, size=3),\n        Layout(Panel(stats_table, title=\"Key Metrics\"), name=\"stats\", size=10),\n        Layout(Panel(category_table, title=\"Categories\"), name=\"categories\"),\n        Layout(Panel(products_table, title=\"Top Products\"), name=\"products\"),\n    )\n\n    console.clear()\n    console.print(layout)\n\n\n",
          "display_code": "    layout.split(\n        Layout(header, size=3),\n        Layout(Panel(stats_table, title=\"Key Metrics\"), name=\"stats\", size=10),\n        Layout(Panel(category_table, title=\"Categories\"), name=\"categories\"),\n        Layout(Panel(products_table, title=\"Top Products\"), name=\"products\"),\n    )\n\n    console.clear()\n    console.print(layout)\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 224,
          "line_range": [
            224,
            234
          ]
        },
        {
          "code": "# Create a partial stream\n",
          "display_code": "",
          "annotation": "Create a partial stream",
          "is_comment": true,
          "start_line": 235,
          "line_range": [
            235,
            235
          ],
          "target_line_range": [
            236,
            246
          ]
        },
        {
          "code": "sales_stream = client.chat.completions.create_partial(\n    model=\"gpt-3.5-turbo\",\n    response_model=SalesData,\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Generate fictional quarterly sales data for an electronics company.\",\n        }\n    ],\n)\n\n",
          "display_code": "sales_stream = client.chat.completions.create_partial(\n    model=\"gpt-3.5-turbo\",\n    response_model=SalesData,\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Generate fictional quarterly sales data for an electronics company.\",\n        }\n    ],\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 236,
          "line_range": [
            236,
            246
          ]
        },
        {
          "code": "# Update visualization as data comes in\n",
          "display_code": "",
          "annotation": "Update visualization as data comes in",
          "is_comment": true,
          "start_line": 247,
          "line_range": [
            247,
            247
          ],
          "target_line_range": [
            248,
            274
          ]
        },
        {
          "code": "for partial_data in sales_stream:\n    render_charts(partial_data)\n    time.sleep(0.5)  # Slow down for demonstration\n\nconsole.print(\"[bold green]\u2705 Dashboard fully loaded!\")\n\n\nclass TaskStatus(str, Enum):\n    PENDING = \"pending\"\n    IN_PROGRESS = \"in_progress\"\n    COMPLETED = \"completed\"\n\n\nclass SubTask(BaseModel):\n    name: str\n    status: TaskStatus = TaskStatus.PENDING\n    details: Optional[str] = None\n\n\nclass AnalysisTask(BaseModel):\n    document_name: str\n    total_words: Optional[int] = None\n    subtasks: List[SubTask] = Field(default_factory=list)\n    key_findings: List[str] = Field(default_factory=list)\n    completion_percentage: Optional[float] = None\n\n\n",
          "display_code": "for partial_data in sales_stream:\n    render_charts(partial_data)\n    time.sleep(0.5)  # Slow down for demonstration\n\nconsole.print(\"[bold green]\u2705 Dashboard fully loaded!\")\n\n\nclass TaskStatus(str, Enum):\n    PENDING = \"pending\"\n    IN_PROGRESS = \"in_progress\"\n    COMPLETED = \"completed\"\n\n\nclass SubTask(BaseModel):\n    name: str\n    status: TaskStatus = TaskStatus.PENDING\n    details: Optional[str] = None\n\n\nclass AnalysisTask(BaseModel):\n    document_name: str\n    total_words: Optional[int] = None\n    subtasks: List[SubTask] = Field(default_factory=list)\n    key_findings: List[str] = Field(default_factory=list)\n    completion_percentage: Optional[float] = None\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 248,
          "line_range": [
            248,
            274
          ]
        },
        {
          "code": "# Create a partial stream for a document analysis task\n",
          "display_code": "",
          "annotation": "Create a partial stream for a document analysis task",
          "is_comment": true,
          "start_line": 275,
          "line_range": [
            275,
            275
          ],
          "target_line_range": [
            276,
            291
          ]
        },
        {
          "code": "analysis_stream = client.chat.completions.create_partial(\n    model=\"gpt-3.5-turbo\",\n    response_model=AnalysisTask,\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"\"\"\n            Simulate a document analysis process for a research paper titled\n            'Advances in Renewable Energy Storage'. Include multiple subtasks\n            and key findings.\n        \"\"\",\n        }\n    ],\n)\n\n\n",
          "display_code": "analysis_stream = client.chat.completions.create_partial(\n    model=\"gpt-3.5-turbo\",\n    response_model=AnalysisTask,\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"\"\"\n            Simulate a document analysis process for a research paper titled\n            'Advances in Renewable Energy Storage'. Include multiple subtasks\n            and key findings.\n        \"\"\",\n        }\n    ],\n)\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 276,
          "line_range": [
            276,
            291
          ]
        },
        {
          "code": "# Display progress updates\n",
          "display_code": "",
          "annotation": "Display progress updates",
          "is_comment": true,
          "start_line": 292,
          "line_range": [
            292,
            292
          ],
          "target_line_range": [
            293,
            295
          ]
        },
        {
          "code": "def render_progress_ui(task):\n    layout = Layout()\n\n",
          "display_code": "def render_progress_ui(task):\n    layout = Layout()\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 293,
          "line_range": [
            293,
            295
          ]
        },
        {
          "code": "    # Header\n",
          "display_code": "",
          "annotation": "Header",
          "is_comment": true,
          "start_line": 296,
          "line_range": [
            296,
            296
          ],
          "target_line_range": [
            297,
            299
          ]
        },
        {
          "code": "    doc_name = task.document_name if task.document_name else \"Loading document...\"\n    header = Panel(f\"Analyzing: {doc_name}\", style=\"bold white on blue\")\n\n",
          "display_code": "    doc_name = task.document_name if task.document_name else \"Loading document...\"\n    header = Panel(f\"Analyzing: {doc_name}\", style=\"bold white on blue\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 297,
          "line_range": [
            297,
            299
          ]
        },
        {
          "code": "    # Document stats\n",
          "display_code": "",
          "annotation": "Document stats",
          "is_comment": true,
          "start_line": 300,
          "line_range": [
            300,
            300
          ],
          "target_line_range": [
            301,
            306
          ]
        },
        {
          "code": "    doc_info = Text()\n    if task.total_words is not None:\n        doc_info.append(f\"Document length: {task.total_words:,} words\")\n    else:\n        doc_info.append(\"Document length: Calculating...\")\n\n",
          "display_code": "    doc_info = Text()\n    if task.total_words is not None:\n        doc_info.append(f\"Document length: {task.total_words:,} words\")\n    else:\n        doc_info.append(\"Document length: Calculating...\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 301,
          "line_range": [
            301,
            306
          ]
        },
        {
          "code": "    # Subtasks progress\n",
          "display_code": "",
          "annotation": "Subtasks progress",
          "is_comment": true,
          "start_line": 307,
          "line_range": [
            307,
            307
          ],
          "target_line_range": [
            308,
            316
          ]
        },
        {
          "code": "    tasks_table = Table(expand=True)\n    tasks_table.add_column(\"Status\")\n    tasks_table.add_column(\"Task\")\n    tasks_table.add_column(\"Details\")\n\n    if not task.subtasks:\n        tasks_table.add_row(\"\u23f1\ufe0f\", \"Preparing analysis tasks...\", \"\")\n    else:\n        for subtask in task.subtasks:\n",
          "display_code": "    tasks_table = Table(expand=True)\n    tasks_table.add_column(\"Status\")\n    tasks_table.add_column(\"Task\")\n    tasks_table.add_column(\"Details\")\n\n    if not task.subtasks:\n        tasks_table.add_row(\"\u23f1\ufe0f\", \"Preparing analysis tasks...\", \"\")\n    else:\n        for subtask in task.subtasks:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 308,
          "line_range": [
            308,
            316
          ]
        },
        {
          "code": "            # Status symbol\n",
          "display_code": "",
          "annotation": "Status symbol",
          "is_comment": true,
          "start_line": 317,
          "line_range": [
            317,
            317
          ],
          "target_line_range": [
            318,
            327
          ]
        },
        {
          "code": "            if subtask.status == TaskStatus.COMPLETED:\n                symbol = \"\u2705\"\n            elif subtask.status == TaskStatus.IN_PROGRESS:\n                symbol = \"\u23f3\"\n            else:\n                symbol = \"\u23f1\ufe0f\"\n\n            details = subtask.details if subtask.details else \"\"\n            tasks_table.add_row(symbol, subtask.name, details)\n\n",
          "display_code": "            if subtask.status == TaskStatus.COMPLETED:\n                symbol = \"\u2705\"\n            elif subtask.status == TaskStatus.IN_PROGRESS:\n                symbol = \"\u23f3\"\n            else:\n                symbol = \"\u23f1\ufe0f\"\n\n            details = subtask.details if subtask.details else \"\"\n            tasks_table.add_row(symbol, subtask.name, details)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 318,
          "line_range": [
            318,
            327
          ]
        },
        {
          "code": "    # Findings so far\n",
          "display_code": "",
          "annotation": "Findings so far",
          "is_comment": true,
          "start_line": 328,
          "line_range": [
            328,
            328
          ],
          "target_line_range": [
            329,
            337
          ]
        },
        {
          "code": "    findings_text = Text()\n    if not task.key_findings:\n        findings_text.append(\"No findings yet...\")\n    else:\n        for i, finding in enumerate(task.key_findings, 1):\n            findings_text.append(\n                f\"{i}. {finding}\\n\" if i < len(task.key_findings) else f\"{i}. {finding}\"\n            )\n\n",
          "display_code": "    findings_text = Text()\n    if not task.key_findings:\n        findings_text.append(\"No findings yet...\")\n    else:\n        for i, finding in enumerate(task.key_findings, 1):\n            findings_text.append(\n                f\"{i}. {finding}\\n\" if i < len(task.key_findings) else f\"{i}. {finding}\"\n            )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 329,
          "line_range": [
            329,
            337
          ]
        },
        {
          "code": "    # Overall progress\n",
          "display_code": "",
          "annotation": "Overall progress",
          "is_comment": true,
          "start_line": 338,
          "line_range": [
            338,
            338
          ],
          "target_line_range": [
            339,
            348
          ]
        },
        {
          "code": "    progress = Progress(\n        TextColumn(\"[bold blue]Overall Progress:\"),\n        BarColumn(),\n        TaskProgressColumn(),\n        expand=True,\n    )\n    task_progress = progress.add_task(\n        \"\", total=1.0, completed=task.completion_percentage or 0\n    )\n\n",
          "display_code": "    progress = Progress(\n        TextColumn(\"[bold blue]Overall Progress:\"),\n        BarColumn(),\n        TaskProgressColumn(),\n        expand=True,\n    )\n    task_progress = progress.add_task(\n        \"\", total=1.0, completed=task.completion_percentage or 0\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 339,
          "line_range": [
            339,
            348
          ]
        },
        {
          "code": "    # Create layout\n",
          "display_code": "",
          "annotation": "Create layout",
          "is_comment": true,
          "start_line": 349,
          "line_range": [
            349,
            349
          ],
          "target_line_range": [
            350,
            361
          ]
        },
        {
          "code": "    layout.split(\n        Layout(header, size=3),\n        Layout(Panel(doc_info, title=\"Document Info\"), size=5),\n        Layout(Panel(tasks_table, title=\"Analysis Progress\"), name=\"tasks\"),\n        Layout(Panel(findings_text, title=\"Key Findings\"), name=\"findings\"),\n        Layout(Panel(progress, title=\"Progress\"), name=\"progress\", size=5),\n    )\n\n    console.clear()\n    console.print(layout)\n\n\n",
          "display_code": "    layout.split(\n        Layout(header, size=3),\n        Layout(Panel(doc_info, title=\"Document Info\"), size=5),\n        Layout(Panel(tasks_table, title=\"Analysis Progress\"), name=\"tasks\"),\n        Layout(Panel(findings_text, title=\"Key Findings\"), name=\"findings\"),\n        Layout(Panel(progress, title=\"Progress\"), name=\"progress\", size=5),\n    )\n\n    console.clear()\n    console.print(layout)\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 350,
          "line_range": [
            350,
            361
          ]
        },
        {
          "code": "# Update UI as analysis progresses\n",
          "display_code": "",
          "annotation": "Update UI as analysis progresses",
          "is_comment": true,
          "start_line": 362,
          "line_range": [
            362,
            362
          ],
          "target_line_range": [
            363,
            379
          ]
        },
        {
          "code": "for partial_analysis in analysis_stream:\n    render_progress_ui(partial_analysis)\n    time.sleep(0.3)  # Slow down for demonstration\n\nconsole.print(\"[bold green]\u2705 Analysis complete!\")\n\n\nclass DocumentSummary(BaseModel):\n    title: str\n    author: Optional[str] = None\n    publication_date: Optional[str] = None\n    word_count: Optional[int] = None\n    summary: str = Field(description=\"Complete summary of the document\")\n    key_points: List[str] = Field(default_factory=list)\n    categories: List[str] = Field(default_factory=list)\n\n\n",
          "display_code": "for partial_analysis in analysis_stream:\n    render_progress_ui(partial_analysis)\n    time.sleep(0.3)  # Slow down for demonstration\n\nconsole.print(\"[bold green]\u2705 Analysis complete!\")\n\n\nclass DocumentSummary(BaseModel):\n    title: str\n    author: Optional[str] = None\n    publication_date: Optional[str] = None\n    word_count: Optional[int] = None\n    summary: str = Field(description=\"Complete summary of the document\")\n    key_points: List[str] = Field(default_factory=list)\n    categories: List[str] = Field(default_factory=list)\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 363,
          "line_range": [
            363,
            379
          ]
        },
        {
          "code": "# Create a streaming document summary\n",
          "display_code": "",
          "annotation": "Create a streaming document summary",
          "is_comment": true,
          "start_line": 380,
          "line_range": [
            380,
            380
          ],
          "target_line_range": [
            381,
            396
          ]
        },
        {
          "code": "summary_stream = client.chat.completions.create_partial(\n    model=\"gpt-3.5-turbo\",\n    response_model=DocumentSummary,\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"\"\"\n            Generate a summary for an academic paper titled:\n            \"The Impact of Artificial Intelligence on Global Labor Markets:\n            A Comprehensive Analysis of Automation Trends from 2020-2023\"\n        \"\"\",\n        }\n    ],\n)\n\n\n",
          "display_code": "summary_stream = client.chat.completions.create_partial(\n    model=\"gpt-3.5-turbo\",\n    response_model=DocumentSummary,\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"\"\"\n            Generate a summary for an academic paper titled:\n            \"The Impact of Artificial Intelligence on Global Labor Markets:\n            A Comprehensive Analysis of Automation Trends from 2020-2023\"\n        \"\"\",\n        }\n    ],\n)\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 381,
          "line_range": [
            381,
            396
          ]
        },
        {
          "code": "# Display document summary with progressive updates\n",
          "display_code": "",
          "annotation": "Display document summary with progressive updates",
          "is_comment": true,
          "start_line": 397,
          "line_range": [
            397,
            397
          ],
          "target_line_range": [
            398,
            400
          ]
        },
        {
          "code": "def render_document_summary(partial_summary):\n    layout = Layout()\n\n",
          "display_code": "def render_document_summary(partial_summary):\n    layout = Layout()\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 398,
          "line_range": [
            398,
            400
          ]
        },
        {
          "code": "    # Document title\n",
          "display_code": "",
          "annotation": "Document title",
          "is_comment": true,
          "start_line": 401,
          "line_range": [
            401,
            401
          ],
          "target_line_range": [
            402,
            404
          ]
        },
        {
          "code": "    title = partial_summary.title if partial_summary.title else \"Loading title...\"\n    header = Panel(title, style=\"bold white on blue\")\n\n",
          "display_code": "    title = partial_summary.title if partial_summary.title else \"Loading title...\"\n    header = Panel(title, style=\"bold white on blue\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 402,
          "line_range": [
            402,
            404
          ]
        },
        {
          "code": "    # Metadata table\n",
          "display_code": "",
          "annotation": "Metadata table",
          "is_comment": true,
          "start_line": 405,
          "line_range": [
            405,
            405
          ],
          "target_line_range": [
            406,
            425
          ]
        },
        {
          "code": "    meta_table = Table(expand=True, show_header=False)\n    meta_table.add_column(\"Field\")\n    meta_table.add_column(\"Value\")\n\n    author = partial_summary.author if partial_summary.author else \"Unknown\"\n    date = (\n        partial_summary.publication_date\n        if partial_summary.publication_date\n        else \"Unknown\"\n    )\n    word_count = (\n        f\"{partial_summary.word_count:,} words\"\n        if partial_summary.word_count is not None\n        else \"Calculating...\"\n    )\n\n    meta_table.add_row(\"\ud83d\udc64 Author\", author)\n    meta_table.add_row(\"\ud83d\udcc5 Published\", date)\n    meta_table.add_row(\"\ud83d\udcca Word Count\", word_count)\n\n",
          "display_code": "    meta_table = Table(expand=True, show_header=False)\n    meta_table.add_column(\"Field\")\n    meta_table.add_column(\"Value\")\n\n    author = partial_summary.author if partial_summary.author else \"Unknown\"\n    date = (\n        partial_summary.publication_date\n        if partial_summary.publication_date\n        else \"Unknown\"\n    )\n    word_count = (\n        f\"{partial_summary.word_count:,} words\"\n        if partial_summary.word_count is not None\n        else \"Calculating...\"\n    )\n\n    meta_table.add_row(\"\ud83d\udc64 Author\", author)\n    meta_table.add_row(\"\ud83d\udcc5 Published\", date)\n    meta_table.add_row(\"\ud83d\udcca Word Count\", word_count)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 406,
          "line_range": [
            406,
            425
          ]
        },
        {
          "code": "    # Categories\n",
          "display_code": "",
          "annotation": "Categories",
          "is_comment": true,
          "start_line": 426,
          "line_range": [
            426,
            426
          ],
          "target_line_range": [
            427,
            432
          ]
        },
        {
          "code": "    categories_text = Text()\n    if not partial_summary.categories:\n        categories_text.append(\"Loading categories...\")\n    else:\n        categories_text.append(\", \".join(partial_summary.categories))\n\n",
          "display_code": "    categories_text = Text()\n    if not partial_summary.categories:\n        categories_text.append(\"Loading categories...\")\n    else:\n        categories_text.append(\", \".join(partial_summary.categories))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 427,
          "line_range": [
            427,
            432
          ]
        },
        {
          "code": "    # Key points\n",
          "display_code": "",
          "annotation": "Key points",
          "is_comment": true,
          "start_line": 433,
          "line_range": [
            433,
            433
          ],
          "target_line_range": [
            434,
            444
          ]
        },
        {
          "code": "    points_text = Text()\n    if not partial_summary.key_points:\n        points_text.append(\"Extracting key points...\")\n    else:\n        for i, point in enumerate(partial_summary.key_points, 1):\n            points_text.append(\n                f\"{i}. {point}\\n\"\n                if i < len(partial_summary.key_points)\n                else f\"{i}. {point}\"\n            )\n\n",
          "display_code": "    points_text = Text()\n    if not partial_summary.key_points:\n        points_text.append(\"Extracting key points...\")\n    else:\n        for i, point in enumerate(partial_summary.key_points, 1):\n            points_text.append(\n                f\"{i}. {point}\\n\"\n                if i < len(partial_summary.key_points)\n                else f\"{i}. {point}\"\n            )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 434,
          "line_range": [
            434,
            444
          ]
        },
        {
          "code": "    # Summary\n",
          "display_code": "",
          "annotation": "Summary",
          "is_comment": true,
          "start_line": 445,
          "line_range": [
            445,
            445
          ],
          "target_line_range": [
            446,
            451
          ]
        },
        {
          "code": "    summary_text = Text()\n    if not partial_summary.summary:\n        summary_text.append(\"Generating summary...\")\n    else:\n        summary_text.append(partial_summary.summary)\n\n",
          "display_code": "    summary_text = Text()\n    if not partial_summary.summary:\n        summary_text.append(\"Generating summary...\")\n    else:\n        summary_text.append(partial_summary.summary)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 446,
          "line_range": [
            446,
            451
          ]
        },
        {
          "code": "    # Create layout\n",
          "display_code": "",
          "annotation": "Create layout",
          "is_comment": true,
          "start_line": 452,
          "line_range": [
            452,
            452
          ],
          "target_line_range": [
            453,
            464
          ]
        },
        {
          "code": "    layout.split(\n        Layout(header, size=3),\n        Layout(Panel(meta_table, title=\"Document Metadata\"), size=10),\n        Layout(Panel(categories_text, title=\"Categories\"), size=5),\n        Layout(Panel(points_text, title=\"Key Points\")),\n        Layout(Panel(summary_text, title=\"Summary\")),\n    )\n\n    console.clear()\n    console.print(layout)\n\n\n",
          "display_code": "    layout.split(\n        Layout(header, size=3),\n        Layout(Panel(meta_table, title=\"Document Metadata\"), size=10),\n        Layout(Panel(categories_text, title=\"Categories\"), size=5),\n        Layout(Panel(points_text, title=\"Key Points\")),\n        Layout(Panel(summary_text, title=\"Summary\")),\n    )\n\n    console.clear()\n    console.print(layout)\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 453,
          "line_range": [
            453,
            464
          ]
        },
        {
          "code": "# Update UI as summary progresses\n",
          "display_code": "",
          "annotation": "Update UI as summary progresses",
          "is_comment": true,
          "start_line": 465,
          "line_range": [
            465,
            465
          ],
          "target_line_range": [
            466,
            470
          ]
        },
        {
          "code": "for partial_summary in summary_stream:\n    render_document_summary(partial_summary)\n    time.sleep(0.3)  # Slow down for demonstration\n\nconsole.print(\"[bold green]\u2705 Document summary complete!\")\n",
          "display_code": "for partial_summary in summary_stream:\n    render_document_summary(partial_summary)\n    time.sleep(0.3)  # Slow down for demonstration\n\nconsole.print(\"[bold green]\u2705 Document summary complete!\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 466,
          "line_range": [
            466,
            470
          ]
        }
      ],
      "shell_segments": [],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "005-streaming",
      "section_title": "Streaming"
    },
    {
      "id": "027-handling-stream-errors",
      "title": "Handling Stream Errors",
      "description": "",
      "order": 27,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# When working with streaming responses, validation errors can occur when the LLM generates invalid data.\n# Instructor provides several ways to handle these errors and recover gracefully.\n",
          "display_code": "",
          "annotation": "When working with streaming responses, validation errors can occur when the LLM generates invalid data.\nInstructor provides several ways to handle these errors and recover gracefully.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            4
          ],
          "target_line_range": [
            5,
            5
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 5,
          "line_range": [
            5,
            5
          ]
        },
        {
          "code": "# First, let's import the necessary libraries\n",
          "display_code": "",
          "annotation": "First, let's import the necessary libraries",
          "is_comment": true,
          "start_line": 6,
          "line_range": [
            6,
            6
          ],
          "target_line_range": [
            7,
            11
          ]
        },
        {
          "code": "from pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\nfrom typing import List, Optional\n\n",
          "display_code": "from pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\nfrom typing import List, Optional\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 7,
          "line_range": [
            7,
            11
          ]
        },
        {
          "code": "# Define a Person model with validation constraints\n",
          "display_code": "",
          "annotation": "Define a Person model with validation constraints",
          "is_comment": true,
          "start_line": 12,
          "line_range": [
            12,
            12
          ],
          "target_line_range": [
            13,
            17
          ]
        },
        {
          "code": "class Person(BaseModel):\n    name: str\n    age: int = Field(gt=0, lt=150)  # Age validation constraint: must be between 1-149\n    occupation: str\n\n",
          "display_code": "class Person(BaseModel):\n    name: str\n    age: int = Field(gt=0, lt=150)  # Age validation constraint: must be between 1-149\n    occupation: str\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 13,
          "line_range": [
            13,
            17
          ]
        },
        {
          "code": "# Patch the OpenAI client with Instructor\n",
          "display_code": "",
          "annotation": "Patch the OpenAI client with Instructor",
          "is_comment": true,
          "start_line": 18,
          "line_range": [
            18,
            18
          ],
          "target_line_range": [
            19,
            20
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 19,
          "line_range": [
            19,
            20
          ]
        },
        {
          "code": "# Basic error handling for a streaming response\n",
          "display_code": "",
          "annotation": "Basic error handling for a streaming response",
          "is_comment": true,
          "start_line": 21,
          "line_range": [
            21,
            21
          ],
          "target_line_range": [
            22,
            23
          ]
        },
        {
          "code": "def stream_with_error_handling():\n    try:\n",
          "display_code": "def stream_with_error_handling():\n    try:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 22,
          "line_range": [
            22,
            23
          ]
        },
        {
          "code": "        # Create a partial stream - we intentionally ask for an invalid age (200 years)\n        # to demonstrate error handling\n",
          "display_code": "",
          "annotation": "Create a partial stream - we intentionally ask for an invalid age (200 years)\nto demonstrate error handling",
          "is_comment": true,
          "start_line": 24,
          "line_range": [
            24,
            25
          ],
          "target_line_range": [
            26,
            33
          ]
        },
        {
          "code": "        person_stream = client.chat.completions.create_partial(\n            model=\"gpt-3.5-turbo\",\n            response_model=Person,\n            messages=[\n                {\"role\": \"user\", \"content\": \"Generate a profile for a fictional person who is 200 years old.\"}\n            ]\n        )\n\n",
          "display_code": "        person_stream = client.chat.completions.create_partial(\n            model=\"gpt-3.5-turbo\",\n            response_model=Person,\n            messages=[\n                {\"role\": \"user\", \"content\": \"Generate a profile for a fictional person who is 200 years old.\"}\n            ]\n        )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 26,
          "line_range": [
            26,
            33
          ]
        },
        {
          "code": "        # Process the stream and show progress\n",
          "display_code": "",
          "annotation": "Process the stream and show progress",
          "is_comment": true,
          "start_line": 34,
          "line_range": [
            34,
            34
          ],
          "target_line_range": [
            35,
            35
          ]
        },
        {
          "code": "        for partial_person in person_stream:\n",
          "display_code": "        for partial_person in person_stream:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 35,
          "line_range": [
            35,
            35
          ]
        },
        {
          "code": "            # Display each partial state as it arrives\n",
          "display_code": "",
          "annotation": "Display each partial state as it arrives",
          "is_comment": true,
          "start_line": 36,
          "line_range": [
            36,
            36
          ],
          "target_line_range": [
            37,
            38
          ]
        },
        {
          "code": "            print(f\"Current state: {partial_person}\")\n\n",
          "display_code": "            print(f\"Current state: {partial_person}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 37,
          "line_range": [
            37,
            38
          ]
        },
        {
          "code": "        # This line will only execute if no exception is raised\n",
          "display_code": "",
          "annotation": "This line will only execute if no exception is raised",
          "is_comment": true,
          "start_line": 39,
          "line_range": [
            39,
            39
          ],
          "target_line_range": [
            40,
            42
          ]
        },
        {
          "code": "        print(\"\\nFinal result:\", partial_person)\n\n    except Exception as e:\n",
          "display_code": "        print(\"\\nFinal result:\", partial_person)\n\n    except Exception as e:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 40,
          "line_range": [
            40,
            42
          ]
        },
        {
          "code": "        # Catch and handle any errors that occur during streaming\n",
          "display_code": "",
          "annotation": "Catch and handle any errors that occur during streaming",
          "is_comment": true,
          "start_line": 43,
          "line_range": [
            43,
            43
          ],
          "target_line_range": [
            44,
            46
          ]
        },
        {
          "code": "        print(f\"\\nError occurred: {type(e).__name__}: {str(e)}\")\n        print(\"Handling the error gracefully...\")\n\n",
          "display_code": "        print(f\"\\nError occurred: {type(e).__name__}: {str(e)}\")\n        print(\"Handling the error gracefully...\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 44,
          "line_range": [
            44,
            46
          ]
        },
        {
          "code": "# Run the function to see the error handling in action\n",
          "display_code": "",
          "annotation": "Run the function to see the error handling in action",
          "is_comment": true,
          "start_line": 47,
          "line_range": [
            47,
            47
          ],
          "target_line_range": [
            48,
            49
          ]
        },
        {
          "code": "stream_with_error_handling()\n\n",
          "display_code": "stream_with_error_handling()\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 48,
          "line_range": [
            48,
            49
          ]
        },
        {
          "code": "# Expected output will show progress until validation fails:\n# Current state: name=None age=None occupation=None\n# Current state: name='Elizabeth' age=None occupation=None\n# Current state: name='Elizabeth Morgan' age=None occupation=None\n# Current state: name='Elizabeth Morgan' age=200 occupation=None\n#\n# Error occurred: ValidationError: 1 validation error for Person\n# age\n#   Input should be less than 150 [type=less_than, input_value=200, input_type=int]\n",
          "display_code": "",
          "annotation": "Expected output will show progress until validation fails:\nCurrent state: name=None age=None occupation=None\nCurrent state: name='Elizabeth' age=None occupation=None\nCurrent state: name='Elizabeth Morgan' age=None occupation=None\nCurrent state: name='Elizabeth Morgan' age=200 occupation=None\n\nError occurred: ValidationError: 1 validation error for Person\nage\nInput should be less than 150 [type=less_than, input_value=200, input_type=int]",
          "is_comment": true,
          "start_line": 50,
          "line_range": [
            50,
            58
          ],
          "target_line_range": [
            59,
            69
          ]
        },
        {
          "code": "\nfrom pydantic import BaseModel, Field, ValidationError\nfrom typing import Optional, List, Any\n\nclass Product(BaseModel):\n    name: str\n    price: float = Field(gt=0)  # Must be positive\n    quantity: int = Field(ge=0)  # Must be non-negative\n    category: str\n\ndef safe_stream_processing():\n",
          "display_code": "\nfrom pydantic import BaseModel, Field, ValidationError\nfrom typing import Optional, List, Any\n\nclass Product(BaseModel):\n    name: str\n    price: float = Field(gt=0)  # Must be positive\n    quantity: int = Field(ge=0)  # Must be non-negative\n    category: str\n\ndef safe_stream_processing():\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 59,
          "line_range": [
            59,
            69
          ]
        },
        {
          "code": "    # Create a partial stream\n",
          "display_code": "",
          "annotation": "Create a partial stream",
          "is_comment": true,
          "start_line": 70,
          "line_range": [
            70,
            70
          ],
          "target_line_range": [
            71,
            79
          ]
        },
        {
          "code": "    try:\n        product_stream = client.chat.completions.create_partial(\n            model=\"gpt-3.5-turbo\",\n            response_model=Product,\n            messages=[\n                {\"role\": \"user\", \"content\": \"Generate a product with negative price.\"},\n            ]\n        )\n\n",
          "display_code": "    try:\n        product_stream = client.chat.completions.create_partial(\n            model=\"gpt-3.5-turbo\",\n            response_model=Product,\n            messages=[\n                {\"role\": \"user\", \"content\": \"Generate a product with negative price.\"},\n            ]\n        )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 71,
          "line_range": [
            71,
            79
          ]
        },
        {
          "code": "        # Try to process the stream\n",
          "display_code": "",
          "annotation": "Try to process the stream",
          "is_comment": true,
          "start_line": 80,
          "line_range": [
            80,
            80
          ],
          "target_line_range": [
            81,
            92
          ]
        },
        {
          "code": "        last_valid_state = None\n\n        try:\n            for partial_product in product_stream:\n                print(f\"Processing: {partial_product}\")\n                last_valid_state = partial_product\n        except ValidationError as e:\n            print(f\"\\nValidation failed: {e}\\n\")\n\n            if last_valid_state:\n                print(f\"Last valid state before error: {last_valid_state}\")\n\n",
          "display_code": "        last_valid_state = None\n\n        try:\n            for partial_product in product_stream:\n                print(f\"Processing: {partial_product}\")\n                last_valid_state = partial_product\n        except ValidationError as e:\n            print(f\"\\nValidation failed: {e}\\n\")\n\n            if last_valid_state:\n                print(f\"Last valid state before error: {last_valid_state}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 81,
          "line_range": [
            81,
            92
          ]
        },
        {
          "code": "                # You could attempt recovery here\n",
          "display_code": "",
          "annotation": "You could attempt recovery here",
          "is_comment": true,
          "start_line": 93,
          "line_range": [
            93,
            93
          ],
          "target_line_range": [
            94,
            107
          ]
        },
        {
          "code": "                corrected_product = Product(\n                    name=last_valid_state.name or \"Unknown Product\",\n                    price=abs(last_valid_state.price) if last_valid_state.price is not None else 9.99,\n                    quantity=last_valid_state.quantity or 0,\n                    category=last_valid_state.category or \"Uncategorized\"\n                )\n\n                print(f\"\\nRecovered with corrected data: {corrected_product}\")\n            else:\n                print(\"No valid state was received before the error\")\n\n    except Exception as outer_e:\n        print(f\"Outer exception: {outer_e}\")\n\n",
          "display_code": "                corrected_product = Product(\n                    name=last_valid_state.name or \"Unknown Product\",\n                    price=abs(last_valid_state.price) if last_valid_state.price is not None else 9.99,\n                    quantity=last_valid_state.quantity or 0,\n                    category=last_valid_state.category or \"Uncategorized\"\n                )\n\n                print(f\"\\nRecovered with corrected data: {corrected_product}\")\n            else:\n                print(\"No valid state was received before the error\")\n\n    except Exception as outer_e:\n        print(f\"Outer exception: {outer_e}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 94,
          "line_range": [
            94,
            107
          ]
        },
        {
          "code": "# Run the function\n",
          "display_code": "",
          "annotation": "Run the function",
          "is_comment": true,
          "start_line": 108,
          "line_range": [
            108,
            108
          ],
          "target_line_range": [
            109,
            119
          ]
        },
        {
          "code": "safe_stream_processing()\n\nfrom pydantic import BaseModel, Field, ValidationError\nfrom typing import Optional, List, Dict, Union, Any\n\nclass StockData(BaseModel):\n    symbol: str\n    price: float = Field(gt=0)\n    volume: int = Field(gt=0)\n    change_percent: float\n\n",
          "display_code": "safe_stream_processing()\n\nfrom pydantic import BaseModel, Field, ValidationError\nfrom typing import Optional, List, Dict, Union, Any\n\nclass StockData(BaseModel):\n    symbol: str\n    price: float = Field(gt=0)\n    volume: int = Field(gt=0)\n    change_percent: float\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 109,
          "line_range": [
            109,
            119
          ]
        },
        {
          "code": "# Define a function to safely extract data with validation\n",
          "display_code": "",
          "annotation": "Define a function to safely extract data with validation",
          "is_comment": true,
          "start_line": 120,
          "line_range": [
            120,
            120
          ],
          "target_line_range": [
            121,
            122
          ]
        },
        {
          "code": "def safe_extract_from_chunk(chunk_data: Dict[str, Any], model_class) -> Optional[Any]:\n    try:\n",
          "display_code": "def safe_extract_from_chunk(chunk_data: Dict[str, Any], model_class) -> Optional[Any]:\n    try:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 121,
          "line_range": [
            121,
            122
          ]
        },
        {
          "code": "        # Try to create a model instance from the chunk data\n",
          "display_code": "",
          "annotation": "Try to create a model instance from the chunk data",
          "is_comment": true,
          "start_line": 123,
          "line_range": [
            123,
            123
          ],
          "target_line_range": [
            124,
            125
          ]
        },
        {
          "code": "        return model_class.model_validate(chunk_data)\n    except ValidationError:\n",
          "display_code": "        return model_class.model_validate(chunk_data)\n    except ValidationError:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 124,
          "line_range": [
            124,
            125
          ]
        },
        {
          "code": "        # Return None if validation fails\n",
          "display_code": "",
          "annotation": "Return None if validation fails",
          "is_comment": true,
          "start_line": 126,
          "line_range": [
            126,
            126
          ],
          "target_line_range": [
            127,
            128
          ]
        },
        {
          "code": "        return None\n\n",
          "display_code": "        return None\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 127,
          "line_range": [
            127,
            128
          ]
        },
        {
          "code": "# Process a stream with manual validation\n",
          "display_code": "",
          "annotation": "Process a stream with manual validation",
          "is_comment": true,
          "start_line": 129,
          "line_range": [
            129,
            129
          ],
          "target_line_range": [
            130,
            130
          ]
        },
        {
          "code": "def stream_with_manual_validation():\n",
          "display_code": "def stream_with_manual_validation():\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 130,
          "line_range": [
            130,
            130
          ]
        },
        {
          "code": "    # Create a stream - note we're not using response_model here\n    # to handle the validation ourselves\n",
          "display_code": "",
          "annotation": "Create a stream - note we're not using response_model here\nto handle the validation ourselves",
          "is_comment": true,
          "start_line": 131,
          "line_range": [
            131,
            132
          ],
          "target_line_range": [
            133,
            151
          ]
        },
        {
          "code": "    stream = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        stream=True,  # Enable streaming\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate stock data for ACME Corp with possible errors.\"}\n        ],\n        tools=[\n            {\n                \"type\": \"function\",\n                \"function\": {\n                    \"name\": \"stock_data\",\n                    \"description\": \"Return stock data\",\n                    \"parameters\": StockData.model_json_schema()\n                }\n            }\n        ],\n        tool_choice={\"type\": \"function\", \"function\": {\"name\": \"stock_data\"}}\n    )\n\n",
          "display_code": "    stream = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        stream=True,  # Enable streaming\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate stock data for ACME Corp with possible errors.\"}\n        ],\n        tools=[\n            {\n                \"type\": \"function\",\n                \"function\": {\n                    \"name\": \"stock_data\",\n                    \"description\": \"Return stock data\",\n                    \"parameters\": StockData.model_json_schema()\n                }\n            }\n        ],\n        tool_choice={\"type\": \"function\", \"function\": {\"name\": \"stock_data\"}}\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 133,
          "line_range": [
            133,
            151
          ]
        },
        {
          "code": "    # Process the stream\n",
          "display_code": "",
          "annotation": "Process the stream",
          "is_comment": true,
          "start_line": 152,
          "line_range": [
            152,
            152
          ],
          "target_line_range": [
            153,
            159
          ]
        },
        {
          "code": "    combined_data = {}\n    invalid_chunks = []\n\n    for chunk in stream:\n        if hasattr(chunk, 'choices') and chunk.choices and hasattr(chunk.choices[0], 'delta'):\n            delta = chunk.choices[0].delta\n\n",
          "display_code": "    combined_data = {}\n    invalid_chunks = []\n\n    for chunk in stream:\n        if hasattr(chunk, 'choices') and chunk.choices and hasattr(chunk.choices[0], 'delta'):\n            delta = chunk.choices[0].delta\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 153,
          "line_range": [
            153,
            159
          ]
        },
        {
          "code": "            # Extract any tool calls data\n",
          "display_code": "",
          "annotation": "Extract any tool calls data",
          "is_comment": true,
          "start_line": 160,
          "line_range": [
            160,
            160
          ],
          "target_line_range": [
            161,
            164
          ]
        },
        {
          "code": "            if hasattr(delta, 'tool_calls') and delta.tool_calls:\n                for tool_call in delta.tool_calls:\n                    if hasattr(tool_call, 'function') and tool_call.function:\n                        if hasattr(tool_call.function, 'arguments') and tool_call.function.arguments:\n",
          "display_code": "            if hasattr(delta, 'tool_calls') and delta.tool_calls:\n                for tool_call in delta.tool_calls:\n                    if hasattr(tool_call, 'function') and tool_call.function:\n                        if hasattr(tool_call.function, 'arguments') and tool_call.function.arguments:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 161,
          "line_range": [
            161,
            164
          ]
        },
        {
          "code": "                            # Try to parse JSON\n",
          "display_code": "",
          "annotation": "Try to parse JSON",
          "is_comment": true,
          "start_line": 165,
          "line_range": [
            165,
            165
          ],
          "target_line_range": [
            166,
            170
          ]
        },
        {
          "code": "                            try:\n                                import json\n                                json_str = tool_call.function.arguments\n                                data = json.loads(json_str)\n\n",
          "display_code": "                            try:\n                                import json\n                                json_str = tool_call.function.arguments\n                                data = json.loads(json_str)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 166,
          "line_range": [
            166,
            170
          ]
        },
        {
          "code": "                                # Update our combined data\n",
          "display_code": "",
          "annotation": "Update our combined data",
          "is_comment": true,
          "start_line": 171,
          "line_range": [
            171,
            171
          ],
          "target_line_range": [
            172,
            173
          ]
        },
        {
          "code": "                                combined_data.update(data)\n\n",
          "display_code": "                                combined_data.update(data)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 172,
          "line_range": [
            172,
            173
          ]
        },
        {
          "code": "                                # Try to validate the current state\n",
          "display_code": "",
          "annotation": "Try to validate the current state",
          "is_comment": true,
          "start_line": 174,
          "line_range": [
            174,
            174
          ],
          "target_line_range": [
            175,
            184
          ]
        },
        {
          "code": "                                result = safe_extract_from_chunk(combined_data, StockData)\n\n                                if result:\n                                    print(f\"Valid partial data: {result}\")\n                                else:\n                                    print(f\"Current data invalid: {combined_data}\")\n                                    invalid_chunks.append(combined_data.copy())\n                            except json.JSONDecodeError:\n                                print(f\"Invalid JSON: {tool_call.function.arguments}\")\n\n",
          "display_code": "                                result = safe_extract_from_chunk(combined_data, StockData)\n\n                                if result:\n                                    print(f\"Valid partial data: {result}\")\n                                else:\n                                    print(f\"Current data invalid: {combined_data}\")\n                                    invalid_chunks.append(combined_data.copy())\n                            except json.JSONDecodeError:\n                                print(f\"Invalid JSON: {tool_call.function.arguments}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 175,
          "line_range": [
            175,
            184
          ]
        },
        {
          "code": "    # Final validation\n",
          "display_code": "",
          "annotation": "Final validation",
          "is_comment": true,
          "start_line": 185,
          "line_range": [
            185,
            185
          ],
          "target_line_range": [
            186,
            192
          ]
        },
        {
          "code": "    try:\n        final_result = StockData.model_validate(combined_data)\n        print(f\"\\nFinal valid result: {final_result}\")\n    except ValidationError as e:\n        print(f\"\\nFinal validation failed: {e}\")\n        print(\"Invalid states encountered:\", invalid_chunks)\n\n",
          "display_code": "    try:\n        final_result = StockData.model_validate(combined_data)\n        print(f\"\\nFinal valid result: {final_result}\")\n    except ValidationError as e:\n        print(f\"\\nFinal validation failed: {e}\")\n        print(\"Invalid states encountered:\", invalid_chunks)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 186,
          "line_range": [
            186,
            192
          ]
        },
        {
          "code": "        # Attempt recovery\n",
          "display_code": "",
          "annotation": "Attempt recovery",
          "is_comment": true,
          "start_line": 193,
          "line_range": [
            193,
            193
          ],
          "target_line_range": [
            194,
            205
          ]
        },
        {
          "code": "        corrected_data = combined_data.copy()\n        if 'price' in corrected_data and corrected_data['price'] <= 0:\n            corrected_data['price'] = abs(corrected_data['price']) or 10.0\n        if 'volume' in corrected_data and corrected_data['volume'] <= 0:\n            corrected_data['volume'] = abs(corrected_data['volume']) or 1000\n\n        try:\n            recovered = StockData.model_validate(corrected_data)\n            print(f\"Recovered result: {recovered}\")\n        except ValidationError:\n            print(\"Could not recover valid data\")\n\n",
          "display_code": "        corrected_data = combined_data.copy()\n        if 'price' in corrected_data and corrected_data['price'] <= 0:\n            corrected_data['price'] = abs(corrected_data['price']) or 10.0\n        if 'volume' in corrected_data and corrected_data['volume'] <= 0:\n            corrected_data['volume'] = abs(corrected_data['volume']) or 1000\n\n        try:\n            recovered = StockData.model_validate(corrected_data)\n            print(f\"Recovered result: {recovered}\")\n        except ValidationError:\n            print(\"Could not recover valid data\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 194,
          "line_range": [
            194,
            205
          ]
        },
        {
          "code": "# Run the function\n",
          "display_code": "",
          "annotation": "Run the function",
          "is_comment": true,
          "start_line": 206,
          "line_range": [
            206,
            206
          ],
          "target_line_range": [
            207,
            211
          ]
        },
        {
          "code": "stream_with_manual_validation()\n\nfrom pydantic import BaseModel, Field, ValidationError\nfrom typing import Optional, List, Any, Union\n\n",
          "display_code": "stream_with_manual_validation()\n\nfrom pydantic import BaseModel, Field, ValidationError\nfrom typing import Optional, List, Any, Union\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 207,
          "line_range": [
            207,
            211
          ]
        },
        {
          "code": "# Define nested models with validation\n",
          "display_code": "",
          "annotation": "Define nested models with validation",
          "is_comment": true,
          "start_line": 212,
          "line_range": [
            212,
            212
          ],
          "target_line_range": [
            213,
            223
          ]
        },
        {
          "code": "class Address(BaseModel):\n    street: str\n    city: str\n    country: str\n    postal_code: str = Field(min_length=5)  # Validation that might fail\n\nclass Person(BaseModel):\n    name: str\n    age: int = Field(gt=0, lt=150)\n    address: Address\n\n",
          "display_code": "class Address(BaseModel):\n    street: str\n    city: str\n    country: str\n    postal_code: str = Field(min_length=5)  # Validation that might fail\n\nclass Person(BaseModel):\n    name: str\n    age: int = Field(gt=0, lt=150)\n    address: Address\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 213,
          "line_range": [
            213,
            223
          ]
        },
        {
          "code": "# Define fallback models with fewer constraints\n",
          "display_code": "",
          "annotation": "Define fallback models with fewer constraints",
          "is_comment": true,
          "start_line": 224,
          "line_range": [
            224,
            224
          ],
          "target_line_range": [
            225,
            235
          ]
        },
        {
          "code": "class SimpleAddress(BaseModel):\n    street: Optional[str] = None\n    city: Optional[str] = None\n    country: Optional[str] = None\n    postal_code: Optional[str] = None\n\nclass SimplePerson(BaseModel):\n    name: Optional[str] = None\n    age: Optional[int] = None\n    address: Optional[SimpleAddress] = None\n\n",
          "display_code": "class SimpleAddress(BaseModel):\n    street: Optional[str] = None\n    city: Optional[str] = None\n    country: Optional[str] = None\n    postal_code: Optional[str] = None\n\nclass SimplePerson(BaseModel):\n    name: Optional[str] = None\n    age: Optional[int] = None\n    address: Optional[SimpleAddress] = None\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 225,
          "line_range": [
            225,
            235
          ]
        },
        {
          "code": "# Function to handle streaming with fallbacks\n",
          "display_code": "",
          "annotation": "Function to handle streaming with fallbacks",
          "is_comment": true,
          "start_line": 236,
          "line_range": [
            236,
            236
          ],
          "target_line_range": [
            237,
            237
          ]
        },
        {
          "code": "def stream_with_fallbacks():\n",
          "display_code": "def stream_with_fallbacks():\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 237,
          "line_range": [
            237,
            237
          ]
        },
        {
          "code": "    # Create a partial stream\n",
          "display_code": "",
          "annotation": "Create a partial stream",
          "is_comment": true,
          "start_line": 238,
          "line_range": [
            238,
            238
          ],
          "target_line_range": [
            239,
            247
          ]
        },
        {
          "code": "    person_stream = client.chat.completions.create_partial(\n        model=\"gpt-3.5-turbo\",\n        response_model=Person,\n        max_retries=1,  # Limit retries\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate a person with an invalid postal code.\"}\n        ]\n    )\n\n",
          "display_code": "    person_stream = client.chat.completions.create_partial(\n        model=\"gpt-3.5-turbo\",\n        response_model=Person,\n        max_retries=1,  # Limit retries\n        messages=[\n            {\"role\": \"user\", \"content\": \"Generate a person with an invalid postal code.\"}\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 239,
          "line_range": [
            239,
            247
          ]
        },
        {
          "code": "    # Try to process with primary model\n",
          "display_code": "",
          "annotation": "Try to process with primary model",
          "is_comment": true,
          "start_line": 248,
          "line_range": [
            248,
            248
          ],
          "target_line_range": [
            249,
            256
          ]
        },
        {
          "code": "    primary_stream_failed = False\n    try:\n        for partial_person in person_stream:\n            print(f\"Primary model state: {partial_person}\")\n    except ValidationError as e:\n        print(f\"\\nValidation error in primary model: {str(e)}\\n\")\n        primary_stream_failed = True\n\n",
          "display_code": "    primary_stream_failed = False\n    try:\n        for partial_person in person_stream:\n            print(f\"Primary model state: {partial_person}\")\n    except ValidationError as e:\n        print(f\"\\nValidation error in primary model: {str(e)}\\n\")\n        primary_stream_failed = True\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 249,
          "line_range": [
            249,
            256
          ]
        },
        {
          "code": "    # If primary fails, try with the fallback model\n",
          "display_code": "",
          "annotation": "If primary fails, try with the fallback model",
          "is_comment": true,
          "start_line": 257,
          "line_range": [
            257,
            257
          ],
          "target_line_range": [
            258,
            260
          ]
        },
        {
          "code": "    if primary_stream_failed:\n        print(\"Falling back to simplified model...\")\n\n",
          "display_code": "    if primary_stream_failed:\n        print(\"Falling back to simplified model...\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 258,
          "line_range": [
            258,
            260
          ]
        },
        {
          "code": "        # Create a new stream with the fallback model\n",
          "display_code": "",
          "annotation": "Create a new stream with the fallback model",
          "is_comment": true,
          "start_line": 261,
          "line_range": [
            261,
            261
          ],
          "target_line_range": [
            262,
            270
          ]
        },
        {
          "code": "        fallback_stream = client.chat.completions.create_partial(\n            model=\"gpt-3.5-turbo\",\n            response_model=SimplePerson,\n            messages=[\n                {\"role\": \"user\", \"content\": \"Generate a person with an invalid postal code.\"}\n            ]\n        )\n\n        try:\n",
          "display_code": "        fallback_stream = client.chat.completions.create_partial(\n            model=\"gpt-3.5-turbo\",\n            response_model=SimplePerson,\n            messages=[\n                {\"role\": \"user\", \"content\": \"Generate a person with an invalid postal code.\"}\n            ]\n        )\n\n        try:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 262,
          "line_range": [
            262,
            270
          ]
        },
        {
          "code": "            # Process with fallback model\n",
          "display_code": "",
          "annotation": "Process with fallback model",
          "is_comment": true,
          "start_line": 271,
          "line_range": [
            271,
            271
          ],
          "target_line_range": [
            272,
            278
          ]
        },
        {
          "code": "            for partial_person in fallback_stream:\n                print(f\"Fallback model state: {partial_person}\")\n\n            print(\"\\nCompleted with fallback model\")\n        except Exception as fallback_error:\n            print(f\"Even fallback model failed: {str(fallback_error)}\")\n\n",
          "display_code": "            for partial_person in fallback_stream:\n                print(f\"Fallback model state: {partial_person}\")\n\n            print(\"\\nCompleted with fallback model\")\n        except Exception as fallback_error:\n            print(f\"Even fallback model failed: {str(fallback_error)}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 272,
          "line_range": [
            272,
            278
          ]
        },
        {
          "code": "# Run the function\n",
          "display_code": "",
          "annotation": "Run the function",
          "is_comment": true,
          "start_line": 279,
          "line_range": [
            279,
            279
          ],
          "target_line_range": [
            280,
            290
          ]
        },
        {
          "code": "stream_with_fallbacks()\n\nfrom pydantic import BaseModel, Field, ValidationError\nfrom typing import Optional, List, Any\n\nclass Review(BaseModel):\n    product_id: str\n    rating: int = Field(ge=1, le=5)\n    comment: str\n    reviewer_name: str\n\n",
          "display_code": "stream_with_fallbacks()\n\nfrom pydantic import BaseModel, Field, ValidationError\nfrom typing import Optional, List, Any\n\nclass Review(BaseModel):\n    product_id: str\n    rating: int = Field(ge=1, le=5)\n    comment: str\n    reviewer_name: str\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 280,
          "line_range": [
            280,
            290
          ]
        },
        {
          "code": "# Function to handle errors in both partial and iterable streams\n",
          "display_code": "",
          "annotation": "Function to handle errors in both partial and iterable streams",
          "is_comment": true,
          "start_line": 291,
          "line_range": [
            291,
            291
          ],
          "target_line_range": [
            292,
            295
          ]
        },
        {
          "code": "def robust_stream_processing():\n    print(\"1. Testing partial stream with validation errors:\\n\")\n\n    try:\n",
          "display_code": "def robust_stream_processing():\n    print(\"1. Testing partial stream with validation errors:\\n\")\n\n    try:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 292,
          "line_range": [
            292,
            295
          ]
        },
        {
          "code": "        # Create a partial stream that might have validation errors\n",
          "display_code": "",
          "annotation": "Create a partial stream that might have validation errors",
          "is_comment": true,
          "start_line": 296,
          "line_range": [
            296,
            296
          ],
          "target_line_range": [
            297,
            313
          ]
        },
        {
          "code": "        review_stream = client.chat.completions.create_partial(\n            model=\"gpt-3.5-turbo\",\n            response_model=Review,\n            messages=[\n                {\"role\": \"user\", \"content\": \"Generate a product review with a rating of 10 stars.\"}\n            ]\n        )\n\n        for partial_review in review_stream:\n            print(f\"Partial: {partial_review}\")\n\n    except ValidationError as e:\n        print(f\"\\nPartial stream validation failed: {str(e)}\\n\")\n\n    print(\"\\n2. Testing iterable stream with validation errors:\\n\")\n\n    try:\n",
          "display_code": "        review_stream = client.chat.completions.create_partial(\n            model=\"gpt-3.5-turbo\",\n            response_model=Review,\n            messages=[\n                {\"role\": \"user\", \"content\": \"Generate a product review with a rating of 10 stars.\"}\n            ]\n        )\n\n        for partial_review in review_stream:\n            print(f\"Partial: {partial_review}\")\n\n    except ValidationError as e:\n        print(f\"\\nPartial stream validation failed: {str(e)}\\n\")\n\n    print(\"\\n2. Testing iterable stream with validation errors:\\n\")\n\n    try:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 297,
          "line_range": [
            297,
            313
          ]
        },
        {
          "code": "        # Create an iterable stream that might have validation errors\n",
          "display_code": "",
          "annotation": "Create an iterable stream that might have validation errors",
          "is_comment": true,
          "start_line": 314,
          "line_range": [
            314,
            314
          ],
          "target_line_range": [
            315,
            322
          ]
        },
        {
          "code": "        reviews_iterable = client.chat.completions.create_iterable(\n            model=\"gpt-3.5-turbo\",\n            response_model=Review,\n            messages=[\n                {\"role\": \"user\", \"content\": \"Generate 3 product reviews, make one with an invalid rating of 0.\"}\n            ]\n        )\n\n",
          "display_code": "        reviews_iterable = client.chat.completions.create_iterable(\n            model=\"gpt-3.5-turbo\",\n            response_model=Review,\n            messages=[\n                {\"role\": \"user\", \"content\": \"Generate 3 product reviews, make one with an invalid rating of 0.\"}\n            ]\n        )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 315,
          "line_range": [
            315,
            322
          ]
        },
        {
          "code": "        # Process the iterable with error handling for each item\n",
          "display_code": "",
          "annotation": "Process the iterable with error handling for each item",
          "is_comment": true,
          "start_line": 323,
          "line_range": [
            323,
            323
          ],
          "target_line_range": [
            324,
            332
          ]
        },
        {
          "code": "        for i, review in enumerate(reviews_iterable):\n            try:\n                print(f\"Item {i+1}: {review}\")\n            except ValidationError as item_error:\n                print(f\"Item {i+1} validation failed: {str(item_error)}\")\n\n    except Exception as outer_error:\n        print(f\"Outer iterable error: {str(outer_error)}\")\n\n",
          "display_code": "        for i, review in enumerate(reviews_iterable):\n            try:\n                print(f\"Item {i+1}: {review}\")\n            except ValidationError as item_error:\n                print(f\"Item {i+1} validation failed: {str(item_error)}\")\n\n    except Exception as outer_error:\n        print(f\"Outer iterable error: {str(outer_error)}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 324,
          "line_range": [
            324,
            332
          ]
        },
        {
          "code": "# Run the function\n",
          "display_code": "",
          "annotation": "Run the function",
          "is_comment": true,
          "start_line": 333,
          "line_range": [
            333,
            333
          ],
          "target_line_range": [
            334,
            335
          ]
        },
        {
          "code": "robust_stream_processing()\n\n",
          "display_code": "robust_stream_processing()\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 334,
          "line_range": [
            334,
            335
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python handling-stream-errors.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "005-streaming",
      "section_title": "Streaming"
    },
    {
      "id": "028-recursive-structures",
      "title": "Recursive Structures",
      "description": "",
      "order": 28,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# - Consider adding helper methods to traverse or manipulate the structure\n",
          "display_code": "",
          "annotation": "- Consider adding helper methods to traverse or manipulate the structure",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor supports defining and extracting recursive data structures, where a model can reference itself in its definition. This is particularly useful for representing hierarchical data like file systems, org charts, or nested comments.\n",
          "display_code": "",
          "annotation": "Instructor supports defining and extracting recursive data structures, where a model can reference itself in its definition. This is particularly useful for representing hierarchical data like file systems, org charts, or nested comments.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nimport enum\nfrom pydantic import BaseModel, Field\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nimport enum\nfrom pydantic import BaseModel, Field\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define the node type enum\n",
          "display_code": "",
          "annotation": "Define the node type enum",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            18
          ]
        },
        {
          "code": "class NodeType(str, enum.Enum):\n    FILE = \"file\"\n    FOLDER = \"folder\"\n\n",
          "display_code": "class NodeType(str, enum.Enum):\n    FILE = \"file\"\n    FOLDER = \"folder\"\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            18
          ]
        },
        {
          "code": "# Define the Node class with a self-reference for children\n",
          "display_code": "",
          "annotation": "Define the Node class with a self-reference for children",
          "is_comment": true,
          "start_line": 19,
          "line_range": [
            19,
            19
          ],
          "target_line_range": [
            20,
            30
          ]
        },
        {
          "code": "class Node(BaseModel):\n    name: str = Field(..., description=\"Name of the node\")\n    children: list[\"Node\"] = Field(\n        default_factory=list,\n        description=\"List of children nodes, only applicable for folders\"\n    )\n    node_type: NodeType = Field(\n        default=NodeType.FILE,\n        description=\"Either a file or folder\"\n    )\n\n",
          "display_code": "class Node(BaseModel):\n    name: str = Field(..., description=\"Name of the node\")\n    children: list[\"Node\"] = Field(\n        default_factory=list,\n        description=\"List of children nodes, only applicable for folders\"\n    )\n    node_type: NodeType = Field(\n        default=NodeType.FILE,\n        description=\"Either a file or folder\"\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 20,
          "line_range": [
            20,
            30
          ]
        },
        {
          "code": "# Important! For recursive models, we need to rebuild the model\n",
          "display_code": "",
          "annotation": "Important! For recursive models, we need to rebuild the model",
          "is_comment": true,
          "start_line": 31,
          "line_range": [
            31,
            31
          ],
          "target_line_range": [
            32,
            33
          ]
        },
        {
          "code": "Node.model_rebuild()\n\n",
          "display_code": "Node.model_rebuild()\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 32,
          "line_range": [
            32,
            33
          ]
        },
        {
          "code": "# Create a container model for the root node\n",
          "display_code": "",
          "annotation": "Create a container model for the root node",
          "is_comment": true,
          "start_line": 34,
          "line_range": [
            34,
            34
          ],
          "target_line_range": [
            35,
            37
          ]
        },
        {
          "code": "class DirectoryTree(BaseModel):\n    root: Node = Field(..., description=\"Root folder of the directory tree\")\n\n",
          "display_code": "class DirectoryTree(BaseModel):\n    root: Node = Field(..., description=\"Root folder of the directory tree\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 35,
          "line_range": [
            35,
            37
          ]
        },
        {
          "code": "# Extract a directory tree from text representation\n",
          "display_code": "",
          "annotation": "Extract a directory tree from text representation",
          "is_comment": true,
          "start_line": 38,
          "line_range": [
            38,
            38
          ],
          "target_line_range": [
            39,
            54
          ]
        },
        {
          "code": "def parse_directory_structure(text_representation: str) -> DirectoryTree:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=DirectoryTree,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Parse the following directory structure into a tree.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": f\"Parse this directory structure:\\n{text_representation}\"\n            }\n        ]\n    )\n\n",
          "display_code": "def parse_directory_structure(text_representation: str) -> DirectoryTree:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=DirectoryTree,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Parse the following directory structure into a tree.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": f\"Parse this directory structure:\\n{text_representation}\"\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 39,
          "line_range": [
            39,
            54
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 55,
          "line_range": [
            55,
            55
          ],
          "target_line_range": [
            56,
            68
          ]
        },
        {
          "code": "directory_structure = '''\nroot\n\u251c\u2500\u2500 images\n\u2502   \u251c\u2500\u2500 logo.png\n\u2502   \u2514\u2500\u2500 banner.jpg\n\u2514\u2500\u2500 docs\n    \u251c\u2500\u2500 readme.md\n    \u2514\u2500\u2500 config\n        \u2514\u2500\u2500 settings.json\n'''\n\nresult = parse_directory_structure(directory_structure)\n\n",
          "display_code": "directory_structure = '''\nroot\n\u251c\u2500\u2500 images\n\u2502   \u251c\u2500\u2500 logo.png\n\u2502   \u2514\u2500\u2500 banner.jpg\n\u2514\u2500\u2500 docs\n    \u251c\u2500\u2500 readme.md\n    \u2514\u2500\u2500 config\n        \u2514\u2500\u2500 settings.json\n'''\n\nresult = parse_directory_structure(directory_structure)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 56,
          "line_range": [
            56,
            68
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python recursive-structures.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "006-advanced-structures",
      "section_title": "Advanced Structures"
    },
    {
      "id": "029-knowledge-graphs",
      "title": "Knowledge Graphs",
      "description": "",
      "order": 29,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# - Visual representation of concepts\n",
          "display_code": "",
          "annotation": "- Visual representation of concepts",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor can be used to extract structured knowledge graphs from text. A knowledge graph represents entities and their relationships, making complex information easier to understand and visualize.\n",
          "display_code": "",
          "annotation": "Instructor can be used to extract structured knowledge graphs from text. A knowledge graph represents entities and their relationships, making complex information easier to understand and visualize.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            9
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            9
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 10,
          "line_range": [
            10,
            10
          ],
          "target_line_range": [
            11,
            12
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 11,
          "line_range": [
            11,
            12
          ]
        },
        {
          "code": "# Define the node structure\n",
          "display_code": "",
          "annotation": "Define the node structure",
          "is_comment": true,
          "start_line": 13,
          "line_range": [
            13,
            13
          ],
          "target_line_range": [
            14,
            18
          ]
        },
        {
          "code": "class Node(BaseModel):\n    id: int\n    label: str\n    color: str\n\n",
          "display_code": "class Node(BaseModel):\n    id: int\n    label: str\n    color: str\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 14,
          "line_range": [
            14,
            18
          ]
        },
        {
          "code": "# Define the edge structure\n",
          "display_code": "",
          "annotation": "Define the edge structure",
          "is_comment": true,
          "start_line": 19,
          "line_range": [
            19,
            19
          ],
          "target_line_range": [
            20,
            25
          ]
        },
        {
          "code": "class Edge(BaseModel):\n    source: int\n    target: int\n    label: str\n    color: str = \"black\"\n\n",
          "display_code": "class Edge(BaseModel):\n    source: int\n    target: int\n    label: str\n    color: str = \"black\"\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 20,
          "line_range": [
            20,
            25
          ]
        },
        {
          "code": "# Define the knowledge graph structure\n",
          "display_code": "",
          "annotation": "Define the knowledge graph structure",
          "is_comment": true,
          "start_line": 26,
          "line_range": [
            26,
            26
          ],
          "target_line_range": [
            27,
            30
          ]
        },
        {
          "code": "class KnowledgeGraph(BaseModel):\n    nodes: list[Node] = Field(..., default_factory=list)\n    edges: list[Edge] = Field(..., default_factory=list)\n\n",
          "display_code": "class KnowledgeGraph(BaseModel):\n    nodes: list[Node] = Field(..., default_factory=list)\n    edges: list[Edge] = Field(..., default_factory=list)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 27,
          "line_range": [
            27,
            30
          ]
        },
        {
          "code": "# Extract a knowledge graph from text\n",
          "display_code": "",
          "annotation": "Extract a knowledge graph from text",
          "is_comment": true,
          "start_line": 31,
          "line_range": [
            31,
            31
          ],
          "target_line_range": [
            32,
            43
          ]
        },
        {
          "code": "def generate_knowledge_graph(input_text: str) -> KnowledgeGraph:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Create a detailed knowledge graph for: {input_text}\"\n            }\n        ],\n        response_model=KnowledgeGraph\n    )\n\n",
          "display_code": "def generate_knowledge_graph(input_text: str) -> KnowledgeGraph:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Create a detailed knowledge graph for: {input_text}\"\n            }\n        ],\n        response_model=KnowledgeGraph\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 32,
          "line_range": [
            32,
            43
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 44,
          "line_range": [
            44,
            44
          ],
          "target_line_range": [
            45,
            46
          ]
        },
        {
          "code": "graph = generate_knowledge_graph(\"Quantum mechanics and its applications\")\n\n",
          "display_code": "graph = generate_knowledge_graph(\"Quantum mechanics and its applications\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 45,
          "line_range": [
            45,
            46
          ]
        },
        {
          "code": "# Print the nodes and edges\n",
          "display_code": "",
          "annotation": "Print the nodes and edges",
          "is_comment": true,
          "start_line": 47,
          "line_range": [
            47,
            47
          ],
          "target_line_range": [
            48,
            53
          ]
        },
        {
          "code": "for node in graph.nodes:\n    print(f\"Node {node.id}: {node.label} ({node.color})\")\n\nfor edge in graph.edges:\n    print(f\"Edge: {edge.source} --({edge.label})--> {edge.target}\")\n\n",
          "display_code": "for node in graph.nodes:\n    print(f\"Node {node.id}: {node.label} ({node.color})\")\n\nfor edge in graph.edges:\n    print(f\"Edge: {edge.source} --({edge.label})--> {edge.target}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 48,
          "line_range": [
            48,
            53
          ]
        },
        {
          "code": "# To visualize the knowledge graph, you can use libraries like graphviz:\n",
          "display_code": "",
          "annotation": "To visualize the knowledge graph, you can use libraries like graphviz:",
          "is_comment": true,
          "start_line": 54,
          "line_range": [
            54,
            54
          ],
          "target_line_range": [
            55,
            59
          ]
        },
        {
          "code": "from graphviz import Digraph\n\ndef visualize_knowledge_graph(kg: KnowledgeGraph):\n    dot = Digraph(comment=\"Knowledge Graph\")\n\n",
          "display_code": "from graphviz import Digraph\n\ndef visualize_knowledge_graph(kg: KnowledgeGraph):\n    dot = Digraph(comment=\"Knowledge Graph\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 55,
          "line_range": [
            55,
            59
          ]
        },
        {
          "code": "    # Add nodes\n",
          "display_code": "",
          "annotation": "Add nodes",
          "is_comment": true,
          "start_line": 60,
          "line_range": [
            60,
            60
          ],
          "target_line_range": [
            61,
            63
          ]
        },
        {
          "code": "    for node in kg.nodes:\n        dot.node(str(node.id), node.label, color=node.color)\n\n",
          "display_code": "    for node in kg.nodes:\n        dot.node(str(node.id), node.label, color=node.color)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 61,
          "line_range": [
            61,
            63
          ]
        },
        {
          "code": "    # Add edges\n",
          "display_code": "",
          "annotation": "Add edges",
          "is_comment": true,
          "start_line": 64,
          "line_range": [
            64,
            64
          ],
          "target_line_range": [
            65,
            68
          ]
        },
        {
          "code": "    for edge in kg.edges:\n        dot.edge(str(edge.source), str(edge.target),\n                 label=edge.label, color=edge.color)\n\n",
          "display_code": "    for edge in kg.edges:\n        dot.edge(str(edge.source), str(edge.target),\n                 label=edge.label, color=edge.color)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 65,
          "line_range": [
            65,
            68
          ]
        },
        {
          "code": "    # Render the graph\n",
          "display_code": "",
          "annotation": "Render the graph",
          "is_comment": true,
          "start_line": 69,
          "line_range": [
            69,
            69
          ],
          "target_line_range": [
            70,
            71
          ]
        },
        {
          "code": "    dot.render(\"knowledge_graph.gv\", view=True)\n\n",
          "display_code": "    dot.render(\"knowledge_graph.gv\", view=True)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 70,
          "line_range": [
            70,
            71
          ]
        },
        {
          "code": "# Visualize the graph\n",
          "display_code": "",
          "annotation": "Visualize the graph",
          "is_comment": true,
          "start_line": 72,
          "line_range": [
            72,
            72
          ],
          "target_line_range": [
            73,
            74
          ]
        },
        {
          "code": "visualize_knowledge_graph(graph)\n\n",
          "display_code": "visualize_knowledge_graph(graph)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 73,
          "line_range": [
            73,
            74
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python knowledge-graphs.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "006-advanced-structures",
      "section_title": "Advanced Structures"
    },
    {
      "id": "030-dependency-trees",
      "title": "Dependency Trees",
      "description": "",
      "order": 30,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# - Identifying bottlenecks in processes\n",
          "display_code": "",
          "annotation": "- Identifying bottlenecks in processes",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Dependency trees represent relationships where some items depend on others. Instructor can extract these structures for tasks like workflow management, build systems, or data processing pipelines.\n",
          "display_code": "",
          "annotation": "Dependency trees represent relationships where some items depend on others. Instructor can extract these structures for tasks like workflow management, build systems, or data processing pipelines.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            9
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            9
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 10,
          "line_range": [
            10,
            10
          ],
          "target_line_range": [
            11,
            12
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 11,
          "line_range": [
            11,
            12
          ]
        },
        {
          "code": "# Define a dependency node\n",
          "display_code": "",
          "annotation": "Define a dependency node",
          "is_comment": true,
          "start_line": 13,
          "line_range": [
            13,
            13
          ],
          "target_line_range": [
            14,
            19
          ]
        },
        {
          "code": "class DependencyNode(BaseModel):\n    id: str\n    description: str\n    dependencies: list[str] = Field(default_factory=list,\n                                   description=\"IDs of nodes this node depends on\")\n\n",
          "display_code": "class DependencyNode(BaseModel):\n    id: str\n    description: str\n    dependencies: list[str] = Field(default_factory=list,\n                                   description=\"IDs of nodes this node depends on\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 14,
          "line_range": [
            14,
            19
          ]
        },
        {
          "code": "# Define the dependency tree\n",
          "display_code": "",
          "annotation": "Define the dependency tree",
          "is_comment": true,
          "start_line": 20,
          "line_range": [
            20,
            20
          ],
          "target_line_range": [
            21,
            25
          ]
        },
        {
          "code": "class DependencyTree(BaseModel):\n    nodes: list[DependencyNode]\n\n    def get_execution_order(self) -> list[str]:\n        \"\"\"Returns topologically sorted execution order.\"\"\"\n",
          "display_code": "class DependencyTree(BaseModel):\n    nodes: list[DependencyNode]\n\n    def get_execution_order(self) -> list[str]:\n        \"\"\"Returns topologically sorted execution order.\"\"\"\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 21,
          "line_range": [
            21,
            25
          ]
        },
        {
          "code": "        # Build dependency graph\n",
          "display_code": "",
          "annotation": "Build dependency graph",
          "is_comment": true,
          "start_line": 26,
          "line_range": [
            26,
            26
          ],
          "target_line_range": [
            27,
            29
          ]
        },
        {
          "code": "        dep_graph = {node.id: set(node.dependencies) for node in self.nodes}\n        result = []\n\n",
          "display_code": "        dep_graph = {node.id: set(node.dependencies) for node in self.nodes}\n        result = []\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 27,
          "line_range": [
            27,
            29
          ]
        },
        {
          "code": "        # Find nodes with no dependencies\n",
          "display_code": "",
          "annotation": "Find nodes with no dependencies",
          "is_comment": true,
          "start_line": 30,
          "line_range": [
            30,
            30
          ],
          "target_line_range": [
            31,
            31
          ]
        },
        {
          "code": "        while dep_graph:\n",
          "display_code": "        while dep_graph:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 31,
          "line_range": [
            31,
            31
          ]
        },
        {
          "code": "            # Find nodes with no dependencies\n",
          "display_code": "",
          "annotation": "Find nodes with no dependencies",
          "is_comment": true,
          "start_line": 32,
          "line_range": [
            32,
            32
          ],
          "target_line_range": [
            33,
            36
          ]
        },
        {
          "code": "            roots = {node for node, deps in dep_graph.items() if not deps}\n            if not roots:\n                raise ValueError(\"Circular dependency detected\")\n\n",
          "display_code": "            roots = {node for node, deps in dep_graph.items() if not deps}\n            if not roots:\n                raise ValueError(\"Circular dependency detected\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 33,
          "line_range": [
            33,
            36
          ]
        },
        {
          "code": "            # Add these nodes to the result\n",
          "display_code": "",
          "annotation": "Add these nodes to the result",
          "is_comment": true,
          "start_line": 37,
          "line_range": [
            37,
            37
          ],
          "target_line_range": [
            38,
            39
          ]
        },
        {
          "code": "            result.extend(sorted(roots))\n\n",
          "display_code": "            result.extend(sorted(roots))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 38,
          "line_range": [
            38,
            39
          ]
        },
        {
          "code": "            # Remove these nodes from the graph\n",
          "display_code": "",
          "annotation": "Remove these nodes from the graph",
          "is_comment": true,
          "start_line": 40,
          "line_range": [
            40,
            40
          ],
          "target_line_range": [
            41,
            48
          ]
        },
        {
          "code": "            dep_graph = {\n                node: (deps - roots)\n                for node, deps in dep_graph.items()\n                if node not in roots\n            }\n\n        return result\n\n",
          "display_code": "            dep_graph = {\n                node: (deps - roots)\n                for node, deps in dep_graph.items()\n                if node not in roots\n            }\n\n        return result\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 41,
          "line_range": [
            41,
            48
          ]
        },
        {
          "code": "# Extract dependencies from a project description\n",
          "display_code": "",
          "annotation": "Extract dependencies from a project description",
          "is_comment": true,
          "start_line": 49,
          "line_range": [
            49,
            49
          ],
          "target_line_range": [
            50,
            65
          ]
        },
        {
          "code": "def extract_dependencies(project_description: str) -> DependencyTree:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract the dependencies between tasks in this project.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": project_description\n            }\n        ],\n        response_model=DependencyTree\n    )\n\n",
          "display_code": "def extract_dependencies(project_description: str) -> DependencyTree:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract the dependencies between tasks in this project.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": project_description\n            }\n        ],\n        response_model=DependencyTree\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 50,
          "line_range": [
            50,
            65
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 66,
          "line_range": [
            66,
            66
          ],
          "target_line_range": [
            67,
            80
          ]
        },
        {
          "code": "project = \"\"\"\nBuilding a web application requires:\n1. Setup development environment\n2. Design database schema (after setup)\n3. Create API endpoints (after database schema)\n4. Build frontend UI (after API design)\n5. Write tests (after API and UI)\n6. Deploy application (after tests pass)\n\"\"\"\n\ndependencies = extract_dependencies(project)\nexecution_order = dependencies.get_execution_order()\nprint(\"Execution order:\", execution_order)\n\n",
          "display_code": "project = \"\"\"\nBuilding a web application requires:\n1. Setup development environment\n2. Design database schema (after setup)\n3. Create API endpoints (after database schema)\n4. Build frontend UI (after API design)\n5. Write tests (after API and UI)\n6. Deploy application (after tests pass)\n\"\"\"\n\ndependencies = extract_dependencies(project)\nexecution_order = dependencies.get_execution_order()\nprint(\"Execution order:\", execution_order)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 67,
          "line_range": [
            67,
            80
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python dependency-trees.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "006-advanced-structures",
      "section_title": "Advanced Structures"
    },
    {
      "id": "031-task-planning",
      "title": "Task Planning",
      "description": "",
      "order": 31,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# - Creating step-by-step solutions\n",
          "display_code": "",
          "annotation": "- Creating step-by-step solutions",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor can be used to create sophisticated task planning systems that break down complex problems into manageable subtasks. This example shows how to implement a task planner with dependencies and execute them in the correct order.\n",
          "display_code": "",
          "annotation": "Instructor can be used to create sophisticated task planning systems that break down complex problems into manageable subtasks. This example shows how to implement a task planner with dependencies and execute them in the correct order.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "import asyncio\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\n\n",
          "display_code": "import asyncio\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define models for task results\n",
          "display_code": "",
          "annotation": "Define models for task results",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            21
          ]
        },
        {
          "code": "class TaskResult(BaseModel):\n    task_id: int\n    result: str\n\nclass TaskResults(BaseModel):\n    results: list[TaskResult]\n\n",
          "display_code": "class TaskResult(BaseModel):\n    task_id: int\n    result: str\n\nclass TaskResults(BaseModel):\n    results: list[TaskResult]\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            21
          ]
        },
        {
          "code": "# Define the Task model\n",
          "display_code": "",
          "annotation": "Define the Task model",
          "is_comment": true,
          "start_line": 22,
          "line_range": [
            22,
            22
          ],
          "target_line_range": [
            23,
            32
          ]
        },
        {
          "code": "class Task(BaseModel):\n    id: int = Field(..., description=\"Unique id of the task\")\n    task: str = Field(..., description=\"The task to be performed\")\n    subtasks: list[int] = Field(\n        default_factory=list,\n        description=\"IDs of subtasks that must be completed before this task\"\n    )\n\n    async def execute(self, with_results: TaskResults) -> TaskResult:\n        \"\"\"Execute this task and return the result.\"\"\"\n",
          "display_code": "class Task(BaseModel):\n    id: int = Field(..., description=\"Unique id of the task\")\n    task: str = Field(..., description=\"The task to be performed\")\n    subtasks: list[int] = Field(\n        default_factory=list,\n        description=\"IDs of subtasks that must be completed before this task\"\n    )\n\n    async def execute(self, with_results: TaskResults) -> TaskResult:\n        \"\"\"Execute this task and return the result.\"\"\"\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 23,
          "line_range": [
            23,
            32
          ]
        },
        {
          "code": "        # In a real implementation, this would perform the actual task\n        # Here we just return a placeholder result\n",
          "display_code": "",
          "annotation": "In a real implementation, this would perform the actual task\nHere we just return a placeholder result",
          "is_comment": true,
          "start_line": 33,
          "line_range": [
            33,
            34
          ],
          "target_line_range": [
            35,
            36
          ]
        },
        {
          "code": "        return TaskResult(task_id=self.id, result=f\"Result for task: {self.task}\")\n\n",
          "display_code": "        return TaskResult(task_id=self.id, result=f\"Result for task: {self.task}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 35,
          "line_range": [
            35,
            36
          ]
        },
        {
          "code": "# Define the TaskPlan model\n",
          "display_code": "",
          "annotation": "Define the TaskPlan model",
          "is_comment": true,
          "start_line": 37,
          "line_range": [
            37,
            37
          ],
          "target_line_range": [
            38,
            49
          ]
        },
        {
          "code": "class TaskPlan(BaseModel):\n    task_graph: list[Task] = Field(\n        ...,\n        description=\"List of tasks and their dependencies\"\n    )\n\n    def _get_execution_order(self) -> list[int]:\n        \"\"\"Compute topological sort of tasks based on dependencies.\"\"\"\n        dep_graph = {task.id: set(task.subtasks) for task in self.task_graph}\n        result = []\n\n        while dep_graph:\n",
          "display_code": "class TaskPlan(BaseModel):\n    task_graph: list[Task] = Field(\n        ...,\n        description=\"List of tasks and their dependencies\"\n    )\n\n    def _get_execution_order(self) -> list[int]:\n        \"\"\"Compute topological sort of tasks based on dependencies.\"\"\"\n        dep_graph = {task.id: set(task.subtasks) for task in self.task_graph}\n        result = []\n\n        while dep_graph:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 38,
          "line_range": [
            38,
            49
          ]
        },
        {
          "code": "            # Find tasks with no remaining dependencies\n",
          "display_code": "",
          "annotation": "Find tasks with no remaining dependencies",
          "is_comment": true,
          "start_line": 50,
          "line_range": [
            50,
            50
          ],
          "target_line_range": [
            51,
            54
          ]
        },
        {
          "code": "            available = {task_id for task_id, deps in dep_graph.items() if not deps}\n            if not available:\n                raise ValueError(\"Circular dependency detected in tasks\")\n\n",
          "display_code": "            available = {task_id for task_id, deps in dep_graph.items() if not deps}\n            if not available:\n                raise ValueError(\"Circular dependency detected in tasks\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 51,
          "line_range": [
            51,
            54
          ]
        },
        {
          "code": "            # Add them to the result\n",
          "display_code": "",
          "annotation": "Add them to the result",
          "is_comment": true,
          "start_line": 55,
          "line_range": [
            55,
            55
          ],
          "target_line_range": [
            56,
            57
          ]
        },
        {
          "code": "            result.extend(sorted(available))\n\n",
          "display_code": "            result.extend(sorted(available))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 56,
          "line_range": [
            56,
            57
          ]
        },
        {
          "code": "            # Remove these tasks from the graph\n",
          "display_code": "",
          "annotation": "Remove these tasks from the graph",
          "is_comment": true,
          "start_line": 58,
          "line_range": [
            58,
            58
          ],
          "target_line_range": [
            59,
            73
          ]
        },
        {
          "code": "            dep_graph = {\n                task_id: (deps - available)\n                for task_id, deps in dep_graph.items()\n                if task_id not in available\n            }\n\n        return result\n\n    async def execute(self) -> dict[int, TaskResult]:\n        \"\"\"Execute all tasks in dependency order.\"\"\"\n        execution_order = self._get_execution_order()\n        tasks_by_id = {task.id: task for task in self.task_graph}\n        results = {}\n\n        while len(results) < len(self.task_graph):\n",
          "display_code": "            dep_graph = {\n                task_id: (deps - available)\n                for task_id, deps in dep_graph.items()\n                if task_id not in available\n            }\n\n        return result\n\n    async def execute(self) -> dict[int, TaskResult]:\n        \"\"\"Execute all tasks in dependency order.\"\"\"\n        execution_order = self._get_execution_order()\n        tasks_by_id = {task.id: task for task in self.task_graph}\n        results = {}\n\n        while len(results) < len(self.task_graph):\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 59,
          "line_range": [
            59,
            73
          ]
        },
        {
          "code": "            # Find tasks ready to execute (all dependencies satisfied)\n",
          "display_code": "",
          "annotation": "Find tasks ready to execute (all dependencies satisfied)",
          "is_comment": true,
          "start_line": 74,
          "line_range": [
            74,
            74
          ],
          "target_line_range": [
            75,
            81
          ]
        },
        {
          "code": "            ready_tasks = [\n                tasks_by_id[task_id]\n                for task_id in execution_order\n                if task_id not in results and\n                all(dep_id in results for dep_id in tasks_by_id[task_id].subtasks)\n            ]\n\n",
          "display_code": "            ready_tasks = [\n                tasks_by_id[task_id]\n                for task_id in execution_order\n                if task_id not in results and\n                all(dep_id in results for dep_id in tasks_by_id[task_id].subtasks)\n            ]\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 75,
          "line_range": [
            75,
            81
          ]
        },
        {
          "code": "            # Execute tasks in parallel\n",
          "display_code": "",
          "annotation": "Execute tasks in parallel",
          "is_comment": true,
          "start_line": 82,
          "line_range": [
            82,
            82
          ],
          "target_line_range": [
            83,
            94
          ]
        },
        {
          "code": "            new_results = await asyncio.gather(*[\n                task.execute(\n                    with_results=TaskResults(\n                        results=[\n                            results[dep_id]\n                            for dep_id in task.subtasks\n                        ]\n                    )\n                )\n                for task in ready_tasks\n            ])\n\n",
          "display_code": "            new_results = await asyncio.gather(*[\n                task.execute(\n                    with_results=TaskResults(\n                        results=[\n                            results[dep_id]\n                            for dep_id in task.subtasks\n                        ]\n                    )\n                )\n                for task in ready_tasks\n            ])\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 83,
          "line_range": [
            83,
            94
          ]
        },
        {
          "code": "            # Store results\n",
          "display_code": "",
          "annotation": "Store results",
          "is_comment": true,
          "start_line": 95,
          "line_range": [
            95,
            95
          ],
          "target_line_range": [
            96,
            100
          ]
        },
        {
          "code": "            for result in new_results:\n                results[result.task_id] = result\n\n        return results\n\n",
          "display_code": "            for result in new_results:\n                results[result.task_id] = result\n\n        return results\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 96,
          "line_range": [
            96,
            100
          ]
        },
        {
          "code": "# Generate a task plan for a complex question\n",
          "display_code": "",
          "annotation": "Generate a task plan for a complex question",
          "is_comment": true,
          "start_line": 101,
          "line_range": [
            101,
            101
          ],
          "target_line_range": [
            102,
            117
          ]
        },
        {
          "code": "def create_task_plan(question: str) -> TaskPlan:\n    return client.chat.completions.create(\n        model=\"gpt-4\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Create a detailed task plan to answer the user's question. Break down the problem into smaller, dependent tasks.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": question\n            }\n        ],\n        response_model=TaskPlan\n    )\n\n",
          "display_code": "def create_task_plan(question: str) -> TaskPlan:\n    return client.chat.completions.create(\n        model=\"gpt-4\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Create a detailed task plan to answer the user's question. Break down the problem into smaller, dependent tasks.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": question\n            }\n        ],\n        response_model=TaskPlan\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 102,
          "line_range": [
            102,
            117
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 118,
          "line_range": [
            118,
            118
          ],
          "target_line_range": [
            119,
            134
          ]
        },
        {
          "code": "async def main():\n    plan = create_task_plan(\n        \"What is the economic impact of renewable energy adoption in developing countries?\"\n    )\n    print(\"Task Plan:\")\n    for task in plan.task_graph:\n        deps = f\" (depends on: {task.subtasks})\" if task.subtasks else \"\"\n        print(f\"Task {task.id}: {task.task}{deps}\")\n\n    print(\"\\nExecuting plan...\")\n    results = await plan.execute()\n\n    print(\"\\nResults:\")\n    for task_id, result in sorted(results.items()):\n        print(f\"Task {task_id}: {result.result}\")\n\n",
          "display_code": "async def main():\n    plan = create_task_plan(\n        \"What is the economic impact of renewable energy adoption in developing countries?\"\n    )\n    print(\"Task Plan:\")\n    for task in plan.task_graph:\n        deps = f\" (depends on: {task.subtasks})\" if task.subtasks else \"\"\n        print(f\"Task {task.id}: {task.task}{deps}\")\n\n    print(\"\\nExecuting plan...\")\n    results = await plan.execute()\n\n    print(\"\\nResults:\")\n    for task_id, result in sorted(results.items()):\n        print(f\"Task {task_id}: {result.result}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 119,
          "line_range": [
            119,
            134
          ]
        },
        {
          "code": "# Run the example\n",
          "display_code": "",
          "annotation": "Run the example",
          "is_comment": true,
          "start_line": 135,
          "line_range": [
            135,
            135
          ],
          "target_line_range": [
            136,
            138
          ]
        },
        {
          "code": "if __name__ == \"__main__\":\n    asyncio.run(main())\n\n",
          "display_code": "if __name__ == \"__main__\":\n    asyncio.run(main())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 136,
          "line_range": [
            136,
            138
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python task-planning.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "006-advanced-structures",
      "section_title": "Advanced Structures"
    },
    {
      "id": "032-document-structure",
      "title": "Document Structure",
      "description": "",
      "order": 32,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# - Document classification and organization\n",
          "display_code": "",
          "annotation": "- Document classification and organization",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor can extract structured representations of documents, such as articles, papers, or reports. This approach helps convert unstructured text into structured data that can be analyzed and processed.\n",
          "display_code": "",
          "annotation": "Instructor can extract structured representations of documents, such as articles, papers, or reports. This approach helps convert unstructured text into structured data that can be analyzed and processed.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import Optional, List\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import Optional, List\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define section structure\n",
          "display_code": "",
          "annotation": "Define section structure",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            19
          ]
        },
        {
          "code": "class Section(BaseModel):\n    heading: str\n    content: str\n    subsections: List[\"Section\"] = Field(default_factory=list)\n\n",
          "display_code": "class Section(BaseModel):\n    heading: str\n    content: str\n    subsections: List[\"Section\"] = Field(default_factory=list)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            19
          ]
        },
        {
          "code": "# Important! For recursive models, we need to rebuild the model\n",
          "display_code": "",
          "annotation": "Important! For recursive models, we need to rebuild the model",
          "is_comment": true,
          "start_line": 20,
          "line_range": [
            20,
            20
          ],
          "target_line_range": [
            21,
            22
          ]
        },
        {
          "code": "Section.model_rebuild()\n\n",
          "display_code": "Section.model_rebuild()\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 21,
          "line_range": [
            21,
            22
          ]
        },
        {
          "code": "# Define document structure\n",
          "display_code": "",
          "annotation": "Define document structure",
          "is_comment": true,
          "start_line": 23,
          "line_range": [
            23,
            23
          ],
          "target_line_range": [
            24,
            30
          ]
        },
        {
          "code": "class Document(BaseModel):\n    title: str\n    abstract: Optional[str] = None\n    authors: List[str] = Field(default_factory=list)\n    sections: List[Section] = Field(default_factory=list)\n    keywords: List[str] = Field(default_factory=list)\n\n",
          "display_code": "class Document(BaseModel):\n    title: str\n    abstract: Optional[str] = None\n    authors: List[str] = Field(default_factory=list)\n    sections: List[Section] = Field(default_factory=list)\n    keywords: List[str] = Field(default_factory=list)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 24,
          "line_range": [
            24,
            30
          ]
        },
        {
          "code": "# Extract document structure from text\n",
          "display_code": "",
          "annotation": "Extract document structure from text",
          "is_comment": true,
          "start_line": 31,
          "line_range": [
            31,
            31
          ],
          "target_line_range": [
            32,
            47
          ]
        },
        {
          "code": "def extract_document_structure(text: str) -> Document:\n    return client.chat.completions.create(\n        model=\"gpt-4\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract the structured representation of this document, including all sections and subsections.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": text\n            }\n        ],\n        response_model=Document\n    )\n\n",
          "display_code": "def extract_document_structure(text: str) -> Document:\n    return client.chat.completions.create(\n        model=\"gpt-4\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract the structured representation of this document, including all sections and subsections.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": text\n            }\n        ],\n        response_model=Document\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 32,
          "line_range": [
            32,
            47
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 48,
          "line_range": [
            48,
            48
          ],
          "target_line_range": [
            49,
            49
          ]
        },
        {
          "code": "document_text = \"\"\"\n",
          "display_code": "document_text = \"\"\"\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 49,
          "line_range": [
            49,
            49
          ]
        },
        {
          "code": "# Machine Learning in Healthcare\n## Authors: Jane Smith, John Doe\n",
          "display_code": "",
          "annotation": "Machine Learning in Healthcare\nAuthors: Jane Smith, John Doe",
          "is_comment": true,
          "start_line": 50,
          "line_range": [
            50,
            51
          ],
          "target_line_range": [
            52,
            52
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 52,
          "line_range": [
            52,
            52
          ]
        },
        {
          "code": "### Abstract\n",
          "display_code": "",
          "annotation": "Abstract",
          "is_comment": true,
          "start_line": 53,
          "line_range": [
            53,
            53
          ],
          "target_line_range": [
            54,
            55
          ]
        },
        {
          "code": "This paper explores the applications of machine learning in healthcare settings.\n\n",
          "display_code": "This paper explores the applications of machine learning in healthcare settings.\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 54,
          "line_range": [
            54,
            55
          ]
        },
        {
          "code": "### Keywords\n",
          "display_code": "",
          "annotation": "Keywords",
          "is_comment": true,
          "start_line": 56,
          "line_range": [
            56,
            56
          ],
          "target_line_range": [
            57,
            58
          ]
        },
        {
          "code": "machine learning, healthcare, AI, medical diagnosis\n\n",
          "display_code": "machine learning, healthcare, AI, medical diagnosis\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 57,
          "line_range": [
            57,
            58
          ]
        },
        {
          "code": "## Introduction\n",
          "display_code": "",
          "annotation": "Introduction",
          "is_comment": true,
          "start_line": 59,
          "line_range": [
            59,
            59
          ],
          "target_line_range": [
            60,
            61
          ]
        },
        {
          "code": "Machine learning has shown promising results in healthcare applications.\n\n",
          "display_code": "Machine learning has shown promising results in healthcare applications.\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 60,
          "line_range": [
            60,
            61
          ]
        },
        {
          "code": "### Background\n",
          "display_code": "",
          "annotation": "Background",
          "is_comment": true,
          "start_line": 62,
          "line_range": [
            62,
            62
          ],
          "target_line_range": [
            63,
            64
          ]
        },
        {
          "code": "Healthcare has historically been slow to adopt new technologies.\n\n",
          "display_code": "Healthcare has historically been slow to adopt new technologies.\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 63,
          "line_range": [
            63,
            64
          ]
        },
        {
          "code": "### Current Challenges\n",
          "display_code": "",
          "annotation": "Current Challenges",
          "is_comment": true,
          "start_line": 65,
          "line_range": [
            65,
            65
          ],
          "target_line_range": [
            66,
            67
          ]
        },
        {
          "code": "Data privacy and model interpretability remain significant challenges.\n\n",
          "display_code": "Data privacy and model interpretability remain significant challenges.\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 66,
          "line_range": [
            66,
            67
          ]
        },
        {
          "code": "## Methods\n",
          "display_code": "",
          "annotation": "Methods",
          "is_comment": true,
          "start_line": 68,
          "line_range": [
            68,
            68
          ],
          "target_line_range": [
            69,
            70
          ]
        },
        {
          "code": "We employed a mixed-methods approach.\n\n",
          "display_code": "We employed a mixed-methods approach.\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 69,
          "line_range": [
            69,
            70
          ]
        },
        {
          "code": "## Results\n",
          "display_code": "",
          "annotation": "Results",
          "is_comment": true,
          "start_line": 71,
          "line_range": [
            71,
            71
          ],
          "target_line_range": [
            72,
            73
          ]
        },
        {
          "code": "Our findings indicate a 30% improvement in diagnostic accuracy.\n\n",
          "display_code": "Our findings indicate a 30% improvement in diagnostic accuracy.\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 72,
          "line_range": [
            72,
            73
          ]
        },
        {
          "code": "## Discussion\n",
          "display_code": "",
          "annotation": "Discussion",
          "is_comment": true,
          "start_line": 74,
          "line_range": [
            74,
            74
          ],
          "target_line_range": [
            75,
            76
          ]
        },
        {
          "code": "These results have significant implications for clinical practice.\n\n",
          "display_code": "These results have significant implications for clinical practice.\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 75,
          "line_range": [
            75,
            76
          ]
        },
        {
          "code": "## Conclusion\n",
          "display_code": "",
          "annotation": "Conclusion",
          "is_comment": true,
          "start_line": 77,
          "line_range": [
            77,
            77
          ],
          "target_line_range": [
            78,
            82
          ]
        },
        {
          "code": "Machine learning will continue to transform healthcare delivery.\n\"\"\"\n\ndoc_structure = extract_document_structure(document_text)\n\n",
          "display_code": "Machine learning will continue to transform healthcare delivery.\n\"\"\"\n\ndoc_structure = extract_document_structure(document_text)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 78,
          "line_range": [
            78,
            82
          ]
        },
        {
          "code": "# Print the document structure\n",
          "display_code": "",
          "annotation": "Print the document structure",
          "is_comment": true,
          "start_line": 83,
          "line_range": [
            83,
            83
          ],
          "target_line_range": [
            84,
            94
          ]
        },
        {
          "code": "print(f\"Title: {doc_structure.title}\")\nprint(f\"Authors: {', '.join(doc_structure.authors)}\")\nif doc_structure.abstract:\n    print(f\"Abstract: {doc_structure.abstract}\")\nprint(f\"Keywords: {', '.join(doc_structure.keywords)}\")\nprint(\"\\nSections:\")\nfor section in doc_structure.sections:\n    print(f\"- {section.heading}\")\n    for subsection in section.subsections:\n        print(f\"  - {subsection.heading}\")\n\n",
          "display_code": "print(f\"Title: {doc_structure.title}\")\nprint(f\"Authors: {', '.join(doc_structure.authors)}\")\nif doc_structure.abstract:\n    print(f\"Abstract: {doc_structure.abstract}\")\nprint(f\"Keywords: {', '.join(doc_structure.keywords)}\")\nprint(\"\\nSections:\")\nfor section in doc_structure.sections:\n    print(f\"- {section.heading}\")\n    for subsection in section.subsections:\n        print(f\"  - {subsection.heading}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 84,
          "line_range": [
            84,
            94
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python document-structure.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "006-advanced-structures",
      "section_title": "Advanced Structures"
    },
    {
      "id": "033-validation-basics",
      "title": "Validation Basics",
      "description": "",
      "order": 33,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# 4. The process repeats until validation passes or max retries is reached\n",
          "display_code": "",
          "annotation": "4. The process repeats until validation passes or max retries is reached",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor leverages Pydantic's validation framework to ensure that outputs from LLMs match your expected schema. This is crucial for building reliable applications.\n",
          "display_code": "",
          "annotation": "Instructor leverages Pydantic's validation framework to ensure that outputs from LLMs match your expected schema. This is crucial for building reliable applications.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            9
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            9
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 10,
          "line_range": [
            10,
            10
          ],
          "target_line_range": [
            11,
            12
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 11,
          "line_range": [
            11,
            12
          ]
        },
        {
          "code": "# Define a model with basic validation\n",
          "display_code": "",
          "annotation": "Define a model with basic validation",
          "is_comment": true,
          "start_line": 13,
          "line_range": [
            13,
            13
          ],
          "target_line_range": [
            14,
            20
          ]
        },
        {
          "code": "class User(BaseModel):\n    name: str = Field(..., description=\"User's full name\")\n    age: int = Field(...,\n                    description=\"User's age in years\",\n                    ge=0, le=120)  # Must be between 0 and 120\n    email: str = Field(..., description=\"User's email address\")\n\n",
          "display_code": "class User(BaseModel):\n    name: str = Field(..., description=\"User's full name\")\n    age: int = Field(...,\n                    description=\"User's age in years\",\n                    ge=0, le=120)  # Must be between 0 and 120\n    email: str = Field(..., description=\"User's email address\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 14,
          "line_range": [
            14,
            20
          ]
        },
        {
          "code": "# Extract user information with validation\n",
          "display_code": "",
          "annotation": "Extract user information with validation",
          "is_comment": true,
          "start_line": 21,
          "line_range": [
            21,
            21
          ],
          "target_line_range": [
            22,
            33
          ]
        },
        {
          "code": "def extract_user(text: str) -> User:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Extract user information from this text: {text}\"\n            }\n        ],\n        response_model=User\n    )\n\n",
          "display_code": "def extract_user(text: str) -> User:\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Extract user information from this text: {text}\"\n            }\n        ],\n        response_model=User\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 22,
          "line_range": [
            22,
            33
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 34,
          "line_range": [
            34,
            34
          ],
          "target_line_range": [
            35,
            38
          ]
        },
        {
          "code": "text = \"John Doe is 25 years old and his email is john.doe@example.com.\"\nuser = extract_user(text)\nprint(user.model_dump_json(indent=2))\n\n",
          "display_code": "text = \"John Doe is 25 years old and his email is john.doe@example.com.\"\nuser = extract_user(text)\nprint(user.model_dump_json(indent=2))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 35,
          "line_range": [
            35,
            38
          ]
        },
        {
          "code": "# When an LLM output fails validation, Instructor can automatically retry the request with the validation error message:\n",
          "display_code": "",
          "annotation": "When an LLM output fails validation, Instructor can automatically retry the request with the validation error message:",
          "is_comment": true,
          "start_line": 39,
          "line_range": [
            39,
            39
          ],
          "target_line_range": [
            40,
            43
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, field_validator\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, field_validator\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 40,
          "line_range": [
            40,
            43
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 44,
          "line_range": [
            44,
            44
          ],
          "target_line_range": [
            45,
            46
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 45,
          "line_range": [
            45,
            46
          ]
        },
        {
          "code": "# Define a model with custom validation\n",
          "display_code": "",
          "annotation": "Define a model with custom validation",
          "is_comment": true,
          "start_line": 47,
          "line_range": [
            47,
            47
          ],
          "target_line_range": [
            48,
            57
          ]
        },
        {
          "code": "class User(BaseModel):\n    name: str\n    age: int\n\n    @field_validator(\"age\")\n    def validate_age(cls, v):\n        if v < 0 or v > 120:\n            raise ValueError(\"Age must be between 0 and 120\")\n        return v\n\n",
          "display_code": "class User(BaseModel):\n    name: str\n    age: int\n\n    @field_validator(\"age\")\n    def validate_age(cls, v):\n        if v < 0 or v > 120:\n            raise ValueError(\"Age must be between 0 and 120\")\n        return v\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 48,
          "line_range": [
            48,
            57
          ]
        },
        {
          "code": "# Extract with automatic retries\n",
          "display_code": "",
          "annotation": "Extract with automatic retries",
          "is_comment": true,
          "start_line": 58,
          "line_range": [
            58,
            58
          ],
          "target_line_range": [
            59,
            72
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract: John Doe, age: 150\"\n        }\n    ],\n    response_model=User,\n    max_retries=2  # Try up to 2 more times if validation fails\n)\n\nprint(user.model_dump_json(indent=2))\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract: John Doe, age: 150\"\n        }\n    ],\n    response_model=User,\n    max_retries=2  # Try up to 2 more times if validation fails\n)\n\nprint(user.model_dump_json(indent=2))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 59,
          "line_range": [
            59,
            72
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python validation-basics.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "007-validation",
      "section_title": "Validation"
    },
    {
      "id": "034-custom-validators",
      "title": "Custom Validators",
      "description": "",
      "order": 34,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# - Context-dependent validation\n",
          "display_code": "",
          "annotation": "- Context-dependent validation",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor allows you to create custom validators to enforce specific rules on LLM outputs. These can range from simple format checks to complex business logic.\n",
          "display_code": "",
          "annotation": "Instructor allows you to create custom validators to enforce specific rules on LLM outputs. These can range from simple format checks to complex business logic.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            9
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, field_validator\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, field_validator\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            9
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 10,
          "line_range": [
            10,
            10
          ],
          "target_line_range": [
            11,
            12
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 11,
          "line_range": [
            11,
            12
          ]
        },
        {
          "code": "# Define a model with a custom validator\n",
          "display_code": "",
          "annotation": "Define a model with a custom validator",
          "is_comment": true,
          "start_line": 13,
          "line_range": [
            13,
            13
          ],
          "target_line_range": [
            14,
            26
          ]
        },
        {
          "code": "class Contact(BaseModel):\n    name: str = Field(description=\"Person's full name\")\n    email: str = Field(description=\"Person's email address\")\n    phone: str = Field(description=\"Person's phone number\")\n\n    @field_validator(\"email\")\n    def validate_email(cls, v):\n        if \"@\" not in v:\n            raise ValueError(\"Email must contain @ symbol\")\n        return v\n\n    @field_validator(\"phone\")\n    def validate_phone(cls, v):\n",
          "display_code": "class Contact(BaseModel):\n    name: str = Field(description=\"Person's full name\")\n    email: str = Field(description=\"Person's email address\")\n    phone: str = Field(description=\"Person's phone number\")\n\n    @field_validator(\"email\")\n    def validate_email(cls, v):\n        if \"@\" not in v:\n            raise ValueError(\"Email must contain @ symbol\")\n        return v\n\n    @field_validator(\"phone\")\n    def validate_phone(cls, v):\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 14,
          "line_range": [
            14,
            26
          ]
        },
        {
          "code": "        # Remove all non-numeric characters\n",
          "display_code": "",
          "annotation": "Remove all non-numeric characters",
          "is_comment": true,
          "start_line": 27,
          "line_range": [
            27,
            27
          ],
          "target_line_range": [
            28,
            32
          ]
        },
        {
          "code": "        digits = ''.join(c for c in v if c.isdigit())\n        if len(digits) < 10:\n            raise ValueError(\"Phone number must have at least 10 digits\")\n        return v\n\n",
          "display_code": "        digits = ''.join(c for c in v if c.isdigit())\n        if len(digits) < 10:\n            raise ValueError(\"Phone number must have at least 10 digits\")\n        return v\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 28,
          "line_range": [
            28,
            32
          ]
        },
        {
          "code": "# Extract contact information with validation\n",
          "display_code": "",
          "annotation": "Extract contact information with validation",
          "is_comment": true,
          "start_line": 33,
          "line_range": [
            33,
            33
          ],
          "target_line_range": [
            34,
            47
          ]
        },
        {
          "code": "contact = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract: John Doe, email: johndoe.example.com, phone: 555-1234\"\n        }\n    ],\n    response_model=Contact,\n    max_retries=2\n)\n\nprint(contact.model_dump_json(indent=2))\n\n",
          "display_code": "contact = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract: John Doe, email: johndoe.example.com, phone: 555-1234\"\n        }\n    ],\n    response_model=Contact,\n    max_retries=2\n)\n\nprint(contact.model_dump_json(indent=2))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 34,
          "line_range": [
            34,
            47
          ]
        },
        {
          "code": "# You can also use validation with annotated types:\n",
          "display_code": "",
          "annotation": "You can also use validation with annotated types:",
          "is_comment": true,
          "start_line": 48,
          "line_range": [
            48,
            48
          ],
          "target_line_range": [
            49,
            51
          ]
        },
        {
          "code": "from typing_extensions import Annotated\nfrom pydantic import AfterValidator\n\n",
          "display_code": "from typing_extensions import Annotated\nfrom pydantic import AfterValidator\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 49,
          "line_range": [
            49,
            51
          ]
        },
        {
          "code": "# Define a validation function\n",
          "display_code": "",
          "annotation": "Define a validation function",
          "is_comment": true,
          "start_line": 52,
          "line_range": [
            52,
            52
          ],
          "target_line_range": [
            53,
            57
          ]
        },
        {
          "code": "def validate_uppercase(v: str) -> str:\n    if v != v.upper():\n        raise ValueError(\"String must be uppercase\")\n    return v\n\n",
          "display_code": "def validate_uppercase(v: str) -> str:\n    if v != v.upper():\n        raise ValueError(\"String must be uppercase\")\n    return v\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 53,
          "line_range": [
            53,
            57
          ]
        },
        {
          "code": "# Define a model with annotated validation\n",
          "display_code": "",
          "annotation": "Define a model with annotated validation",
          "is_comment": true,
          "start_line": 58,
          "line_range": [
            58,
            58
          ],
          "target_line_range": [
            59,
            68
          ]
        },
        {
          "code": "class Document(BaseModel):\n    title: Annotated[str, AfterValidator(validate_uppercase)]\n    content: str\n\n    @field_validator(\"content\")\n    def validate_content_length(cls, v):\n        if len(v.split()) < 5:\n            raise ValueError(\"Content must be at least 5 words long\")\n        return v\n\n",
          "display_code": "class Document(BaseModel):\n    title: Annotated[str, AfterValidator(validate_uppercase)]\n    content: str\n\n    @field_validator(\"content\")\n    def validate_content_length(cls, v):\n        if len(v.split()) < 5:\n            raise ValueError(\"Content must be at least 5 words long\")\n        return v\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 59,
          "line_range": [
            59,
            68
          ]
        },
        {
          "code": "# For even more advanced validation, you can use LLM-based validators:\n",
          "display_code": "",
          "annotation": "For even more advanced validation, you can use LLM-based validators:",
          "is_comment": true,
          "start_line": 69,
          "line_range": [
            69,
            69
          ],
          "target_line_range": [
            70,
            75
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, BeforeValidator\nfrom typing_extensions import Annotated\nfrom instructor import llm_validator\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, BeforeValidator\nfrom typing_extensions import Annotated\nfrom instructor import llm_validator\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 70,
          "line_range": [
            70,
            75
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 76,
          "line_range": [
            76,
            76
          ],
          "target_line_range": [
            77,
            78
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 77,
          "line_range": [
            77,
            78
          ]
        },
        {
          "code": "# Define a model with LLM-based validation\n",
          "display_code": "",
          "annotation": "Define a model with LLM-based validation",
          "is_comment": true,
          "start_line": 79,
          "line_range": [
            79,
            79
          ],
          "target_line_range": [
            80,
            87
          ]
        },
        {
          "code": "class Review(BaseModel):\n    product: str\n    content: Annotated[\n        str,\n        BeforeValidator(llm_validator(\"must be positive and respectful\", client=client))\n    ]\n    rating: int\n\n",
          "display_code": "class Review(BaseModel):\n    product: str\n    content: Annotated[\n        str,\n        BeforeValidator(llm_validator(\"must be positive and respectful\", client=client))\n    ]\n    rating: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 80,
          "line_range": [
            80,
            87
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 88,
          "line_range": [
            88,
            88
          ],
          "target_line_range": [
            89,
            100
          ]
        },
        {
          "code": "review = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract: iPhone 14, content: This product is terrible and I hate it, rating: 1\"\n        }\n    ],\n    response_model=Review,\n    max_retries=2\n)\n\n",
          "display_code": "review = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract: iPhone 14, content: This product is terrible and I hate it, rating: 1\"\n        }\n    ],\n    response_model=Review,\n    max_retries=2\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 89,
          "line_range": [
            89,
            100
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python custom-validators.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "007-validation",
      "section_title": "Validation"
    },
    {
      "id": "035-retry-mechanisms",
      "title": "Retry Mechanisms",
      "description": "",
      "order": 35,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# - Creating robust production applications\n",
          "display_code": "",
          "annotation": "- Creating robust production applications",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor provides flexible retry mechanisms for handling validation failures. This helps create more robust applications that can recover from parsing errors or validation issues.\n",
          "display_code": "",
          "annotation": "Instructor provides flexible retry mechanisms for handling validation failures. This helps create more robust applications that can recover from parsing errors or validation issues.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            9
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, field_validator\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, field_validator\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            9
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 10,
          "line_range": [
            10,
            10
          ],
          "target_line_range": [
            11,
            12
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 11,
          "line_range": [
            11,
            12
          ]
        },
        {
          "code": "# Define a model with validation\n",
          "display_code": "",
          "annotation": "Define a model with validation",
          "is_comment": true,
          "start_line": 13,
          "line_range": [
            13,
            13
          ],
          "target_line_range": [
            14,
            23
          ]
        },
        {
          "code": "class Profile(BaseModel):\n    username: str = Field(description=\"Username without spaces\")\n    age: int = Field(description=\"Age in years\", ge=13)\n\n    @field_validator(\"username\")\n    def validate_username(cls, v):\n        if \" \" in v:\n            raise ValueError(\"Username cannot contain spaces\")\n        return v\n\n",
          "display_code": "class Profile(BaseModel):\n    username: str = Field(description=\"Username without spaces\")\n    age: int = Field(description=\"Age in years\", ge=13)\n\n    @field_validator(\"username\")\n    def validate_username(cls, v):\n        if \" \" in v:\n            raise ValueError(\"Username cannot contain spaces\")\n        return v\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 14,
          "line_range": [
            14,
            23
          ]
        },
        {
          "code": "# Basic retry approach - specify max_retries\n",
          "display_code": "",
          "annotation": "Basic retry approach - specify max_retries",
          "is_comment": true,
          "start_line": 24,
          "line_range": [
            24,
            24
          ],
          "target_line_range": [
            25,
            38
          ]
        },
        {
          "code": "profile = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract: username: John Doe, age: 25\"\n        }\n    ],\n    response_model=Profile,\n    max_retries=3  # Try up to 3 more times if validation fails\n)\n\nprint(profile.model_dump_json(indent=2))\n\n",
          "display_code": "profile = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract: username: John Doe, age: 25\"\n        }\n    ],\n    response_model=Profile,\n    max_retries=3  # Try up to 3 more times if validation fails\n)\n\nprint(profile.model_dump_json(indent=2))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 25,
          "line_range": [
            25,
            38
          ]
        },
        {
          "code": "# For more advanced retry logic, you can use the Tenacity library:\n",
          "display_code": "",
          "annotation": "For more advanced retry logic, you can use the Tenacity library:",
          "is_comment": true,
          "start_line": 39,
          "line_range": [
            39,
            39
          ],
          "target_line_range": [
            40,
            44
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, field_validator\nfrom tenacity import Retrying, stop_after_attempt, wait_fixed\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, field_validator\nfrom tenacity import Retrying, stop_after_attempt, wait_fixed\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 40,
          "line_range": [
            40,
            44
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 45,
          "line_range": [
            45,
            45
          ],
          "target_line_range": [
            46,
            47
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 46,
          "line_range": [
            46,
            47
          ]
        },
        {
          "code": "# Define a model with validation\n",
          "display_code": "",
          "annotation": "Define a model with validation",
          "is_comment": true,
          "start_line": 48,
          "line_range": [
            48,
            48
          ],
          "target_line_range": [
            49,
            58
          ]
        },
        {
          "code": "class User(BaseModel):\n    name: str\n    age: int\n\n    @field_validator(\"name\")\n    def validate_name(cls, v):\n        if not v.isupper():\n            raise ValueError(\"Name must be uppercase\")\n        return v\n\n",
          "display_code": "class User(BaseModel):\n    name: str\n    age: int\n\n    @field_validator(\"name\")\n    def validate_name(cls, v):\n        if not v.isupper():\n            raise ValueError(\"Name must be uppercase\")\n        return v\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 49,
          "line_range": [
            49,
            58
          ]
        },
        {
          "code": "# Use tenacity for advanced retry configuration\n",
          "display_code": "",
          "annotation": "Use tenacity for advanced retry configuration",
          "is_comment": true,
          "start_line": 59,
          "line_range": [
            59,
            59
          ],
          "target_line_range": [
            60,
            76
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract: John is 30 years old\"\n        }\n    ],\n    response_model=User,\n    max_retries=Retrying(\n        stop=stop_after_attempt(3),  # Stop after 3 attempts\n        wait=wait_fixed(1),  # Wait 1 second between attempts\n    )\n)\n\nprint(user.model_dump_json(indent=2))\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract: John is 30 years old\"\n        }\n    ],\n    response_model=User,\n    max_retries=Retrying(\n        stop=stop_after_attempt(3),  # Stop after 3 attempts\n        wait=wait_fixed(1),  # Wait 1 second between attempts\n    )\n)\n\nprint(user.model_dump_json(indent=2))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 60,
          "line_range": [
            60,
            76
          ]
        },
        {
          "code": "# You can also catch retry exceptions to handle persistent failures:\n",
          "display_code": "",
          "annotation": "You can also catch retry exceptions to handle persistent failures:",
          "is_comment": true,
          "start_line": 77,
          "line_range": [
            77,
            77
          ],
          "target_line_range": [
            78,
            82
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, field_validator\nfrom instructor.exceptions import InstructorRetryException\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, field_validator\nfrom instructor.exceptions import InstructorRetryException\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 78,
          "line_range": [
            78,
            82
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 83,
          "line_range": [
            83,
            83
          ],
          "target_line_range": [
            84,
            85
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 84,
          "line_range": [
            84,
            85
          ]
        },
        {
          "code": "# Define a model with validation that will always fail\n",
          "display_code": "",
          "annotation": "Define a model with validation that will always fail",
          "is_comment": true,
          "start_line": 86,
          "line_range": [
            86,
            86
          ],
          "target_line_range": [
            87,
            94
          ]
        },
        {
          "code": "class ImpossibleModel(BaseModel):\n    name: str\n    age: int\n\n    @field_validator(\"age\")\n    def validate_age(cls, v):\n        raise ValueError(\"This validator will always fail\")\n\n",
          "display_code": "class ImpossibleModel(BaseModel):\n    name: str\n    age: int\n\n    @field_validator(\"age\")\n    def validate_age(cls, v):\n        raise ValueError(\"This validator will always fail\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 87,
          "line_range": [
            87,
            94
          ]
        },
        {
          "code": "# Handle retry exceptions\n",
          "display_code": "",
          "annotation": "Handle retry exceptions",
          "is_comment": true,
          "start_line": 95,
          "line_range": [
            95,
            95
          ],
          "target_line_range": [
            96,
            111
          ]
        },
        {
          "code": "try:\n    result = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": \"Extract: Jane is 25 years old\"\n            }\n        ],\n        response_model=ImpossibleModel,\n        max_retries=2\n    )\nexcept InstructorRetryException as e:\n    print(f\"Failed after {e.n_attempts} attempts\")\n    print(f\"Last error message: {e.messages[-1]['content']}\")\n\n",
          "display_code": "try:\n    result = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": \"Extract: Jane is 25 years old\"\n            }\n        ],\n        response_model=ImpossibleModel,\n        max_retries=2\n    )\nexcept InstructorRetryException as e:\n    print(f\"Failed after {e.n_attempts} attempts\")\n    print(f\"Last error message: {e.messages[-1]['content']}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 96,
          "line_range": [
            96,
            111
          ]
        },
        {
          "code": "    # Implement fallback strategy here\n",
          "display_code": "",
          "annotation": "Implement fallback strategy here",
          "is_comment": true,
          "start_line": 112,
          "line_range": [
            112,
            112
          ],
          "target_line_range": [
            113,
            115
          ]
        },
        {
          "code": "    fallback_result = {\"name\": \"Jane\", \"age\": 0}\n    print(f\"Using fallback: {fallback_result}\")\n\n",
          "display_code": "    fallback_result = {\"name\": \"Jane\", \"age\": 0}\n    print(f\"Using fallback: {fallback_result}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 113,
          "line_range": [
            113,
            115
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python retry-mechanisms.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "007-validation",
      "section_title": "Validation"
    },
    {
      "id": "036-fallback-strategies",
      "title": "Fallback Strategies",
      "description": "",
      "order": 36,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# - Default values for missing information\n",
          "display_code": "",
          "annotation": "- Default values for missing information",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# When working with LLMs, it's important to have fallback strategies for handling persistent failures or unexpected issues. Instructor provides several ways to implement robust fallback mechanisms.\n",
          "display_code": "",
          "annotation": "When working with LLMs, it's important to have fallback strategies for handling persistent failures or unexpected issues. Instructor provides several ways to implement robust fallback mechanisms.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, ValidationError\nfrom instructor.exceptions import InstructorRetryException\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, ValidationError\nfrom instructor.exceptions import InstructorRetryException\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define primary model with strict validation\n",
          "display_code": "",
          "annotation": "Define primary model with strict validation",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            21
          ]
        },
        {
          "code": "class DetailedUserProfile(BaseModel):\n    name: str = Field(description=\"User's full name\")\n    age: int = Field(description=\"User's age in years\", ge=18)\n    occupation: str = Field(description=\"User's job or profession\")\n    income: int = Field(description=\"User's annual income in USD\", ge=0)\n    education: str = Field(description=\"User's highest education level\")\n\n",
          "display_code": "class DetailedUserProfile(BaseModel):\n    name: str = Field(description=\"User's full name\")\n    age: int = Field(description=\"User's age in years\", ge=18)\n    occupation: str = Field(description=\"User's job or profession\")\n    income: int = Field(description=\"User's annual income in USD\", ge=0)\n    education: str = Field(description=\"User's highest education level\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            21
          ]
        },
        {
          "code": "# Define simpler fallback model\n",
          "display_code": "",
          "annotation": "Define simpler fallback model",
          "is_comment": true,
          "start_line": 22,
          "line_range": [
            22,
            22
          ],
          "target_line_range": [
            23,
            26
          ]
        },
        {
          "code": "class BasicUserProfile(BaseModel):\n    name: str = Field(description=\"User's name\")\n    age: int = Field(description=\"User's age\", ge=0)\n\n",
          "display_code": "class BasicUserProfile(BaseModel):\n    name: str = Field(description=\"User's name\")\n    age: int = Field(description=\"User's age\", ge=0)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 23,
          "line_range": [
            23,
            26
          ]
        },
        {
          "code": "# Try extraction with fallback strategy\n",
          "display_code": "",
          "annotation": "Try extraction with fallback strategy",
          "is_comment": true,
          "start_line": 27,
          "line_range": [
            27,
            27
          ],
          "target_line_range": [
            28,
            29
          ]
        },
        {
          "code": "def extract_user_with_fallback(text: str):\n    try:\n",
          "display_code": "def extract_user_with_fallback(text: str):\n    try:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 28,
          "line_range": [
            28,
            29
          ]
        },
        {
          "code": "        # First attempt with detailed model\n",
          "display_code": "",
          "annotation": "First attempt with detailed model",
          "is_comment": true,
          "start_line": 30,
          "line_range": [
            30,
            30
          ],
          "target_line_range": [
            31,
            43
          ]
        },
        {
          "code": "        return client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Extract user information: {text}\"\n                }\n            ],\n            response_model=DetailedUserProfile,\n            max_retries=2\n        )\n    except InstructorRetryException:\n        print(\"Detailed extraction failed, falling back to basic profile\")\n",
          "display_code": "        return client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Extract user information: {text}\"\n                }\n            ],\n            response_model=DetailedUserProfile,\n            max_retries=2\n        )\n    except InstructorRetryException:\n        print(\"Detailed extraction failed, falling back to basic profile\")\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 31,
          "line_range": [
            31,
            43
          ]
        },
        {
          "code": "        # Fall back to simpler model\n",
          "display_code": "",
          "annotation": "Fall back to simpler model",
          "is_comment": true,
          "start_line": 44,
          "line_range": [
            44,
            44
          ],
          "target_line_range": [
            45,
            56
          ]
        },
        {
          "code": "        return client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Extract basic user information: {text}\"\n                }\n            ],\n            response_model=BasicUserProfile,\n            max_retries=1\n        )\n\n",
          "display_code": "        return client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Extract basic user information: {text}\"\n                }\n            ],\n            response_model=BasicUserProfile,\n            max_retries=1\n        )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 45,
          "line_range": [
            45,
            56
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 57,
          "line_range": [
            57,
            57
          ],
          "target_line_range": [
            58,
            61
          ]
        },
        {
          "code": "text = \"John is 25 years old\"\nuser = extract_user_with_fallback(text)\nprint(user.model_dump_json(indent=2))\n\n",
          "display_code": "text = \"John is 25 years old\"\nuser = extract_user_with_fallback(text)\nprint(user.model_dump_json(indent=2))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 58,
          "line_range": [
            58,
            61
          ]
        },
        {
          "code": "# Another approach is to use optional fields for less reliable information:\n",
          "display_code": "",
          "annotation": "Another approach is to use optional fields for less reliable information:",
          "is_comment": true,
          "start_line": 62,
          "line_range": [
            62,
            62
          ],
          "target_line_range": [
            63,
            67
          ]
        },
        {
          "code": "from typing import Optional\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\n\n",
          "display_code": "from typing import Optional\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 63,
          "line_range": [
            63,
            67
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 68,
          "line_range": [
            68,
            68
          ],
          "target_line_range": [
            69,
            70
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 69,
          "line_range": [
            69,
            70
          ]
        },
        {
          "code": "# Define model with optional fields\n",
          "display_code": "",
          "annotation": "Define model with optional fields",
          "is_comment": true,
          "start_line": 71,
          "line_range": [
            71,
            71
          ],
          "target_line_range": [
            72,
            77
          ]
        },
        {
          "code": "class FlexibleProfile(BaseModel):\n    name: str = Field(description=\"Person's name\")\n    age: Optional[int] = Field(None, description=\"Person's age if mentioned\")\n    location: Optional[str] = Field(None, description=\"Person's location if mentioned\")\n    occupation: Optional[str] = Field(None, description=\"Person's job if mentioned\")\n\n",
          "display_code": "class FlexibleProfile(BaseModel):\n    name: str = Field(description=\"Person's name\")\n    age: Optional[int] = Field(None, description=\"Person's age if mentioned\")\n    location: Optional[str] = Field(None, description=\"Person's location if mentioned\")\n    occupation: Optional[str] = Field(None, description=\"Person's job if mentioned\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 72,
          "line_range": [
            72,
            77
          ]
        },
        {
          "code": "# Extract what's available without failing\n",
          "display_code": "",
          "annotation": "Extract what's available without failing",
          "is_comment": true,
          "start_line": 78,
          "line_range": [
            78,
            78
          ],
          "target_line_range": [
            79,
            91
          ]
        },
        {
          "code": "profile = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Sarah is a software engineer from Boston\"\n        }\n    ],\n    response_model=FlexibleProfile\n)\n\nprint(profile.model_dump_json(indent=2))\n\n",
          "display_code": "profile = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Sarah is a software engineer from Boston\"\n        }\n    ],\n    response_model=FlexibleProfile\n)\n\nprint(profile.model_dump_json(indent=2))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 79,
          "line_range": [
            79,
            91
          ]
        },
        {
          "code": "# For critical applications, you can implement a more comprehensive fallback strategy:\n",
          "display_code": "",
          "annotation": "For critical applications, you can implement a more comprehensive fallback strategy:",
          "is_comment": true,
          "start_line": 92,
          "line_range": [
            92,
            92
          ],
          "target_line_range": [
            93,
            97
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, ValidationError\nfrom enum import Enum\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, ValidationError\nfrom enum import Enum\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 93,
          "line_range": [
            93,
            97
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 98,
          "line_range": [
            98,
            98
          ],
          "target_line_range": [
            99,
            100
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 99,
          "line_range": [
            99,
            100
          ]
        },
        {
          "code": "# Define extraction result status\n",
          "display_code": "",
          "annotation": "Define extraction result status",
          "is_comment": true,
          "start_line": 101,
          "line_range": [
            101,
            101
          ],
          "target_line_range": [
            102,
            106
          ]
        },
        {
          "code": "class ExtractionStatus(str, Enum):\n    SUCCESS = \"success\"\n    PARTIAL = \"partial\"\n    FAILED = \"failed\"\n\n",
          "display_code": "class ExtractionStatus(str, Enum):\n    SUCCESS = \"success\"\n    PARTIAL = \"partial\"\n    FAILED = \"failed\"\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 102,
          "line_range": [
            102,
            106
          ]
        },
        {
          "code": "# Define target model\n",
          "display_code": "",
          "annotation": "Define target model",
          "is_comment": true,
          "start_line": 107,
          "line_range": [
            107,
            107
          ],
          "target_line_range": [
            108,
            112
          ]
        },
        {
          "code": "class Contact(BaseModel):\n    name: str\n    email: str\n    phone: str\n\n",
          "display_code": "class Contact(BaseModel):\n    name: str\n    email: str\n    phone: str\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 108,
          "line_range": [
            108,
            112
          ]
        },
        {
          "code": "# Define wrapper for extraction result\n",
          "display_code": "",
          "annotation": "Define wrapper for extraction result",
          "is_comment": true,
          "start_line": 113,
          "line_range": [
            113,
            113
          ],
          "target_line_range": [
            114,
            118
          ]
        },
        {
          "code": "class ExtractionResult(BaseModel):\n    status: ExtractionStatus\n    data: dict\n    error_message: str = \"\"\n\n",
          "display_code": "class ExtractionResult(BaseModel):\n    status: ExtractionStatus\n    data: dict\n    error_message: str = \"\"\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 114,
          "line_range": [
            114,
            118
          ]
        },
        {
          "code": "# Robust extraction function with fallbacks\n",
          "display_code": "",
          "annotation": "Robust extraction function with fallbacks",
          "is_comment": true,
          "start_line": 119,
          "line_range": [
            119,
            119
          ],
          "target_line_range": [
            120,
            121
          ]
        },
        {
          "code": "def extract_with_robustness(text: str) -> ExtractionResult:\n    try:\n",
          "display_code": "def extract_with_robustness(text: str) -> ExtractionResult:\n    try:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 120,
          "line_range": [
            120,
            121
          ]
        },
        {
          "code": "        # Primary extraction attempt\n",
          "display_code": "",
          "annotation": "Primary extraction attempt",
          "is_comment": true,
          "start_line": 122,
          "line_range": [
            122,
            122
          ],
          "target_line_range": [
            123,
            133
          ]
        },
        {
          "code": "        result = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[{\"role\": \"user\", \"content\": f\"Extract contact info: {text}\"}],\n            response_model=Contact,\n            max_retries=2\n        )\n        return ExtractionResult(\n            status=ExtractionStatus.SUCCESS,\n            data=result.model_dump()\n        )\n    except InstructorRetryException as e:\n",
          "display_code": "        result = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[{\"role\": \"user\", \"content\": f\"Extract contact info: {text}\"}],\n            response_model=Contact,\n            max_retries=2\n        )\n        return ExtractionResult(\n            status=ExtractionStatus.SUCCESS,\n            data=result.model_dump()\n        )\n    except InstructorRetryException as e:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 123,
          "line_range": [
            123,
            133
          ]
        },
        {
          "code": "        # Attempt partial extraction\n",
          "display_code": "",
          "annotation": "Attempt partial extraction",
          "is_comment": true,
          "start_line": 134,
          "line_range": [
            134,
            134
          ],
          "target_line_range": [
            135,
            136
          ]
        },
        {
          "code": "        try:\n            partial_data = {}\n",
          "display_code": "        try:\n            partial_data = {}\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 135,
          "line_range": [
            135,
            136
          ]
        },
        {
          "code": "            # Parse the error message\n",
          "display_code": "",
          "annotation": "Parse the error message",
          "is_comment": true,
          "start_line": 137,
          "line_range": [
            137,
            137
          ],
          "target_line_range": [
            138,
            139
          ]
        },
        {
          "code": "            error_msg = e.messages[-1][\"content\"]\n\n",
          "display_code": "            error_msg = e.messages[-1][\"content\"]\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 138,
          "line_range": [
            138,
            139
          ]
        },
        {
          "code": "            # Try to salvage whatever fields we can\n",
          "display_code": "",
          "annotation": "Try to salvage whatever fields we can",
          "is_comment": true,
          "start_line": 140,
          "line_range": [
            140,
            140
          ],
          "target_line_range": [
            141,
            168
          ]
        },
        {
          "code": "            text_lines = text.split('\\n')\n            for line in text_lines:\n                if \"name:\" in line.lower():\n                    partial_data[\"name\"] = line.split(\"name:\")[1].strip()\n                if \"email:\" in line.lower():\n                    partial_data[\"email\"] = line.split(\"email:\")[1].strip()\n                if \"phone:\" in line.lower():\n                    partial_data[\"phone\"] = line.split(\"phone:\")[1].strip()\n\n            if partial_data:\n                return ExtractionResult(\n                    status=ExtractionStatus.PARTIAL,\n                    data=partial_data,\n                    error_message=error_msg\n                )\n            else:\n                return ExtractionResult(\n                    status=ExtractionStatus.FAILED,\n                    data={},\n                    error_message=error_msg\n                )\n        except Exception as nested_error:\n            return ExtractionResult(\n                status=ExtractionStatus.FAILED,\n                data={},\n                error_message=f\"Complete extraction failure: {str(nested_error)}\"\n            )\n\n",
          "display_code": "            text_lines = text.split('\\n')\n            for line in text_lines:\n                if \"name:\" in line.lower():\n                    partial_data[\"name\"] = line.split(\"name:\")[1].strip()\n                if \"email:\" in line.lower():\n                    partial_data[\"email\"] = line.split(\"email:\")[1].strip()\n                if \"phone:\" in line.lower():\n                    partial_data[\"phone\"] = line.split(\"phone:\")[1].strip()\n\n            if partial_data:\n                return ExtractionResult(\n                    status=ExtractionStatus.PARTIAL,\n                    data=partial_data,\n                    error_message=error_msg\n                )\n            else:\n                return ExtractionResult(\n                    status=ExtractionStatus.FAILED,\n                    data={},\n                    error_message=error_msg\n                )\n        except Exception as nested_error:\n            return ExtractionResult(\n                status=ExtractionStatus.FAILED,\n                data={},\n                error_message=f\"Complete extraction failure: {str(nested_error)}\"\n            )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 141,
          "line_range": [
            141,
            168
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python fallback-strategies.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "007-validation",
      "section_title": "Validation"
    },
    {
      "id": "037-field-level-validation",
      "title": "Field-level Validation",
      "description": "",
      "order": 37,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# - Domain-specific rules for business logic\n",
          "display_code": "",
          "annotation": "- Domain-specific rules for business logic",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor supports detailed field-level validation to ensure that specific parts of the LLM output meet your requirements. This allows for fine-grained control over the extracted data.\n",
          "display_code": "",
          "annotation": "Instructor supports detailed field-level validation to ensure that specific parts of the LLM output meet your requirements. This allows for fine-grained control over the extracted data.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, field_validator\nimport re\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field, field_validator\nimport re\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define a model with field-level validation\n",
          "display_code": "",
          "annotation": "Define a model with field-level validation",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            42
          ]
        },
        {
          "code": "class UserProfile(BaseModel):\n    username: str = Field(\n        description=\"Username (lowercase, no spaces)\",\n        min_length=3,\n        max_length=20\n    )\n    email: str = Field(\n        description=\"Valid email address\"\n    )\n    age: int = Field(\n        description=\"Age in years\",\n        ge=13,  # Greater than or equal to 13\n        le=120  # Less than or equal to 120\n    )\n\n    @field_validator(\"username\")\n    def validate_username(cls, v):\n        if not v.islower() or \" \" in v:\n            raise ValueError(\"Username must be lowercase and contain no spaces\")\n        return v\n\n    @field_validator(\"email\")\n    def validate_email(cls, v):\n        pattern = r\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\"\n        if not re.match(pattern, v):\n            raise ValueError(\"Invalid email format\")\n        return v\n\n",
          "display_code": "class UserProfile(BaseModel):\n    username: str = Field(\n        description=\"Username (lowercase, no spaces)\",\n        min_length=3,\n        max_length=20\n    )\n    email: str = Field(\n        description=\"Valid email address\"\n    )\n    age: int = Field(\n        description=\"Age in years\",\n        ge=13,  # Greater than or equal to 13\n        le=120  # Less than or equal to 120\n    )\n\n    @field_validator(\"username\")\n    def validate_username(cls, v):\n        if not v.islower() or \" \" in v:\n            raise ValueError(\"Username must be lowercase and contain no spaces\")\n        return v\n\n    @field_validator(\"email\")\n    def validate_email(cls, v):\n        pattern = r\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\"\n        if not re.match(pattern, v):\n            raise ValueError(\"Invalid email format\")\n        return v\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            42
          ]
        },
        {
          "code": "# Extract user profile with validation\n",
          "display_code": "",
          "annotation": "Extract user profile with validation",
          "is_comment": true,
          "start_line": 43,
          "line_range": [
            43,
            43
          ],
          "target_line_range": [
            44,
            57
          ]
        },
        {
          "code": "profile = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract user profile: John Doe, john.doe@example.com, 25 years old\"\n        }\n    ],\n    response_model=UserProfile,\n    max_retries=2\n)\n\nprint(profile.model_dump_json(indent=2))\n\n",
          "display_code": "profile = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract user profile: John Doe, john.doe@example.com, 25 years old\"\n        }\n    ],\n    response_model=UserProfile,\n    max_retries=2\n)\n\nprint(profile.model_dump_json(indent=2))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 44,
          "line_range": [
            44,
            57
          ]
        },
        {
          "code": "# You can also use Pydantic's Field parameters for basic constraints:\n",
          "display_code": "",
          "annotation": "You can also use Pydantic's Field parameters for basic constraints:",
          "is_comment": true,
          "start_line": 58,
          "line_range": [
            58,
            58
          ],
          "target_line_range": [
            59,
            63
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 59,
          "line_range": [
            59,
            63
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 64,
          "line_range": [
            64,
            64
          ],
          "target_line_range": [
            65,
            66
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 65,
          "line_range": [
            65,
            66
          ]
        },
        {
          "code": "# Define a model with Field constraints\n",
          "display_code": "",
          "annotation": "Define a model with Field constraints",
          "is_comment": true,
          "start_line": 67,
          "line_range": [
            67,
            67
          ],
          "target_line_range": [
            68,
            88
          ]
        },
        {
          "code": "class Product(BaseModel):\n    name: str = Field(\n        description=\"Product name\",\n        min_length=2,\n        max_length=100\n    )\n    price: float = Field(\n        description=\"Product price in USD\",\n        gt=0  # Greater than 0\n    )\n    description: str = Field(\n        description=\"Product description\",\n        min_length=10,\n        max_length=1000\n    )\n    tags: List[str] = Field(\n        description=\"Product tags\",\n        min_length=1,  # At least one tag\n        max_length=10  # At most 10 tags\n    )\n\n",
          "display_code": "class Product(BaseModel):\n    name: str = Field(\n        description=\"Product name\",\n        min_length=2,\n        max_length=100\n    )\n    price: float = Field(\n        description=\"Product price in USD\",\n        gt=0  # Greater than 0\n    )\n    description: str = Field(\n        description=\"Product description\",\n        min_length=10,\n        max_length=1000\n    )\n    tags: List[str] = Field(\n        description=\"Product tags\",\n        min_length=1,  # At least one tag\n        max_length=10  # At most 10 tags\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 68,
          "line_range": [
            68,
            88
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 89,
          "line_range": [
            89,
            89
          ],
          "target_line_range": [
            90,
            102
          ]
        },
        {
          "code": "product = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract product info: iPhone, $999, Latest smartphone with advanced features, tags: electronics, smartphone, apple\"\n        }\n    ],\n    response_model=Product\n)\n\nprint(product.model_dump_json(indent=2))\n\n",
          "display_code": "product = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"Extract product info: iPhone, $999, Latest smartphone with advanced features, tags: electronics, smartphone, apple\"\n        }\n    ],\n    response_model=Product\n)\n\nprint(product.model_dump_json(indent=2))\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 90,
          "line_range": [
            90,
            102
          ]
        },
        {
          "code": "# For more complex validation, you can use annotated types:\n",
          "display_code": "",
          "annotation": "For more complex validation, you can use annotated types:",
          "is_comment": true,
          "start_line": 103,
          "line_range": [
            103,
            103
          ],
          "target_line_range": [
            104,
            109
          ]
        },
        {
          "code": "from typing_extensions import Annotated\nfrom pydantic import AfterValidator\nimport re\n\ndef validate_phone_number(v: str) -> str:\n    \"\"\"Validate phone number format.\"\"\"\n",
          "display_code": "from typing_extensions import Annotated\nfrom pydantic import AfterValidator\nimport re\n\ndef validate_phone_number(v: str) -> str:\n    \"\"\"Validate phone number format.\"\"\"\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 104,
          "line_range": [
            104,
            109
          ]
        },
        {
          "code": "    # Remove all non-numeric characters\n",
          "display_code": "",
          "annotation": "Remove all non-numeric characters",
          "is_comment": true,
          "start_line": 110,
          "line_range": [
            110,
            110
          ],
          "target_line_range": [
            111,
            129
          ]
        },
        {
          "code": "    digits = ''.join(c for c in v if c.isdigit())\n    if len(digits) < 10:\n        raise ValueError(\"Phone number must have at least 10 digits\")\n    return v\n\ndef validate_zip_code(v: str) -> str:\n    \"\"\"Validate US zip code format.\"\"\"\n    pattern = r\"^\\d{5}(-\\d{4})?$\"\n    if not re.match(pattern, v):\n        raise ValueError(\"Invalid zip code format (must be 12345 or 12345-6789)\")\n    return v\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    state: str\n    zip_code: Annotated[str, AfterValidator(validate_zip_code)]\n    phone: Annotated[str, AfterValidator(validate_phone_number)]\n\n",
          "display_code": "    digits = ''.join(c for c in v if c.isdigit())\n    if len(digits) < 10:\n        raise ValueError(\"Phone number must have at least 10 digits\")\n    return v\n\ndef validate_zip_code(v: str) -> str:\n    \"\"\"Validate US zip code format.\"\"\"\n    pattern = r\"^\\d{5}(-\\d{4})?$\"\n    if not re.match(pattern, v):\n        raise ValueError(\"Invalid zip code format (must be 12345 or 12345-6789)\")\n    return v\n\nclass Address(BaseModel):\n    street: str\n    city: str\n    state: str\n    zip_code: Annotated[str, AfterValidator(validate_zip_code)]\n    phone: Annotated[str, AfterValidator(validate_phone_number)]\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 111,
          "line_range": [
            111,
            129
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python field-level-validation.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "007-validation",
      "section_title": "Validation"
    },
    {
      "id": "038-vision-inputs",
      "title": "Vision",
      "description": "",
      "order": 38,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# - Providing automatic detection of image paths and URLs\n",
          "display_code": "",
          "annotation": "- Providing automatic detection of image paths and URLs",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor provides simple, unified handling of vision inputs across different LLM providers through its `Image` class, which automatically handles the details of image formatting for each provider.\n",
          "display_code": "",
          "annotation": "Instructor provides simple, unified handling of vision inputs across different LLM providers through its `Image` class, which automatically handles the details of image formatting for each provider.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define a model for image analysis\n",
          "display_code": "",
          "annotation": "Define a model for image analysis",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            19
          ]
        },
        {
          "code": "class ImageContent(BaseModel):\n    description: str = Field(description=\"A detailed description of the image\")\n    objects: List[str] = Field(description=\"List of main objects in the image\")\n    colors: List[str] = Field(description=\"Dominant colors in the image\")\n\n",
          "display_code": "class ImageContent(BaseModel):\n    description: str = Field(description=\"A detailed description of the image\")\n    objects: List[str] = Field(description=\"List of main objects in the image\")\n    colors: List[str] = Field(description=\"Dominant colors in the image\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            19
          ]
        },
        {
          "code": "# Creating an Image object from a file path\n",
          "display_code": "",
          "annotation": "Creating an Image object from a file path",
          "is_comment": true,
          "start_line": 20,
          "line_range": [
            20,
            20
          ],
          "target_line_range": [
            21,
            21
          ]
        },
        {
          "code": "def analyze_image_from_file(file_path: str) -> ImageContent:\n",
          "display_code": "def analyze_image_from_file(file_path: str) -> ImageContent:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 21,
          "line_range": [
            21,
            21
          ]
        },
        {
          "code": "    # Load the image using Instructor's Image class\n",
          "display_code": "",
          "annotation": "Load the image using Instructor's Image class",
          "is_comment": true,
          "start_line": 22,
          "line_range": [
            22,
            22
          ],
          "target_line_range": [
            23,
            38
          ]
        },
        {
          "code": "    image = instructor.Image.from_path(file_path)\n\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=ImageContent,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Describe this image in detail:\",\n                    image  # The Image object is handled automatically\n                ]\n            }\n        ]\n    )\n\n",
          "display_code": "    image = instructor.Image.from_path(file_path)\n\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=ImageContent,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Describe this image in detail:\",\n                    image  # The Image object is handled automatically\n                ]\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 23,
          "line_range": [
            23,
            38
          ]
        },
        {
          "code": "# Creating an Image object from a URL\n",
          "display_code": "",
          "annotation": "Creating an Image object from a URL",
          "is_comment": true,
          "start_line": 39,
          "line_range": [
            39,
            39
          ],
          "target_line_range": [
            40,
            40
          ]
        },
        {
          "code": "def analyze_image_from_url(image_url: str) -> ImageContent:\n",
          "display_code": "def analyze_image_from_url(image_url: str) -> ImageContent:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 40,
          "line_range": [
            40,
            40
          ]
        },
        {
          "code": "    # Load the image from a URL\n",
          "display_code": "",
          "annotation": "Load the image from a URL",
          "is_comment": true,
          "start_line": 41,
          "line_range": [
            41,
            41
          ],
          "target_line_range": [
            42,
            57
          ]
        },
        {
          "code": "    image = instructor.Image.from_url(image_url)\n\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=ImageContent,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Describe this image in detail:\",\n                    image\n                ]\n            }\n        ]\n    )\n\n",
          "display_code": "    image = instructor.Image.from_url(image_url)\n\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=ImageContent,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Describe this image in detail:\",\n                    image\n                ]\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 42,
          "line_range": [
            42,
            57
          ]
        },
        {
          "code": "# Using autodetect_images for convenience\n",
          "display_code": "",
          "annotation": "Using autodetect_images for convenience",
          "is_comment": true,
          "start_line": 58,
          "line_range": [
            58,
            58
          ],
          "target_line_range": [
            59,
            74
          ]
        },
        {
          "code": "def analyze_with_autodetect(image_path_or_url: str) -> ImageContent:\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=ImageContent,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Describe this image in detail:\",\n                    image_path_or_url  # Will be automatically detected as an image\n                ]\n            }\n        ],\n        autodetect_images=True  # Automatically converts paths/URLs to Image objects\n    )\n\n",
          "display_code": "def analyze_with_autodetect(image_path_or_url: str) -> ImageContent:\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=ImageContent,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Describe this image in detail:\",\n                    image_path_or_url  # Will be automatically detected as an image\n                ]\n            }\n        ],\n        autodetect_images=True  # Automatically converts paths/URLs to Image objects\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 59,
          "line_range": [
            59,
            74
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 75,
          "line_range": [
            75,
            75
          ],
          "target_line_range": [
            76,
            80
          ]
        },
        {
          "code": "result = analyze_with_autodetect(\"https://example.com/image.jpg\")\nprint(f\"Description: {result.description}\")\nprint(f\"Objects: {', '.join(result.objects)}\")\nprint(f\"Colors: {', '.join(result.colors)}\")\n\n",
          "display_code": "result = analyze_with_autodetect(\"https://example.com/image.jpg\")\nprint(f\"Description: {result.description}\")\nprint(f\"Objects: {', '.join(result.objects)}\")\nprint(f\"Colors: {', '.join(result.colors)}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 76,
          "line_range": [
            76,
            80
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python vision-inputs.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "008-multimodal",
      "section_title": "Multimodal Inputs"
    },
    {
      "id": "039-image-to-structured-data",
      "title": "Image Extraction",
      "description": "",
      "order": 39,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# - Integration with downstream processing pipelines\n",
          "display_code": "",
          "annotation": "- Integration with downstream processing pipelines",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor excels at transforming images into structured data, combining vision capabilities with Pydantic models for reliable extraction.\n",
          "display_code": "",
          "annotation": "Instructor excels at transforming images into structured data, combining vision capabilities with Pydantic models for reliable extraction.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List, Optional\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define a structured data model for product information\n",
          "display_code": "",
          "annotation": "Define a structured data model for product information",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            21
          ]
        },
        {
          "code": "class Product(BaseModel):\n    name: str = Field(description=\"Product name\")\n    price: float = Field(description=\"Product price in USD\")\n    description: str = Field(description=\"Brief product description\")\n    features: List[str] = Field(description=\"Key product features\")\n    brand: Optional[str] = Field(None, description=\"Brand name if visible\")\n\n",
          "display_code": "class Product(BaseModel):\n    name: str = Field(description=\"Product name\")\n    price: float = Field(description=\"Product price in USD\")\n    description: str = Field(description=\"Brief product description\")\n    features: List[str] = Field(description=\"Key product features\")\n    brand: Optional[str] = Field(None, description=\"Brand name if visible\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            21
          ]
        },
        {
          "code": "# Extract product information from an image\n",
          "display_code": "",
          "annotation": "Extract product information from an image",
          "is_comment": true,
          "start_line": 22,
          "line_range": [
            22,
            22
          ],
          "target_line_range": [
            23,
            38
          ]
        },
        {
          "code": "def extract_product_info(image_path_or_url: str) -> Product:\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=Product,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Extract detailed product information from this image:\",\n                    image_path_or_url\n                ]\n            }\n        ],\n        autodetect_images=True  # Automatically handle the image\n    )\n\n",
          "display_code": "def extract_product_info(image_path_or_url: str) -> Product:\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=Product,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Extract detailed product information from this image:\",\n                    image_path_or_url\n                ]\n            }\n        ],\n        autodetect_images=True  # Automatically handle the image\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 23,
          "line_range": [
            23,
            38
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 39,
          "line_range": [
            39,
            39
          ],
          "target_line_range": [
            40,
            46
          ]
        },
        {
          "code": "product = extract_product_info(\"path/to/product_image.jpg\")\nprint(f\"Product: {product.name} (${product.price:.2f})\")\nprint(f\"Description: {product.description}\")\nprint(f\"Features: {', '.join(product.features)}\")\nif product.brand:\n    print(f\"Brand: {product.brand}\")\n\n",
          "display_code": "product = extract_product_info(\"path/to/product_image.jpg\")\nprint(f\"Product: {product.name} (${product.price:.2f})\")\nprint(f\"Description: {product.description}\")\nprint(f\"Features: {', '.join(product.features)}\")\nif product.brand:\n    print(f\"Brand: {product.brand}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 40,
          "line_range": [
            40,
            46
          ]
        },
        {
          "code": "# You can extract more complex data structures from images:\n",
          "display_code": "",
          "annotation": "You can extract more complex data structures from images:",
          "is_comment": true,
          "start_line": 47,
          "line_range": [
            47,
            47
          ],
          "target_line_range": [
            48,
            52
          ]
        },
        {
          "code": "from typing import List, Optional\nfrom pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\n\n",
          "display_code": "from typing import List, Optional\nfrom pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 48,
          "line_range": [
            48,
            52
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 53,
          "line_range": [
            53,
            53
          ],
          "target_line_range": [
            54,
            55
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 54,
          "line_range": [
            54,
            55
          ]
        },
        {
          "code": "# Define a recipe structure\n",
          "display_code": "",
          "annotation": "Define a recipe structure",
          "is_comment": true,
          "start_line": 56,
          "line_range": [
            56,
            56
          ],
          "target_line_range": [
            57,
            74
          ]
        },
        {
          "code": "class Ingredient(BaseModel):\n    name: str = Field(description=\"Ingredient name\")\n    quantity: str = Field(description=\"Amount needed, including units\")\n    optional: bool = Field(description=\"Whether this ingredient is optional\")\n\nclass Step(BaseModel):\n    instruction: str = Field(description=\"Cooking instruction\")\n    time_minutes: Optional[int] = Field(None, description=\"Time required for this step in minutes\")\n\nclass Recipe(BaseModel):\n    title: str = Field(description=\"Recipe title\")\n    servings: int = Field(description=\"Number of servings\")\n    prep_time_minutes: int = Field(description=\"Preparation time in minutes\")\n    cook_time_minutes: int = Field(description=\"Cooking time in minutes\")\n    ingredients: List[Ingredient] = Field(description=\"List of ingredients\")\n    steps: List[Step] = Field(description=\"Cooking steps in order\")\n    difficulty: str = Field(description=\"Recipe difficulty (easy, medium, hard)\")\n\n",
          "display_code": "class Ingredient(BaseModel):\n    name: str = Field(description=\"Ingredient name\")\n    quantity: str = Field(description=\"Amount needed, including units\")\n    optional: bool = Field(description=\"Whether this ingredient is optional\")\n\nclass Step(BaseModel):\n    instruction: str = Field(description=\"Cooking instruction\")\n    time_minutes: Optional[int] = Field(None, description=\"Time required for this step in minutes\")\n\nclass Recipe(BaseModel):\n    title: str = Field(description=\"Recipe title\")\n    servings: int = Field(description=\"Number of servings\")\n    prep_time_minutes: int = Field(description=\"Preparation time in minutes\")\n    cook_time_minutes: int = Field(description=\"Cooking time in minutes\")\n    ingredients: List[Ingredient] = Field(description=\"List of ingredients\")\n    steps: List[Step] = Field(description=\"Cooking steps in order\")\n    difficulty: str = Field(description=\"Recipe difficulty (easy, medium, hard)\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 57,
          "line_range": [
            57,
            74
          ]
        },
        {
          "code": "# Extract recipe from an image\n",
          "display_code": "",
          "annotation": "Extract recipe from an image",
          "is_comment": true,
          "start_line": 75,
          "line_range": [
            75,
            75
          ],
          "target_line_range": [
            76,
            76
          ]
        },
        {
          "code": "def extract_recipe(image_path: str) -> Recipe:\n",
          "display_code": "def extract_recipe(image_path: str) -> Recipe:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 76,
          "line_range": [
            76,
            76
          ]
        },
        {
          "code": "    # Create an Image object\n",
          "display_code": "",
          "annotation": "Create an Image object",
          "is_comment": true,
          "start_line": 77,
          "line_range": [
            77,
            77
          ],
          "target_line_range": [
            78,
            97
          ]
        },
        {
          "code": "    image = instructor.Image.from_path(image_path)\n\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=Recipe,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract complete recipe information from the provided image.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Please extract the detailed recipe information from this image:\",\n                    image\n                ]\n            }\n        ]\n    )\n\n",
          "display_code": "    image = instructor.Image.from_path(image_path)\n\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=Recipe,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract complete recipe information from the provided image.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Please extract the detailed recipe information from this image:\",\n                    image\n                ]\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 78,
          "line_range": [
            78,
            97
          ]
        },
        {
          "code": "# The function would be used like this:\n# recipe = extract_recipe(\"path/to/recipe_card.jpg\")\n",
          "display_code": "",
          "annotation": "The function would be used like this:\nrecipe = extract_recipe(\"path/to/recipe_card.jpg\")",
          "is_comment": true,
          "start_line": 98,
          "line_range": [
            98,
            99
          ],
          "target_line_range": [
            100,
            100
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 100,
          "line_range": [
            100,
            100
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python image-to-structured-data.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "008-multimodal",
      "section_title": "Multimodal Inputs"
    },
    {
      "id": "040-table-extraction",
      "title": "Table Extraction",
      "description": "",
      "order": 40,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# Add descriptive metadata like captions to tables\n",
          "display_code": "",
          "annotation": "Add descriptive metadata like captions to tables",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor makes it easy to extract structured tables from images and convert them to pandas dataframes for analysis.\n",
          "display_code": "",
          "annotation": "Instructor makes it easy to extract structured tables from images and convert them to pandas dataframes for analysis.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            19
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nimport pandas as pd\nfrom typing import Annotated, Any\nfrom io import StringIO\nfrom pydantic import (\n    BaseModel,\n    BeforeValidator,\n    PlainSerializer,\n    InstanceOf,\n    WithJsonSchema,\n)\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nimport pandas as pd\nfrom typing import Annotated, Any\nfrom io import StringIO\nfrom pydantic import (\n    BaseModel,\n    BeforeValidator,\n    PlainSerializer,\n    InstanceOf,\n    WithJsonSchema,\n)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            19
          ]
        },
        {
          "code": "# Initialize the client with instructor (MD_JSON mode works well for tables)\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor (MD_JSON mode works well for tables)",
          "is_comment": true,
          "start_line": 20,
          "line_range": [
            20,
            20
          ],
          "target_line_range": [
            21,
            23
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI(), mode=instructor.Mode.MD_JSON)\n\n\n",
          "display_code": "client = instructor.from_openai(OpenAI(), mode=instructor.Mode.MD_JSON)\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 21,
          "line_range": [
            21,
            23
          ]
        },
        {
          "code": "# Define functions to convert between dataframe and markdown\n",
          "display_code": "",
          "annotation": "Define functions to convert between dataframe and markdown",
          "is_comment": true,
          "start_line": 24,
          "line_range": [
            24,
            24
          ],
          "target_line_range": [
            25,
            45
          ]
        },
        {
          "code": "def to_markdown(df: pd.DataFrame) -> str:\n    \"\"\"Convert a dataframe to markdown format.\"\"\"\n    return df.to_markdown()\n\n\ndef md_to_df(data: Any) -> Any:\n    \"\"\"Convert markdown table to a pandas dataframe.\"\"\"\n    if isinstance(data, str):\n        return (\n            pd.read_csv(\n                StringIO(data),\n                sep=\"|\",\n                index_col=1,\n            )\n            .dropna(axis=1, how=\"all\")\n            .iloc[1:]\n            .map(lambda x: x.strip())\n        )\n    return data\n\n\n",
          "display_code": "def to_markdown(df: pd.DataFrame) -> str:\n    \"\"\"Convert a dataframe to markdown format.\"\"\"\n    return df.to_markdown()\n\n\ndef md_to_df(data: Any) -> Any:\n    \"\"\"Convert markdown table to a pandas dataframe.\"\"\"\n    if isinstance(data, str):\n        return (\n            pd.read_csv(\n                StringIO(data),\n                sep=\"|\",\n                index_col=1,\n            )\n            .dropna(axis=1, how=\"all\")\n            .iloc[1:]\n            .map(lambda x: x.strip())\n        )\n    return data\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 25,
          "line_range": [
            25,
            45
          ]
        },
        {
          "code": "# Define a custom type for markdown dataframes\n",
          "display_code": "",
          "annotation": "Define a custom type for markdown dataframes",
          "is_comment": true,
          "start_line": 46,
          "line_range": [
            46,
            46
          ],
          "target_line_range": [
            47,
            59
          ]
        },
        {
          "code": "MarkdownDataFrame = Annotated[\n    InstanceOf[pd.DataFrame],\n    BeforeValidator(md_to_df),\n    PlainSerializer(to_markdown),\n    WithJsonSchema(\n        {\n            \"type\": \"string\",\n            \"description\": \"The markdown representation of the table\",\n        }\n    ),\n]\n\n\n",
          "display_code": "MarkdownDataFrame = Annotated[\n    InstanceOf[pd.DataFrame],\n    BeforeValidator(md_to_df),\n    PlainSerializer(to_markdown),\n    WithJsonSchema(\n        {\n            \"type\": \"string\",\n            \"description\": \"The markdown representation of the table\",\n        }\n    ),\n]\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 47,
          "line_range": [
            47,
            59
          ]
        },
        {
          "code": "# Define the table model\n",
          "display_code": "",
          "annotation": "Define the table model",
          "is_comment": true,
          "start_line": 60,
          "line_range": [
            60,
            60
          ],
          "target_line_range": [
            61,
            67
          ]
        },
        {
          "code": "class Table(BaseModel):\n    caption: str = Field(description=\"A descriptive caption for the table\")\n    dataframe: MarkdownDataFrame = Field(\n        description=\"The table data as a markdown table\"\n    )\n\n\n",
          "display_code": "class Table(BaseModel):\n    caption: str = Field(description=\"A descriptive caption for the table\")\n    dataframe: MarkdownDataFrame = Field(\n        description=\"The table data as a markdown table\"\n    )\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 61,
          "line_range": [
            61,
            67
          ]
        },
        {
          "code": "# Function to extract tables from images\n# Create an image object or use autodetect\n",
          "display_code": "",
          "annotation": "Function to extract tables from images\nCreate an image object or use autodetect",
          "is_comment": true,
          "start_line": 68,
          "line_range": [
            68,
            69
          ],
          "target_line_range": [
            70,
            95
          ]
        },
        {
          "code": "def extract_table_from_image(image_path_or_url: str) -> Table:\n    \"\"\"Extract a table from an image and return it as a structured object.\"\"\"\n    if image_path_or_url.startswith((\"http://\", \"https://\")):\n        image = instructor.Image.from_url(image_path_or_url)\n    else:\n        image = instructor.Image.from_path(image_path_or_url)\n\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=Table,\n        max_tokens=1800,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": \"Extract the table from this image with a descriptive caption.\",\n                    },\n                    image,\n                ],\n            }\n        ],\n    )\n\n\n",
          "display_code": "def extract_table_from_image(image_path_or_url: str) -> Table:\n    \"\"\"Extract a table from an image and return it as a structured object.\"\"\"\n    if image_path_or_url.startswith((\"http://\", \"https://\")):\n        image = instructor.Image.from_url(image_path_or_url)\n    else:\n        image = instructor.Image.from_path(image_path_or_url)\n\n    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=Table,\n        max_tokens=1800,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": \"Extract the table from this image with a descriptive caption.\",\n                    },\n                    image,\n                ],\n            }\n        ],\n    )\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 70,
          "line_range": [
            70,
            95
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 96,
          "line_range": [
            96,
            96
          ],
          "target_line_range": [
            97,
            104
          ]
        },
        {
          "code": "def analyze_table_data(image_path: str):\n    \"\"\"Extract and analyze a table from an image.\"\"\"\n    table = extract_table_from_image(image_path)\n\n    print(f\"Table Caption: {table.caption}\")\n    print(\"\\nExtracted Table:\")\n    print(table.dataframe)\n\n",
          "display_code": "def analyze_table_data(image_path: str):\n    \"\"\"Extract and analyze a table from an image.\"\"\"\n    table = extract_table_from_image(image_path)\n\n    print(f\"Table Caption: {table.caption}\")\n    print(\"\\nExtracted Table:\")\n    print(table.dataframe)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 97,
          "line_range": [
            97,
            104
          ]
        },
        {
          "code": "    # Perform data analysis if it's a pandas DataFrame\n",
          "display_code": "",
          "annotation": "Perform data analysis if it's a pandas DataFrame",
          "is_comment": true,
          "start_line": 105,
          "line_range": [
            105,
            105
          ],
          "target_line_range": [
            106,
            110
          ]
        },
        {
          "code": "    if isinstance(table.dataframe, pd.DataFrame):\n        print(\"\\nData Analysis:\")\n        print(f\"- Rows: {len(table.dataframe)}\")\n        print(f\"- Columns: {len(table.dataframe.columns)}\")\n\n",
          "display_code": "    if isinstance(table.dataframe, pd.DataFrame):\n        print(\"\\nData Analysis:\")\n        print(f\"- Rows: {len(table.dataframe)}\")\n        print(f\"- Columns: {len(table.dataframe.columns)}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 106,
          "line_range": [
            106,
            110
          ]
        },
        {
          "code": "        # Basic statistics if numeric columns exist\n",
          "display_code": "",
          "annotation": "Basic statistics if numeric columns exist",
          "is_comment": true,
          "start_line": 111,
          "line_range": [
            111,
            111
          ],
          "target_line_range": [
            112,
            125
          ]
        },
        {
          "code": "        numeric_cols = table.dataframe.select_dtypes(include=[\"number\"]).columns\n        if len(numeric_cols) > 0:\n            print(\"\\nNumeric Column Statistics:\")\n            for col in numeric_cols:\n                col_data = table.dataframe[col]\n                print(\n                    f\"- {col}: Min={col_data.min()}, Max={col_data.max()}, Mean={col_data.mean():.2f}\"\n                )\n\n        return table.dataframe\n\n    return None\n\n\n",
          "display_code": "        numeric_cols = table.dataframe.select_dtypes(include=[\"number\"]).columns\n        if len(numeric_cols) > 0:\n            print(\"\\nNumeric Column Statistics:\")\n            for col in numeric_cols:\n                col_data = table.dataframe[col]\n                print(\n                    f\"- {col}: Min={col_data.min()}, Max={col_data.max()}, Mean={col_data.mean():.2f}\"\n                )\n\n        return table.dataframe\n\n    return None\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 112,
          "line_range": [
            112,
            125
          ]
        },
        {
          "code": "# This would be called as:\n# df = analyze_table_data(\"path/to/table_image.jpg\")\n# After this, you can use pandas operations on the dataframe\n# For multiple tables in a single image, you can use the iterable response:\n",
          "display_code": "",
          "annotation": "This would be called as:\ndf = analyze_table_data(\"path/to/table_image.jpg\")\nAfter this, you can use pandas operations on the dataframe\nFor multiple tables in a single image, you can use the iterable response:",
          "is_comment": true,
          "start_line": 126,
          "line_range": [
            126,
            129
          ],
          "target_line_range": [
            130,
            157
          ]
        },
        {
          "code": "def extract_multiple_tables(image_path_or_url: str) -> list[Table]:\n    \"\"\"Extract all tables from an image.\"\"\"\n    if image_path_or_url.startswith((\"http://\", \"https://\")):\n        image = instructor.Image.from_url(image_path_or_url)\n    else:\n        image = instructor.Image.from_path(image_path_or_url)\n\n    tables = client.chat.completions.create_iterable(\n        model=\"gpt-4-vision-preview\",\n        response_model=Table,\n        max_tokens=1800,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": \"Extract all tables from this image. Each table should be separate and have its own caption.\",\n                    },\n                    image,\n                ],\n            }\n        ],\n    )\n\n    return list(tables)\n\n\n",
          "display_code": "def extract_multiple_tables(image_path_or_url: str) -> list[Table]:\n    \"\"\"Extract all tables from an image.\"\"\"\n    if image_path_or_url.startswith((\"http://\", \"https://\")):\n        image = instructor.Image.from_url(image_path_or_url)\n    else:\n        image = instructor.Image.from_path(image_path_or_url)\n\n    tables = client.chat.completions.create_iterable(\n        model=\"gpt-4-vision-preview\",\n        response_model=Table,\n        max_tokens=1800,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": \"Extract all tables from this image. Each table should be separate and have its own caption.\",\n                    },\n                    image,\n                ],\n            }\n        ],\n    )\n\n    return list(tables)\n\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 130,
          "line_range": [
            130,
            157
          ]
        },
        {
          "code": "# Process multiple tables from one image\n# Convert to dataframe and return list of dataframes\n",
          "display_code": "",
          "annotation": "Process multiple tables from one image\nConvert to dataframe and return list of dataframes",
          "is_comment": true,
          "start_line": 158,
          "line_range": [
            158,
            159
          ],
          "target_line_range": [
            160,
            171
          ]
        },
        {
          "code": "def analyze_multiple_tables(image_path: str):\n    \"\"\"Extract and analyze all tables from an image.\"\"\"\n    tables = extract_multiple_tables(image_path)\n\n    print(f\"Found {len(tables)} tables in the image.\")\n\n    for i, table in enumerate(tables):\n        print(f\"\\n--- Table {i+1}: {table.caption} ---\")\n        print(table.dataframe)\n\n        if isinstance(table.dataframe, pd.DataFrame):\n            yield table.dataframe\n",
          "display_code": "def analyze_multiple_tables(image_path: str):\n    \"\"\"Extract and analyze all tables from an image.\"\"\"\n    tables = extract_multiple_tables(image_path)\n\n    print(f\"Found {len(tables)} tables in the image.\")\n\n    for i, table in enumerate(tables):\n        print(f\"\\n--- Table {i+1}: {table.caption} ---\")\n        print(table.dataframe)\n\n        if isinstance(table.dataframe, pd.DataFrame):\n            yield table.dataframe\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 160,
          "line_range": [
            160,
            171
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python table-extraction.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "008-multimodal",
      "section_title": "Multimodal Inputs"
    },
    {
      "id": "041-audio-extraction",
      "title": "Audio Extraction",
      "description": "",
      "order": 41,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# - Handle multilingual audio content\n",
          "display_code": "",
          "annotation": "- Handle multilingual audio content",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor supports extracting structured data from audio files using the `Audio` class, making it easy to process speech and audio content.\n",
          "display_code": "",
          "annotation": "Instructor supports extracting structured data from audio files using the `Audio` class, making it easy to process speech and audio content.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom instructor.multimodal import Audio\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom instructor.multimodal import Audio\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define a model for audio transcription\n",
          "display_code": "",
          "annotation": "Define a model for audio transcription",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            20
          ]
        },
        {
          "code": "class AudioTranscription(BaseModel):\n    text: str = Field(description=\"Full transcription of the audio\")\n    speaker: str = Field(description=\"Identity of the speaker if known\")\n    language: str = Field(description=\"Language spoken in the audio\")\n    confidence: float = Field(description=\"Confidence score for the transcription\", ge=0.0, le=1.0)\n\n",
          "display_code": "class AudioTranscription(BaseModel):\n    text: str = Field(description=\"Full transcription of the audio\")\n    speaker: str = Field(description=\"Identity of the speaker if known\")\n    language: str = Field(description=\"Language spoken in the audio\")\n    confidence: float = Field(description=\"Confidence score for the transcription\", ge=0.0, le=1.0)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            20
          ]
        },
        {
          "code": "# Extract transcription from audio\n",
          "display_code": "",
          "annotation": "Extract transcription from audio",
          "is_comment": true,
          "start_line": 21,
          "line_range": [
            21,
            21
          ],
          "target_line_range": [
            22,
            23
          ]
        },
        {
          "code": "def transcribe_audio(audio_path: str) -> AudioTranscription:\n    \"\"\"Extract structured transcription from an audio file.\"\"\"\n",
          "display_code": "def transcribe_audio(audio_path: str) -> AudioTranscription:\n    \"\"\"Extract structured transcription from an audio file.\"\"\"\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 22,
          "line_range": [
            22,
            23
          ]
        },
        {
          "code": "    # Load the audio using Instructor's Audio class\n",
          "display_code": "",
          "annotation": "Load the audio using Instructor's Audio class",
          "is_comment": true,
          "start_line": 24,
          "line_range": [
            24,
            24
          ],
          "target_line_range": [
            25,
            40
          ]
        },
        {
          "code": "    audio = Audio.from_path(audio_path)\n\n    return client.chat.completions.create(\n        model=\"gpt-4o-audio-preview\",  # Audio-capable model\n        response_model=AudioTranscription,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Transcribe this audio file and identify the speaker and language:\",\n                    audio  # The Audio object is handled automatically\n                ]\n            }\n        ]\n    )\n\n",
          "display_code": "    audio = Audio.from_path(audio_path)\n\n    return client.chat.completions.create(\n        model=\"gpt-4o-audio-preview\",  # Audio-capable model\n        response_model=AudioTranscription,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Transcribe this audio file and identify the speaker and language:\",\n                    audio  # The Audio object is handled automatically\n                ]\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 25,
          "line_range": [
            25,
            40
          ]
        },
        {
          "code": "# Example usage\n# transcript = transcribe_audio(\"path/to/audio.wav\")\n# print(f\"Transcript: {transcript.text}\")\n# print(f\"Speaker: {transcript.speaker}\")\n# print(f\"Language: {transcript.language}\")\n# print(f\"Confidence: {transcript.confidence:.2f}\")\n",
          "display_code": "",
          "annotation": "Example usage\ntranscript = transcribe_audio(\"path/to/audio.wav\")\nprint(f\"Transcript: {transcript.text}\")\nprint(f\"Speaker: {transcript.speaker}\")\nprint(f\"Language: {transcript.language}\")\nprint(f\"Confidence: {transcript.confidence:.2f}\")",
          "is_comment": true,
          "start_line": 41,
          "line_range": [
            41,
            46
          ],
          "target_line_range": [
            47,
            47
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 47,
          "line_range": [
            47,
            47
          ]
        },
        {
          "code": "# For more specific information extraction from audio:\n",
          "display_code": "",
          "annotation": "For more specific information extraction from audio:",
          "is_comment": true,
          "start_line": 48,
          "line_range": [
            48,
            48
          ],
          "target_line_range": [
            49,
            54
          ]
        },
        {
          "code": "from typing import List, Optional\nfrom pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\nfrom instructor.multimodal import Audio\n\n",
          "display_code": "from typing import List, Optional\nfrom pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\nfrom instructor.multimodal import Audio\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 49,
          "line_range": [
            49,
            54
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 55,
          "line_range": [
            55,
            55
          ],
          "target_line_range": [
            56,
            57
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 56,
          "line_range": [
            56,
            57
          ]
        },
        {
          "code": "# Define a model for person information\n",
          "display_code": "",
          "annotation": "Define a model for person information",
          "is_comment": true,
          "start_line": 58,
          "line_range": [
            58,
            58
          ],
          "target_line_range": [
            59,
            63
          ]
        },
        {
          "code": "class Person(BaseModel):\n    name: str = Field(description=\"Person's full name\")\n    age: int = Field(description=\"Person's age in years\")\n    occupation: Optional[str] = Field(None, description=\"Person's job or profession if mentioned\")\n\n",
          "display_code": "class Person(BaseModel):\n    name: str = Field(description=\"Person's full name\")\n    age: int = Field(description=\"Person's age in years\")\n    occupation: Optional[str] = Field(None, description=\"Person's job or profession if mentioned\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 59,
          "line_range": [
            59,
            63
          ]
        },
        {
          "code": "# Define a model for meeting information\n",
          "display_code": "",
          "annotation": "Define a model for meeting information",
          "is_comment": true,
          "start_line": 64,
          "line_range": [
            64,
            64
          ],
          "target_line_range": [
            65,
            76
          ]
        },
        {
          "code": "class MeetingPoint(BaseModel):\n    topic: str = Field(description=\"Topic discussed\")\n    decision: Optional[str] = Field(None, description=\"Decision made on this topic\")\n    action_items: List[str] = Field(default_factory=list, description=\"Action items related to this topic\")\n\nclass Meeting(BaseModel):\n    title: str = Field(description=\"Meeting title or purpose\")\n    date: Optional[str] = Field(None, description=\"Meeting date if mentioned\")\n    participants: List[str] = Field(description=\"Names of meeting participants\")\n    key_points: List[MeetingPoint] = Field(description=\"Key discussion points and decisions\")\n    summary: str = Field(description=\"Brief summary of the meeting\")\n\n",
          "display_code": "class MeetingPoint(BaseModel):\n    topic: str = Field(description=\"Topic discussed\")\n    decision: Optional[str] = Field(None, description=\"Decision made on this topic\")\n    action_items: List[str] = Field(default_factory=list, description=\"Action items related to this topic\")\n\nclass Meeting(BaseModel):\n    title: str = Field(description=\"Meeting title or purpose\")\n    date: Optional[str] = Field(None, description=\"Meeting date if mentioned\")\n    participants: List[str] = Field(description=\"Names of meeting participants\")\n    key_points: List[MeetingPoint] = Field(description=\"Key discussion points and decisions\")\n    summary: str = Field(description=\"Brief summary of the meeting\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 65,
          "line_range": [
            65,
            76
          ]
        },
        {
          "code": "# Extract structured information from audio\n",
          "display_code": "",
          "annotation": "Extract structured information from audio",
          "is_comment": true,
          "start_line": 77,
          "line_range": [
            77,
            77
          ],
          "target_line_range": [
            78,
            99
          ]
        },
        {
          "code": "def extract_meeting_info(audio_path: str) -> Meeting:\n    \"\"\"Extract structured meeting information from audio recording.\"\"\"\n    audio = Audio.from_path(audio_path)\n\n    return client.chat.completions.create(\n        model=\"gpt-4o-audio-preview\",\n        response_model=Meeting,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract detailed meeting information from this audio recording.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Extract the complete meeting details from this recording:\",\n                    audio\n                ]\n            }\n        ]\n    )\n\n",
          "display_code": "def extract_meeting_info(audio_path: str) -> Meeting:\n    \"\"\"Extract structured meeting information from audio recording.\"\"\"\n    audio = Audio.from_path(audio_path)\n\n    return client.chat.completions.create(\n        model=\"gpt-4o-audio-preview\",\n        response_model=Meeting,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract detailed meeting information from this audio recording.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Extract the complete meeting details from this recording:\",\n                    audio\n                ]\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 78,
          "line_range": [
            78,
            99
          ]
        },
        {
          "code": "# Extract person information\n",
          "display_code": "",
          "annotation": "Extract person information",
          "is_comment": true,
          "start_line": 100,
          "line_range": [
            100,
            100
          ],
          "target_line_range": [
            101,
            118
          ]
        },
        {
          "code": "def extract_person_from_audio(audio_path: str) -> Person:\n    \"\"\"Extract structured person information from audio.\"\"\"\n    audio = Audio.from_path(audio_path)\n\n    return client.chat.completions.create(\n        model=\"gpt-4o-audio-preview\",\n        response_model=Person,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Extract the person's name, age, and occupation from this audio:\",\n                    audio\n                ]\n            }\n        ]\n    )\n\n",
          "display_code": "def extract_person_from_audio(audio_path: str) -> Person:\n    \"\"\"Extract structured person information from audio.\"\"\"\n    audio = Audio.from_path(audio_path)\n\n    return client.chat.completions.create(\n        model=\"gpt-4o-audio-preview\",\n        response_model=Person,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Extract the person's name, age, and occupation from this audio:\",\n                    audio\n                ]\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 101,
          "line_range": [
            101,
            118
          ]
        },
        {
          "code": "# Example usage\n# person = extract_person_from_audio(\"path/to/introduction.wav\")\n# print(f\"Name: {person.name}, Age: {person.age}\")\n# if person.occupation:\n#     print(f\"Occupation: {person.occupation}\")\n",
          "display_code": "",
          "annotation": "Example usage\nperson = extract_person_from_audio(\"path/to/introduction.wav\")\nprint(f\"Name: {person.name}, Age: {person.age}\")\nif person.occupation:\nprint(f\"Occupation: {person.occupation}\")",
          "is_comment": true,
          "start_line": 119,
          "line_range": [
            119,
            123
          ],
          "target_line_range": [
            124,
            124
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 124,
          "line_range": [
            124,
            124
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python audio-extraction.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "008-multimodal",
      "section_title": "Multimodal Inputs"
    },
    {
      "id": "042-pdf-extraction",
      "title": "PDF Extraction",
      "description": "",
      "order": 42,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# - Integrate PDF processing into data pipelines\n",
          "display_code": "",
          "annotation": "- Integrate PDF processing into data pipelines",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor provides support for working with PDF documents through a combination of vision capabilities and structured extraction.\n",
          "display_code": "",
          "annotation": "Instructor provides support for working with PDF documents through a combination of vision capabilities and structured extraction.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            12
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List\nimport tempfile\nfrom pdf2image import convert_from_path\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List\nimport tempfile\nfrom pdf2image import convert_from_path\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            12
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 13,
          "line_range": [
            13,
            13
          ],
          "target_line_range": [
            14,
            15
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 14,
          "line_range": [
            14,
            15
          ]
        },
        {
          "code": "# Define models for document extraction\n",
          "display_code": "",
          "annotation": "Define models for document extraction",
          "is_comment": true,
          "start_line": 16,
          "line_range": [
            16,
            16
          ],
          "target_line_range": [
            17,
            26
          ]
        },
        {
          "code": "class Section(BaseModel):\n    title: str = Field(description=\"Section title\")\n    content: str = Field(description=\"Section content\")\n\nclass Document(BaseModel):\n    title: str = Field(description=\"Document title\")\n    author: str = Field(description=\"Document author\")\n    sections: List[Section] = Field(description=\"Document sections\")\n    summary: str = Field(description=\"Brief document summary\")\n\n",
          "display_code": "class Section(BaseModel):\n    title: str = Field(description=\"Section title\")\n    content: str = Field(description=\"Section content\")\n\nclass Document(BaseModel):\n    title: str = Field(description=\"Document title\")\n    author: str = Field(description=\"Document author\")\n    sections: List[Section] = Field(description=\"Document sections\")\n    summary: str = Field(description=\"Brief document summary\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 17,
          "line_range": [
            17,
            26
          ]
        },
        {
          "code": "# Extract content from a PDF page as an image\n",
          "display_code": "",
          "annotation": "Extract content from a PDF page as an image",
          "is_comment": true,
          "start_line": 27,
          "line_range": [
            27,
            27
          ],
          "target_line_range": [
            28,
            29
          ]
        },
        {
          "code": "def extract_from_pdf_page(pdf_path: str, page_number: int = 0) -> Document:\n    \"\"\"Extract structured information from a PDF page.\"\"\"\n",
          "display_code": "def extract_from_pdf_page(pdf_path: str, page_number: int = 0) -> Document:\n    \"\"\"Extract structured information from a PDF page.\"\"\"\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 28,
          "line_range": [
            28,
            29
          ]
        },
        {
          "code": "    # Convert the PDF page to an image\n",
          "display_code": "",
          "annotation": "Convert the PDF page to an image",
          "is_comment": true,
          "start_line": 30,
          "line_range": [
            30,
            30
          ],
          "target_line_range": [
            31,
            32
          ]
        },
        {
          "code": "    images = convert_from_path(pdf_path, first_page=page_number+1, last_page=page_number+1)\n\n",
          "display_code": "    images = convert_from_path(pdf_path, first_page=page_number+1, last_page=page_number+1)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 31,
          "line_range": [
            31,
            32
          ]
        },
        {
          "code": "    # Save the image to a temporary file\n",
          "display_code": "",
          "annotation": "Save the image to a temporary file",
          "is_comment": true,
          "start_line": 33,
          "line_range": [
            33,
            33
          ],
          "target_line_range": [
            34,
            37
          ]
        },
        {
          "code": "    with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp:\n        temp_path = temp.name\n        images[0].save(temp_path, 'JPEG')\n\n",
          "display_code": "    with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp:\n        temp_path = temp.name\n        images[0].save(temp_path, 'JPEG')\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 34,
          "line_range": [
            34,
            37
          ]
        },
        {
          "code": "    # Create an Image object\n",
          "display_code": "",
          "annotation": "Create an Image object",
          "is_comment": true,
          "start_line": 38,
          "line_range": [
            38,
            38
          ],
          "target_line_range": [
            39,
            40
          ]
        },
        {
          "code": "    image = instructor.Image.from_path(temp_path)\n\n",
          "display_code": "    image = instructor.Image.from_path(temp_path)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 39,
          "line_range": [
            39,
            40
          ]
        },
        {
          "code": "    # Extract information using vision capabilities\n",
          "display_code": "",
          "annotation": "Extract information using vision capabilities",
          "is_comment": true,
          "start_line": 41,
          "line_range": [
            41,
            41
          ],
          "target_line_range": [
            42,
            59
          ]
        },
        {
          "code": "    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=Document,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract structured information from this document page.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Extract the complete document structure from this page:\",\n                    image\n                ]\n            }\n        ]\n    )\n\n",
          "display_code": "    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=Document,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Extract structured information from this document page.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Extract the complete document structure from this page:\",\n                    image\n                ]\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 42,
          "line_range": [
            42,
            59
          ]
        },
        {
          "code": "# Process multiple pages\n",
          "display_code": "",
          "annotation": "Process multiple pages",
          "is_comment": true,
          "start_line": 60,
          "line_range": [
            60,
            60
          ],
          "target_line_range": [
            61,
            64
          ]
        },
        {
          "code": "def process_pdf_document(pdf_path: str, max_pages: int = 5) -> List[Document]:\n    \"\"\"Process multiple pages from a PDF document.\"\"\"\n    results = []\n\n",
          "display_code": "def process_pdf_document(pdf_path: str, max_pages: int = 5) -> List[Document]:\n    \"\"\"Process multiple pages from a PDF document.\"\"\"\n    results = []\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 61,
          "line_range": [
            61,
            64
          ]
        },
        {
          "code": "    # Get the number of pages\n",
          "display_code": "",
          "annotation": "Get the number of pages",
          "is_comment": true,
          "start_line": 65,
          "line_range": [
            65,
            65
          ],
          "target_line_range": [
            66,
            70
          ]
        },
        {
          "code": "    from pypdf import PdfReader\n    reader = PdfReader(pdf_path)\n    num_pages = len(reader.pages)\n    actual_pages = min(num_pages, max_pages)\n\n",
          "display_code": "    from pypdf import PdfReader\n    reader = PdfReader(pdf_path)\n    num_pages = len(reader.pages)\n    actual_pages = min(num_pages, max_pages)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 66,
          "line_range": [
            66,
            70
          ]
        },
        {
          "code": "    # Process each page\n",
          "display_code": "",
          "annotation": "Process each page",
          "is_comment": true,
          "start_line": 71,
          "line_range": [
            71,
            71
          ],
          "target_line_range": [
            72,
            78
          ]
        },
        {
          "code": "    for i in range(actual_pages):\n        page_result = extract_from_pdf_page(pdf_path, i)\n        results.append(page_result)\n        print(f\"Processed page {i+1}/{actual_pages}\")\n\n    return results\n\n",
          "display_code": "    for i in range(actual_pages):\n        page_result = extract_from_pdf_page(pdf_path, i)\n        results.append(page_result)\n        print(f\"Processed page {i+1}/{actual_pages}\")\n\n    return results\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 72,
          "line_range": [
            72,
            78
          ]
        },
        {
          "code": "# Example usage\n# documents = process_pdf_document(\"path/to/document.pdf\", max_pages=3)\n# for i, doc in enumerate(documents):\n#     print(f\"Page {i+1}: {doc.title} by {doc.author}\")\n#     print(f\"Summary: {doc.summary}\")\n#     print(f\"Sections: {len(doc.sections)}\")\n",
          "display_code": "",
          "annotation": "Example usage\ndocuments = process_pdf_document(\"path/to/document.pdf\", max_pages=3)\nfor i, doc in enumerate(documents):\nprint(f\"Page {i+1}: {doc.title} by {doc.author}\")\nprint(f\"Summary: {doc.summary}\")\nprint(f\"Sections: {len(doc.sections)}\")",
          "is_comment": true,
          "start_line": 79,
          "line_range": [
            79,
            84
          ],
          "target_line_range": [
            85,
            85
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 85,
          "line_range": [
            85,
            85
          ]
        },
        {
          "code": "# For more specific document types, you can create specialized models:\n",
          "display_code": "",
          "annotation": "For more specific document types, you can create specialized models:",
          "is_comment": true,
          "start_line": 86,
          "line_range": [
            86,
            86
          ],
          "target_line_range": [
            87,
            93
          ]
        },
        {
          "code": "from typing import List, Optional\nfrom pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\nfrom pdf2image import convert_from_path\nimport tempfile\n\n",
          "display_code": "from typing import List, Optional\nfrom pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\nfrom pdf2image import convert_from_path\nimport tempfile\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 87,
          "line_range": [
            87,
            93
          ]
        },
        {
          "code": "# Initialize the client\n",
          "display_code": "",
          "annotation": "Initialize the client",
          "is_comment": true,
          "start_line": 94,
          "line_range": [
            94,
            94
          ],
          "target_line_range": [
            95,
            96
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 95,
          "line_range": [
            95,
            96
          ]
        },
        {
          "code": "# Define a model for invoice extraction\n",
          "display_code": "",
          "annotation": "Define a model for invoice extraction",
          "is_comment": true,
          "start_line": 97,
          "line_range": [
            97,
            97
          ],
          "target_line_range": [
            98,
            113
          ]
        },
        {
          "code": "class LineItem(BaseModel):\n    description: str = Field(description=\"Description of the item or service\")\n    quantity: float = Field(description=\"Quantity of the item\")\n    unit_price: float = Field(description=\"Price per unit\")\n    amount: float = Field(description=\"Total amount for this line\")\n\nclass Invoice(BaseModel):\n    invoice_number: str = Field(description=\"Invoice identifier\")\n    date: str = Field(description=\"Invoice date\")\n    vendor: str = Field(description=\"Name of the vendor/seller\")\n    customer: str = Field(description=\"Name of the customer/buyer\")\n    items: List[LineItem] = Field(description=\"Line items in the invoice\")\n    subtotal: float = Field(description=\"Sum of all items before tax\")\n    tax: Optional[float] = Field(None, description=\"Tax amount\")\n    total: float = Field(description=\"Total invoice amount\")\n\n",
          "display_code": "class LineItem(BaseModel):\n    description: str = Field(description=\"Description of the item or service\")\n    quantity: float = Field(description=\"Quantity of the item\")\n    unit_price: float = Field(description=\"Price per unit\")\n    amount: float = Field(description=\"Total amount for this line\")\n\nclass Invoice(BaseModel):\n    invoice_number: str = Field(description=\"Invoice identifier\")\n    date: str = Field(description=\"Invoice date\")\n    vendor: str = Field(description=\"Name of the vendor/seller\")\n    customer: str = Field(description=\"Name of the customer/buyer\")\n    items: List[LineItem] = Field(description=\"Line items in the invoice\")\n    subtotal: float = Field(description=\"Sum of all items before tax\")\n    tax: Optional[float] = Field(None, description=\"Tax amount\")\n    total: float = Field(description=\"Total invoice amount\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 98,
          "line_range": [
            98,
            113
          ]
        },
        {
          "code": "# Extract invoice from PDF\n",
          "display_code": "",
          "annotation": "Extract invoice from PDF",
          "is_comment": true,
          "start_line": 114,
          "line_range": [
            114,
            114
          ],
          "target_line_range": [
            115,
            116
          ]
        },
        {
          "code": "def extract_invoice(pdf_path: str) -> Invoice:\n    \"\"\"Extract structured invoice data from a PDF.\"\"\"\n",
          "display_code": "def extract_invoice(pdf_path: str) -> Invoice:\n    \"\"\"Extract structured invoice data from a PDF.\"\"\"\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 115,
          "line_range": [
            115,
            116
          ]
        },
        {
          "code": "    # Convert first page to image\n",
          "display_code": "",
          "annotation": "Convert first page to image",
          "is_comment": true,
          "start_line": 117,
          "line_range": [
            117,
            117
          ],
          "target_line_range": [
            118,
            119
          ]
        },
        {
          "code": "    images = convert_from_path(pdf_path, first_page=1, last_page=1)\n\n",
          "display_code": "    images = convert_from_path(pdf_path, first_page=1, last_page=1)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 118,
          "line_range": [
            118,
            119
          ]
        },
        {
          "code": "    # Save to temp file\n",
          "display_code": "",
          "annotation": "Save to temp file",
          "is_comment": true,
          "start_line": 120,
          "line_range": [
            120,
            120
          ],
          "target_line_range": [
            121,
            124
          ]
        },
        {
          "code": "    with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp:\n        temp_path = temp.name\n        images[0].save(temp_path, 'JPEG')\n\n",
          "display_code": "    with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as temp:\n        temp_path = temp.name\n        images[0].save(temp_path, 'JPEG')\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 121,
          "line_range": [
            121,
            124
          ]
        },
        {
          "code": "    # Create image object\n",
          "display_code": "",
          "annotation": "Create image object",
          "is_comment": true,
          "start_line": 125,
          "line_range": [
            125,
            125
          ],
          "target_line_range": [
            126,
            127
          ]
        },
        {
          "code": "    image = instructor.Image.from_path(temp_path)\n\n",
          "display_code": "    image = instructor.Image.from_path(temp_path)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 126,
          "line_range": [
            126,
            127
          ]
        },
        {
          "code": "    # Extract invoice data\n",
          "display_code": "",
          "annotation": "Extract invoice data",
          "is_comment": true,
          "start_line": 128,
          "line_range": [
            128,
            128
          ],
          "target_line_range": [
            129,
            146
          ]
        },
        {
          "code": "    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=Invoice,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You are an invoice processing assistant that extracts structured data from invoice images.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Extract complete invoice details from this document:\",\n                    image\n                ]\n            }\n        ]\n    )\n\n",
          "display_code": "    return client.chat.completions.create(\n        model=\"gpt-4-vision-preview\",\n        response_model=Invoice,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"You are an invoice processing assistant that extracts structured data from invoice images.\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    \"Extract complete invoice details from this document:\",\n                    image\n                ]\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 129,
          "line_range": [
            129,
            146
          ]
        },
        {
          "code": "# Example usage\n# invoice = extract_invoice(\"path/to/invoice.pdf\")\n# print(f\"Invoice #{invoice.invoice_number} from {invoice.vendor}\")\n# print(f\"Date: {invoice.date}\")\n# print(f\"Total: ${invoice.total:.2f}\")\n# print(\"Line items:\")\n# for item in invoice.items:\n#     print(f\"- {item.description}: {item.quantity} x ${item.unit_price:.2f} = ${item.amount:.2f}\")\n",
          "display_code": "",
          "annotation": "Example usage\ninvoice = extract_invoice(\"path/to/invoice.pdf\")\nprint(f\"Invoice #{invoice.invoice_number} from {invoice.vendor}\")\nprint(f\"Date: {invoice.date}\")\nprint(f\"Total: ${invoice.total:.2f}\")\nprint(\"Line items:\")\nfor item in invoice.items:\nprint(f\"- {item.description}: {item.quantity} x ${item.unit_price:.2f} = ${item.amount:.2f}\")",
          "is_comment": true,
          "start_line": 147,
          "line_range": [
            147,
            154
          ],
          "target_line_range": [
            155,
            155
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 155,
          "line_range": [
            155,
            155
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python pdf-extraction.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "008-multimodal",
      "section_title": "Multimodal Inputs"
    },
    {
      "id": "043-caching-responses",
      "title": "Caching Responses",
      "description": "",
      "order": 43,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# - Redis caching: Works across multiple servers or processes\n",
          "display_code": "",
          "annotation": "- Redis caching: Works across multiple servers or processes",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Caching LLM responses can significantly improve performance and reduce costs. Instructor supports several caching strategies to suit different needs.\n",
          "display_code": "",
          "annotation": "Caching LLM responses can significantly improve performance and reduce costs. Instructor supports several caching strategies to suit different needs.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "import functools\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\n",
          "display_code": "import functools\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define a simple model\n",
          "display_code": "",
          "annotation": "Define a simple model",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            18
          ]
        },
        {
          "code": "class User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "class User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            18
          ]
        },
        {
          "code": "# Simple in-memory caching with functools.cache\n",
          "display_code": "",
          "annotation": "Simple in-memory caching with functools.cache",
          "is_comment": true,
          "start_line": 19,
          "line_range": [
            19,
            19
          ],
          "target_line_range": [
            20,
            33
          ]
        },
        {
          "code": "@functools.cache\ndef extract_user(text: str) -> User:\n    \"\"\"Extract user information with in-memory caching.\"\"\"\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Extract user information from: {text}\"\n            }\n        ]\n    )\n\n",
          "display_code": "@functools.cache\ndef extract_user(text: str) -> User:\n    \"\"\"Extract user information with in-memory caching.\"\"\"\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=User,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Extract user information from: {text}\"\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 20,
          "line_range": [
            20,
            33
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 34,
          "line_range": [
            34,
            34
          ],
          "target_line_range": [
            35,
            37
          ]
        },
        {
          "code": "user1 = extract_user(\"John is 30 years old\")\nprint(user1)\n\n",
          "display_code": "user1 = extract_user(\"John is 30 years old\")\nprint(user1)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 35,
          "line_range": [
            35,
            37
          ]
        },
        {
          "code": "# This call will use the cached result (no API call)\n",
          "display_code": "",
          "annotation": "This call will use the cached result (no API call)",
          "is_comment": true,
          "start_line": 38,
          "line_range": [
            38,
            38
          ],
          "target_line_range": [
            39,
            41
          ]
        },
        {
          "code": "user2 = extract_user(\"John is 30 years old\")\nprint(user2)\n\n",
          "display_code": "user2 = extract_user(\"John is 30 years old\")\nprint(user2)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 39,
          "line_range": [
            39,
            41
          ]
        },
        {
          "code": "# For persistent caching across sessions, you can use disk-based caching:\n",
          "display_code": "",
          "annotation": "For persistent caching across sessions, you can use disk-based caching:",
          "is_comment": true,
          "start_line": 42,
          "line_range": [
            42,
            42
          ],
          "target_line_range": [
            43,
            49
          ]
        },
        {
          "code": "import functools\nimport inspect\nimport instructor\nimport diskcache\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\n",
          "display_code": "import functools\nimport inspect\nimport instructor\nimport diskcache\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 43,
          "line_range": [
            43,
            49
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 50,
          "line_range": [
            50,
            50
          ],
          "target_line_range": [
            51,
            52
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 51,
          "line_range": [
            51,
            52
          ]
        },
        {
          "code": "# Initialize disk cache\n",
          "display_code": "",
          "annotation": "Initialize disk cache",
          "is_comment": true,
          "start_line": 53,
          "line_range": [
            53,
            53
          ],
          "target_line_range": [
            54,
            55
          ]
        },
        {
          "code": "cache = diskcache.Cache('./my_cache_directory')\n\n",
          "display_code": "cache = diskcache.Cache('./my_cache_directory')\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 54,
          "line_range": [
            54,
            55
          ]
        },
        {
          "code": "# Define a caching decorator for Pydantic models\n",
          "display_code": "",
          "annotation": "Define a caching decorator for Pydantic models",
          "is_comment": true,
          "start_line": 56,
          "line_range": [
            56,
            56
          ],
          "target_line_range": [
            57,
            64
          ]
        },
        {
          "code": "def instructor_cache(func):\n    \"\"\"Cache a function that returns a Pydantic model.\"\"\"\n    return_type = inspect.signature(func).return_annotation\n    if not issubclass(return_type, BaseModel):\n        raise ValueError(\"The return type must be a Pydantic model\")\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n",
          "display_code": "def instructor_cache(func):\n    \"\"\"Cache a function that returns a Pydantic model.\"\"\"\n    return_type = inspect.signature(func).return_annotation\n    if not issubclass(return_type, BaseModel):\n        raise ValueError(\"The return type must be a Pydantic model\")\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 57,
          "line_range": [
            57,
            64
          ]
        },
        {
          "code": "        # Create a cache key from the function name and arguments\n",
          "display_code": "",
          "annotation": "Create a cache key from the function name and arguments",
          "is_comment": true,
          "start_line": 65,
          "line_range": [
            65,
            65
          ],
          "target_line_range": [
            66,
            67
          ]
        },
        {
          "code": "        key = f\"{func.__name__}-{functools._make_key(args, kwargs, typed=False)}\"\n\n",
          "display_code": "        key = f\"{func.__name__}-{functools._make_key(args, kwargs, typed=False)}\"\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 66,
          "line_range": [
            66,
            67
          ]
        },
        {
          "code": "        # Check if result is already cached\n",
          "display_code": "",
          "annotation": "Check if result is already cached",
          "is_comment": true,
          "start_line": 68,
          "line_range": [
            68,
            68
          ],
          "target_line_range": [
            69,
            69
          ]
        },
        {
          "code": "        if (cached := cache.get(key)) is not None:\n",
          "display_code": "        if (cached := cache.get(key)) is not None:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 69,
          "line_range": [
            69,
            69
          ]
        },
        {
          "code": "            # Deserialize from JSON based on the return type\n",
          "display_code": "",
          "annotation": "Deserialize from JSON based on the return type",
          "is_comment": true,
          "start_line": 70,
          "line_range": [
            70,
            70
          ],
          "target_line_range": [
            71,
            72
          ]
        },
        {
          "code": "            return return_type.model_validate_json(cached)\n\n",
          "display_code": "            return return_type.model_validate_json(cached)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 71,
          "line_range": [
            71,
            72
          ]
        },
        {
          "code": "        # Call the function and cache its result\n",
          "display_code": "",
          "annotation": "Call the function and cache its result",
          "is_comment": true,
          "start_line": 73,
          "line_range": [
            73,
            73
          ],
          "target_line_range": [
            74,
            81
          ]
        },
        {
          "code": "        result = func(*args, **kwargs)\n        serialized_result = result.model_dump_json()\n        cache.set(key, serialized_result)\n\n        return result\n\n    return wrapper\n\n",
          "display_code": "        result = func(*args, **kwargs)\n        serialized_result = result.model_dump_json()\n        cache.set(key, serialized_result)\n\n        return result\n\n    return wrapper\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 74,
          "line_range": [
            74,
            81
          ]
        },
        {
          "code": "# Define a model\n",
          "display_code": "",
          "annotation": "Define a model",
          "is_comment": true,
          "start_line": 82,
          "line_range": [
            82,
            82
          ],
          "target_line_range": [
            83,
            87
          ]
        },
        {
          "code": "class Product(BaseModel):\n    name: str\n    price: float\n    category: str\n\n",
          "display_code": "class Product(BaseModel):\n    name: str\n    price: float\n    category: str\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 83,
          "line_range": [
            83,
            87
          ]
        },
        {
          "code": "# Use the caching decorator\n",
          "display_code": "",
          "annotation": "Use the caching decorator",
          "is_comment": true,
          "start_line": 88,
          "line_range": [
            88,
            88
          ],
          "target_line_range": [
            89,
            102
          ]
        },
        {
          "code": "@instructor_cache\ndef extract_product(text: str) -> Product:\n    \"\"\"Extract product information with disk caching.\"\"\"\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=Product,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Extract product information from: {text}\"\n            }\n        ]\n    )\n\n",
          "display_code": "@instructor_cache\ndef extract_product(text: str) -> Product:\n    \"\"\"Extract product information with disk caching.\"\"\"\n    return client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=Product,\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Extract product information from: {text}\"\n            }\n        ]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 89,
          "line_range": [
            89,
            102
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 103,
          "line_range": [
            103,
            103
          ],
          "target_line_range": [
            104,
            106
          ]
        },
        {
          "code": "product = extract_product(\"iPhone 14 Pro costs $999 and is in the smartphones category\")\nprint(product)\n\n",
          "display_code": "product = extract_product(\"iPhone 14 Pro costs $999 and is in the smartphones category\")\nprint(product)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 104,
          "line_range": [
            104,
            106
          ]
        },
        {
          "code": "# For distributed systems, Redis caching is a great option:\n",
          "display_code": "",
          "annotation": "For distributed systems, Redis caching is a great option:",
          "is_comment": true,
          "start_line": 107,
          "line_range": [
            107,
            107
          ],
          "target_line_range": [
            108,
            114
          ]
        },
        {
          "code": "import redis\nimport functools\nimport inspect\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\n",
          "display_code": "import redis\nimport functools\nimport inspect\nimport instructor\nfrom openai import OpenAI\nfrom pydantic import BaseModel\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 108,
          "line_range": [
            108,
            114
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 115,
          "line_range": [
            115,
            115
          ],
          "target_line_range": [
            116,
            117
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 116,
          "line_range": [
            116,
            117
          ]
        },
        {
          "code": "# Initialize Redis cache\n",
          "display_code": "",
          "annotation": "Initialize Redis cache",
          "is_comment": true,
          "start_line": 118,
          "line_range": [
            118,
            118
          ],
          "target_line_range": [
            119,
            120
          ]
        },
        {
          "code": "cache = redis.Redis(host=\"localhost\", port=6379, db=0)\n\n",
          "display_code": "cache = redis.Redis(host=\"localhost\", port=6379, db=0)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 119,
          "line_range": [
            119,
            120
          ]
        },
        {
          "code": "# Define a caching decorator for Redis\n",
          "display_code": "",
          "annotation": "Define a caching decorator for Redis",
          "is_comment": true,
          "start_line": 121,
          "line_range": [
            121,
            121
          ],
          "target_line_range": [
            122,
            129
          ]
        },
        {
          "code": "def redis_cache(func):\n    \"\"\"Cache a function that returns a Pydantic model using Redis.\"\"\"\n    return_type = inspect.signature(func).return_annotation\n    if not issubclass(return_type, BaseModel):\n        raise ValueError(\"The return type must be a Pydantic model\")\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n",
          "display_code": "def redis_cache(func):\n    \"\"\"Cache a function that returns a Pydantic model using Redis.\"\"\"\n    return_type = inspect.signature(func).return_annotation\n    if not issubclass(return_type, BaseModel):\n        raise ValueError(\"The return type must be a Pydantic model\")\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 122,
          "line_range": [
            122,
            129
          ]
        },
        {
          "code": "        # Create a cache key from the function name and arguments\n",
          "display_code": "",
          "annotation": "Create a cache key from the function name and arguments",
          "is_comment": true,
          "start_line": 130,
          "line_range": [
            130,
            130
          ],
          "target_line_range": [
            131,
            132
          ]
        },
        {
          "code": "        key = f\"{func.__name__}-{functools._make_key(args, kwargs, typed=False)}\"\n\n",
          "display_code": "        key = f\"{func.__name__}-{functools._make_key(args, kwargs, typed=False)}\"\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 131,
          "line_range": [
            131,
            132
          ]
        },
        {
          "code": "        # Check if result is already cached\n",
          "display_code": "",
          "annotation": "Check if result is already cached",
          "is_comment": true,
          "start_line": 133,
          "line_range": [
            133,
            133
          ],
          "target_line_range": [
            134,
            134
          ]
        },
        {
          "code": "        if (cached := cache.get(key)) is not None:\n",
          "display_code": "        if (cached := cache.get(key)) is not None:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 134,
          "line_range": [
            134,
            134
          ]
        },
        {
          "code": "            # Deserialize from JSON based on the return type\n",
          "display_code": "",
          "annotation": "Deserialize from JSON based on the return type",
          "is_comment": true,
          "start_line": 135,
          "line_range": [
            135,
            135
          ],
          "target_line_range": [
            136,
            137
          ]
        },
        {
          "code": "            return return_type.model_validate_json(cached)\n\n",
          "display_code": "            return return_type.model_validate_json(cached)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 136,
          "line_range": [
            136,
            137
          ]
        },
        {
          "code": "        # Call the function and cache its result\n",
          "display_code": "",
          "annotation": "Call the function and cache its result",
          "is_comment": true,
          "start_line": 138,
          "line_range": [
            138,
            138
          ],
          "target_line_range": [
            139,
            146
          ]
        },
        {
          "code": "        result = func(*args, **kwargs)\n        serialized_result = result.model_dump_json()\n        cache.set(key, serialized_result)\n\n        return result\n\n    return wrapper\n\n",
          "display_code": "        result = func(*args, **kwargs)\n        serialized_result = result.model_dump_json()\n        cache.set(key, serialized_result)\n\n        return result\n\n    return wrapper\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 139,
          "line_range": [
            139,
            146
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python caching-responses.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "009-performance",
      "section_title": "Performance and Optimization"
    },
    {
      "id": "044-parallel-extraction",
      "title": "Parallel Extraction",
      "description": "",
      "order": 44,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# - More efficient use of context window for related extractions\n",
          "display_code": "",
          "annotation": "- More efficient use of context window for related extractions",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor supports parallel function calling, allowing you to extract multiple pieces of information simultaneously. This can significantly reduce latency in your applications.\n",
          "display_code": "",
          "annotation": "Instructor supports parallel function calling, allowing you to extract multiple pieces of information simultaneously. This can significantly reduce latency in your applications.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "import instructor\nfrom openai import OpenAI\nfrom typing import Iterable, Literal, Union\nfrom pydantic import BaseModel\n\n",
          "display_code": "import instructor\nfrom openai import OpenAI\nfrom typing import Iterable, Literal, Union\nfrom pydantic import BaseModel\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor in parallel mode\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor in parallel mode",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI(), mode=instructor.Mode.PARALLEL_TOOLS)\n\n",
          "display_code": "client = instructor.from_openai(OpenAI(), mode=instructor.Mode.PARALLEL_TOOLS)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define multiple response models\n",
          "display_code": "",
          "annotation": "Define multiple response models",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            21
          ]
        },
        {
          "code": "class Weather(BaseModel):\n    location: str\n    units: Literal[\"imperial\", \"metric\"]\n\nclass SearchQuery(BaseModel):\n    query: str\n\n",
          "display_code": "class Weather(BaseModel):\n    location: str\n    units: Literal[\"imperial\", \"metric\"]\n\nclass SearchQuery(BaseModel):\n    query: str\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            21
          ]
        },
        {
          "code": "# Extract multiple pieces of information in parallel\n",
          "display_code": "",
          "annotation": "Extract multiple pieces of information in parallel",
          "is_comment": true,
          "start_line": 22,
          "line_range": [
            22,
            22
          ],
          "target_line_range": [
            23,
            35
          ]
        },
        {
          "code": "def extract_parallel_info(user_query: str) -> list[Union[Weather, SearchQuery]]:\n    function_calls = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"You must always use tools\"},\n            {\n                \"role\": \"user\",\n                \"content\": user_query\n            }\n        ],\n        response_model=Iterable[Weather | SearchQuery]\n    )\n\n",
          "display_code": "def extract_parallel_info(user_query: str) -> list[Union[Weather, SearchQuery]]:\n    function_calls = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"You must always use tools\"},\n            {\n                \"role\": \"user\",\n                \"content\": user_query\n            }\n        ],\n        response_model=Iterable[Weather | SearchQuery]\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 23,
          "line_range": [
            23,
            35
          ]
        },
        {
          "code": "    # Convert the iterable to a list\n",
          "display_code": "",
          "annotation": "Convert the iterable to a list",
          "is_comment": true,
          "start_line": 36,
          "line_range": [
            36,
            36
          ],
          "target_line_range": [
            37,
            38
          ]
        },
        {
          "code": "    return list(function_calls)\n\n",
          "display_code": "    return list(function_calls)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 37,
          "line_range": [
            37,
            38
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 39,
          "line_range": [
            39,
            39
          ],
          "target_line_range": [
            40,
            49
          ]
        },
        {
          "code": "results = extract_parallel_info(\n    \"What's the weather in New York and Tokyo? Also, find information about renewable energy.\"\n)\n\nfor result in results:\n    if isinstance(result, Weather):\n        print(f\"Weather request for {result.location} in {result.units} units\")\n    elif isinstance(result, SearchQuery):\n        print(f\"Search query: {result.query}\")\n\n",
          "display_code": "results = extract_parallel_info(\n    \"What's the weather in New York and Tokyo? Also, find information about renewable energy.\"\n)\n\nfor result in results:\n    if isinstance(result, Weather):\n        print(f\"Weather request for {result.location} in {result.units} units\")\n    elif isinstance(result, SearchQuery):\n        print(f\"Search query: {result.query}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 40,
          "line_range": [
            40,
            49
          ]
        },
        {
          "code": "# You can also define more complex parallel extractions:\n",
          "display_code": "",
          "annotation": "You can also define more complex parallel extractions:",
          "is_comment": true,
          "start_line": 50,
          "line_range": [
            50,
            50
          ],
          "target_line_range": [
            51,
            55
          ]
        },
        {
          "code": "from typing import Iterable, Union\nfrom pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\n\n",
          "display_code": "from typing import Iterable, Union\nfrom pydantic import BaseModel, Field\nimport instructor\nfrom openai import OpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 51,
          "line_range": [
            51,
            55
          ]
        },
        {
          "code": "# Initialize client with parallel mode\n",
          "display_code": "",
          "annotation": "Initialize client with parallel mode",
          "is_comment": true,
          "start_line": 56,
          "line_range": [
            56,
            56
          ],
          "target_line_range": [
            57,
            58
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI(), mode=instructor.Mode.PARALLEL_TOOLS)\n\n",
          "display_code": "client = instructor.from_openai(OpenAI(), mode=instructor.Mode.PARALLEL_TOOLS)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 57,
          "line_range": [
            57,
            58
          ]
        },
        {
          "code": "# Define extraction models\n",
          "display_code": "",
          "annotation": "Define extraction models",
          "is_comment": true,
          "start_line": 59,
          "line_range": [
            59,
            59
          ],
          "target_line_range": [
            60,
            74
          ]
        },
        {
          "code": "class Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\nclass Company(BaseModel):\n    name: str\n    industry: str\n    year_founded: int\n\nclass Location(BaseModel):\n    city: str\n    country: str\n    population: int = Field(description=\"Approximate population\")\n\n",
          "display_code": "class Person(BaseModel):\n    name: str\n    age: int\n    occupation: str\n\nclass Company(BaseModel):\n    name: str\n    industry: str\n    year_founded: int\n\nclass Location(BaseModel):\n    city: str\n    country: str\n    population: int = Field(description=\"Approximate population\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 60,
          "line_range": [
            60,
            74
          ]
        },
        {
          "code": "# Extract multiple entity types from text\n",
          "display_code": "",
          "annotation": "Extract multiple entity types from text",
          "is_comment": true,
          "start_line": 75,
          "line_range": [
            75,
            75
          ],
          "target_line_range": [
            76,
            87
          ]
        },
        {
          "code": "def extract_entities(text: str) -> list[Union[Person, Company, Location]]:\n    results = client.chat.completions.create(\n        model=\"gpt-4-turbo\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"Extract all relevant entities from the text.\"},\n            {\"role\": \"user\", \"content\": text}\n        ],\n        response_model=Iterable[Person | Company | Location]\n    )\n\n    return list(results)\n\n",
          "display_code": "def extract_entities(text: str) -> list[Union[Person, Company, Location]]:\n    results = client.chat.completions.create(\n        model=\"gpt-4-turbo\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"Extract all relevant entities from the text.\"},\n            {\"role\": \"user\", \"content\": text}\n        ],\n        response_model=Iterable[Person | Company | Location]\n    )\n\n    return list(results)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 76,
          "line_range": [
            76,
            87
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 88,
          "line_range": [
            88,
            88
          ],
          "target_line_range": [
            89,
            98
          ]
        },
        {
          "code": "text = \"\"\"\nJohn Smith is a 35-year-old software engineer living in San Francisco, USA,\na city with about 815,000 people. He works at TechCorp, a software development\ncompany founded in 2005 that specializes in AI applications. His colleague\nMaria Rodriguez, 29, is a data scientist who recently moved from Madrid, Spain,\na city of approximately 3.2 million people.\n\"\"\"\n\nentities = extract_entities(text)\n\n",
          "display_code": "text = \"\"\"\nJohn Smith is a 35-year-old software engineer living in San Francisco, USA,\na city with about 815,000 people. He works at TechCorp, a software development\ncompany founded in 2005 that specializes in AI applications. His colleague\nMaria Rodriguez, 29, is a data scientist who recently moved from Madrid, Spain,\na city of approximately 3.2 million people.\n\"\"\"\n\nentities = extract_entities(text)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 89,
          "line_range": [
            89,
            98
          ]
        },
        {
          "code": "# Process different entity types\n",
          "display_code": "",
          "annotation": "Process different entity types",
          "is_comment": true,
          "start_line": 99,
          "line_range": [
            99,
            99
          ],
          "target_line_range": [
            100,
            105
          ]
        },
        {
          "code": "people = [e for e in entities if isinstance(e, Person)]\ncompanies = [e for e in entities if isinstance(e, Company)]\nlocations = [e for e in entities if isinstance(e, Location)]\n\nprint(f\"Found {len(people)} people, {len(companies)} companies, and {len(locations)} locations\")\n\n",
          "display_code": "people = [e for e in entities if isinstance(e, Person)]\ncompanies = [e for e in entities if isinstance(e, Company)]\nlocations = [e for e in entities if isinstance(e, Location)]\n\nprint(f\"Found {len(people)} people, {len(companies)} companies, and {len(locations)} locations\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 100,
          "line_range": [
            100,
            105
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python parallel-extraction.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "009-performance",
      "section_title": "Performance and Optimization"
    },
    {
      "id": "045-batch-processing",
      "title": "Batch Processing",
      "description": "",
      "order": 45,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# - Structured output for easy data analysis\n",
          "display_code": "",
          "annotation": "- Structured output for easy data analysis",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor supports batch processing for efficiently handling multiple requests, which is essential for large-scale data processing.\n",
          "display_code": "",
          "annotation": "Instructor supports batch processing for efficiently handling multiple requests, which is essential for large-scale data processing.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            11
          ]
        },
        {
          "code": "import asyncio\nimport instructor\nfrom openai import AsyncOpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List, Tuple\n\n",
          "display_code": "import asyncio\nimport instructor\nfrom openai import AsyncOpenAI\nfrom pydantic import BaseModel, Field\nfrom typing import List, Tuple\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            11
          ]
        },
        {
          "code": "# Initialize the async client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the async client with instructor",
          "is_comment": true,
          "start_line": 12,
          "line_range": [
            12,
            12
          ],
          "target_line_range": [
            13,
            14
          ]
        },
        {
          "code": "client = instructor.from_openai(AsyncOpenAI())\n\n",
          "display_code": "client = instructor.from_openai(AsyncOpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 13,
          "line_range": [
            13,
            14
          ]
        },
        {
          "code": "# Semaphore to limit concurrent requests (respect API rate limits)\n",
          "display_code": "",
          "annotation": "Semaphore to limit concurrent requests (respect API rate limits)",
          "is_comment": true,
          "start_line": 15,
          "line_range": [
            15,
            15
          ],
          "target_line_range": [
            16,
            17
          ]
        },
        {
          "code": "sem = asyncio.Semaphore(5)\n\n",
          "display_code": "sem = asyncio.Semaphore(5)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 16,
          "line_range": [
            16,
            17
          ]
        },
        {
          "code": "# Define a model for sentiment analysis\n",
          "display_code": "",
          "annotation": "Define a model for sentiment analysis",
          "is_comment": true,
          "start_line": 18,
          "line_range": [
            18,
            18
          ],
          "target_line_range": [
            19,
            23
          ]
        },
        {
          "code": "class SentimentAnalysis(BaseModel):\n    sentiment: str = Field(description=\"The sentiment of the text (positive, negative, or neutral)\")\n    confidence: float = Field(description=\"Confidence score from 0.0 to 1.0\")\n    reasoning: str = Field(description=\"Brief explanation for the sentiment classification\")\n\n",
          "display_code": "class SentimentAnalysis(BaseModel):\n    sentiment: str = Field(description=\"The sentiment of the text (positive, negative, or neutral)\")\n    confidence: float = Field(description=\"Confidence score from 0.0 to 1.0\")\n    reasoning: str = Field(description=\"Brief explanation for the sentiment classification\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 19,
          "line_range": [
            19,
            23
          ]
        },
        {
          "code": "# Function to analyze sentiment of a single text\n",
          "display_code": "",
          "annotation": "Function to analyze sentiment of a single text",
          "is_comment": true,
          "start_line": 24,
          "line_range": [
            24,
            24
          ],
          "target_line_range": [
            25,
            38
          ]
        },
        {
          "code": "async def analyze_sentiment(text: str) -> Tuple[str, SentimentAnalysis]:\n    async with sem:  # Rate limiting\n        result = await client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            response_model=SentimentAnalysis,\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Analyze the sentiment of this text: {text}\"\n                }\n            ]\n        )\n        return text, result\n\n",
          "display_code": "async def analyze_sentiment(text: str) -> Tuple[str, SentimentAnalysis]:\n    async with sem:  # Rate limiting\n        result = await client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            response_model=SentimentAnalysis,\n            messages=[\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Analyze the sentiment of this text: {text}\"\n                }\n            ]\n        )\n        return text, result\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 25,
          "line_range": [
            25,
            38
          ]
        },
        {
          "code": "# Process a batch of texts\n",
          "display_code": "",
          "annotation": "Process a batch of texts",
          "is_comment": true,
          "start_line": 39,
          "line_range": [
            39,
            39
          ],
          "target_line_range": [
            40,
            40
          ]
        },
        {
          "code": "async def process_batch(texts: List[str]):\n",
          "display_code": "async def process_batch(texts: List[str]):\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 40,
          "line_range": [
            40,
            40
          ]
        },
        {
          "code": "    # Create tasks for all texts\n",
          "display_code": "",
          "annotation": "Create tasks for all texts",
          "is_comment": true,
          "start_line": 41,
          "line_range": [
            41,
            41
          ],
          "target_line_range": [
            42,
            43
          ]
        },
        {
          "code": "    tasks = [analyze_sentiment(text) for text in texts]\n\n",
          "display_code": "    tasks = [analyze_sentiment(text) for text in texts]\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 42,
          "line_range": [
            42,
            43
          ]
        },
        {
          "code": "    # Process tasks as they complete\n",
          "display_code": "",
          "annotation": "Process tasks as they complete",
          "is_comment": true,
          "start_line": 44,
          "line_range": [
            44,
            44
          ],
          "target_line_range": [
            45,
            56
          ]
        },
        {
          "code": "    results = []\n    for task in asyncio.as_completed(tasks):\n        original_text, sentiment = await task\n        results.append({\n            \"text\": original_text,\n            \"sentiment\": sentiment.sentiment,\n            \"confidence\": sentiment.confidence,\n            \"reasoning\": sentiment.reasoning\n        })\n\n    return results\n\n",
          "display_code": "    results = []\n    for task in asyncio.as_completed(tasks):\n        original_text, sentiment = await task\n        results.append({\n            \"text\": original_text,\n            \"sentiment\": sentiment.sentiment,\n            \"confidence\": sentiment.confidence,\n            \"reasoning\": sentiment.reasoning\n        })\n\n    return results\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 45,
          "line_range": [
            45,
            56
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 57,
          "line_range": [
            57,
            57
          ],
          "target_line_range": [
            58,
            74
          ]
        },
        {
          "code": "async def main():\n    texts = [\n        \"I absolutely love this product! It's amazing.\",\n        \"The service was terrible and the staff was rude.\",\n        \"The weather is cloudy today with a chance of rain.\",\n        \"I'm disappointed with the quality of this item.\",\n        \"The conference was informative and well-organized.\"\n    ]\n\n    results = await process_batch(texts)\n\n    for result in results:\n        print(f\"Text: {result['text']}\")\n        print(f\"Sentiment: {result['sentiment']} (Confidence: {result['confidence']:.2f})\")\n        print(f\"Reasoning: {result['reasoning']}\")\n        print(\"-\" * 50)\n\n",
          "display_code": "async def main():\n    texts = [\n        \"I absolutely love this product! It's amazing.\",\n        \"The service was terrible and the staff was rude.\",\n        \"The weather is cloudy today with a chance of rain.\",\n        \"I'm disappointed with the quality of this item.\",\n        \"The conference was informative and well-organized.\"\n    ]\n\n    results = await process_batch(texts)\n\n    for result in results:\n        print(f\"Text: {result['text']}\")\n        print(f\"Sentiment: {result['sentiment']} (Confidence: {result['confidence']:.2f})\")\n        print(f\"Reasoning: {result['reasoning']}\")\n        print(\"-\" * 50)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 58,
          "line_range": [
            58,
            74
          ]
        },
        {
          "code": "# Run the example\n",
          "display_code": "",
          "annotation": "Run the example",
          "is_comment": true,
          "start_line": 75,
          "line_range": [
            75,
            75
          ],
          "target_line_range": [
            76,
            78
          ]
        },
        {
          "code": "if __name__ == \"__main__\":\n    asyncio.run(main())\n\n",
          "display_code": "if __name__ == \"__main__\":\n    asyncio.run(main())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 76,
          "line_range": [
            76,
            78
          ]
        },
        {
          "code": "# For larger datasets, you can implement a more comprehensive batch processing solution:\n",
          "display_code": "",
          "annotation": "For larger datasets, you can implement a more comprehensive batch processing solution:",
          "is_comment": true,
          "start_line": 79,
          "line_range": [
            79,
            79
          ],
          "target_line_range": [
            80,
            87
          ]
        },
        {
          "code": "import json\nimport asyncio\nimport instructor\nfrom openai import AsyncOpenAI\nfrom pydantic import BaseModel, Field\nfrom enum import Enum\nfrom typing import List, Dict, Any, Optional\n\n",
          "display_code": "import json\nimport asyncio\nimport instructor\nfrom openai import AsyncOpenAI\nfrom pydantic import BaseModel, Field\nfrom enum import Enum\nfrom typing import List, Dict, Any, Optional\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 80,
          "line_range": [
            80,
            87
          ]
        },
        {
          "code": "# Initialize the client\n",
          "display_code": "",
          "annotation": "Initialize the client",
          "is_comment": true,
          "start_line": 88,
          "line_range": [
            88,
            88
          ],
          "target_line_range": [
            89,
            90
          ]
        },
        {
          "code": "client = instructor.from_openai(AsyncOpenAI())\n\n",
          "display_code": "client = instructor.from_openai(AsyncOpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 89,
          "line_range": [
            89,
            90
          ]
        },
        {
          "code": "# Define classification types\n",
          "display_code": "",
          "annotation": "Define classification types",
          "is_comment": true,
          "start_line": 91,
          "line_range": [
            91,
            91
          ],
          "target_line_range": [
            92,
            103
          ]
        },
        {
          "code": "class Category(str, Enum):\n    PRODUCT = \"PRODUCT\"\n    SERVICE = \"SERVICE\"\n    FEATURE = \"FEATURE\"\n    SUPPORT = \"SUPPORT\"\n    OTHER = \"OTHER\"\n\nclass FeedbackClassification(BaseModel):\n    categories: List[Category] = Field(description=\"Categories that apply to this feedback\")\n    priority: int = Field(description=\"Priority score from 1-5, where 5 is highest priority\", ge=1, le=5)\n    analysis: str = Field(description=\"Brief analysis of the feedback\")\n\n",
          "display_code": "class Category(str, Enum):\n    PRODUCT = \"PRODUCT\"\n    SERVICE = \"SERVICE\"\n    FEATURE = \"FEATURE\"\n    SUPPORT = \"SUPPORT\"\n    OTHER = \"OTHER\"\n\nclass FeedbackClassification(BaseModel):\n    categories: List[Category] = Field(description=\"Categories that apply to this feedback\")\n    priority: int = Field(description=\"Priority score from 1-5, where 5 is highest priority\", ge=1, le=5)\n    analysis: str = Field(description=\"Brief analysis of the feedback\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 92,
          "line_range": [
            92,
            103
          ]
        },
        {
          "code": "# Process function with error handling and retries\n",
          "display_code": "",
          "annotation": "Process function with error handling and retries",
          "is_comment": true,
          "start_line": 104,
          "line_range": [
            104,
            104
          ],
          "target_line_range": [
            105,
            139
          ]
        },
        {
          "code": "async def process_item(item: str, retry_count: int = 2) -> Dict[str, Any]:\n    attempts = 0\n    while attempts <= retry_count:\n        try:\n            result = await client.chat.completions.create(\n                model=\"gpt-3.5-turbo\",\n                response_model=FeedbackClassification,\n                messages=[\n                    {\n                        \"role\": \"system\",\n                        \"content\": \"You are a customer feedback analyzer. Categorize and prioritize the feedback.\"\n                    },\n                    {\n                        \"role\": \"user\",\n                        \"content\": f\"Analyze this feedback: {item}\"\n                    }\n                ]\n            )\n            return {\n                \"feedback\": item,\n                \"categories\": [c.value for c in result.categories],\n                \"priority\": result.priority,\n                \"analysis\": result.analysis,\n                \"status\": \"success\"\n            }\n        except Exception as e:\n            attempts += 1\n            if attempts > retry_count:\n                return {\n                    \"feedback\": item,\n                    \"error\": str(e),\n                    \"status\": \"failed\"\n                }\n            await asyncio.sleep(1)  # Backoff before retry\n\n",
          "display_code": "async def process_item(item: str, retry_count: int = 2) -> Dict[str, Any]:\n    attempts = 0\n    while attempts <= retry_count:\n        try:\n            result = await client.chat.completions.create(\n                model=\"gpt-3.5-turbo\",\n                response_model=FeedbackClassification,\n                messages=[\n                    {\n                        \"role\": \"system\",\n                        \"content\": \"You are a customer feedback analyzer. Categorize and prioritize the feedback.\"\n                    },\n                    {\n                        \"role\": \"user\",\n                        \"content\": f\"Analyze this feedback: {item}\"\n                    }\n                ]\n            )\n            return {\n                \"feedback\": item,\n                \"categories\": [c.value for c in result.categories],\n                \"priority\": result.priority,\n                \"analysis\": result.analysis,\n                \"status\": \"success\"\n            }\n        except Exception as e:\n            attempts += 1\n            if attempts > retry_count:\n                return {\n                    \"feedback\": item,\n                    \"error\": str(e),\n                    \"status\": \"failed\"\n                }\n            await asyncio.sleep(1)  # Backoff before retry\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 105,
          "line_range": [
            105,
            139
          ]
        },
        {
          "code": "# Batch processor with chunking and progress tracking\n",
          "display_code": "",
          "annotation": "Batch processor with chunking and progress tracking",
          "is_comment": true,
          "start_line": 140,
          "line_range": [
            140,
            140
          ],
          "target_line_range": [
            141,
            150
          ]
        },
        {
          "code": "async def batch_process(items: List[str],\n                        chunk_size: int = 10,\n                        concurrency_limit: int = 5,\n                        output_file: Optional[str] = None):\n\n    sem = asyncio.Semaphore(concurrency_limit)\n    results = []\n    processed = 0\n    total = len(items)\n\n",
          "display_code": "async def batch_process(items: List[str],\n                        chunk_size: int = 10,\n                        concurrency_limit: int = 5,\n                        output_file: Optional[str] = None):\n\n    sem = asyncio.Semaphore(concurrency_limit)\n    results = []\n    processed = 0\n    total = len(items)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 141,
          "line_range": [
            141,
            150
          ]
        },
        {
          "code": "    # Process in chunks to avoid memory issues with very large datasets\n",
          "display_code": "",
          "annotation": "Process in chunks to avoid memory issues with very large datasets",
          "is_comment": true,
          "start_line": 151,
          "line_range": [
            151,
            151
          ],
          "target_line_range": [
            152,
            154
          ]
        },
        {
          "code": "    for i in range(0, total, chunk_size):\n        chunk = items[i:i+chunk_size]\n\n",
          "display_code": "    for i in range(0, total, chunk_size):\n        chunk = items[i:i+chunk_size]\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 152,
          "line_range": [
            152,
            154
          ]
        },
        {
          "code": "        # Create tasks with semaphore for rate limiting\n",
          "display_code": "",
          "annotation": "Create tasks with semaphore for rate limiting",
          "is_comment": true,
          "start_line": 155,
          "line_range": [
            155,
            155
          ],
          "target_line_range": [
            156,
            161
          ]
        },
        {
          "code": "        async def process_with_sem(item):\n            async with sem:\n                return await process_item(item)\n\n        tasks = [process_with_sem(item) for item in chunk]\n\n",
          "display_code": "        async def process_with_sem(item):\n            async with sem:\n                return await process_item(item)\n\n        tasks = [process_with_sem(item) for item in chunk]\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 156,
          "line_range": [
            156,
            161
          ]
        },
        {
          "code": "        # Process chunk and update progress\n",
          "display_code": "",
          "annotation": "Process chunk and update progress",
          "is_comment": true,
          "start_line": 162,
          "line_range": [
            162,
            162
          ],
          "target_line_range": [
            163,
            168
          ]
        },
        {
          "code": "        chunk_results = await asyncio.gather(*tasks)\n        results.extend(chunk_results)\n\n        processed += len(chunk)\n        print(f\"Progress: {processed}/{total} ({processed/total*100:.1f}%)\")\n\n",
          "display_code": "        chunk_results = await asyncio.gather(*tasks)\n        results.extend(chunk_results)\n\n        processed += len(chunk)\n        print(f\"Progress: {processed}/{total} ({processed/total*100:.1f}%)\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 163,
          "line_range": [
            163,
            168
          ]
        },
        {
          "code": "        # Optionally save results to file incrementally\n",
          "display_code": "",
          "annotation": "Optionally save results to file incrementally",
          "is_comment": true,
          "start_line": 169,
          "line_range": [
            169,
            169
          ],
          "target_line_range": [
            170,
            176
          ]
        },
        {
          "code": "        if output_file:\n            with open(output_file, \"a\") as f:\n                for result in chunk_results:\n                    f.write(json.dumps(result) + \"\\n\")\n\n    return results\n\n",
          "display_code": "        if output_file:\n            with open(output_file, \"a\") as f:\n                for result in chunk_results:\n                    f.write(json.dumps(result) + \"\\n\")\n\n    return results\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 170,
          "line_range": [
            170,
            176
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 177,
          "line_range": [
            177,
            177
          ],
          "target_line_range": [
            178,
            178
          ]
        },
        {
          "code": "async def main():\n",
          "display_code": "async def main():\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 178,
          "line_range": [
            178,
            178
          ]
        },
        {
          "code": "    # Sample feedback data\n",
          "display_code": "",
          "annotation": "Sample feedback data",
          "is_comment": true,
          "start_line": 179,
          "line_range": [
            179,
            179
          ],
          "target_line_range": [
            180,
            184
          ]
        },
        {
          "code": "    feedback_items = [\n        \"Your app crashes every time I try to upload a photo. Please fix this ASAP!\",\n        \"I love the new dark mode feature. It makes the app much easier on the eyes.\",\n        \"The checkout process is too complicated. I gave up trying to make a purchase.\",\n        \"Your customer service rep was very helpful in resolving my issue.\",\n",
          "display_code": "    feedback_items = [\n        \"Your app crashes every time I try to upload a photo. Please fix this ASAP!\",\n        \"I love the new dark mode feature. It makes the app much easier on the eyes.\",\n        \"The checkout process is too complicated. I gave up trying to make a purchase.\",\n        \"Your customer service rep was very helpful in resolving my issue.\",\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 180,
          "line_range": [
            180,
            184
          ]
        },
        {
          "code": "        # Add more items as needed\n",
          "display_code": "",
          "annotation": "Add more items as needed",
          "is_comment": true,
          "start_line": 185,
          "line_range": [
            185,
            185
          ],
          "target_line_range": [
            186,
            192
          ]
        },
        {
          "code": "    ]\n\n    results = await batch_process(\n        items=feedback_items,\n        output_file=\"feedback_results.jsonl\"\n    )\n\n",
          "display_code": "    ]\n\n    results = await batch_process(\n        items=feedback_items,\n        output_file=\"feedback_results.jsonl\"\n    )\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 186,
          "line_range": [
            186,
            192
          ]
        },
        {
          "code": "    # Analyze results\n",
          "display_code": "",
          "annotation": "Analyze results",
          "is_comment": true,
          "start_line": 193,
          "line_range": [
            193,
            193
          ],
          "target_line_range": [
            194,
            196
          ]
        },
        {
          "code": "    success_count = sum(1 for r in results if r[\"status\"] == \"success\")\n    print(f\"Successfully processed: {success_count}/{len(results)}\")\n\n",
          "display_code": "    success_count = sum(1 for r in results if r[\"status\"] == \"success\")\n    print(f\"Successfully processed: {success_count}/{len(results)}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 194,
          "line_range": [
            194,
            196
          ]
        },
        {
          "code": "    # Calculate average priority\n",
          "display_code": "",
          "annotation": "Calculate average priority",
          "is_comment": true,
          "start_line": 197,
          "line_range": [
            197,
            197
          ],
          "target_line_range": [
            198,
            201
          ]
        },
        {
          "code": "    priorities = [r.get(\"priority\", 0) for r in results if r[\"status\"] == \"success\"]\n    if priorities:\n        print(f\"Average priority: {sum(priorities)/len(priorities):.1f}\")\n\n",
          "display_code": "    priorities = [r.get(\"priority\", 0) for r in results if r[\"status\"] == \"success\"]\n    if priorities:\n        print(f\"Average priority: {sum(priorities)/len(priorities):.1f}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 198,
          "line_range": [
            198,
            201
          ]
        },
        {
          "code": "    # Count categories\n",
          "display_code": "",
          "annotation": "Count categories",
          "is_comment": true,
          "start_line": 202,
          "line_range": [
            202,
            202
          ],
          "target_line_range": [
            203,
            215
          ]
        },
        {
          "code": "    categories = {}\n    for r in results:\n        if r[\"status\"] == \"success\":\n            for cat in r.get(\"categories\", []):\n                categories[cat] = categories.get(cat, 0) + 1\n\n    print(\"Category distribution:\")\n    for cat, count in categories.items():\n        print(f\"  {cat}: {count}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n\n",
          "display_code": "    categories = {}\n    for r in results:\n        if r[\"status\"] == \"success\":\n            for cat in r.get(\"categories\", []):\n                categories[cat] = categories.get(cat, 0) + 1\n\n    print(\"Category distribution:\")\n    for cat, count in categories.items():\n        print(f\"  {cat}: {count}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 203,
          "line_range": [
            203,
            215
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python batch-processing.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "009-performance",
      "section_title": "Performance and Optimization"
    },
    {
      "id": "046-hooks-and-callbacks",
      "title": "Hooks and Callbacks",
      "description": "",
      "order": 46,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# - Testing and mocking\n",
          "display_code": "",
          "annotation": "- Testing and mocking",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Instructor provides a powerful hooks system that allows you to intercept and handle events during the completion and parsing process. Hooks can be used for logging, error handling, and custom behaviors.\n",
          "display_code": "",
          "annotation": "Instructor provides a powerful hooks system that allows you to intercept and handle events during the completion and parsing process. Hooks can be used for logging, error handling, and custom behaviors.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "import instructor\nimport openai\nimport pprint\nfrom pydantic import BaseModel\n\n",
          "display_code": "import instructor\nimport openai\nimport pprint\nfrom pydantic import BaseModel\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(openai.OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(openai.OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define a simple response model\n",
          "display_code": "",
          "annotation": "Define a simple response model",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            18
          ]
        },
        {
          "code": "class User(BaseModel):\n    name: str\n    age: int\n\n",
          "display_code": "class User(BaseModel):\n    name: str\n    age: int\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            18
          ]
        },
        {
          "code": "# Define hook handlers\n",
          "display_code": "",
          "annotation": "Define hook handlers",
          "is_comment": true,
          "start_line": 19,
          "line_range": [
            19,
            19
          ],
          "target_line_range": [
            20,
            35
          ]
        },
        {
          "code": "def log_completion_kwargs(*args, **kwargs):\n    \"\"\"Log all arguments passed to the completion function.\"\"\"\n    print(\"Arguments sent to completion:\")\n    pprint.pprint(kwargs)\n\ndef log_completion_response(response):\n    \"\"\"Log the raw response from the API.\"\"\"\n    print(\"API Response received:\")\n    print(f\"Model: {response.model}\")\n    print(f\"Usage: {response.usage.total_tokens} tokens\")\n\ndef handle_error(error):\n    \"\"\"Handle any errors that occur during completion.\"\"\"\n    print(f\"Error type: {type(error).__name__}\")\n    print(f\"Error message: {str(error)}\")\n\n",
          "display_code": "def log_completion_kwargs(*args, **kwargs):\n    \"\"\"Log all arguments passed to the completion function.\"\"\"\n    print(\"Arguments sent to completion:\")\n    pprint.pprint(kwargs)\n\ndef log_completion_response(response):\n    \"\"\"Log the raw response from the API.\"\"\"\n    print(\"API Response received:\")\n    print(f\"Model: {response.model}\")\n    print(f\"Usage: {response.usage.total_tokens} tokens\")\n\ndef handle_error(error):\n    \"\"\"Handle any errors that occur during completion.\"\"\"\n    print(f\"Error type: {type(error).__name__}\")\n    print(f\"Error message: {str(error)}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 20,
          "line_range": [
            20,
            35
          ]
        },
        {
          "code": "# Register the hooks\n",
          "display_code": "",
          "annotation": "Register the hooks",
          "is_comment": true,
          "start_line": 36,
          "line_range": [
            36,
            36
          ],
          "target_line_range": [
            37,
            41
          ]
        },
        {
          "code": "client.on(\"completion:kwargs\", log_completion_kwargs)\nclient.on(\"completion:response\", log_completion_response)\nclient.on(\"completion:error\", handle_error)\nclient.on(\"parse:error\", handle_error)\n\n",
          "display_code": "client.on(\"completion:kwargs\", log_completion_kwargs)\nclient.on(\"completion:response\", log_completion_response)\nclient.on(\"completion:error\", handle_error)\nclient.on(\"parse:error\", handle_error)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 37,
          "line_range": [
            37,
            41
          ]
        },
        {
          "code": "# Make a request with registered hooks\n",
          "display_code": "",
          "annotation": "Make a request with registered hooks",
          "is_comment": true,
          "start_line": 42,
          "line_range": [
            42,
            42
          ],
          "target_line_range": [
            43,
            52
          ]
        },
        {
          "code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract the user info: John is 25 years old.\"}\n    ],\n    response_model=User\n)\n\nprint(\"Extracted user:\", user)\n\n",
          "display_code": "user = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Extract the user info: John is 25 years old.\"}\n    ],\n    response_model=User\n)\n\nprint(\"Extracted user:\", user)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 43,
          "line_range": [
            43,
            52
          ]
        },
        {
          "code": "# Removing a specific hook\n",
          "display_code": "",
          "annotation": "Removing a specific hook",
          "is_comment": true,
          "start_line": 53,
          "line_range": [
            53,
            53
          ],
          "target_line_range": [
            54,
            55
          ]
        },
        {
          "code": "client.off(\"completion:kwargs\", log_completion_kwargs)\n\n",
          "display_code": "client.off(\"completion:kwargs\", log_completion_kwargs)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 54,
          "line_range": [
            54,
            55
          ]
        },
        {
          "code": "# Clearing all hooks for a specific event\n",
          "display_code": "",
          "annotation": "Clearing all hooks for a specific event",
          "is_comment": true,
          "start_line": 56,
          "line_range": [
            56,
            56
          ],
          "target_line_range": [
            57,
            58
          ]
        },
        {
          "code": "client.clear(\"completion:error\")\n\n",
          "display_code": "client.clear(\"completion:error\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 57,
          "line_range": [
            57,
            58
          ]
        },
        {
          "code": "# Clearing all hooks\n",
          "display_code": "",
          "annotation": "Clearing all hooks",
          "is_comment": true,
          "start_line": 59,
          "line_range": [
            59,
            59
          ],
          "target_line_range": [
            60,
            61
          ]
        },
        {
          "code": "client.clear()\n\n",
          "display_code": "client.clear()\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 60,
          "line_range": [
            60,
            61
          ]
        },
        {
          "code": "# You can also use hooks for more advanced use cases such as telemetry or performance monitoring:\n",
          "display_code": "",
          "annotation": "You can also use hooks for more advanced use cases such as telemetry or performance monitoring:",
          "is_comment": true,
          "start_line": 62,
          "line_range": [
            62,
            62
          ],
          "target_line_range": [
            63,
            67
          ]
        },
        {
          "code": "import time\nimport instructor\nimport openai\nfrom pydantic import BaseModel\n\n",
          "display_code": "import time\nimport instructor\nimport openai\nfrom pydantic import BaseModel\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 63,
          "line_range": [
            63,
            67
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 68,
          "line_range": [
            68,
            68
          ],
          "target_line_range": [
            69,
            70
          ]
        },
        {
          "code": "client = instructor.from_openai(openai.OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(openai.OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 69,
          "line_range": [
            69,
            70
          ]
        },
        {
          "code": "# Track performance metrics\n",
          "display_code": "",
          "annotation": "Track performance metrics",
          "is_comment": true,
          "start_line": 71,
          "line_range": [
            71,
            71
          ],
          "target_line_range": [
            72,
            108
          ]
        },
        {
          "code": "class Metrics:\n    def __init__(self):\n        self.request_times = []\n        self.token_counts = []\n        self.error_count = 0\n        self.request_start_time = None\n\n    def start_request(self, *args, **kwargs):\n        self.request_start_time = time.time()\n\n    def end_request(self, response):\n        if self.request_start_time is not None:\n            elapsed = time.time() - self.request_start_time\n            self.request_times.append(elapsed)\n            self.token_counts.append(response.usage.total_tokens)\n            print(f\"Request completed in {elapsed:.2f}s, {response.usage.total_tokens} tokens\")\n\n    def record_error(self, error):\n        self.error_count += 1\n        print(f\"Error recorded: {str(error)}\")\n\n    def report(self):\n        if not self.request_times:\n            return \"No requests recorded.\"\n\n        avg_time = sum(self.request_times) / len(self.request_times)\n        avg_tokens = sum(self.token_counts) / len(self.token_counts)\n        total_tokens = sum(self.token_counts)\n\n        return {\n            \"total_requests\": len(self.request_times),\n            \"avg_request_time\": f\"{avg_time:.2f}s\",\n            \"avg_tokens_per_request\": int(avg_tokens),\n            \"total_tokens\": total_tokens,\n            \"error_count\": self.error_count\n        }\n\n",
          "display_code": "class Metrics:\n    def __init__(self):\n        self.request_times = []\n        self.token_counts = []\n        self.error_count = 0\n        self.request_start_time = None\n\n    def start_request(self, *args, **kwargs):\n        self.request_start_time = time.time()\n\n    def end_request(self, response):\n        if self.request_start_time is not None:\n            elapsed = time.time() - self.request_start_time\n            self.request_times.append(elapsed)\n            self.token_counts.append(response.usage.total_tokens)\n            print(f\"Request completed in {elapsed:.2f}s, {response.usage.total_tokens} tokens\")\n\n    def record_error(self, error):\n        self.error_count += 1\n        print(f\"Error recorded: {str(error)}\")\n\n    def report(self):\n        if not self.request_times:\n            return \"No requests recorded.\"\n\n        avg_time = sum(self.request_times) / len(self.request_times)\n        avg_tokens = sum(self.token_counts) / len(self.token_counts)\n        total_tokens = sum(self.token_counts)\n\n        return {\n            \"total_requests\": len(self.request_times),\n            \"avg_request_time\": f\"{avg_time:.2f}s\",\n            \"avg_tokens_per_request\": int(avg_tokens),\n            \"total_tokens\": total_tokens,\n            \"error_count\": self.error_count\n        }\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 72,
          "line_range": [
            72,
            108
          ]
        },
        {
          "code": "# Create metrics tracker\n",
          "display_code": "",
          "annotation": "Create metrics tracker",
          "is_comment": true,
          "start_line": 109,
          "line_range": [
            109,
            109
          ],
          "target_line_range": [
            110,
            111
          ]
        },
        {
          "code": "metrics = Metrics()\n\n",
          "display_code": "metrics = Metrics()\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 110,
          "line_range": [
            110,
            111
          ]
        },
        {
          "code": "# Register hooks\n",
          "display_code": "",
          "annotation": "Register hooks",
          "is_comment": true,
          "start_line": 112,
          "line_range": [
            112,
            112
          ],
          "target_line_range": [
            113,
            117
          ]
        },
        {
          "code": "client.on(\"completion:kwargs\", metrics.start_request)\nclient.on(\"completion:response\", metrics.end_request)\nclient.on(\"completion:error\", metrics.record_error)\nclient.on(\"parse:error\", metrics.record_error)\n\n",
          "display_code": "client.on(\"completion:kwargs\", metrics.start_request)\nclient.on(\"completion:response\", metrics.end_request)\nclient.on(\"completion:error\", metrics.record_error)\nclient.on(\"parse:error\", metrics.record_error)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 113,
          "line_range": [
            113,
            117
          ]
        },
        {
          "code": "# Run a few example requests\n",
          "display_code": "",
          "annotation": "Run a few example requests",
          "is_comment": true,
          "start_line": 118,
          "line_range": [
            118,
            118
          ],
          "target_line_range": [
            119,
            140
          ]
        },
        {
          "code": "class Product(BaseModel):\n    name: str\n    price: float\n    category: str\n\nfor i, query in enumerate([\n    \"iPhone 13, $799, Smartphones\",\n    \"Air Fryer, $129.99, Kitchen Appliances\",\n    \"Nike Running Shoes, $89.95, Athletic Footwear\"\n]):\n    try:\n        product = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[\n                {\"role\": \"user\", \"content\": f\"Extract product info: {query}\"}\n            ],\n            response_model=Product\n        )\n        print(f\"Product {i+1}: {product.name}, ${product.price}, {product.category}\")\n    except Exception as e:\n        print(f\"Failed to extract product {i+1}: {e}\")\n\n",
          "display_code": "class Product(BaseModel):\n    name: str\n    price: float\n    category: str\n\nfor i, query in enumerate([\n    \"iPhone 13, $799, Smartphones\",\n    \"Air Fryer, $129.99, Kitchen Appliances\",\n    \"Nike Running Shoes, $89.95, Athletic Footwear\"\n]):\n    try:\n        product = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[\n                {\"role\": \"user\", \"content\": f\"Extract product info: {query}\"}\n            ],\n            response_model=Product\n        )\n        print(f\"Product {i+1}: {product.name}, ${product.price}, {product.category}\")\n    except Exception as e:\n        print(f\"Failed to extract product {i+1}: {e}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 119,
          "line_range": [
            119,
            140
          ]
        },
        {
          "code": "# Print performance report\n",
          "display_code": "",
          "annotation": "Print performance report",
          "is_comment": true,
          "start_line": 141,
          "line_range": [
            141,
            141
          ],
          "target_line_range": [
            142,
            146
          ]
        },
        {
          "code": "performance_report = metrics.report()\nprint(\"\\nPerformance Report:\")\nfor key, value in performance_report.items():\n    print(f\"  {key}: {value}\")\n\n",
          "display_code": "performance_report = metrics.report()\nprint(\"\\nPerformance Report:\")\nfor key, value in performance_report.items():\n    print(f\"  {key}: {value}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 142,
          "line_range": [
            142,
            146
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python hooks-and-callbacks.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "009-performance",
      "section_title": "Performance and Optimization"
    },
    {
      "id": "047-type-adapters",
      "title": "Type Adapters",
      "description": "",
      "order": 47,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# - Better error messaging for validation failures\n",
          "display_code": "",
          "annotation": "- Better error messaging for validation failures",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        },
        {
          "code": "# Pydantic's Type Adapter is a powerful feature that allows you to wrap arbitrary data parsing logic with Pydantic's validation. Instructor leverages this to provide flexible data conversion and validation.\n",
          "display_code": "",
          "annotation": "Pydantic's Type Adapter is a powerful feature that allows you to wrap arbitrary data parsing logic with Pydantic's validation. Instructor leverages this to provide flexible data conversion and validation.",
          "is_comment": true,
          "start_line": 5,
          "line_range": [
            5,
            5
          ],
          "target_line_range": [
            6,
            10
          ]
        },
        {
          "code": "from typing import List, Dict, Any\nfrom pydantic import TypeAdapter, BaseModel\nimport instructor\nfrom openai import OpenAI\n\n",
          "display_code": "from typing import List, Dict, Any\nfrom pydantic import TypeAdapter, BaseModel\nimport instructor\nfrom openai import OpenAI\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 6,
          "line_range": [
            6,
            10
          ]
        },
        {
          "code": "# Initialize the client with instructor\n",
          "display_code": "",
          "annotation": "Initialize the client with instructor",
          "is_comment": true,
          "start_line": 11,
          "line_range": [
            11,
            11
          ],
          "target_line_range": [
            12,
            13
          ]
        },
        {
          "code": "client = instructor.from_openai(OpenAI())\n\n",
          "display_code": "client = instructor.from_openai(OpenAI())\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 12,
          "line_range": [
            12,
            13
          ]
        },
        {
          "code": "# Define a model for validation\n",
          "display_code": "",
          "annotation": "Define a model for validation",
          "is_comment": true,
          "start_line": 14,
          "line_range": [
            14,
            14
          ],
          "target_line_range": [
            15,
            19
          ]
        },
        {
          "code": "class User(BaseModel):\n    name: str\n    age: int\n    skills: List[str]\n\n",
          "display_code": "class User(BaseModel):\n    name: str\n    age: int\n    skills: List[str]\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 15,
          "line_range": [
            15,
            19
          ]
        },
        {
          "code": "# Create a type adapter for a list of users\n",
          "display_code": "",
          "annotation": "Create a type adapter for a list of users",
          "is_comment": true,
          "start_line": 20,
          "line_range": [
            20,
            20
          ],
          "target_line_range": [
            21,
            22
          ]
        },
        {
          "code": "UserListAdapter = TypeAdapter(List[User])\n\n",
          "display_code": "UserListAdapter = TypeAdapter(List[User])\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 21,
          "line_range": [
            21,
            22
          ]
        },
        {
          "code": "# Define an extraction function\n",
          "display_code": "",
          "annotation": "Define an extraction function",
          "is_comment": true,
          "start_line": 23,
          "line_range": [
            23,
            23
          ],
          "target_line_range": [
            24,
            24
          ]
        },
        {
          "code": "def extract_users_from_text(text: str) -> List[User]:\n",
          "display_code": "def extract_users_from_text(text: str) -> List[User]:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 24,
          "line_range": [
            24,
            24
          ]
        },
        {
          "code": "    # Get raw JSON data from LLM\n",
          "display_code": "",
          "annotation": "Get raw JSON data from LLM",
          "is_comment": true,
          "start_line": 25,
          "line_range": [
            25,
            25
          ],
          "target_line_range": [
            26,
            37
          ]
        },
        {
          "code": "    raw_data = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Extract all users from this text as a JSON array: {text}\"\n            }\n        ],\n        response_format={\"type\": \"json_object\"},\n        temperature=0\n    ).choices[0].message.content\n\n",
          "display_code": "    raw_data = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=[\n            {\n                \"role\": \"user\",\n                \"content\": f\"Extract all users from this text as a JSON array: {text}\"\n            }\n        ],\n        response_format={\"type\": \"json_object\"},\n        temperature=0\n    ).choices[0].message.content\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 26,
          "line_range": [
            26,
            37
          ]
        },
        {
          "code": "    # Parse JSON\n",
          "display_code": "",
          "annotation": "Parse JSON",
          "is_comment": true,
          "start_line": 38,
          "line_range": [
            38,
            38
          ],
          "target_line_range": [
            39,
            41
          ]
        },
        {
          "code": "    import json\n    try:\n        data = json.loads(raw_data)\n",
          "display_code": "    import json\n    try:\n        data = json.loads(raw_data)\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 39,
          "line_range": [
            39,
            41
          ]
        },
        {
          "code": "        # Use type adapter for validation\n",
          "display_code": "",
          "annotation": "Use type adapter for validation",
          "is_comment": true,
          "start_line": 42,
          "line_range": [
            42,
            42
          ],
          "target_line_range": [
            43,
            48
          ]
        },
        {
          "code": "        users = UserListAdapter.validate_python(data.get(\"users\", []))\n        return users\n    except Exception as e:\n        print(f\"Error parsing data: {e}\")\n        return []\n\n",
          "display_code": "        users = UserListAdapter.validate_python(data.get(\"users\", []))\n        return users\n    except Exception as e:\n        print(f\"Error parsing data: {e}\")\n        return []\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 43,
          "line_range": [
            43,
            48
          ]
        },
        {
          "code": "# Example usage\n",
          "display_code": "",
          "annotation": "Example usage",
          "is_comment": true,
          "start_line": 49,
          "line_range": [
            49,
            49
          ],
          "target_line_range": [
            50,
            60
          ]
        },
        {
          "code": "text = \"\"\"\nTeam members:\n- John Smith, 32 years old, skills: Python, JavaScript, Docker\n- Maria Garcia, 28 years old, skills: UX Design, Figma, HTML/CSS\n- Alex Johnson, 35 years old, skills: Project Management, Agile, Scrum\n\"\"\"\n\nusers = extract_users_from_text(text)\nfor user in users:\n    print(f\"{user.name} ({user.age}): {', '.join(user.skills)}\")\n\n",
          "display_code": "text = \"\"\"\nTeam members:\n- John Smith, 32 years old, skills: Python, JavaScript, Docker\n- Maria Garcia, 28 years old, skills: UX Design, Figma, HTML/CSS\n- Alex Johnson, 35 years old, skills: Project Management, Agile, Scrum\n\"\"\"\n\nusers = extract_users_from_text(text)\nfor user in users:\n    print(f\"{user.name} ({user.age}): {', '.join(user.skills)}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 50,
          "line_range": [
            50,
            60
          ]
        },
        {
          "code": "# Type adapters can also be used with dictionaries and more complex structures:\n",
          "display_code": "",
          "annotation": "Type adapters can also be used with dictionaries and more complex structures:",
          "is_comment": true,
          "start_line": 61,
          "line_range": [
            61,
            61
          ],
          "target_line_range": [
            62,
            64
          ]
        },
        {
          "code": "from typing import Dict, List, Union, Any\nfrom pydantic import TypeAdapter, BaseModel, Field\n\n",
          "display_code": "from typing import Dict, List, Union, Any\nfrom pydantic import TypeAdapter, BaseModel, Field\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 62,
          "line_range": [
            62,
            64
          ]
        },
        {
          "code": "# Define some models\n",
          "display_code": "",
          "annotation": "Define some models",
          "is_comment": true,
          "start_line": 65,
          "line_range": [
            65,
            65
          ],
          "target_line_range": [
            66,
            77
          ]
        },
        {
          "code": "class Comment(BaseModel):\n    user: str\n    text: str\n    timestamp: str\n\nclass Post(BaseModel):\n    id: int\n    title: str\n    content: str\n    tags: List[str]\n    comments: List[Comment]\n\n",
          "display_code": "class Comment(BaseModel):\n    user: str\n    text: str\n    timestamp: str\n\nclass Post(BaseModel):\n    id: int\n    title: str\n    content: str\n    tags: List[str]\n    comments: List[Comment]\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 66,
          "line_range": [
            66,
            77
          ]
        },
        {
          "code": "# Create type adapters\n",
          "display_code": "",
          "annotation": "Create type adapters",
          "is_comment": true,
          "start_line": 78,
          "line_range": [
            78,
            78
          ],
          "target_line_range": [
            79,
            82
          ]
        },
        {
          "code": "CommentAdapter = TypeAdapter(Comment)\nPostAdapter = TypeAdapter(Post)\nPostDictAdapter = TypeAdapter(Dict[str, Post])\n\n",
          "display_code": "CommentAdapter = TypeAdapter(Comment)\nPostAdapter = TypeAdapter(Post)\nPostDictAdapter = TypeAdapter(Dict[str, Post])\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 79,
          "line_range": [
            79,
            82
          ]
        },
        {
          "code": "# Process raw data with type adapters\n",
          "display_code": "",
          "annotation": "Process raw data with type adapters",
          "is_comment": true,
          "start_line": 83,
          "line_range": [
            83,
            83
          ],
          "target_line_range": [
            84,
            92
          ]
        },
        {
          "code": "def process_comment(raw_comment: Dict[str, Any]) -> Comment:\n    return CommentAdapter.validate_python(raw_comment)\n\ndef process_post(raw_post: Dict[str, Any]) -> Post:\n    return PostAdapter.validate_python(raw_post)\n\ndef process_posts_dict(raw_posts: Dict[str, Any]) -> Dict[str, Post]:\n    return PostDictAdapter.validate_python(raw_posts)\n\n",
          "display_code": "def process_comment(raw_comment: Dict[str, Any]) -> Comment:\n    return CommentAdapter.validate_python(raw_comment)\n\ndef process_post(raw_post: Dict[str, Any]) -> Post:\n    return PostAdapter.validate_python(raw_post)\n\ndef process_posts_dict(raw_posts: Dict[str, Any]) -> Dict[str, Post]:\n    return PostDictAdapter.validate_python(raw_posts)\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 84,
          "line_range": [
            84,
            92
          ]
        },
        {
          "code": "# Example data\n",
          "display_code": "",
          "annotation": "Example data",
          "is_comment": true,
          "start_line": 93,
          "line_range": [
            93,
            93
          ],
          "target_line_range": [
            94,
            110
          ]
        },
        {
          "code": "raw_comment = {\n    \"user\": \"alice\",\n    \"text\": \"Great post!\",\n    \"timestamp\": \"2023-06-15T14:30:00Z\"\n}\n\nraw_post = {\n    \"id\": 1,\n    \"title\": \"Introduction to Type Adapters\",\n    \"content\": \"Type adapters are a powerful feature...\",\n    \"tags\": [\"pydantic\", \"python\", \"validation\"],\n    \"comments\": [\n        raw_comment,\n        {\"user\": \"bob\", \"text\": \"Thanks for sharing!\", \"timestamp\": \"2023-06-15T15:45:00Z\"}\n    ]\n}\n\n",
          "display_code": "raw_comment = {\n    \"user\": \"alice\",\n    \"text\": \"Great post!\",\n    \"timestamp\": \"2023-06-15T14:30:00Z\"\n}\n\nraw_post = {\n    \"id\": 1,\n    \"title\": \"Introduction to Type Adapters\",\n    \"content\": \"Type adapters are a powerful feature...\",\n    \"tags\": [\"pydantic\", \"python\", \"validation\"],\n    \"comments\": [\n        raw_comment,\n        {\"user\": \"bob\", \"text\": \"Thanks for sharing!\", \"timestamp\": \"2023-06-15T15:45:00Z\"}\n    ]\n}\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 94,
          "line_range": [
            94,
            110
          ]
        },
        {
          "code": "# Validate and convert the data\n",
          "display_code": "",
          "annotation": "Validate and convert the data",
          "is_comment": true,
          "start_line": 111,
          "line_range": [
            111,
            111
          ],
          "target_line_range": [
            112,
            117
          ]
        },
        {
          "code": "comment = process_comment(raw_comment)\npost = process_post(raw_post)\n\nprint(f\"Comment by {comment.user}: {comment.text}\")\nprint(f\"Post: {post.title} with {len(post.comments)} comments and tags: {', '.join(post.tags)}\")\n\n",
          "display_code": "comment = process_comment(raw_comment)\npost = process_post(raw_post)\n\nprint(f\"Comment by {comment.user}: {comment.text}\")\nprint(f\"Post: {post.title} with {len(post.comments)} comments and tags: {', '.join(post.tags)}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 112,
          "line_range": [
            112,
            117
          ]
        },
        {
          "code": "# Type adapters can be particularly useful when working with external APIs or complex data structures:\n",
          "display_code": "",
          "annotation": "Type adapters can be particularly useful when working with external APIs or complex data structures:",
          "is_comment": true,
          "start_line": 118,
          "line_range": [
            118,
            118
          ],
          "target_line_range": [
            119,
            121
          ]
        },
        {
          "code": "from typing import List, Dict, Any, Optional\nfrom pydantic import TypeAdapter, BaseModel, Field\n\n",
          "display_code": "from typing import List, Dict, Any, Optional\nfrom pydantic import TypeAdapter, BaseModel, Field\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 119,
          "line_range": [
            119,
            121
          ]
        },
        {
          "code": "# Define complex nested structures\n",
          "display_code": "",
          "annotation": "Define complex nested structures",
          "is_comment": true,
          "start_line": 122,
          "line_range": [
            122,
            122
          ],
          "target_line_range": [
            123,
            140
          ]
        },
        {
          "code": "class Address(BaseModel):\n    street: str\n    city: str\n    postal_code: str\n    country: str\n\nclass ContactInfo(BaseModel):\n    email: str\n    phone: Optional[str] = None\n    address: Address\n\nclass Customer(BaseModel):\n    id: str\n    name: str\n    contact_info: ContactInfo\n    account_type: str\n    active: bool\n\n",
          "display_code": "class Address(BaseModel):\n    street: str\n    city: str\n    postal_code: str\n    country: str\n\nclass ContactInfo(BaseModel):\n    email: str\n    phone: Optional[str] = None\n    address: Address\n\nclass Customer(BaseModel):\n    id: str\n    name: str\n    contact_info: ContactInfo\n    account_type: str\n    active: bool\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 123,
          "line_range": [
            123,
            140
          ]
        },
        {
          "code": "# Create nested type adapters\n",
          "display_code": "",
          "annotation": "Create nested type adapters",
          "is_comment": true,
          "start_line": 141,
          "line_range": [
            141,
            141
          ],
          "target_line_range": [
            142,
            146
          ]
        },
        {
          "code": "AddressAdapter = TypeAdapter(Address)\nContactInfoAdapter = TypeAdapter(ContactInfo)\nCustomerAdapter = TypeAdapter(Customer)\nCustomerListAdapter = TypeAdapter(List[Customer])\n\n",
          "display_code": "AddressAdapter = TypeAdapter(Address)\nContactInfoAdapter = TypeAdapter(ContactInfo)\nCustomerAdapter = TypeAdapter(Customer)\nCustomerListAdapter = TypeAdapter(List[Customer])\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 142,
          "line_range": [
            142,
            146
          ]
        },
        {
          "code": "# Process data with validation\n",
          "display_code": "",
          "annotation": "Process data with validation",
          "is_comment": true,
          "start_line": 147,
          "line_range": [
            147,
            147
          ],
          "target_line_range": [
            148,
            149
          ]
        },
        {
          "code": "def process_customers(data: Dict[str, Any]) -> List[Customer]:\n    try:\n",
          "display_code": "def process_customers(data: Dict[str, Any]) -> List[Customer]:\n    try:\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 148,
          "line_range": [
            148,
            149
          ]
        },
        {
          "code": "        # Extract customer data from a complex API response\n",
          "display_code": "",
          "annotation": "Extract customer data from a complex API response",
          "is_comment": true,
          "start_line": 150,
          "line_range": [
            150,
            150
          ],
          "target_line_range": [
            151,
            156
          ]
        },
        {
          "code": "        customers_data = data.get(\"results\", {}).get(\"customers\", [])\n        return CustomerListAdapter.validate_python(customers_data)\n    except Exception as e:\n        print(f\"Validation error: {e}\")\n        return []\n\n",
          "display_code": "        customers_data = data.get(\"results\", {}).get(\"customers\", [])\n        return CustomerListAdapter.validate_python(customers_data)\n    except Exception as e:\n        print(f\"Validation error: {e}\")\n        return []\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 151,
          "line_range": [
            151,
            156
          ]
        },
        {
          "code": "# Example API response data\n",
          "display_code": "",
          "annotation": "Example API response data",
          "is_comment": true,
          "start_line": 157,
          "line_range": [
            157,
            157
          ],
          "target_line_range": [
            158,
            196
          ]
        },
        {
          "code": "api_response = {\n    \"status\": \"success\",\n    \"results\": {\n        \"customers\": [\n            {\n                \"id\": \"cust-001\",\n                \"name\": \"Acme Corporation\",\n                \"contact_info\": {\n                    \"email\": \"contact@acme.com\",\n                    \"phone\": \"555-123-4567\",\n                    \"address\": {\n                        \"street\": \"123 Main St\",\n                        \"city\": \"San Francisco\",\n                        \"postal_code\": \"94105\",\n                        \"country\": \"USA\"\n                    }\n                },\n                \"account_type\": \"enterprise\",\n                \"active\": True\n            },\n            {\n                \"id\": \"cust-002\",\n                \"name\": \"Globex Inc\",\n                \"contact_info\": {\n                    \"email\": \"info@globex.com\",\n                    \"address\": {\n                        \"street\": \"456 Market St\",\n                        \"city\": \"New York\",\n                        \"postal_code\": \"10001\",\n                        \"country\": \"USA\"\n                    }\n                },\n                \"account_type\": \"small_business\",\n                \"active\": True\n            }\n        ]\n    }\n}\n\n",
          "display_code": "api_response = {\n    \"status\": \"success\",\n    \"results\": {\n        \"customers\": [\n            {\n                \"id\": \"cust-001\",\n                \"name\": \"Acme Corporation\",\n                \"contact_info\": {\n                    \"email\": \"contact@acme.com\",\n                    \"phone\": \"555-123-4567\",\n                    \"address\": {\n                        \"street\": \"123 Main St\",\n                        \"city\": \"San Francisco\",\n                        \"postal_code\": \"94105\",\n                        \"country\": \"USA\"\n                    }\n                },\n                \"account_type\": \"enterprise\",\n                \"active\": True\n            },\n            {\n                \"id\": \"cust-002\",\n                \"name\": \"Globex Inc\",\n                \"contact_info\": {\n                    \"email\": \"info@globex.com\",\n                    \"address\": {\n                        \"street\": \"456 Market St\",\n                        \"city\": \"New York\",\n                        \"postal_code\": \"10001\",\n                        \"country\": \"USA\"\n                    }\n                },\n                \"account_type\": \"small_business\",\n                \"active\": True\n            }\n        ]\n    }\n}\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 158,
          "line_range": [
            158,
            196
          ]
        },
        {
          "code": "# Process and validate the data\n",
          "display_code": "",
          "annotation": "Process and validate the data",
          "is_comment": true,
          "start_line": 197,
          "line_range": [
            197,
            197
          ],
          "target_line_range": [
            198,
            204
          ]
        },
        {
          "code": "customers = process_customers(api_response)\nprint(f\"Processed {len(customers)} valid customers\")\nfor customer in customers:\n    print(f\"- {customer.name} ({customer.id})\")\n    print(f\"  Email: {customer.contact_info.email}\")\n    print(f\"  Address: {customer.contact_info.address.city}, {customer.contact_info.address.country}\")\n\n",
          "display_code": "customers = process_customers(api_response)\nprint(f\"Processed {len(customers)} valid customers\")\nfor customer in customers:\n    print(f\"- {customer.name} ({customer.id})\")\n    print(f\"  Email: {customer.contact_info.email}\")\n    print(f\"  Address: {customer.contact_info.address.city}, {customer.contact_info.address.country}\")\n\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 198,
          "line_range": [
            198,
            204
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python type-adapters.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/jxnl/instructor"
      ],
      "section_id": "009-performance",
      "section_title": "Performance and Optimization"
    },
    {
      "id": "050-resources",
      "title": "Resources",
      "description": "",
      "order": 50,
      "code_segments": [
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 2,
          "line_range": [
            2,
            2
          ]
        },
        {
          "code": "# - [Pydantic](https://docs.pydantic.dev/): Instructor leverages Pydantic for data validation and settings management.\n",
          "display_code": "",
          "annotation": "- [Pydantic](https://docs.pydantic.dev/): Instructor leverages Pydantic for data validation and settings management.",
          "is_comment": true,
          "start_line": 3,
          "line_range": [
            3,
            3
          ],
          "target_line_range": [
            4,
            4
          ]
        },
        {
          "code": "\n",
          "display_code": "\n",
          "annotation": "",
          "is_comment": false,
          "start_line": 4,
          "line_range": [
            4,
            4
          ]
        }
      ],
      "shell_segments": [
        {
          "explanation": "First, install Instructor and any dependencies",
          "command": "pip install instructor pydantic",
          "output": ""
        },
        {
          "explanation": "Run the Python script",
          "command": "python resources.py",
          "output": ""
        }
      ],
      "image_data": [],
      "documentation_links": [
        "https://github.com/instructor-ai/instructor",
        "https://python.useinstructor.com/",
        "https://discord.gg/bD9YE9JArw",
        "https://twitter.com/jxnlco",
        "https://python.useinstructor.com/blog",
        "https://github.com/instructor-ai/instructor/tree/main/examples",
        "https://python.useinstructor.com/",
        "https://github.com/instructor-ai/instructor/issues",
        "https://discord.gg/bD9YE9JArw",
        "https://github.com/instructor-ai/instructor/issues/new",
        "https://github.com/instructor-ai/instructor",
        "https://discord.gg/bD9YE9JArw",
        "https://python.useinstructor.com/blog",
        "https://github.com/instructor-ai/instructor/blob/main/CONTRIBUTING.md",
        "https://github.com/instructor-ai/instructor/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22",
        "https://docs.pydantic.dev/"
      ],
      "section_id": "999-misc",
      "section_title": "Miscellaneous Examples"
    }
  ],
  "sections": [
    {
      "id": "001-getting-started",
      "title": "Getting Started",
      "description": "Introduction to structured outputs with Instructor and setting up your environment",
      "order": 1,
      "examples": [
        "001-getting-started",
        "002-installation",
        "003-first-extraction",
        "004-response-models",
        "005-client-setup"
      ]
    },
    {
      "id": "002-providers",
      "title": "LLM Providers",
      "description": "Using Instructor with different LLM providers",
      "order": 2,
      "examples": [
        "006-openai",
        "007-anthropic",
        "008-gemini",
        "009-cohere",
        "010-mistral",
        "011-other-providers"
      ]
    },
    {
      "id": "003-basic-extraction",
      "title": "Basic Extraction Patterns",
      "description": "Common patterns for extracting structured data",
      "order": 3,
      "examples": [
        "012-simple-object",
        "013-list-extraction",
        "014-nested-structures",
        "015-field-validation",
        "016-optional-fields",
        "017-working-with-enums"
      ]
    },
    {
      "id": "004-classification",
      "title": "Classification and Analysis",
      "description": "Using structured outputs for classification tasks",
      "order": 4,
      "examples": [
        "018-simple-classification",
        "019-multi-label-classification",
        "020-sentiment-analysis",
        "021-entity-classification",
        "022-confidence-scores"
      ]
    },
    {
      "id": "005-streaming",
      "title": "Streaming",
      "description": "Working with streaming responses",
      "order": 5,
      "examples": [
        "023-streaming-basics",
        "024-partial-objects",
        "025-streaming-lists",
        "026-progressive-updates",
        "027-handling-stream-errors"
      ]
    },
    {
      "id": "006-advanced-structures",
      "title": "Advanced Structures",
      "description": "Building complex structured outputs",
      "order": 6,
      "examples": [
        "028-recursive-structures",
        "029-knowledge-graphs",
        "030-dependency-trees",
        "031-task-planning",
        "032-document-structure"
      ]
    },
    {
      "id": "007-validation",
      "title": "Validation",
      "description": "Ensuring data quality with validation",
      "order": 7,
      "examples": [
        "033-validation-basics",
        "034-custom-validators",
        "035-retry-mechanisms",
        "036-fallback-strategies",
        "037-field-level-validation"
      ]
    },
    {
      "id": "008-multimodal",
      "title": "Multimodal Inputs",
      "description": "Working with images, audio, and documents",
      "order": 8,
      "examples": [
        "038-vision-inputs",
        "039-image-to-structured-data",
        "040-table-extraction",
        "041-audio-extraction",
        "042-pdf-extraction"
      ]
    },
    {
      "id": "009-performance",
      "title": "Performance and Optimization",
      "description": "Optimizing performance for production use",
      "order": 9,
      "examples": [
        "043-caching-responses",
        "044-parallel-extraction",
        "045-batch-processing",
        "046-hooks-and-callbacks",
        "047-type-adapters"
      ]
    },
    {
      "id": "999-misc",
      "title": "Miscellaneous Examples",
      "description": "Additional examples that don't fit into other categories",
      "order": 999
    }
  ]
}